<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c44{margin-left:-25.7pt;padding-top:9.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c59{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Courier New";font-style:normal}.c54{margin-left:-25.7pt;padding-top:4.1pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.6pt;font-family:"Arial";font-style:normal}.c77{margin-left:-16.6pt;padding-top:7pt;text-indent:26.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.4pt}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c39{margin-left:-21.1pt;padding-top:1.7pt;text-indent:36pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.6pt}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.3pt;font-family:"Arial";font-style:normal}.c46{margin-left:-25.7pt;padding-top:1.7pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c47{margin-left:-16.6pt;padding-top:9.4pt;text-indent:26.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c34{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.2pt;font-family:"Arial";font-style:normal}.c33{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12pt;font-family:"Arial";font-style:normal}.c15{margin-left:-16.6pt;padding-top:1.7pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Arial";font-style:normal}.c79{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c19{margin-left:-16.6pt;padding-top:0.5pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c38{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:6.6pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Courier New";font-style:normal}.c50{margin-left:-25.7pt;padding-top:3.8pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.6pt;font-family:"Arial";font-style:normal}.c57{margin-left:-16.6pt;padding-top:4.1pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c72{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c68{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.4pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Arial";font-style:normal}.c62{margin-left:-25.7pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:104.3pt}.c75{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:5pt}.c32{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c53{margin-left:-21.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15pt}.c40{margin-left:2.8pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.4pt}.c26{margin-left:-21.1pt;padding-top:3.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:146.6pt}.c74{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.8pt}.c48{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.9pt}.c35{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.2pt}.c69{margin-left:-21.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-16.2pt}.c27{margin-left:-16.6pt;padding-top:8.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:136.1pt}.c65{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23.8pt}.c30{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.2pt}.c37{margin-left:218.2pt;padding-top:64.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c49{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.4pt}.c55{margin-left:-6.2pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-7pt}.c67{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c36{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.4pt}.c45{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.1pt}.c58{margin-left:218.2pt;padding-top:66pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c78{margin-left:-25.7pt;padding-top:13.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-2.2pt}.c73{margin-left:47.9pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:39.1pt}.c70{margin-left:-21.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:1.6pt}.c61{margin-left:36.9pt;padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:31.9pt}.c71{margin-left:-16.6pt;padding-top:25.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:1.9pt}.c51{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.2pt}.c60{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.9pt}.c76{margin-left:-25.7pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:115.4pt}.c66{margin-left:-25.7pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:70.2pt}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c18{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c24{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c41{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c56{margin-left:-12.1pt;margin-right:-18.7pt}.c64{margin-left:-16.6pt;margin-right:111.4pt}.c25{margin-left:73.6pt;margin-right:28.1pt}.c52{text-indent:36.1pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c41"><p class="c10"><span class="c79">Continuous Imputation of Missing Values in Streams of Pattern-Determining Time Series </span></p><p class="c1"><span class="c6">Kevin Wellenzohn Michael H. B&ouml;hlen </span><span class="c31">Department of Computer Science </span><span class="c14">{wellenzohn, </span><span class="c31">University of </span><span class="c14">boehlen}@ifi.uzh.ch </span></p><p class="c1"><span class="c31">Zurich, Switzerland </span><span class="c6">Anton Dign&ouml;s Johann Gamper </span><span class="c14">Hannes Mitterer </span><span class="c31">Faculty of Computer Science </span><span class="c14">firstname.lastname@unibz.it </span><span class="c31">Free University of Bolzano, Italy </span><span class="c6">ABSTRACT </span><span class="c0">Time series data is ubiquitous but often incomplete, e.g., due to sensor failures and transmission errors. Since many applications require complete data, missing values must be imputed before fur- ther data processing is possible. </span></p><p class="c18"><span class="c0">We propose Top-k Case Matching (TKCM) to impute missing values in streams of time series data. TKCM defines for each time series a set of reference time series and exploits similar historical situations in the reference time series for the imputation. A situa- tion is characterized by the anchor point of a pattern that consists of l consecutive measurements over the reference time series. A missing value in a time series s is derived from the values of s at the anchor points of the k most similar patterns. We show that TKCM imputes missing values consistently if the reference time series pattern-determine time series s, i.e., the pattern of length l at time t</span><span class="c2">n </span><span class="c11">is repeated at least k times in the reference time se- </span><span class="c0">ries and the corresponding values of s at the anchor time points are similar to each other. In contrast to previous work, we support time series that are not linearly correlated but, e.g., phase shifted. TKCM is resilient to consecutively missing values, and the accu- racy of the imputed values does not decrease if blocks of values are missing. The results of an exhaustive experimental evaluation using real-world and synthetic data shows that we outperform the state-of-the-art solutions. </span></p><p class="c1"><span class="c6">1. INTRODUCTION </span></p><p class="c18"><span class="c0">Time series data appears in many application domains, e.g., me- teorology, sensor networks, the financial world, and network mon- itoring. Often time series data is incomplete with values missing because of sensor failures, transmission errors, etc. Many applica- tions require complete data, hence missing values must be recov- ered before further data processing is possible. </span></p><p class="c18"><span class="c0">Our research is motivated by the problem of missing values in the data collected by the S&uuml;dtiroler Beratungsring f&uuml;r Obst- und Weinbau (SBR). The SBR monitors and analyzes meteorological data streams in real time and alerts wine and apple farmers of po- tential harvest threats, such as frost, apple scab, and fire blight. The SBR operates a network of more than 130 weather stations in South </span></p><p class="c18"><span class="c9">&copy;2017, Copyright is with the authors. Published in Proc. 20th Inter- national Conference on Extending Database Technology (EDBT), March 21-24, 2017 - Venice, Italy: ISBN 978-3-89318-073-8, on OpenProceed- ings.org. Distribution of this paper is permitted under the terms of the Cre- ative Commons license CC-by-nc-nd 4.0 </span></p><p class="c18"><span class="c0">Tyrol, each of which records approximately 20 meteorological pa- rameters at a sample rate of five minutes. The measurements date back to 2007 with a total of 88.9M measurements. For illustration purposes, we use the temperature taken at one meter above ground level, which ranges from &minus;20.3&deg;C to +40.3&deg;C and has a total of 7.8M (= 8%) missing values. Currently, missing values are manu- ally imputed by domain experts, based on the values at neighboring stations. </span></p><p class="c18"><span class="c0">Various works have observed that time series are correlated and imputation techniques have been proposed that exploit the informa- tion of co-evolving time series [12, 13, 14, 16, 25]. Popular solu- tions include SVD based matrix decomposition techniques [11, 12], multivariate autoregression analysis [25], and PCA (principal com- ponent analysis) guided data summarization [16, 17, 23]. These approaches perform well if the time series are linearly correlated according to the Pearson correlation. The imputation accuracy de- teriorates if the time series are shifted and have a Pearson correla- tion close to zero. </span></p><p class="c18"><span class="c0">In this paper, we propose Top-k Case Matching (TKCM) to im- pute missing values in streams of non-linearly correlated time se- ries. TKCM defines for each time series s a small set R</span><span class="c3">s </span><span class="c0">of ref- erence time series. If the value in s at the current time t</span><span class="c2">n </span><span class="c11">is miss- </span><span class="c0">ing, TKCM defines a query pattern P(t</span><span class="c3">n</span><span class="c0">) that is anchored at t</span><span class="c3">n </span><span class="c0">and composed of the l most recent measurements of the reference time series. Then, the k most similar non-overlapping patterns to the query pattern within a given time window are determined. The missing value is derived from the values of time series s at the an- chor points of the k most similar patterns. This process is illustrated in Fig. 1, where the value of the time series s at the current time t</span><span class="c2">n </span><span class="c0">is missing (small circle on the right). There are two reference time series of s, i.e., R</span><span class="c2">s </span><span class="c11">= {r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2</span><span class="c11">}. The query pattern P(t</span><span class="c2">n</span><span class="c11">) is com- </span><span class="c0">posed of the snippets of the reference time series in the black frame. The k = 2 most similar patterns to the query pattern are anchored at t</span><span class="c2">i </span><span class="c11">and t</span><span class="c2">j </span><span class="c11">and are shown as dashed rectangles. The missing value </span><span class="c0">of s is derived from the values of s at the anchor points t</span><span class="c3">i </span><span class="c0">and t</span><span class="c3">j </span><span class="c0">(small circles). </span></p><p class="c24"><span class="c0">TKCM exploits two common properties of time series. First, time series often exhibit (not necessarily regularly) repeating pat- terns, also referred to as seasonal patterns. Second, time series are (not necessarily linearly) correlated in the sense that, whenever a pattern in a set of reference time series repeats, time series s ex- hibits similar values. If these two properties are satisfied we say that series at s, time denoted t</span><span class="c2">n </span><span class="c11">the </span><span class="c0">by </span><span class="c11">reference </span><span class="c0">R</span><span class="c2">s</span><span class="c11">,t</span><span class="c2">n </span><span class="c3">pd</span><span class="c11">time &minus;&rarr; s. series In other R</span><span class="c2">s </span><span class="c11">pattern-determine words, whenever simi- time </span></p><p class="c18"><span class="c0">lar patterns occur in R</span><span class="c3">s</span><span class="c0">, the values of time series s are similar to each other, too. In contrast to previous work, this property allows not only linearly correlated reference time series but permits phase shifts. For instance, in Fig. 1 the two (shifted) reference time se- </span></p><p class="c1"><span class="c17">Series ISSN: 2367-2005 330 </span><span class="c38">10.5441/002/edbt.2017.30 </span></p><p class="c1"><span class="c13">0</span><span class="c7">20 10</span><span class="c13">missing </span><span class="c5">value </span></p><p class="c1"><span class="c7">13 </span></p><p class="c24"><span class="c7">3</span><span class="c13">-711.03.14 t</span><span class="c5">j </span><span class="c13">12.03.14 13.03.14 t</span><span class="c5">i </span><span class="c13">14.03.14 t</span><span class="c5">n </span><span class="c0">s</span><span class="c11">r</span><span class="c2">1</span><span class="c7">17 </span><span class="c3">P(t</span><span class="c5">j</span><span class="c3">) </span><span class="c2">P(t</span><span class="c5">i</span><span class="c3">) P (t</span><span class="c5">n</span><span class="c2">) </span><span class="c11">r</span><span class="c2">2 </span><span class="c7">7</span><span class="c13">-3</span><span class="c0">Time </span></p><p class="c1"><span class="c0">Figure 1: Imputation of a missing value of s at time t</span><span class="c3">n</span><span class="c0">. </span></p><p class="c18"><span class="c0">ries R</span><span class="c2">s </span><span class="c11">= {r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2</span><span class="c11">} pattern-determine time series s at time t</span><span class="c2">n</span><span class="c11">. We </span><span class="c0">show that TKCM imputes missing values consistently if the time series are pattern determining. </span></p><p class="c1"><span class="c0">The paper makes the following technical contributions: </span></p><p class="c18"><span class="c0">&bull; We present and formalize Top-k Case Matching (TKCM) to impute missing values in streams of pattern-determining time series, which covers non-linear relationships between time series. </span></p><p class="c18"><span class="c0">&bull; We show that TKCM computes correct results for shifted time series that are not linearly correlated. We use a pattern of length l &gt; 1 to exploit several consecutive measurements to find similar historical situations. </span></p><p class="c18"><span class="c0">&bull; We propose a dynamic programming scheme to find the k non-overlapping patterns that minimize the sum of dissimi- larities with respect to the query pattern. </span></p><p class="c18"><span class="c0">&bull; We empirically show on real-world and synthetic datasets that TKCM: (a) outperforms state-of-the-art solutions, (b) can impute values in time series with phase shifts, and (c) is resilient to large blocks of consecutively missing values. </span></p><p class="c18"><span class="c0">The paper is structured as follows. Section 2 discusses related works. After the preliminaries in Section 3 we describe our ap- proach in Section 4. Section 5 analyzes the properties of TKCM and works out the differences between linear and non-linear cor- relations. In Section 6 we provide an implementation of TKCM that uses a dynamic programming solution to find the k non- overlapping patterns that are most similar to the query pattern. We continue with the experimental evaluation in Section 7 before we conclude this paper and present future research directions in Sec- tion 8. </span></p><p class="c1"><span class="c6">2. RELATED WORK </span></p><p class="c18"><span class="c0">The need to recover missing data arises in many applications, ranging from meteorology [18, 26], to social science [20], machine learning [2], motion capture systems [14] and DNA microarray analysis [24]. Imputing a missing value means to recover it with a good estimate that is derived from intrinsic relationships in the underlying dataset. </span></p><p class="c1"><span class="c0">Simple imputation techniques include mean and mode imputa- tion [2], which replace the missing value with the mean or mode of </span></p><p class="c18"><span class="c0">the same attribute. Interpolation techniques, such as linear interpo- lation and spline interpolation, estimate the missing value from im- mediately preceding and succeeding values of the same attribute. If the gap is long, i.e., if many consecutive values are missing, these interpolation techniques perform badly. For instance, if an entire period of a sine wave is missing, linear interpolation would replace the gap with a straight line. Regression methods [25] estimate the missing value of a time series (e.g., temperature in Zurich) based on the value of other time series (e.g., temperature in Bern and Basel). Paulhus et al. [18] observed that nearby weather stations have similar values and computed a missing value at one station as the average of the values of nearby stations. Yozgatligil et al. [26] give a recent survey of imputation methods for meteorological time series and cover approaches based on neural networks and multiple imputation [19]. </span></p><p class="c18"><span class="c0">The ARIMA model [4] is a popular time series forecasting model that is a generalization of the auto-regressive (AR) model. ARIMA assumes a linear dependency of unknown future values on known past values of the time series. Finding the proper values for p, d, q in an ARIMA(p, d, q) model is tedious, complex and involves man- ual analysis, known as the Box-Jenkins methodology [4]. </span></p><p class="c18"><span class="c0">Batista et al. [2] study the problem of missing data in the context of machine learning algorithms and present the k-Nearest Neigh- bor Imputation (kNNI) method to recover these values. For a multi-attribute object (e.g., breast cancer test with multiple mea- surements) that has a missing value for one attribute A, the kNNI approach looks for k objects with similar values for the other at- tributes according to a distance metric that is not specified. The missing value is derived from the values of attribute A in these ob- jects. Troyanskaya et al. [24] extend kNNI to weight the k most similar items according to their similarity. Our approach, TKCM, uses the concept of nearest neighbors (k most similar patterns), but is designed for time series streams and uses a two-dimensional query pattern for which the k most similar non-overlapping pat- terns according to the Euclidean distance are searched. </span></p><p class="c18"><span class="c0">Khayati et al. [11] propose REBOM to recover blocks of miss- ing values in irregular time series with non-repeating trends. The algorithm builds a matrix which stores the incomplete time series and the n most linearly correlated time series according to Pear- son correlation. Missing values are first initialized, e.g., using lin- ear interpolation. Then the matrix is iteratively decomposed using the Singular Value Decomposition (SVD) method, where the least significant singular values are truncated. Due to the quadratic run- time complexity, REBOM does not scale to long time series. Next, Khayati et al. [12] present a solution with linear space complexity based on the Centroid Decomposition (CD), which is an approxi- mation of SVD. Unlike our approach, SVD and CD assume a lin- ear correlation between an incomplete time series and its reference time series. If time series are not linearly correlated, the imputation accuracy deteriorates since these trends are captured by the trun- cated least significant singular values. Khayati et al. [13] show that CD imputes more accurately than SVD when some reference time series are shifted and hence lowly linearly-correlated, because CD prioritizes highly linearly-correlated reference time series. Never- theless, their experiments show that adding more lowly-correlated reference time series has a negative impact on CD&rsquo;s accuracy. </span></p><p class="c18"><span class="c0">Sorjamaa et al. [15, 22] propose an imputation method based on a Self-Organizing-Map (SOM), which is an unsupervised learning technique based on neural networks. A combination of SVD and SOM [22] uses SVD for the imputation after initializing missing values in the matrix by a SOM classifier, whereas [15] combines two SOM classifiers for the imputation. Both methods are only evaluated on linearly correlated time series. </span></p><p class="c1"><span class="c17">331 </span></p><p class="c44"><span class="c0">DynaMMo [14] is used for mining, summarizing, and imput- ing time series extracted from human motion capture systems. It is based on Kalman filters, which, similar to SVD, assume a lin- ear correlation between time series to accurately estimate unknown values. Moreover, unlike our approach, DynaMMo allows only one reference time series, which often is insufficient for an accurate im- putation. </span></p><p class="c72"><span class="c0">The works most similar to our approach are MUSCLES [25] and SPIRIT [16, 17, 23], which focus on the online imputation of miss- ing values in streams of time series data. Both algorithms use vari- ants of auto-regressive (AR) models and exploit linear correlations between data streams. When the linear correlation diminishes, as in the case of shifted time series, none of the two approaches performs well.</span><span class="c11">MUSCLES [25] is an online algorithm that is based on a mul- </span><span class="c0">tivariate auto-regression model, whose parameters are incremen- tally updated using the Recursive Least Squares method. Besides past values of the incomplete time series, MUSCLES takes also the most recent values of co-evolving and linearly correlated time se- ries into account that are within a window p. How to choose p is not discussed; in the experiments p = 6 is used. After p consecutive missing values, MUSCLES relies exclusively on imputed values for the incomplete time series. Since small imputation inaccuracies accumulate over a long stretch of missing values, MUSCLES ac- curacy deteriorates. Additionally, MUSCLES does not scale well to a large number of streams, unless an expensive offline subset selection on the time series is performed [17]. </span></p><p class="c46"><span class="c0">SPIRIT [16, 17, 23] uses an online Principal Component Analy- sis (PCA) to reduce a set of n co-evolving and correlated streams to a small number of k hidden variables that summarize the most important trends in the original data. For each hidden variable, SPIRIT fits one AR model on past values, which is incrementally updated as new data arrives. If a value is missing, the AR models are used to forecast the current value of each variable, from which an estimate of the missing value is derived. The imputed value, along with the non-missing values, is then used to update the fore- casting models. Updating the models with imputed models incurs similar problems as MUSCLES since inaccuracies are propagated. Since PCA and SVD are based on the same underlying principle, PCA shares SVD&rsquo;s weaknesses for shifted time series. </span></p><p class="c46"><span class="c0">From an implementation perspective, TKCM needs to find sim- ilar patterns in time series. This problem has been studied exten- sively for a single time series, yielding different dimensionality re- duction techniques, e.g., Discrete Fourier Transform [6], Piecewise Aggregate Approximation [7], and iSAX [21]. Keogh et al. [10] present a fast approach to find a subsequence (i.e., one-dimensional pattern), termed shapelet, of a time series that is most representa- tive for a set of time series. Finding patterns in our approach is more complex. We seek patterns that span several time series, and we have to select the k most similar non-overlapping patterns. The main focus of this work is not performance, but an accurate impu- tation of shifted time series streams. </span></p><p class="c62"><span class="c6">3. PRELIMINARIES </span></p><p class="c54"><span class="c0">Consider a set S = {s</span><span class="c3">1</span><span class="c0">,s</span><span class="c3">2</span><span class="c0">,...} of streaming time series. Each time series reports values from a sensor measured at time points ...,t</span><span class="c3">n&minus;2</span><span class="c0">,t</span><span class="c3">n&minus;1</span><span class="c0">,t</span><span class="c3">n</span><span class="c0">, where t</span><span class="c3">n </span><span class="c0">denotes the current time, i.e., the time of the latest measurement. The value of a time series s &isin; S at time t</span><span class="c2">i </span><span class="c11">is denoted as s(t</span><span class="c2">i</span><span class="c11">). We write s(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL </span><span class="c11">to denote that </span><span class="c0">the current value of s is missing. W = {t</span><span class="c3">n&minus;L+1</span><span class="c0">,...,t</span><span class="c3">n&minus;1</span><span class="c0">,t</span><span class="c3">n</span><span class="c0">} denotes the L time points in our streaming window for which we keep measurements in main memory. We assume that the streaming window W is long enough to include the query pattern and k non- </span></p><p class="c1 c64"><span class="c0">overlapping similar patterns. </span></p><p class="c15"><span class="c0">For each time series s &isin; S there exists an ordered sequence &#12296;r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2</span><span class="c11">,...&#12297; of candidate reference time series, where r</span><span class="c2">i </span><span class="c11">&isin; S\{s}. </span><span class="c0">They have been identified by domain experts and are consulted if the current value in s is missing and must be recovered. The candi- date reference time series of s are ranked according to how suitable they are for imputing a missing value in s. A single reference time series does not yield a robust method to estimate a missing value. Instead the d best candidate reference time series that do not have a missing value at the current time t</span><span class="c3">n </span><span class="c0">are used. Let s &isin; S be an incomplete time series with s(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL</span><span class="c11">. The reference time se- </span><span class="c0">ries R</span><span class="c3">s </span><span class="c0">for s at the current time t</span><span class="c3">n </span><span class="c0">are the first d time series in the ordered sequence for which r(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL</span><span class="c11">. </span></p><p class="c19"><span class="c0">Note that there can be multiple incomplete time series with a missing value at t</span><span class="c2">n</span><span class="c11">. For each incomplete time series s</span><span class="c2">i </span><span class="c11">its miss- </span><span class="c0">ing value s</span><span class="c2">i</span><span class="c11">(t</span><span class="c2">n</span><span class="c11">) is imputed individually using the respective set of </span><span class="c0">reference time series R</span><span class="c3">s</span><span class="c5">i</span><span class="c0">. </span></p><p class="c77"><span class="c0">Example 1. As a running example, we use the four time se- ries in Table 2. The current time is t</span><span class="c3">n </span><span class="c0">= 14:20. Time se- ries s is incomplete, hence the missing value at 14:20 must be imputed. We assume a sliding window of one hour, containing L = 12 measurements. For all time points before t</span><span class="c3">n </span><span class="c0">the val- ues either have been reported by the sensor or have been imputed, e.g., r</span><span class="c2">2</span><span class="c11">(13:40) = </span><span class="c0">&#770;</span><span class="c11">18.8&deg;C. The candidate reference time series are </span><span class="c0">&#12296;r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2</span><span class="c11">,r</span><span class="c2">3</span><span class="c11">&#12297;. At the current time t</span><span class="c2">n </span><span class="c11">= 14:20, the d = 2 reference </span><span class="c0">time series for s are R</span><span class="c3">s </span><span class="c0">= {r</span><span class="c3">1</span><span class="c0">,r</span><span class="c3">2</span><span class="c0">}. When the current time was t</span><span class="c2">n </span><span class="c11">= 13:40, we had R</span><span class="c2">s </span><span class="c11">= {r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">3</span><span class="c11">} since r</span><span class="c2">2</span><span class="c11">(13:40) was missing. </span><span class="c29">2</span><span class="c11">Notation Description </span><span class="c0">t</span><span class="c3">n </span><span class="c0">Current time S = {s</span><span class="c2">1</span><span class="c11">,s</span><span class="c2">2</span><span class="c11">,...} Set of time series </span><span class="c0">s(t</span><span class="c3">n</span><span class="c0">) = N</span><span class="c16">IL </span><span class="c0">Missing value of time series s at time t</span><span class="c3">n </span><span class="c0">&circ;s(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL </span><span class="c11">Imputed value of time series s at time t</span><span class="c2">n </span><span class="c0">d Number of reference time series R</span><span class="c3">s </span><span class="c0">= {r</span><span class="c3">1</span><span class="c0">,...,r</span><span class="c3">d</span><span class="c0">} Set of d reference time series for s W = {...,t</span><span class="c2">n</span><span class="c11">} Time points in streaming window </span><span class="c0">L Length of streaming window W l Pattern length P(t</span><span class="c3">i</span><span class="c0">) Pattern anchored at time t</span><span class="c3">i </span><span class="c0">k Number of anchor points A = {t</span><span class="c2">i</span><span class="c5">1</span><span class="c0">,...,t</span><span class="c2">i</span><span class="c5">k</span><span class="c0">} k most similar anchor points </span></p><p class="c73"><span class="c0">Table 1: Summary of notation. </span></p><p class="c71"><span class="c6">4. TOP-K CASE MATCHING (TKCM) </span></p><p class="c27"><span class="c6">4.1 Approach </span></p><p class="c57"><span class="c0">For the recovery of a missing value in an incomplete time series we look for patterns in the past when the values of the reference time series were similar to the current values. </span></p><p class="c47"><span class="c0">Definition 1. (Pattern) Let R</span><span class="c2">s </span><span class="c11">= {r</span><span class="c2">1</span><span class="c11">,...,r</span><span class="c2">d</span><span class="c11">} be the reference </span><span class="c0">time series for an incomplete time series s. The pattern P(t</span><span class="c2">i</span><span class="c11">) of </span><span class="c0">length l &gt; 0 over R</span><span class="c3">s </span><span class="c0">that is anchored at time t</span><span class="c3">i </span><span class="c0">is defined as a d&times;l matrix P(t</span><span class="c2">i</span><span class="c11">) as follows: </span></p><p class="c61"><span class="c0">P(t</span><span class="c3">i</span><span class="c0">) = ((r</span><span class="c3">1</span><span class="c0">(t</span><span class="c3">i&minus;l+1</span><span class="c0">),...,r</span><span class="c3">1</span><span class="c0">(t</span><span class="c3">i</span><span class="c0">)), </span></p><p class="c10 c25"><span class="c0">.</span><span class="c11">.. </span><span class="c0">.</span><span class="c11">.. </span><span class="c0">(r</span><span class="c2">d</span><span class="c11">(t</span><span class="c2">i&minus;l+1</span><span class="c11">),...,r</span><span class="c2">d</span><span class="c11">(t</span><span class="c2">i</span><span class="c11">))). </span></p><p class="c37"><span class="c17">332 </span></p><p class="c1"><span class="c9">Time t &middot;&middot;&middot; 13:25 13:30 13:35 13:40 13:45 13:50 13:55 14:00 14:05 14:10 14:15 14:20 </span></p><p class="c24"><span class="c9">s &middot;&middot;&middot; 22.8&deg;C 21.4&deg;C 21.8&deg;C 23.1&deg;C </span><span class="c22">&#770;</span><span class="c9">23.5&deg;C 22.8&deg;C 21.2&deg;C 21.9&deg;C 23.5&deg;C 22.8&deg;C 21.2&deg;C N</span><span class="c68">IL </span><span class="c9">r</span><span class="c3">1 </span><span class="c9">rr</span><span class="c2">2 3 </span><span class="c9">&middot;&middot;&middot; 16.5&deg;C 17.2&deg;C 17.8&deg;C 16.6&deg;C </span><span class="c20">&middot;&middot;&middot; 20.3&deg;C 19.8&deg;C 18.6&deg;C 18.8&deg;C </span><span class="c9">&#770;</span><span class="c20">&middot;&middot;&middot; 14.0&deg;C 14.8&deg;C 13.6&deg;C 13.0&deg;C </span><span class="c9">15.8&deg;C 16.2&deg;C 17.4&deg;C 17.7&deg;C 15.3&deg;C 16.3&deg;C 17.1&deg;C 17.5&deg;C </span><span class="c20">20.0&deg;C </span><span class="c9">&#770;</span><span class="c20">20.5&deg;C </span><span class="c9">&#770;</span><span class="c20">19.8&deg;C 18.2&deg;C 20.1&deg;C 20.2&deg;C 19.9&deg;C 18.2&deg;C 14.5&deg;C 14.3&deg;C 14.0&deg;C 15.0&deg;C 13.0&deg;C 14.5&deg;C 14.3&deg;C 14.6&deg;C </span></p><p class="c1"><span class="c0">Table 2: Time series s with a missing value at time t</span><span class="c2">n </span><span class="c11">= 14:20 and the three reference time series r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2 </span><span class="c11">and r</span><span class="c2">3</span><span class="c11">. </span></p><p class="c18"><span class="c0">A pattern is anchored at a time point t</span><span class="c2">i </span><span class="c11">and consists of the values </span><span class="c0">from t</span><span class="c2">i&minus;l+1 </span><span class="c11">to t</span><span class="c2">i </span><span class="c11">of each reference time series. Each row repre- </span><span class="c0">sents a subsequence of a reference time series, and each column represents the values of the reference time series at a time point. The pattern contains for each reference time series only the values at time t</span><span class="c2">i</span><span class="c11">, if l = 1. The pattern includes additionally the preceding </span><span class="c0">l &minus; 1 values, and hence captures the trend, if l &gt; 1. </span></p><p class="c18"><span class="c0">Example 2. Figure 2 shows two patterns over the reference time series R</span><span class="c3">s </span><span class="c0">= {r</span><span class="c3">1</span><span class="c0">,r</span><span class="c3">2</span><span class="c0">} in our running example (cf. Table 2). Both patterns have length l = 3 and are anchored at time points 14:00 and 14:20, respectively. Pattern P(14:00) contains one imputed value, namely r</span><span class="c3">2</span><span class="c0">(13:50) = 20.5&deg;C. </span><span class="c4">&#770;</span><span class="c0">Since l &gt; 1 the pattern cap- tures the current trend of the time series. </span><span class="c29">2 </span></p><p class="c1"><span class="c8">16.2 17.4 17.7 </span></p><p class="c1"><span class="c59">&#770;</span><span class="c42">20.5 </span><span class="c8">19.8 18.2 </span></p><p class="c1"><span class="c13">13:50 13:55 14:00 </span></p><p class="c18"><span class="c0">The first condition states that all patterns are within the time win- dow and do not overlap P(t</span><span class="c2">n</span><span class="c11">). The second condition states that the </span><span class="c0">patterns do not overlap each other. The third condition ensures that the patterns that are anchored at the time points in A minimize the sum of the dissimilarities with respect to query pattern P(t</span><span class="c3">n</span><span class="c0">). </span></p><p class="c18"><span class="c0">We pick only non-overlapping patterns to avoid near duplicates [5, 8]. Our experiments have shown that if overlapping patterns were allowed, the k most similar anchor points for some pattern P(t</span><span class="c2">i</span><span class="c11">) are frequently time points t</span><span class="c2">i+1 </span><span class="c11">and t</span><span class="c2">i&minus;1</span><span class="c11">, which anchor the </span><span class="c0">first and second most similar patterns, etc. This is clearly not de- sired. Instead, non-overlapping patterns guarantee that we find a diverse set of patterns on which the imputation is based. </span></p><p class="c24"><span class="c0">The missing value in the incomplete time series s is the average of the values of s at the most similar time points. </span><span class="c13">l = 3 </span></p><p class="c1"><span class="c13">l = 3 </span></p><p class="c1"><span class="c0">Definition 4. (Imputed Value) Let s be a time series with refer- </span><span class="c13">r</span><span class="c5">1</span><span class="c0">ence time series R</span><span class="c2">s </span><span class="c11">at t</span><span class="c2">n </span><span class="c11">and missing value s(t</span><span class="c2">n</span><span class="c11">). Furthermore, </span></p><p class="c1"><span class="c13">d = 2 </span></p><p class="c1"><span class="c13">d = 2 </span></p><p class="c1"><span class="c0">let A be the k most similar time points to the current time. The </span></p><p class="c1"><span class="c5">r2 </span></p><p class="c1"><span class="c0">imputed value &circ;s(t</span><span class="c2">n</span><span class="c11">) for time series s at time t</span><span class="c2">n </span><span class="c11">is </span></p><p class="c1"><span class="c9">(a) </span><span class="c8">P (14:00) </span></p><p class="c1"><span class="c9">(b) </span><span class="c8">P (14:20) </span></p><p class="c18"><span class="c0">&circ;s(t</span><span class="c3">n</span><span class="c0">) = k </span><span class="c4">1</span><span class="c0">Figure 2: Two patterns of length l = 3 over d = 2 reference time series. </span></p><p class="c18"><span class="c0">The pattern that is anchored at the current time is termed query pattern P(t</span><span class="c2">n</span><span class="c11">). We search in the reference time series for the k </span><span class="c0">patterns that are most similar to P(t</span><span class="c3">n</span><span class="c0">) using the L</span><span class="c3">2 </span><span class="c0">norm. </span></p><p class="c18"><span class="c0">Definition 2. (Pattern Dissimilarity) Let s be an incomplete time series with reference time series R</span><span class="c3">s </span><span class="c0">at time t</span><span class="c3">n</span><span class="c0">. The dissimi- larity, &delta;, between two patterns P(t</span><span class="c2">m</span><span class="c11">) and P(t</span><span class="c2">n</span><span class="c11">) is defined as </span></p><p class="c1"><span class="c0">&delta;(P(t</span><span class="c2">m</span><span class="c11">),P(t</span><span class="c2">n</span><span class="c11">)) = </span></p><p class="c1"><span class="c8">16.3 17.1 17.5 </span></p><p class="c1"><span class="c8">20.2 19.9 18.2 </span></p><p class="c1"><span class="c13">14:10 14:15 14:20 </span></p><p class="c1"><span class="c13">r</span><span class="c5">1r2 </span></p><p class="c1"><span class="c0">&sum;</span><span class="c2">t&isin;A</span><span class="c0">s(t). (4) </span></p><p class="c18"><span class="c0">Example 4. Figure 3 shows a graphical representation of our running example (cf. Table 2). The value of s at time t</span><span class="c2">n </span><span class="c11">= 14:20 </span><span class="c0">is missing and must be imputed. The query pattern P(14:20) is framed in black. The two patterns most similar to the query pat- tern are shown as dashed rectangles and are anchored at time 14:00 and 13:35, respectively. Thus, A = {14:00,13:35} are the anchor points. The missing value is computed as the average of the val- ues s(14:00) and s(13:35): &circ;s(14:20) = (21.9&deg;C + 21.8&deg;C)/2 = </span></p><p class="c1"><span class="c0">&radic; </span><span class="c11">&sum;</span><span class="c0">&sum;(r</span><span class="c2">i</span><span class="c11">(t</span><span class="c2">m&minus;j</span><span class="c11">) &minus; r</span><span class="c2">i</span><span class="c11">(t</span><span class="c2">n&minus;j</span><span class="c11">))</span><span class="c3">2</span><span class="c11">. </span></p><p class="c1"><span class="c0">21.85&deg;C. </span><span class="c29">2 </span></p><p class="c1"><span class="c2">r</span><span class="c5">i</span><span class="c3">&isin;R</span><span class="c5">s </span><span class="c2">0&le;j&lt;l</span><span class="c0">Example 3. The dissimilarity between the two patterns in </span><span class="c4">23</span><span class="c0">Figure </span><span class="c11">&radic;(17.7 </span><span class="c0">2 </span><span class="c11">&minus; </span><span class="c0">is </span><span class="c11">17.5)</span><span class="c0">computed </span><span class="c3">2 </span><span class="c11">+ (17.4 </span><span class="c0">as </span><span class="c11">&minus; </span><span class="c0">follows: </span><span class="c11">17.1)</span><span class="c3">2 </span><span class="c11">+ </span><span class="c0">&delta;(P(14:00),P(14:20)) </span><span class="c11">(16.2 &minus; 16.3)</span><span class="c3">2 </span><span class="c11">+ ... </span><span class="c0">= </span><span class="c11">= </span><span class="c0">210.43. </span><span class="c29">2 </span></p><p class="c1"><span class="c0">The dissimilarity measure is used to determine the k most similar </span><span class="c4">17</span><span class="c0">patterns to query pattern P(t</span><span class="c3">n</span><span class="c0">). The anchor time points of these k patterns are referred to as the k most similar anchor points A. </span></p><p class="c1"><span class="c0">15Definition 3. (k Most Similar Anchor Points) Let P(t</span><span class="c3">n</span><span class="c0">) be the query pattern for incomplete time series s at time t</span><span class="c2">n </span><span class="c11">with reference </span><span class="c0">time series R</span><span class="c3">s</span><span class="c0">, and L be the length of the streaming time window. The k most similar anchor points to t</span><span class="c2">n </span><span class="c11">are a set A &sube; W, with </span><span class="c0">|A| = k, for which the following holds: </span></p><p class="c1"><span class="c0">&forall;t &isin; A : t</span><span class="c2">n&minus;L+l </span><span class="c11">&le; t &le; t</span><span class="c2">n&minus;l </span><span class="c11">(1) </span><span class="c0">&forall;t, t &isin; A : t = t &rarr; |t &minus; t | &ge; l (2) </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:25 </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:30</span><span class="c0">1</span><span class="c4">3:35 </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:40 </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:45 </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:50 </span></p><p class="c1"><span class="c0">1</span><span class="c4">3:55</span><span class="c0">1</span><span class="c4">4:00 </span></p><p class="c1"><span class="c0">1</span><span class="c4">4:05 </span></p><p class="c1"><span class="c0">1</span><span class="c4">4:10 </span></p><p class="c1"><span class="c0">1t</span><span class="c4">4</span><span class="c28">n</span><span class="c4">:1= 5 </span></p><p class="c1"><span class="c4">14:20 </span></p><p class="c1"><span class="c0">&forall;A : </span><span class="c11">&sum;</span><span class="c0">(1) &and; (2) &and; |A | = k &rarr; </span><span class="c2">t</span><span class="c5">i</span><span class="c3">&isin;A</span><span class="c4">&delta;(P(t</span><span class="c3">i</span><span class="c0">),P(t</span><span class="c2">n</span><span class="c11">)) &le; </span><span class="c0">&sum;</span><span class="c2">t</span><span class="c5">i</span><span class="c3">&isin;A </span></p><p class="c1"><span class="c0">s</span><span class="c11">r</span><span class="c2">1</span><span class="c11">r</span><span class="c2">2 </span></p><p class="c1"><span class="c0">Figure 3: The k = 2 most similar non-overlapping patterns for query pattern P(14:20) are P(14:00) and P(13:35). </span></p><p class="c1"><span class="c17">333 </span></p><p class="c1"><span class="c4">20 </span></p><p class="c1"><span class="c0">18Time </span></p><p class="c1"><span class="c0">&delta;(P(t</span><span class="c2">i</span><span class="c11">),P(t</span><span class="c2">n</span><span class="c11">)) </span><span class="c0">(3) </span></p><p class="c1"><span class="c6">5. ANALYSIS </span></p><p class="c1"><span class="c6">5.1 Correlation </span></p><p class="c18"><span class="c0">A salient property of TKCM is its ability to handle time series that are shifted and hence not linearly correlated. The Pearson cor- relation, the most common correlation measure, quantifies the de- gree of &rho;(s, linear r) = </span></p><p class="c1"><span class="c0">correlation </span><span class="c11">&radic;&sum;</span><span class="c2">t&isin;W</span><span class="c0">&sum;between (s(t) </span><span class="c2">t&isin;W</span><span class="c0">(s(t) &minus; time &minus; &nbsp;&#772;s)</span><span class="c28">2</span><span class="c0">series s and r, as </span></p><p class="c1"><span class="c4">&radic;</span><span class="c0">&nbsp;&#772;s)(r(t) &sum;</span><span class="c2">t&isin;W</span><span class="c0">&minus; (r(t) &nbsp;&#772;r) &minus; &nbsp;&#772;r)</span><span class="c28">2 </span><span class="c4">, </span></p><p class="c18"><span class="c0">where &nbsp;&#772;s and &nbsp;&#772;r are the means of, respectively, s and r in window W. Pearson correlation ranges from &minus;1 to 1, indicating total negative and positive correlation, respectively. Thus, s and r are linearly correlated if |&rho;(s, r)| is high. If &rho;(s, r)=0 time series s and r are not linearly correlated. </span></p><p class="c18"><span class="c0">Intuitively, a linear correlation ensures that (a) if one time series has close values for two time points, also the other has close values for these two time points and (b) if one time series has far apart values for two time points, also the other has far apart values for these two time points. </span></p><p class="c18"><span class="c0">Example 5. Consider Figure 4a with time series s(t) = sind(t) and r</span><span class="c3">1</span><span class="c0">(t) = 1.5 &times; sind(t)+1, having different amplitudes and offsets. The value of r</span><span class="c2">1 </span><span class="c11">at t = 840 is r</span><span class="c2">1</span><span class="c11">(840) = 2.3, and the same </span><span class="c0">value r</span><span class="c3">1</span><span class="c0">(t) appears for time points t &isin; {780,480,420,120,60}. Figure 4a illustrates that these are exactly the time points for which s has the same value of s(840) = 0.86. Thus, the time series are perfectly linearly correlated. Figure 4b uses a scatterplot to display the correlation between s and r</span><span class="c2">1</span><span class="c11">. The scatterplot displays </span><span class="c0">for each time point t the point (r</span><span class="c3">1</span><span class="c0">(t),s(t)). For instance, at time t = 840 we have r</span><span class="c2">1</span><span class="c11">(840) = 2.3 and s(840) = 0.86 and the point </span><span class="c0">(2.3, 0.86) is displayed in the scatterplot. The more the scatter- plot resembles a line with a non-zero slope, the higher the linear correlation and hence Pearson correlation. </span><span class="c29">2 </span></p><p class="c1"><span class="c7">2 10</span><span class="c8">s</span><span class="c13">&minus;1</span><span class="c42">r</span><span class="c5">1 </span></p><p class="c1"><span class="c13">0 180 360 540 720 840 </span></p><p class="c1"><span class="c13">0.86</span><span class="c7">1 </span></p><p class="c1"><span class="c8">s(t) </span></p><p class="c1"><span class="c7">0 2 </span></p><p class="c1"><span class="c7">10</span><span class="c13">&minus;1&minus;10 1 2 2.3 </span></p><p class="c1"><span class="c0">t [minutes] </span></p><p class="c1"><span class="c8">r</span><span class="c5">1</span><span class="c42">(t) </span><span class="c9">(a) </span><span class="c8">Time series s and r</span><span class="c5">1 </span></p><p class="c1"><span class="c9">(b) </span><span class="c8">Scatterplot of linear correlation </span></p><p class="c1"><span class="c0">Figure 4: Linearly correlated time series s(t) = sind(t) and r</span><span class="c2">1</span><span class="c11">(t)=1.5 &times; sind(t)+1. </span></p><p class="c18"><span class="c0">Example 5 illustrates how the imputation for linearly correlated time series works. If s(t</span><span class="c3">n</span><span class="c0">) is missing, we know that whenever time series r</span><span class="c2">1 </span><span class="c11">observes value r</span><span class="c2">1</span><span class="c11">(t</span><span class="c2">n</span><span class="c11">) (e.g., 2.3), time series s observes </span><span class="c0">the same value s(t) (e.g., 0.86). Hence we can use value s(t) for any t where r</span><span class="c3">1</span><span class="c0">(t)=2.3 to impute value s(t</span><span class="c3">n</span><span class="c0">). </span></p><p class="c18"><span class="c0">In contrast, if the Pearson correlation approaches zero, s can have very different values although the reference time series has the same value. This is illustrated in Example 6. </span></p><p class="c18"><span class="c0">Example 6. Figure 5a depicts the time series s(t) = sind(t) and r</span><span class="c2">2</span><span class="c11">(t) = sind(t&minus;90). The two time series have the same amplitude </span><span class="c0">and offset but they are phase shifted. Time series r</span><span class="c3">2 </span><span class="c0">has the value r</span><span class="c2">2</span><span class="c11">(840) = 0.5 also for time points t &isin; {600,480,240,120}. </span></p><p class="c18"><span class="c0">However, s has different values, i.e., value s(t) = 0.86 for time points t &isin; {480,120} and value s(t) = &minus;0.86 for time points t = {600,240}. The scatterplot in Figure 5b shows that the data points do not cluster around a line, which means that they are non- linearly correlated. Their Pearson correlation is &minus;0.0085. Note that for the same value of r</span><span class="c2">2</span><span class="c11">(t) we can have two different values </span><span class="c0">for s(t). For instance, for r</span><span class="c3">2</span><span class="c0">(t)=0.5 we have either s(t)=0.86 or s(t) = &minus;0.86. </span><span class="c29">2 </span></p><p class="c1"><span class="c7">2 </span></p><p class="c1"><span class="c13">0.86</span><span class="c7">1 10</span><span class="c8">s</span><span class="c13">&minus;1</span><span class="c8">s(t) </span></p><p class="c1"><span class="c42">r</span><span class="c5">2 </span></p><p class="c1"><span class="c13">0 180 360 540 720 840 </span></p><p class="c10"><span class="c8">r</span><span class="c5">2</span><span class="c42">(t) </span><span class="c9">(b) </span><span class="c8">Scatterplot of non-linear correlation </span></p><p class="c1"><span class="c0">Figure 5: Non-linearly correlated time series s(t) = sind(t) and r</span><span class="c2">2</span><span class="c11">(t) = sind(t &minus; 90) </span></p><p class="c1"><span class="c0">Example 6 illustrates the key problem with non-linear correla- tions: the values of one time series can no longer be used to reli- ably determine a missing value in another time series. In the exper- iments we will see that this leads to imputations with a high root mean square error. </span><span class="c6">5.2 Pattern Length </span></p><p class="c18"><span class="c0">The previous section illustrated that shifted time series that are not linearly correlated are difficult to handle. Intuitively, for shifted time series it is not sufficient to consider a single point in time. In- stead it is necessary to consider a pattern that includes neighboring time points to correctly relate time series. This section illustrates that a pattern with a length l &gt; 1 improves the imputation for non- linear correlations. We write P</span><span class="c2">l</span><span class="c11">(t) to denote a pattern of length l </span><span class="c0">anchored at time t. </span></p><p class="c18"><span class="c0">Example 7. Figure 6 displays s and, for each time point t, the pattern dissimilarity of the pattern anchored at r</span><span class="c3">1</span><span class="c0">(t) to the query pattern P(840), i.e., &delta;(P(t),P(840)). Figure 6a does this for pat- tern length l = 1. The pattern dissimilarity is zero whenever the value of s is equal to s(840). Figure 6b shows what happens if we increase the pattern length to l = 60. Also for this case whenever the pattern dissimilarity for the reference time series r</span><span class="c3">1 </span><span class="c0">is zero, i.e., for 480 and 120, we have value 0.86 for time series s. Observe that for increasing values of l less patterns with distance zero exist (e.g., two in Fig. 6b instead of 5 in Fig. 6a). But the patterns with l &gt; 1 at distance zero describe the situation better: s(840) is located at a down-slope, and in Fig. 6b values of s where the pattern distance is zero only exist at down-slopes, while in Fig. 6a we have such values at both up- and down-slopes. </span><span class="c29">2 </span></p><p class="c18"><span class="c0">Example 8. For shifted time series a pattern length l &gt; 1 in ad- dition captures the trend of time series and yields a more accurate imputation. First, Figure 7a illustrates s and the pattern dissimilar- ity to r</span><span class="c2">2 </span><span class="c11">for l = 1. Figure 7b shows the same setting with l = 60. </span><span class="c0">With l &gt; 1 the pattern dissimilarity reaches zero only for time points 480 and 120, where time series s has value 0.86, which is the expected value for missing value s(840). This illustrates that by increasing l, TKCM finds anchor points where the incomplete </span></p><p class="c1"><span class="c17">334 </span></p><p class="c1"><span class="c7">0 2 10</span><span class="c13">&minus;1</span><span class="c7">&minus;0.86</span><span class="c13">&minus;1 </span><span class="c0">t [minutes] </span></p><p class="c1"><span class="c9">(a) </span><span class="c8">Time series s and r</span><span class="c5">2 </span></p><p class="c1"><span class="c13">&minus;1 0 0.5 1 </span></p><p class="c1"><span class="c13">0</span><span class="c7">6 42</span><span class="c0">t [minutes] </span></p><p class="c24"><span class="c7">6 </span><span class="c13">s</span><span class="c5">&delta;(P(t), P (840)) </span><span class="c43">for </span><span class="c5">r1 </span><span class="c7">42</span><span class="c13">00 180 360 540 720 840 </span></p><p class="c1"><span class="c13">0 180 360 540 720 840 </span></p><p class="c1"><span class="c0">t [minutes] </span><span class="c9">(a) </span><span class="c8">Pattern length l = 1 </span></p><p class="c1"><span class="c9">(b) </span><span class="c8">Pattern length l = 60 </span></p><p class="c1"><span class="c0">Figure 6: A longer pattern reduces the number of patterns that are identical to the query pattern. </span></p><p class="c18"><span class="c0">time series s has similar values and trends. Consequently, TKCM uses pattern length l to effectively deal with shifted time series that are not linearly correlated. </span><span class="c29">2 </span></p><p class="c1"><span class="c7">3 </span></p><p class="c1"><span class="c7">210</span><span class="c13">&minus;10 180 360 540 720 840 </span></p><p class="c1"><span class="c0">t [minutes] </span></p><p class="c1"><span class="c7">3 </span><span class="c13">s</span><span class="c5">&delta;(P (t), P(840)) </span><span class="c43">for </span><span class="c5">r2 </span></p><p class="c1"><span class="c7">210</span><span class="c13">&minus;1</span><span class="c0">t [minutes] </span><span class="c9">(a) </span><span class="c8">Pattern length l = 1 </span></p><p class="c1"><span class="c9">(b) </span><span class="c8">Pattern length l = 60 </span></p><p class="c1"><span class="c0">Figure 7: For shifted time series a longer pattern finds historical situations that are similar in value and trend. </span></p><p class="c18"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">5.1. (Monotonicity in Pattern Length) The number of patterns that are within a distance &tau; to query pattern P(t</span><span class="c3">n</span><span class="c0">) de- creases as the pattern length l increases: </span></p><p class="c1"><span class="c0">|{t</span><span class="c3">m</span><span class="c0">|&delta;(P</span><span class="c3">l+1</span><span class="c0">(t</span><span class="c3">m</span><span class="c0">),P</span><span class="c3">l+1</span><span class="c0">(t</span><span class="c3">n</span><span class="c0">))&le;&tau;}| &le; |{t</span><span class="c3">m</span><span class="c0">|&delta;(P</span><span class="c3">l</span><span class="c0">(t</span><span class="c3">m</span><span class="c0">),P</span><span class="c3">l</span><span class="c0">(t</span><span class="c3">n</span><span class="c0">))&le;&tau;}| </span></p><p class="c1"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. Let &#8710; = &delta;(P</span><span class="c2">l</span><span class="c11">(t</span><span class="c2">m</span><span class="c11">),P</span><span class="c2">l</span><span class="c11">(t</span><span class="c2">n</span><span class="c11">)). If pattern </span><span class="c0">length </span><span class="c11">&radic;&#8710;</span><span class="c3">2 </span><span class="c11">+ </span><span class="c0">l &sum;is </span><span class="c2">r</span><span class="c5">i</span><span class="c3">&isin;R</span><span class="c0">increased </span><span class="c5">s</span><span class="c0">(r</span><span class="c3">i</span><span class="c0">(t</span><span class="c3">m&minus;l</span><span class="c0">) we &minus; r</span><span class="c3">i</span><span class="c0">(t</span><span class="c3">n&minus;l</span><span class="c0">))get &delta;(P</span><span class="c2">l+1</span><span class="c11">(t</span><span class="c28">2</span><span class="c0">. </span><span class="c2">m</span><span class="c11">),P</span><span class="c2">l+1</span><span class="c11">(t</span><span class="c2">n</span><span class="c11">)) = </span><span class="c0">Observe that both terms under the square root are non-negative, hence &delta; is mono- tonically increasing as l increases. It follows that the number of patterns with distance &le; &tau; decreases as l grows. </span><span class="c6">5.3 Consistent Imputation </span></p><p class="c24"><span class="c0">Definition 5. (Pattern-Determining at time t</span><span class="c3">n</span><span class="c0">) At time t</span><span class="c3">n </span><span class="c0">the reference time R</span><span class="c3">s</span><span class="c0">,t</span><span class="c3">n </span><span class="c28">pd</span><span class="c0">&minus;&rarr;s, if </span><span class="c13">0 180 360 540 720 840 </span><span class="c0">series R</span><span class="c2">s </span><span class="c11">pattern-determine time series s, written </span><span class="c0">for the k most similar anchor points A (cf. Def. 3) and patterns of length l the following holds for a small value &epsilon;: </span></p><p class="c1"><span class="c0">&forall;t</span><span class="c3">i</span><span class="c0">,t</span><span class="c3">j </span><span class="c0">&isin; A : |s(t</span><span class="c3">i</span><span class="c0">) &minus; s(t</span><span class="c3">j</span><span class="c0">)| &le; &epsilon; </span></p><p class="c18"><span class="c0">Example 9. In our running example (cf. Fig. 3), the query pattern P(t</span><span class="c2">n</span><span class="c11">=14:20) is based on the two reference time series </span><span class="c0">R</span><span class="c2">s </span><span class="c11">= {r</span><span class="c2">1</span><span class="c11">,r</span><span class="c2">2</span><span class="c11">}. The k = 2 most similar anchor points are </span><span class="c0">A = {14:00, 13:35}, and the values of s at these two anchors are 21.9&deg;C and 21.8&deg;C, respectively. The two reference time series R</span><span class="c3">s </span><span class="c0">pattern-determine s at time t</span><span class="c3">n </span><span class="c0">(written R</span><span class="c3">s</span><span class="c0">,14:20 </span><span class="c28">pd</span><span class="c0">&minus;&rarr; s) with &epsilon; = |21.9&deg;C &minus; 21.8&deg;C| = 0.1&deg;C. </span><span class="c29">2 </span></p><p class="c18"><span class="c0">Pattern-determining time series guarantee that for a missing value s(t</span><span class="c3">n</span><span class="c0">) we find in the sliding window at least k similar pat- terns P(t</span><span class="c2">i</span><span class="c5">1</span><span class="c0">),...,P(t</span><span class="c2">i</span><span class="c5">k</span><span class="c0">) to P(t</span><span class="c2">n</span><span class="c11">) and the missing value s(t</span><span class="c2">n</span><span class="c11">) is </span><span class="c0">similar to the observed values s(t</span><span class="c2">i</span><span class="c11">). </span></p><p class="c18"><span class="c0">Definition 6. (Consistent Time Series) Let s be a time series with missing value s(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL</span><span class="c11">. Let &circ;s be a time series where the </span><span class="c0">missing value s(t</span><span class="c3">n</span><span class="c0">) has been imputed, that is &circ;s(t</span><span class="c3">n</span><span class="c0">) = N</span><span class="c16">IL </span><span class="c0">and &forall;t &isin; W \ {t</span><span class="c2">n</span><span class="c11">} : &circ;s(t) = s(t). Time series &circ;s is consistent if </span><span class="c0">&forall;t &isin; A : |&circ;s(t) &minus; &circ;s(t</span><span class="c3">n</span><span class="c0">)| &le; &epsilon;. </span></p><p class="c18"><span class="c0">When TKCM imputes an incomplete time series s, we get an imputed time series &circ;s. Intuitively, &circ;s is consistent if its value at the current time t</span><span class="c2">n </span><span class="c11">is similar to past values when the reference time </span><span class="c0">series observed a similar pattern. </span></p><p class="c18"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">5.2. Let s be an incomplete time series with a missing value s(t</span><span class="c2">n</span><span class="c11">) = N</span><span class="c33">IL </span><span class="c11">and R</span><span class="c2">s </span><span class="c11">its reference time series. Let &circ;s be the </span><span class="c0">imputed time series produced by TKCM. If (a) R</span><span class="c3">s</span><span class="c0">,t</span><span class="c3">n </span><span class="c28">pd</span><span class="c0">&minus;&rarr;s and (b) s(t</span><span class="c2">n</span><span class="c11">) is imputed as defined in Eq. 4, &circ;s is a consistent time series. </span></p><p class="c18"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. Let P(t</span><span class="c2">n</span><span class="c11">) be the query pattern that TKCM constructs </span><span class="c0">for the reference time series in R</span><span class="c3">s </span><span class="c0">with pattern length l. TKCM looks for the k most similar anchor points A with respect to P(t</span><span class="c2">n</span><span class="c11">). </span><span class="c0">Since the reference time series R</span><span class="c2">s </span><span class="c11">pattern-determine s at time t</span><span class="c2">n</span><span class="c11">, </span><span class="c0">we have that &forall;t, t &isin; A : |s(t) &minus; s(t )| &le; &epsilon;. The imputed value &circ;s(t</span><span class="c2">n</span><span class="c11">) is the average of s at the anchor points (cf. Eq. 4). Since all </span><span class="c0">values of s at A are similar among each other within a distance of &epsilon;, their mean &circ;s(t</span><span class="c2">n</span><span class="c11">) is equally similar within an &epsilon; distance to all of </span><span class="c0">them, i.e. &forall;t &isin; A : |&circ;s(t) &minus; &circ;s(t</span><span class="c3">n</span><span class="c0">)| &le; &epsilon;. Consequently the imputed time series &circ;s is consistent. </span></p><p class="c18"><span class="c0">Next, we give an example of pattern-determining time series to illustrate what kind of phenomena TKCM can handle. Specifically, we show that sine waves of the form f(t) = A &times; sind(t</span><span class="c28">360</span><span class="c3">P </span><span class="c4">+ </span><span class="c0">&phi;) + o with amplitude A, period P, offset o, and phase shift &phi; are pattern-determining and that TKCM achieves consistent imputation on these series. The experiments in Section 7 confirm that this also holds for real world time series. </span></p><p class="c18"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">5.3. Assume s(t) = A</span><span class="c3">1 </span><span class="c0">&times; sind(t </span><span class="c28">360</span><span class="c3">P </span><span class="c4">+ &phi;</span><span class="c28">1</span><span class="c4">) + o</span><span class="c28">1 </span><span class="c4">and </span><span class="c0">r(t) = A</span><span class="c2">2 </span><span class="c11">&times; sind(t</span><span class="c3">360</span><span class="c2">P </span><span class="c0">+ &phi;</span><span class="c2">2</span><span class="c11">) + o</span><span class="c2">2</span><span class="c11">. Then R</span><span class="c2">s </span><span class="c11">= {r} is pattern- </span><span class="c0">determining s at time t</span><span class="c3">n </span><span class="c0">for l &gt; 1, k &ge; 1 and L &ge; kP + l. </span></p><p class="c18"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. Observe that for l &gt; 1, pattern P(t</span><span class="c3">n</span><span class="c0">) occurs exactly once every full period, i.e., P(t) = P(t</span><span class="c2">n</span><span class="c11">) only if t = t</span><span class="c2">n&minus;iP </span><span class="c11">for </span><span class="c0">every i &isin; </span><span class="c29">N</span><span class="c0">. Since L &ge; kP +l we know there are k patterns P(t), such that P(t) = P(t</span><span class="c2">n</span><span class="c11">). Since s has the same periodicity as r, we </span><span class="c0">know that &forall;t, t &isin; A : |s(t) &minus; s(t )| &le; 0 = &epsilon;. </span></p><p class="c1"><span class="c6">6. IMPLEMENTATION OF TKCM </span></p><p class="c1"><span class="c6">6.1 Overview </span></p><p class="c1"><span class="c0">To impute a missing value in a time series s at the current time t</span><span class="c3">n</span><span class="c0">, TKCM performs three steps: </span></p><p class="c18"><span class="c0">1. Pattern Extraction: Extract the anchor points of all candidate patterns from the streaming window W and compute the dis- similarity of these patterns to query pattern P(t</span><span class="c2">n</span><span class="c11">) (cf. Defi- </span><span class="c0">nition 2). </span></p><p class="c18"><span class="c0">2. Pattern Selection: Select from the anchor points determined in step 1 the subset A of the time points that anchor the k most similar non-overlapping patterns (cf. Definition 3). </span></p><p class="c1"><span class="c17">335 </span></p><p class="c1"><span class="c0">3. Value Imputation: Impute the missing value at t</span><span class="c2">n </span><span class="c11">using an- </span></p><p class="c1"><span class="c0">chor points A (cf. Definition 4). </span></p><p class="c18"><span class="c0">In step 2, TKCM must find the k patterns that neither overlap each other nor P(t</span><span class="c3">n</span><span class="c0">), and that minimize the sum of dissimilarities with respect to P(t</span><span class="c2">n</span><span class="c11">). A simple greedy algorithm that sorts the an- </span><span class="c0">chor points according to dissimilarity and picks the first k ones that do not overlap fails to minimize the sum of dissimilarities. There- fore, we propose a dynamic programming scheme that exploits an optimal sub-structure of this problem. Let D[j] denote the dissimi- larity between the jth pattern in the window and the query pattern, and M[i, j] denote the sum of dissimilarities of the i most simi- lar non-overlapping patterns from among the first j patterns in W, where i &le; j. M[i, j]=0 if i = 0, because no patterns have to be chosen. Similarly, M[i, j] = &infin; if i &gt; j because we cannot possibly find i non-overlapping patterns if we have only j&lt;i to choose from. Otherwise, we have two options: either (a) we omit the jth pattern and pick i patterns that possibly overlap it; or (b) we pick the jth pattern having dissimilarity D[j] and have space left for i&minus;1 patterns that do not overlap it. In the latter case, the first pattern to no longer overlap the jth pattern, if one exists, is the (j &minus; l)th pattern. </span></p><p class="c1"><span class="c0">This yields the following recurrence that minimizes the sum of dissimilarities: </span></p><p class="c24"><span class="c0">M[i, j]=</span><span class="c4">&#63729;</span><span class="c0">&#63732;</span><span class="c11">&#63732;&#63730;</span><span class="c9">0 &infin; if i = 0, if i&gt;j, </span><span class="c11">&#63732;&#63732;&#63731;</span><span class="c9">min </span></p><p class="c1"><span class="c9">{</span><span class="c20">M[i, j&minus;1] </span></p><p class="c1"><span class="c9">D[j] + M[i&minus;1,j &minus; l] </span><span class="c22">otherwise </span></p><p class="c1"><span class="c0">(5) </span></p><p class="c1"><span class="c0">The sum of dissimilarities of the k most similar anchor points is given by M[k, L&minus;2l+1], since L&minus;2l+1 is the number of anchor points when we exclude the l &minus; 1 first and l last time points in W (cf. Def. 3). </span><span class="c6">6.2 Algorithm </span></p><p class="c18"><span class="c0">The implementation uses one ring buffer of length L for each time series s and an offset O into the ring buffers to efficiently update the streaming window. The value at time t</span><span class="c3">n </span><span class="c0">is located at s[O] and the oldest value at s[(O+1)%L], where % is the modulo operator. TKCM&rsquo;s pseudo code is listed in Algorithm 1. The input parameters are the ring buffer for the incomplete time series s with a missing value at s[O], d ring buffers R for the reference time series, the window size L, the pattern length l, and the number of anchor points k. The algorithm stores the imputed value in s[O] and returns it. </span></p><p class="c18"><span class="c0">For processing, the algorithm uses an array D to store pattern dissimilarities, a (k+1) &times; (L&minus;2l+2) matrix M to store the result for the dynamic programming algorithm, and an array A of size k to store the k most similar anchor points. </span></p><p class="c18"><span class="c0">Lines 1&ndash;7 correspond to step 1, where the dissimilarities of all patterns in W are computed and stored in array D. The first l&minus;1 and the last l time points are ignored as described above. In step 2, the algorithm finds the k most similar anchor points (Lines 8&ndash;23). Lines 8&ndash;14 implement the recurrence in Equation 5. max(j&minus;l,0) computes the predecessor of the jth pattern, yield- ing j = 0 if no such predecessor exists. Once matrix M is filled, M[k, L&minus;2l+1] contains the sum of dissimilarities of the k most similar anchor points A. Finally, TKCM backtracks in lines 15&ndash;23 to find the anchor points A. The algorithm starts in the lower- right most cell M[k, L&minus;2l+1] and applies the recurrence back- wards. If for a cell M[i, j] we have M[i, j] = M[i, j&minus;1] the jth anchor point is skipped as it is not part of the optimal solution, and the algorithm proceeds at cell M[i, j&minus;1]. Otherwise, the jth </span></p><p class="c1"><span class="c0">Algorithm 1: TKCM </span></p><p class="c1"><span class="c9">Input: Ring buffer s, Array R of d ring buffers, window size L, </span></p><p class="c1"><span class="c9">pattern length l, and k. Output: Imputed value in s[O]. </span><span class="c23">1 </span><span class="c9">for j &larr; 1 to L&minus;2&lowast;l+1 do </span><span class="c23">2 </span><span class="c9">D[j] &larr; 0; </span><span class="c23">3 </span><span class="c9">for i &larr; 0 to d&minus;1 do </span><span class="c23">4 </span><span class="c9">for x &larr; 0 to l&minus;1 do </span><span class="c23">5 </span><span class="c9">y &larr; l+j&minus;x&minus;1; </span><span class="c23">6 </span><span class="c9">D[j] &larr; D[j]+(R[i][(O+y)%L]&minus;R[i][(O&minus;x)%L])</span><span class="c28">2</span><span class="c9">; </span></p><p class="c1"><span class="c23">7 </span><span class="c9">D[j] &larr; sqrt(D[j]); </span><span class="c23">8 </span><span class="c9">for j &larr; 0 to L&minus;2&lowast;l+1 do </span><span class="c23">9 </span><span class="c9">M[0][j] &larr; 0; </span><span class="c23">10 </span><span class="c9">for i &larr; 1 to k do </span><span class="c23">11 </span><span class="c9">if i&gt;j then </span><span class="c23">12 </span><span class="c9">M[i][j]&larr;&infin;; </span><span class="c23">13 </span><span class="c9">else </span><span class="c23">14 </span><span class="c9">M[i][j]&larr;min(M[i][j&minus;1],D[j]+M[i&minus;1][max(j&minus;l, 0)]); </span></p><p class="c1"><span class="c23">15 </span><span class="c9">i &larr; k; </span><span class="c23">16 </span><span class="c9">j &larr; L&minus;2&lowast;l+1; </span><span class="c23">17 </span><span class="c9">while i &gt; 0 do </span><span class="c23">18 </span><span class="c9">if M[i][j] = M[i][j&minus;1] then </span><span class="c23">19 </span><span class="c9">j&minus;&minus;; </span><span class="c23">20 </span><span class="c9">else </span><span class="c23">21 </span><span class="c9">A[i&minus;1] &larr; j; </span><span class="c23">22 </span><span class="c9">i&minus;&minus;; </span><span class="c23">23 </span><span class="c9">j &larr; max(j&minus;l, 0); </span></p><p class="c1"><span class="c23">24 </span><span class="c9">s[O] &larr; 0; </span><span class="c23">25 </span><span class="c9">for i &larr; 0 to k&minus;1 do </span><span class="c23">26 </span><span class="c9">s[O] &larr; s[O]+(s[(O+l+A[i]&minus;1)%L]/k); </span><span class="c23">27 </span><span class="c9">return s[O]; </span></p><p class="c18"><span class="c0">anchor point is added to A and the algorithm proceeds with cell M[i&minus;1,max(j&minus;l,0)] until i reaches 0, indicating that k anchor points have been chosen. Finally, in lines 24&ndash;27, which correspond to step 3, the algorithm imputes the missing value using the k most similar anchor points according to Definition 4. </span></p><p class="c18"><span class="c0">Example 10. The top of Fig. 8 shows a streaming window of length L = 10 with current time t</span><span class="c3">n </span><span class="c0">= t</span><span class="c3">13</span><span class="c0">. The query pat- tern of length l = 3 and all extracted patterns are shown as red and black intervals, respectively. The first (i.e., j = 1) pattern is P(t</span><span class="c3">6</span><span class="c0">) and the last pattern is P(t</span><span class="c3">10</span><span class="c0">). The lower left table lists the patterns in the streaming window, their index j, predecessor, and dissimilarity with respect to query pattern P(t</span><span class="c3">13</span><span class="c0">). For in- stance, P(t</span><span class="c2">8</span><span class="c11">) with index j = 3 has no non-overlapping prede- </span><span class="c0">cessor, hence max(j &minus; l,0) = 0. The right table shows the matrix M computed by Algorithm 1. For instance, M[1,1] is the result of computing min(D[1] +M[1&minus;1,max(1&minus;3,0)],M[1,1&minus;1]) = min(0.5+0, &infin;)=0.5. M[2,5] = 1.2 in the lower-right corner contains the minimum sum of dissimilarity. To retrieve the k most similar non-overlapping patterns, the algorithm starts at M[2,5] and follows the highlighted path through the matrix: gray means that a pattern was omitted and green means that a pattern is part of the final result. For instance, M[2,5] is equal to M[2,4], hence the j = 5th pattern P(t</span><span class="c2">10</span><span class="c11">) is not part of the solution. M[2,4], in turn, </span><span class="c0">is the result of D[4]+M[1,1] = 0.7+0.5=1.2, hence j = 4th pattern P(t</span><span class="c2">9</span><span class="c11">) is part of the solution. Continuing with M[1,1] we </span><span class="c0">find another match before reaching M[0,0]. The algorithm finds the k = 2 anchor points A = {t</span><span class="c3">6</span><span class="c0">,t</span><span class="c3">9</span><span class="c0">} and computes the imputed value &circ;s(t</span><span class="c2">13</span><span class="c11">) = </span><span class="c3">1</span><span class="c11">/</span><span class="c2">2</span><span class="c11">(s(t</span><span class="c2">6</span><span class="c11">) + s(t</span><span class="c2">9</span><span class="c11">)). </span></p><p class="c1"><span class="c17">336 </span></p><p class="c1"><span class="c13">P (6),&delta;=0.5 </span></p><p class="c1"><span class="c13">P (7),&delta;=0.3 </span></p><p class="c1"><span class="c13">P (8),&delta;=2.1 </span></p><p class="c1"><span class="c13">P(9),&delta;=0.7 </span></p><p class="c1"><span class="c13">P(10),&delta;=4.0 </span></p><p class="c1"><span class="c13">P (t</span><span class="c5">n</span><span class="c13">=t</span><span class="c5">13</span><span class="c13">) </span></p><p class="c1"><span class="c7">4 5 6 7 8 9 10 11 12 13 </span></p><p class="c1"><span class="c8">t </span><span class="c13">L=10 </span></p><p class="c1"><span class="c13">P (t) j max(j&minus;l, 0) D[j] </span></p><p class="c1"><span class="c13">j = 0 </span><span class="c5">1 2 3 4 5 </span></p><p class="c1"><span class="c13">P P P P P (t(t(t(t(t</span><span class="c5">106789</span><span class="c13">0 0 0 0 0 0 &infin; 0.5 0.3 0.3 0.3 0.3 </span></p><p class="c1"><span class="c13">&infin; &infin; &infin; &infin; 1.2 1.2 ) i = 0) ) </span><span class="c5">1</span><span class="c13">) </span><span class="c5">2 </span><span class="c13">) 1 2 3 4 5 0 0 0 1 2 0.5 0.3 2.1 0.7 4.0 </span></p><p class="c18"><span class="c0">Figure 8: Dynamic programming algorithm to compute the time points of the top k = 2 non-overlapping patterns of length l = 3 that minimize the sum of dissimilarities. </span></p><p class="c1"><span class="c6">6.3 Complexity Analysis </span></p><p class="c18"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">6.1. When the current time t</span><span class="c3">n </span><span class="c0">advances, TKCM needs O(1) time per stream s to update the corresponding ring buffer of size O(L). </span></p><p class="c1"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. When t</span><span class="c2">n </span><span class="c11">advances, a new value replaces an old value </span><span class="c0">in the time series, requiring O(1) time in a ring buffer of size L. </span></p><p class="c1"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">6.2. The time complexity of TKCM to impute a missing value is O((l &times; d + k) &times; L). </span></p><p class="c18"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. Initially TKCM computes the dissimilarity of O(L) patterns, each of size l &times; d, having an overall time complexity of O(l &times; d&times; L). Next the algorithm iterates over the O(k &times;L) sized dynamic programming matrix M. Hence the overall time complex- ity is O(l &times; d &times; L + k &times; L). </span></p><p class="c1"><span class="c0">L</span><span class="c16">EMMA </span><span class="c0">6.3. The space complexity of TKCM to impute a miss- ing value is O(k &times; L). </span></p><p class="c18"><span class="c0">P</span><span class="c16">ROOF</span><span class="c0">. The pattern extraction phase requires O(L) space to store the dissimilarities of all patterns. TKCM needs O(k &times; L) space for matrix M. </span></p><p class="c1"><span class="c6">7. EXPERIMENTAL EVALUATION </span></p><p class="c18"><span class="c0">In the experiments we simulate large blocks of consecutively missing values (e.g. one week). We repeatedly call TKCM to im- pute each missing value. This simulates a common sensor failure that requires a technician to reach a faulty weather station and re- place the broken sensor. As accuracy measure we use the root mean square error (RMSE), defined as </span></p><p class="c1"><span class="c0">RMSE = </span></p><p class="c1"><span class="c0">&radic; </span><span class="c11">1|T| </span></p><p class="c1"><span class="c0">&sum;</span><span class="c2">t</span><span class="c5">n</span><span class="c2">&isin;T</span><span class="c0">(s(t</span><span class="c2">n </span><span class="c11">) &minus; &circ;s(t</span><span class="c2">n</span><span class="c11">))</span><span class="c3">2</span><span class="c11">, </span><span class="c0">where T is the set of missing time points. The experiments are conducted on a Linux server, running Ubuntu 14.04 server edition. It is powered by an Intel Xeon X5650 CPU with a frequency of 2.67GHz and 24GB of main memory. TKCM is implemented in C and compiled with Clang 3.4-1, based on LLVM 3.4. </span><span class="c6">7.1 Datasets and Setup </span></p><p class="c18"><span class="c0">We use both real-world and synthetic datasets in our experimen- tal evaluation. First, we use the SBR dataset of meteorological time series in South Tyrol (cf. Sec. 1). Second, we shift the time series </span></p><p class="c18"><span class="c0">of the SBR data set by a (different) random amount up to one day and call this dataset SBR-1d. Third, we use the Flights dataset [3] that consists of eight time series, each of length 8801 (6 days). A time series describes at time t the number of airplanes that departed from a given airport and are in the air at time t. Fourth, we use the publicly available Chlorine dataset [1] used by SPIRIT [16]. This synthetic dataset was generated by a simulation of a drinking water distribution system; it describes the chlorine concentration at 166 junctions over a time frame of 4310 time points (15 days) with a sample rate of 5 minutes. The propagation of the chlorine level in the system causes phase shifts in the dataset. Fig. 9 shows an excerpt of three sample time series from each dataset. Each time series has different amplitudes, phase shifts, and trends. </span></p><p class="c1"><span class="c22">] C&deg;[.pme</span><span class="c9">T</span><span class="c21">30 2520</span><span class="c12">15</span><span class="c9">(a) SBR dataset </span></p><p class="c1"><span class="c22">] C&deg;[.pme</span><span class="c9">T</span><span class="c21">30 2520</span><span class="c12">15</span><span class="c9">(b) SBR-1d dataset </span></p><p class="c1"><span class="c22">s thgilF</span><span class="c9">#</span><span class="c21">80 604020</span><span class="c12">0</span><span class="c9">(c) Flights dataset </span><span class="c22">l evelenirolh</span><span class="c9">C</span><span class="c12">0 </span></p><p class="c1"><span class="c0">Figure 9: Three sample time series from each dataset. </span></p><p class="c18"><span class="c0">We compare TKCM to three competitors: CD [13] (provided by the author), MUSCLES [25] (implemented in Matlab), and SPIRIT [23] (obtained from [1], Matlab code). SPIRIT&rsquo;s Matlab code does not impute missing values, hence we extended the code to use one autoregressive model per hidden variable as described in [23]. SPIRIT automatically adds or removes hidden variables as the streams evolve. When a hidden variable appears, a new autore- gressive model of order p = 6 needs to be fitted, which requires at least p values of the new hidden variable before it can be used. If in that time a value needs to be imputed, the model is not yet ready. Consequently we fixed the number of hidden variables at two, which gave generally the best results in our experiments. For MUSCLES and SPIRIT we use a tracking window size of p = 6 as recommended by the authors [23, 25]. Contrary to the author&rsquo;s rec- ommendation we set the exponential forgetting factor &lambda; to 1 rather than to 0.96 &le; &lambda; &le; 0.98. We found that for &lambda; &lt; 1 the accuracy de- creases, because the algorithms &ldquo;forget&rdquo; the old non-imputed (and accurate) values and adapt more to the new imputed (and inaccu- rate) values. CD has no parameters to tune. The code for our MUS- CLES, SPIRIT, and TKCM implementations is available online</span><span class="c28">1</span><span class="c0">. </span></p><p class="c1"><span class="c3">1</span><span class="c11">http://www.ifi.uzh.ch/en/dbtg/Staff/wellenzohn/dasa.html </span></p><p class="c1"><span class="c17">337 </span></p><p class="c1"><span class="c12">0.2 </span></p><p class="c1"><span class="c12">0.1 </span></p><p class="c1"><span class="c9">(d) Chlorine </span></p><p class="c1"><span class="c6">7.2 Calibration </span></p><p class="c18"><span class="c0">We begin with an initial calibration of TKCM&rsquo;s parameters d, k, and L. Unless otherwise noted we set the parameters to the following default values; d = 3 reference time series, k = 5 most similar anchor points, a streaming window of L = 1 year, and pattern length l = 72. </span></p><p class="c18"><span class="c0">In the left column of Fig. 10 we show TKCM&rsquo;s accuracy for increasing values of d on three datasets; for brevity we omit the SBR dataset as it shows identical behavior to the SBR-1d dataset. TKCM&rsquo;s accuracy significantly increases (that is the RMSE de- creases) as d increases up to d = 3 reference time series, while d &gt; 3 does not provide significantly better accuracy. Since the Flights dataset has only 8 time series, we can set d at most to 7. The right column of Fig. 10 shows the impact of parameter k on TKCM&rsquo;s accuracy. In general we tend to pick small values of k, e.g., k &isin; [3,10] to get the best possible (most similar) patterns from the window. Larger values of k may add less similar patterns, in particular for short streaming windows. We observed that for the two small datasets Flights and Chlorine k = 5 is sufficient. TKCM&rsquo;s accuracy noticeably decreases on the Flights dataset for k &gt; 5, because the dataset contains only measurements for 6 days and if one day is missing we try to find more than 5 similar situa- tions within 5 days, which makes no sense. For the larger (1 year) SBR and SBR-1d datasets we found that there is a marginal accu- racy increase even from k = 5 to k = 10, after which the accuracy remains stable. Therefore, our recommendation is to use a small value of k, e.g. k = 5, and if the dataset is large, one can safely double k. </span></p><p class="c1"><span class="c13">2.5</span><span class="c7">2 </span></p><p class="c1"><span class="c13">1.5</span><span class="c7">10 </span></p><p class="c1"><span class="c7">86</span><span class="c13">4</span><span class="c5">2</span><span class="c13">0.04 </span></p><p class="c1"><span class="c13">0.03 </span></p><p class="c1"><span class="c13">0.02 </span></p><p class="c1"><span class="c13">0.01 </span></p><p class="c1"><span class="c7">0 </span></p><p class="c1"><span class="c13">2 4 6 8 10 </span><span class="c8"># Reference time series d </span></p><p class="c1"><span class="c13">2 4 6 8 10 </span></p><p class="c1"><span class="c8"># Anchor points k </span></p><p class="c1"><span class="c0">Figure 10: Calibration shows that d = 3 and k = 5 are good default values. </span></p><p class="c18"><span class="c0">For the small Flights and Chlorine datasets (6 and 15 days, re- spectively) we use in our experiments the entire time range as streaming window length L. For the SBR and SBR-1d datasets we use a streaming window length L = 105120 (1 year), be- cause one year covers the whole temperature range and contains each pattern several times. This choice is conservative; we found that already a window size of 6 months gives a good accuracy of RMSE = 1.8&deg;C, which only dropped to 1.7&deg;C for a 5 year win- dow. In general, larger window sizes L provide only a slightly superior accuracy. </span></p><p class="c1"><span class="c6">7.3 Accuracy </span></p><p class="c1"><span class="c34">7.3.1 Pattern Length </span><span class="c0">l </span></p><p class="c18"><span class="c0">For shifted time series, the pattern length l is the key to an accu- rate and robust imputation. In Fig. 11, we evaluate l by varying the pattern length l from 1 to 144 (i.e., a pattern that spans 12 hours). As expected, for the (non-shifted) SBR dataset l has close to no im- pact on TKCM&rsquo;s accuracy, because there is a high linear correlation between the incomplete time series and its d = 3 reference time series. For the SBR-1d dataset the RMSE drops by about 0.5&deg;C (25%) by increasing l to 72. On the flight dataset we observe an improvement of 50% for l = 72 and 60% for l = 144. The reason why we see an improvement beyond l = 72 is the different sample rate of 1 minute of the Flights dataset as opposed to the 5 minutes in the SBR dataset. While l = 72 yields a pattern that spans 6 hours in the SBR dataset, it only spans 1 hour in the Flights dataset. On the Chlorine dataset we observe an accuracy increase of 60% with pattern length l = 72, after which the accuracy slightly decreases. </span></p><p class="c1"><span class="c13">1.4 </span></p><p class="c1"><span class="c13">2.5 </span></p><p class="c1"><span class="c13">1.2 </span></p><p class="c1"><span class="c7">1 </span></p><p class="c1"><span class="c13">0.81 36 72 108 144 </span></p><p class="c1"><span class="c8">(a) SBR: l </span></p><p class="c1"><span class="c8">(b) SBR-1d: l </span></p><p class="c1"><span class="c7">10 </span></p><p class="c1"><span class="c7">8642</span><span class="c13">1 36 72 108 144 </span><span class="c8">(c) Flights: l </span></p><p class="c1"><span class="c7">2 </span></p><p class="c1"><span class="c13">0.6 </span></p><p class="c1"><span class="c7">1.5</span><span class="c13">1 36 72 108 144 0.04 </span></p><p class="c1"><span class="c8">(d) Chlorine: l </span></p><p class="c1"><span class="c0">Figure 11: Pattern length l evaluated on each dataset. </span></p><p class="c18"><span class="c0">To put these raw numbers into perspective and see the real impact of l, we compare TKCM&rsquo;s recovery of an incomplete time series s in Fig. 12 with pattern length l = 1 (left column) and l = 72 (right column). Observe how much TKCM&rsquo;s recovery oscillates with l = 1 and how well TKCM adapts to the assumed missing time series s with l = 72. Even for the SBR dataset there is a slight oscillation, albeit minimal compared to the three shifted datasets. The reason for this strong oscillation when l = 1 is that with a short pattern, the reference time series do not pattern-determine the incomplete time series. The difference in dissimilarity between &ldquo;good&rdquo; patterns and &ldquo;bad&rdquo; patterns is too small for TKCM to de- tect, as explained in Sec. 5.1. Put differently, in the presence of shifts, time series are no longer linearly correlated; whenever a ref- erence time series observes a very similar value, the incomplete time series has very different values. </span></p><p class="c18"><span class="c0">Fig. 13a shows the scatterplot of an incomplete time series s in the Chlorine dataset against one of its reference time series r</span><span class="c3">1</span><span class="c0">. There is clearly no strong linear correlation (&rho;(s, r</span><span class="c3">1</span><span class="c0">) = 0.5): e.g. for r</span><span class="c2">1</span><span class="c11">(t) = 0.1, s(t) has two different values (0 and </span><span class="c0">0.15). Fig. 13b shows that the average &epsilon; (cf. Def. 5) decreases as l increases on the Chlorine dataset with k = 5. Value &epsilon; = max</span><span class="c2">t,t &isin;A </span><span class="c11">|s(t) &minus; s(t )| essentially describes the range of the val- </span><span class="c0">ues of s at the k most similar anchor points A. The lower &epsilon; gets, the less the values of s differ at the most similar anchor points, which indicates that the reference time series strongly pattern determine s for k and l. Notice that the average &epsilon; increases after l = 72, which </span></p><p class="c1"><span class="c17">338 </span></p><p class="c1"><span class="c13">0.03 </span></p><p class="c1"><span class="c13">0.02 </span></p><p class="c1"><span class="c13">0.01 </span></p><p class="c1"><span class="c7">0 </span></p><p class="c1"><span class="c13">1 36 72 108 144 </span></p><p class="c1"><span class="c13">s s imputed by TKCM </span></p><p class="c1"><span class="c7">25 </span></p><p class="c1"><span class="c7">20</span><span class="c13">15</span><span class="c7">2520</span><span class="c13">15</span><span class="c7">6040</span><span class="c13">200.2 </span></p><p class="c1"><span class="c13">0.1 </span></p><p class="c1"><span class="c13">0 </span></p><p class="c1"><span class="c8">l = 1 l = 72 </span></p><p class="c18"><span class="c0">Figure 12: The reason for the strong oscillation in TKCM&rsquo;s recov- ery with l = 1 are shifts in the reference time series. Increasing the pattern length l helps TKCM to detect shifts. </span></p><p class="c1"><span class="c0">coincides with our observations in Fig. 11d. </span></p><p class="c1"><span class="c13">0.2 </span></p><p class="c1"><span class="c13">0.06 </span></p><p class="c1"><span class="c13">0.1 </span></p><p class="c1"><span class="c13">0.05 </span></p><p class="c1"><span class="c13">0 </span></p><p class="c1"><span class="c13">0.04 </span></p><p class="c1"><span class="c13">0 0.1 0.2 </span></p><p class="c1"><span class="c13">1 36 72 108 144 </span><span class="c8">(a) r</span><span class="c5">1</span><span class="c42">(t) </span></p><p class="c1"><span class="c8">(b) Pattern length l </span></p><p class="c1"><span class="c0">Figure 13: Left: Scatterplot of s against the reference time series r</span><span class="c3">1</span><span class="c0">. Right: Range of s at the k anchor points (Chlorine dataset). </span></p><p class="c1"><span class="c34">7.3.2 Missing Block Length </span></p><p class="c18"><span class="c0">In Fig. 14 we study TKCM&rsquo;s accuracy in terms of the length of the missing block, i.e., the number of consecutively missing values that TKCM needs to impute. First, we use our large dataset SBR-1d and simulate sensor failures of up to several weeks. Fig. 14a shows that the accuracy of TKCM only slightly decreases by 0.2&deg;C as the block length grows from 1 to 4 weeks, after which the accuracy plateaus. Next, we increase the missing block length for the small dataset Chlorine from 10% to 80% of the dataset size. We start with the remaining 90% to 20% of the dataset in the streaming window of length L = 4310 and impute the rest of the dataset as missing values. Fig. 14b shows that also for this case the accuracy decreases only slowly. </span></p><p class="c1"><span class="c34">7.3.3 Comparison with Competitors </span></p><p class="c1"><span class="c34">SBR. </span><span class="c0">We first perform a baseline comparison of all algorithms on the SBR dataset that has no phase shifts. Fig. 15a shows an excerpt </span></p><p class="c1"><span class="c13">0.04 </span></p><p class="c1"><span class="c8">(b) Block length [% of L] </span></p><p class="c1"><span class="c0">Figure 14: Impact of the missing block length on the accuracy (Chlorine dataset). </span></p><p class="c18"><span class="c0">of the experiment where we assume a block of values is missing in time series s, and impute the missing values with each approach. TKCM, SPIRIT, MUSCLES, and CD perform virtually equally well. Observe that the last valley in the temperature curve shows a higher temperature than the previous valleys. While TKCM and CD are able to capture this trend, MUSCLES and SPIRIT impute a too low value. The most likely reason is that the models that MUS- CLES and SPIRIT build are not able to adapt quickly enough to the new behavior of the time series, while TKCM adapts instanta- neously to the changing behavior. </span></p><p class="c18"><span class="c34">SBR-1d. </span><span class="c0">Next we impute the same block of missing values in the SBR-1d dataset that has shifted time series. Observe how TKCM&rsquo;s accuracy only slightly decreases in Fig. 15b; TKCM slightly misses the second last downwards slope, but the last valley is again accu- rately imputed. SPIRIT completely misses the amplitude; its re- covered peaks are too low and its valleys are too high in tempera- ture. Moreover, the overall trend of the missing block is not well recovered. MUSCLES recovery is borderline at best; the overall periodicity of the signal is recovered, but MUSCLES was not able to recover any feature of s. Moreover, s has a slightly increas- ing temperature trend, but MUSCLES&rsquo; recovery has a decreasing trend. CD&rsquo;s recovery is shifted with respect to s, as also indicated by the discontinuous imputation at the very beginning of the miss- ing block. </span></p><p class="c18"><span class="c34">Flights. </span><span class="c0">On the Flights dataset we observe a similar behavior as in the previous experiment. Fig. 15c shows that TKCM cap- tures each peak and valley accurately, while SPIRIT&rsquo;s accuracy de- creases over time. Initially, the trend of s is vaguely captured, but after the highest peak, the trend of SPIRIT&rsquo;s imputation is inverse (i.e., peaks and valleys are swapped) with respect to the true sig- nal. Again, MUSCLES produces an extremely smoothed signal, that does not resemble the true time series; peaks and valleys are not recovered. CD&rsquo;s recovery is only partially shown as many re- covered values are negative. Most likely, the large block of missing values (ca. 20% of the dataset) is the reason. </span></p><p class="c18"><span class="c34">Chlorine. </span><span class="c0">In the Chlorine dataset TKCM captures the trend of s generally well, the valleys are almost perfectly recovered, while the peaks are slightly less accurate. SPIRIT&rsquo;s recovery does not capture the amplitude of s, and also the trend of the recovery does not match that of s. MUSCLES completely misses the first peak, imputing it with a valley instead; also the general trend of MUS- CLES&rsquo; recovery does not resemble s. In this dataset we found MUSCLES and SPIRIT to perform with widely differing accura- cies, sometimes their imputations is good, sometimes worse than in this example. There is no clear pattern when either approach works or fails. CD&rsquo;s recovered signal has a very small amplitude and also the trend does not capture that of s. </span></p><p class="c1"><span class="c17">339 </span></p><p class="c1"><span class="c13">2.5 </span></p><p class="c1"><span class="c8">(a) Block length [weeks] </span></p><p class="c1"><span class="c13">0.03 </span></p><p class="c1"><span class="c7">2 </span></p><p class="c1"><span class="c13">0.02 </span></p><p class="c1"><span class="c7">1.5</span><span class="c13">2 4 6 0.01 </span><span class="c7">0 </span></p><p class="c1"><span class="c13">20 40 60 80 </span></p><p class="c1"><span class="c9">T</span><span class="c22">] C&deg;[.pme</span><span class="c21">60 </span></p><p class="c1"><span class="c22">s thgilF</span><span class="c9">#</span><span class="c21">4020</span><span class="c12">0</span><span class="c9">(c) Flight dataset </span></p><p class="c1"><span class="c22">l evelenirolh</span><span class="c9">C</span><span class="c12">0</span><span class="c13">.</span><span class="c12">2 0</span><span class="c13">.</span><span class="c12">1 </span></p><p class="c1"><span class="c12">0 </span></p><p class="c1"><span class="c9">(d) Chlorine dataset </span></p><p class="c1"><span class="c0">Figure 15: Imputation of incomplete time series s with different imputation techniques on four different datasets. </span></p><p class="c18"><span class="c34">Summary. </span><span class="c0">Fig. 16 shows the RMSE for all compared algorithms on each dataset. In this comparison we impute 4 time series per data set; with missing block lengths per time series of 1 week in the SBR and SBR-1d datasets, and 20% of the dataset size for Flights and Chlorine. All algorithms are given the same amount of data (L measurements per time series). We use L = 6 months for the SBR and SBR-1d datasets, because of CD&rsquo;s prohibitively large runtime for L = 1 year (our default) and the default L for the remain- ing datasets. The experiments show that only for the non-shifted SBR dataset all algorithms provide a comparable accuracy. For the remaining three shifted datasets, TKCM clearly outperforms its competitors both in terms of perceived accuracy (Fig. 15) and raw RMSE (Fig. 16). Our general observation is that non-shifted linearly-correlated data poses no significant challenge to any al- gorithm. As soon as shifts are present in the data, the accuracy of state-of-the-art solutions is largely unpredictable, ranging from good to unusable. </span></p><p class="c1"><span class="c6">7.4 Runtime </span></p><p class="c18"><span class="c0">As discussed in Sec. 6.3, TKCM&rsquo;s time complexity is linear with respect to all parameters (l, d, k, and L) as confirmed by Fig. 17. In this experiments on the SBR-1d dataset we vary each parameter, leaving the other three parameters at their defaults (l = 72, d = 3, k = 5 and L = 1 year). Fig. 17a and Fig. 17b show TKCM&rsquo;s run- time with respect to the size of the query pattern P(t</span><span class="c3">n</span><span class="c0">), Fig. 17c shows the impact of the number of anchor points k, and Fig. 17d shows the impact of the streaming window size L on the runtime. Parameter L has the largest impact on TKCM&rsquo;s runtime, followed </span></p><p class="c1"><span class="c9">T</span><span class="c22">emp.[&deg;C] </span></p><p class="c1"><span class="c13">s SPIRIT MUSCLES CD TKCM </span></p><p class="c1"><span class="c21">25 </span></p><p class="c1"><span class="c21">20</span><span class="c12">15</span><span class="c9">(a) SBR dataset </span></p><p class="c1"><span class="c21">25 </span></p><p class="c1"><span class="c21">20</span><span class="c12">15</span><span class="c9">(b) SBR-1d dataset </span></p><p class="c1"><span class="c8">TKCM SPIRIT MUSCLES CD </span></p><p class="c1"><span class="c7">6 </span></p><p class="c1"><span class="c7">6 </span></p><p class="c1"><span class="c7">442.57 2</span><span class="c13">1.07 </span><span class="c5">0.88 0.89 </span><span class="c13">1.32 </span><span class="c7">2</span><span class="c13">1.82 0</span><span class="c8">SBR </span></p><p class="c1"><span class="c13">04.34 </span></p><p class="c1"><span class="c13">2.12 </span></p><p class="c1"><span class="c8">SBR-1d </span></p><p class="c1"><span class="c7">20 </span></p><p class="c1"><span class="c7">10</span><span class="c13">3.57 00.08 </span></p><p class="c1"><span class="c13">20.7 </span></p><p class="c1"><span class="c13">14.67 </span></p><p class="c1"><span class="c13">8.35 </span></p><p class="c1"><span class="c13">0.014 </span></p><p class="c1"><span class="c8">Flights </span></p><p class="c1"><span class="c13">0.06 </span></p><p class="c1"><span class="c13">0.049 </span></p><p class="c1"><span class="c13">0.054 </span></p><p class="c1"><span class="c13">0.04 </span></p><p class="c1"><span class="c13">0.036 </span></p><p class="c1"><span class="c8">Chlorine </span></p><p class="c1"><span class="c0">Figure 16: Comparison of TKCM, SPIRIT, MUSCLES, and CD for each dataset. </span></p><p class="c18"><span class="c0">by l and d with similar impact. Parameter k is relatively cheap &ndash; even if set to very large values, e.g., k &gt; 50. For our default pa- rameter settings we observe a runtime of approximately 2 seconds to impute a single missing value. </span></p><p class="c1"><span class="c7">8 </span></p><p class="c1"><span class="c7">6420</span><span class="c13">50 100 </span><span class="c8">(a) Pattern length l </span></p><p class="c1"><span class="c13">0.02 </span></p><p class="c1"><span class="c13">0 </span></p><p class="c10"><span class="c13">1 2 3 4 5 </span><span class="c8">(b) # reference time series d </span></p><p class="c1"><span class="c63">) ces(emitnu</span><span class="c8">R</span><span class="c7">8 6420</span><span class="c13">100 200 300 1 2 3 4 </span></p><p class="c1"><span class="c8">(c) # anchor points k </span></p><p class="c1"><span class="c8">(d) Window size L (years) </span></p><p class="c18"><span class="c0">Figure 17: Runtime experiments. TKCM&rsquo;s time complexity is linear with respect to all its parameters l, d, k, and L (SBR-1d dataset). </span></p><p class="c18"><span class="c34">Performance breakdown. </span><span class="c0">As described in Sec. 6 the two main phases of TKCM are pattern extraction (PE) and pattern se- lection (PS). In our default setup, the PE-phase accounts for 92% of TKCM&rsquo;s overall runtime. If we further subdivide the PE-phase, we see that 82% of the overall runtime are required to fetch data from main memory and 10% are used to compute the pattern dissimilar- ity &delta;. If we increase k to 300 we see the runtime of the PS-phase climbing from 8% up to 25%. Thus, for the default value of k, the runtime incurred by the PS-phase is outweighed by the PE-phase. Hence, to improve TKCM&rsquo;s performance, future research must fo- cus on speeding up the pattern extraction phase. </span></p><p class="c18"><span class="c34">Comparison. </span><span class="c0">A direct comparison of the runtimes of the con- sidered approaches is not meaningful, because the systems are im- plemented in different programming languages (TKCM in C, CD in Java, MUSCLES and SPIRIT in Matlab). To give a rough feeling for the overall performance we consider each approach in turn. CD is an offline algorithm and not applicable to streams. CD&rsquo;s matrix decomposition lasted in our experiments roughly 20 minutes per execution and is hence not applicable to streaming environments. Both SPIRIT and MUSCLES required one millisecond to impute one missing value, TKCM requires roughly 2 seconds. </span></p><p class="c1"><span class="c17">340 </span></p><p class="c78"><span class="c6">8. CONCLUSION AND FUTURE WORK </span></p><p class="c50"><span class="c0">We studied the problem of missing values in meteorological streams of time series data and presented an algorithm, termed TKCM, to accurately impute missing values in a streaming envi- ronment. If the current value in a time series s is missing, TKCM determines a two-dimensional query pattern over the last l mea- surements of d reference time series. It then retrieves the anchor points of the k most similar non-overlapping patterns to the query pattern. The missing value is computed from the values of s at these k anchor points. We show that TKCM achieves consistent imputation if the reference time series pattern-determine s, which covers non-linear relationships between time series such as phase shifts. An extensive experimental evaluation using four real-world and synthetic datasets confirms that TKCM is accurate and outper- forms state-of-the-art competitors. </span></p><p class="c46"><span class="c0">Future work points in several directions. First, we will work on the efficiency of TKCM, in particular the pattern extraction phase, which proved to be the most time-consuming component. In partic- ular, we plan to reduce the number of extracted patterns by pruning patterns that cannot possibly belong to an optimal solution. Sec- ond, we plan to investigate how to automatically determine the best candidate reference time series, although in many application do- mains (and especially in meteorology) we can rely on human ex- perts. Third, we plan to compare different dissimilarity functions &delta; (e.g. L</span><span class="c3">1</span><span class="c0">-norm, DTW [9], etc.). Moreover, it would be interesting to compute an alignment between shifted time series (e.g., using DTW [9]) and to compare TKCM&rsquo;s accuracy on the aligned time series using a pattern length l = 1 to the accuracy on the shifted time series using l &gt; 1. </span></p><p class="c66"><span class="c6">9. ACKNOWLEDGMENTS </span></p><p class="c50"><span class="c0">The work has been done as part of the DASA project, which is funded by the Foundation of the Free University of Bozen-Bolzano. We wish to thank our partners at the S&uuml;dtiroler Beratungsring and the Research Centre for Agriculture and Forestry Laimburg for the good collaboration and helpful domain insights they provided, in particular Armin Hofer, Martin Thalheimer, and Robert Wiedmer. We also want to thank Mourad Khayati for his input and for sharing his CD implementation used in the experimental evaluation. We thank the anonymous reviewers for their valuable comments and suggestions. </span></p><p class="c76"><span class="c6">10. REFERENCES </span></p><p class="c26"><span class="c0">[1] SPIRIT project. </span></p><p class="c53"><span class="c0">https://www.cs.cmu.edu/afs/cs/project/spirit-1/www/. Accessed: 2016-05-29. [2] G. E. A. P. A. Batista and M. C. Monard. An analysis of four missing data treatment methods for supervised learning. Applied Artificial Intelligence, 17(5-6), 2003. [3] A. Behrend and G. Sch&uuml;ller. A case study in optimizing </span></p><p class="c70"><span class="c0">continuous queries using the magic update technique. In SSDBM, pages 31:1&ndash;31:4, 2014. [4] G. E. P. Box and G. Jenkins. Time Series Analysis, </span></p><p class="c69"><span class="c0">Forecasting and Control. Holden-Day, Incorporated, 1990. [5] B. Chiu, E. Keogh, and S. Lonardi. Probabilistic discovery of </span></p><p class="c39"><span class="c0">time series motifs. In KDD, pages 493&ndash;498, 2003. [6] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast subsequence matching in time-series databases. SIGMOD Rec., 23(2):419&ndash;429, May 1994. [7] E. Keogh, K. Chakrabarti, M. Pazzani, and S. Mehrotra. </span></p><p class="c55"><span class="c0">Dimensionality reduction for fast similarity search in large </span></p><p class="c1 c56"><span class="c0">time series databases. Knowledge and information Systems, 3(3):263&ndash;286, 2001. [8] E. Keogh, J. Lin, and A. Fu. HOT SAX: Efficiently finding the most unusual time series subsequence. In ICDM, pages 226&ndash;233, 2005. [9] E. J. Keogh. Exact indexing of dynamic time warping. In </span></p><p class="c36 c52"><span class="c0">VLDB, 2002. [10] E. J. Keogh and T. Rakthanmanon. Fast shapelets: A scalable </span></p><p class="c60"><span class="c0">algorithm for discovering time series shapelets. In ICDM, pages 668&ndash;676, 2013. [11] M. Khayati and M. H. B&ouml;hlen. REBOM: recovery of blocks </span></p><p class="c65"><span class="c0">of missing values in time series. In COMAD, pages 44&ndash;55, 2012. [12] M. Khayati, M. H. B&ouml;hlen, and J. Gamper. Memory-efficient </span></p><p class="c74"><span class="c0">centroid decomposition for long time series. In ICDE, pages 100&ndash;111, 2014. [13] M. Khayati, P. Cudr&eacute;-Mauroux, and M. H. B&ouml;hlen. Using </span></p><p class="c36"><span class="c0">lowly correlated time series to recover missing values in time series: a comparison between SVD and CD. In SSTD, pages 237&ndash;254, 2015. [14] L. Li, J. McCann, N. S. Pollard, and C. Faloutsos. </span></p><p class="c35"><span class="c0">DynaMMo: Mining and summarization of coevolving sequences with missing values. In KDD, pages 507&ndash;516, 2009. [15] P. Merlin, A. Sorjamaa, B. Maillet, and A. Lendasse. X-SOM </span></p><p class="c51"><span class="c0">and L-SOM: A double classification approach for missing value imputation. Neurocomputing, 73(7-9):1103&ndash;1108, 2010. [16] S. Papadimitriou, J. Sun, and C. Faloutsos. Streaming pattern </span></p><p class="c49"><span class="c0">discovery in multiple time-series. In VLDB, pages 697&ndash;708, 2005. [17] S. Papadimitriou, J. Sun, C. Faloutsos, and P. S. Yu. </span></p><p class="c48"><span class="c0">Dimensionality reduction and filtering on time series sensor streams. In Managing and Mining Sensor Data, pages 103&ndash;141. 2013. [18] J. L. H. Paulhus and M. A. Kohler. Interpolation of Missing </span></p><p class="c32"><span class="c0">Precipitation Records. Monthly Weather Review, 80(8), Aug. 1952. [19] D. Rubin. Multiple Imputation after 18+ Years. Journal of the American Statistical Association, 91(434), 1996. [20] J. L. Schafer and J. W. Graham. Missing data: our view of the state of the art. Psychological Methods, 7, 2002. [21] J. Shieh and E. Keogh. iSAX: Indexing and mining terabyte </span></p><p class="c75"><span class="c0">sized time series. In KDD, pages 623&ndash;631, 2008. [22] A. Sorjamaa, P. Merlin, B. Maillet, and A. Lendasse. </span></p><p class="c45"><span class="c0">SOM+EOF for finding missing values. In ESANN, pages 115&ndash;120, 2007. [23] J. Sun, S. Papadimitriou, and C. Faloutsos. Online latent </span></p><p class="c67"><span class="c0">variable detection in sensor networks. In ICDE, pages 1126&ndash;1127, 2005. [24] O. G. Troyanskaya, M. N. Cantor, G. Sherlock, P. O. Brown, T. Hastie, R. Tibshirani, D. Botstein, and R. B. Altman. Missing value estimation methods for DNA microarrays. Bioinformatics, 17(6), 2001. [25] B. Yi, N. Sidiropoulos, T. Johnson, H. V. Jagadish, </span></p><p class="c30"><span class="c0">C. Faloutsos, and A. Biliris. Online data mining for co-evolving time sequences. In ICDE, pages 13&ndash;22, 2000. [26] C. Yozgatligil, S. Aslan, C. Iyigun, and I. Batmaz. </span></p><p class="c40"><span class="c0">Comparison of missing value imputation methods in time series: the case of turkish meteorological data. Theoretical and Applied Climatology, 112(1-2), 2013. </span></p><p class="c58"><span class="c17">341 </span></p></body></html>