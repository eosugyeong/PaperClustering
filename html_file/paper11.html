<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c70{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c37{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Arial";font-style:normal}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c148{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:14.3pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c54{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.7pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:9.1pt;font-family:"Arial";font-style:normal}.c68{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.2pt;font-family:"Arial";font-style:normal}.c34{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c87{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.4pt;font-family:"Arial";font-style:italic}.c10{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.4pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4pt;font-family:"Arial";font-style:normal}.c152{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c109{margin-left:-15pt;padding-top:1.7pt;text-indent:29.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.8pt}.c73{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.3pt;font-family:"Arial";font-style:normal}.c167{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.1pt;font-family:"Arial";font-style:normal}.c26{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:8.8pt;font-family:"Arial";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.4pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12.4pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.1pt;font-family:"Arial";font-style:normal}.c53{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c112{margin-left:-28.6pt;padding-top:1.4pt;text-indent:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.5pt}.c62{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c118{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:12.4pt;font-family:"Arial";font-style:normal}.c85{margin-left:-19.5pt;padding-top:1.7pt;text-indent:28.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.6pt}.c133{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:14.6pt;font-family:"Arial";font-style:normal}.c86{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c116{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c102{margin-left:-28.6pt;padding-top:1.7pt;text-indent:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.5pt}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.9pt;font-family:"Arial";font-style:normal}.c52{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12.8pt;font-family:"Arial";font-style:normal}.c80{margin-left:-28.6pt;padding-top:1.4pt;text-indent:47.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.5pt}.c99{margin-left:-19.5pt;padding-top:1.4pt;text-indent:28.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.3pt}.c126{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.9pt;font-family:"Arial";font-style:normal}.c72{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.9pt;font-family:"Arial";font-style:normal}.c120{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c69{margin-left:-28.6pt;padding-top:3.8pt;text-indent:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.5pt}.c32{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:8.6pt;font-family:"Arial";font-style:normal}.c83{margin-left:-19.5pt;padding-top:1.7pt;text-indent:28.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.3pt}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.8pt;font-family:"Arial";font-style:italic}.c57{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.6pt;font-family:"Arial";font-style:normal}.c138{margin-left:-28.6pt;padding-top:1.4pt;text-indent:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.3pt}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:5.2pt;font-family:"Arial";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.4pt;font-family:"Arial";font-style:normal}.c103{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:16.6pt;font-family:"Arial";font-style:normal}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c106{margin-left:-19.5pt;padding-top:1.4pt;text-indent:28.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.3pt}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.4pt;font-family:"Arial";font-style:normal}.c151{margin-left:-28.6pt;padding-top:1.7pt;text-indent:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.3pt}.c137{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c59{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:15.1pt;font-family:"Arial";font-style:normal}.c75{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.7pt;font-family:"Arial";font-style:normal}.c45{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:7.4pt;font-family:"Arial";font-style:normal}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c78{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:6.7pt;font-family:"Arial";font-style:normal}.c98{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.2pt;font-family:"Arial";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c74{margin-left:83.7pt;padding-top:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:34.6pt}.c108{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-9.9pt}.c84{margin-left:170.6pt;padding-top:168.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.1pt}.c27{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.6pt}.c49{margin-left:-28.6pt;padding-top:16.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.5pt}.c139{margin-left:-28.6pt;padding-top:19.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.5pt}.c51{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.8pt}.c154{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:5pt}.c117{margin-left:-0.8pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.5pt}.c158{margin-left:218.2pt;padding-top:567.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c129{margin-left:-15pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-20.2pt}.c145{margin-left:-2.4pt;padding-top:76.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:195.5pt}.c44{margin-left:-19.5pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:0.7pt}.c130{margin-left:-28.6pt;padding-top:16.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:32.1pt}.c111{margin-left:-19.5pt;padding-top:16.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:64.1pt}.c23{margin-left:-28.6pt;padding-top:15.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.3pt}.c115{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3pt}.c136{margin-left:170.6pt;padding-top:3.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-4.3pt}.c89{margin-left:-0.8pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.1pt}.c40{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:4.7pt}.c135{margin-left:-77.8pt;padding-top:117.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:195.8pt}.c155{margin-left:-28.6pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.1pt}.c0{margin-left:-7.9pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:195.5pt}.c97{margin-left:84.9pt;padding-top:82.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:32.9pt}.c159{margin-left:218.2pt;padding-top:31.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c157{margin-left:-76.6pt;padding-top:82.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:194.6pt}.c134{margin-left:-19.5pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:10.3pt}.c65{margin-left:-15pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:3.6pt}.c48{margin-left:218.2pt;padding-top:36.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c147{margin-left:36pt;padding-top:10.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:111.3pt}.c38{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-8.5pt}.c113{margin-left:177.4pt;padding-top:82.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-59.6pt}.c146{margin-left:-15pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.8pt}.c92{margin-left:85.1pt;padding-top:82.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:32.2pt}.c88{margin-left:84.2pt;padding-top:117.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:34.1pt}.c66{margin-left:-152pt;padding-top:6.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:318.2pt}.c144{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-2.7pt}.c95{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.3pt}.c153{margin-left:-15pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.9pt}.c71{margin-left:15.8pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:102.2pt}.c16{margin-left:-19.5pt;padding-top:16.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:115.4pt}.c67{margin-left:-15pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.6pt}.c90{margin-left:-5pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:195.5pt}.c94{margin-left:-152pt;padding-top:6.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:341pt}.c119{margin-left:-28.6pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:39.3pt}.c50{margin-left:-97.8pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:288.2pt}.c166{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-2.5pt}.c82{margin-left:-28.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1pt}.c121{margin-left:-77.8pt;padding-top:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:196.1pt}.c81{margin-left:-28.6pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:106pt}.c91{margin-left:14.6pt;padding-top:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:103.6pt}.c55{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-9.7pt}.c143{margin-left:-28.6pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11.4pt}.c123{margin-left:-28.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.4pt}.c104{margin-left:-15pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:20.2pt}.c42{margin-left:-19.5pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:3.8pt}.c160{margin-left:14.6pt;padding-top:117.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:103.6pt}.c124{margin-left:218.2pt;padding-top:37.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c18{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c60{padding-top:3.8pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c156{padding-top:3.6pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c105{padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c164{padding-top:6.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c56{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c96{padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c110{padding-top:17.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c125{padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c22{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c58{padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c128{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c149{margin-left:-19.5pt;text-indent:28.4pt;margin-right:-29.5pt}.c107{margin-left:-83.8pt;margin-right:176.4pt}.c141{margin-left:-259pt;margin-right:449.5pt}.c76{margin-left:94.2pt;margin-right:31.7pt}.c170{margin-left:-28.6pt;margin-right:-12.3pt}.c165{margin-left:-152pt;margin-right:341pt}.c100{margin-left:-11.8pt;margin-right:204.6pt}.c8{margin-left:170.8pt;margin-right:-9.4pt}.c131{margin-left:12.5pt;margin-right:87.8pt}.c6{margin-left:-104.2pt;margin-right:297.1pt}.c168{margin-left:84.2pt;margin-right:34.1pt}.c30{margin-left:9pt;margin-right:152.4pt}.c161{margin-left:-152.2pt;margin-right:318.5pt}.c132{margin-left:71.4pt;margin-right:8.6pt}.c162{margin-left:-19.5pt;margin-right:43.2pt}.c31{margin-left:9.5pt;margin-right:179.5pt}.c93{margin-left:-19.5pt;margin-right:-22.6pt}.c33{margin-left:-152pt;margin-right:313.4pt}.c150{margin-left:85.1pt;margin-right:32.2pt}.c15{margin-left:66.6pt;margin-right:126.7pt}.c63{margin-left:-259pt;margin-right:356.2pt}.c9{margin-left:170.8pt;margin-right:18pt}.c61{margin-left:-97.8pt;margin-right:288.2pt}.c142{margin-left:-15pt;margin-right:-22.3pt}.c20{margin-left:170.8pt;margin-right:-4.6pt}.c140{margin-left:84.9pt;margin-right:32.9pt}.c36{margin-left:9pt;margin-right:157.2pt}.c169{margin-left:-61.3pt;margin-right:199.2pt}.c64{margin-left:9.5pt;margin-right:152.2pt}.c13{margin-left:61.1pt;margin-right:126.7pt}.c47{margin-left:-152.2pt;margin-right:313.9pt}.c46{margin-left:-94.9pt;margin-right:288.2pt}.c79{margin-left:83.7pt;margin-right:34.6pt}.c101{margin-left:9.5pt;margin-right:156.7pt}.c11{margin-left:57pt;margin-right:135.8pt}.c122{margin-left:-19.5pt;margin-right:-22.3pt}.c127{margin-left:170.6pt;margin-right:-9.1pt}.c163{margin-left:-19.5pt;margin-right:-19.2pt}.c77{margin-left:-100.4pt;margin-right:288.2pt}.c114{margin-left:156.2pt;margin-right:34.2pt}.c14{margin-left:63.8pt;margin-right:126.7pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c128"><p class="c56"><span class="c62">Efficient evaluation of threshold queries of derived fields in a numerical simulation database </span></p><p class="c4"><span class="c34">Kalin Kanov </span><span class="c35">Department of Computer Science IDIES Johns Hopkins University Baltimore, </span><span class="c120">kalin@cs.jhu.edu </span></p><p class="c4"><span class="c35">MD 21218 </span><span class="c34">Randal Burns </span><span class="c35">Department of Computer Science IDIES Johns Hopkins University </span><span class="c120">randal@cs.jhu.edu </span></p><p class="c4"><span class="c35">Baltimore, MD 21218 </span><span class="c34">Cristian C. Lalescu </span><span class="c35">Department of Applied Mathematics and Statistics IDIES Johns Hopkins University </span><span class="c120">clalesc1@jhu.edu </span><span class="c35">Baltimore, MD 21218 </span><span class="c34">ABSTRACT </span><span class="c1">In this paper, we present a method for the efficient eval- uation of threshold queries of derived fields for large nu- merical simulation datasets stored in a cluster of relational databases. The datasets produced by these simulations are in the TB and even PB ranges. Data-intensive computa- tions that examine entire time-steps of the simulation data are impractical to perform locally by the user, taking days or months to iterate over the entire dataset. The inte- grated method for the evaluation of threshold queries that we have developed achieves scalability through data-parallel execution of the computations on the nodes of an analysis database cluster. We extend the scientific analysis environ- ment with the introduction of an application-aware cache for query results, building on the concept of semantic caching. The cache has little overhead and improves query perfor- mance by over an order of magnitude for queries that hit the cache. Caching the results of threshold queries preserves both the I/O and computation effort used to obtain them. In the case of computational turbulence, this allows scientists to quickly focus on the most intense events and interesting regions in any time-step or the dataset as a whole, which greatly speeds up the rate of scientific exploration and dis- covery. </span></p><p class="c4"><span class="c34">Categories and Subject Descriptors </span><span class="c1">H.2.8 [Database Management]: Database Applications &ndash; Scientific Databases; H.2.4 [Database Management]: Systems &ndash; Distributed Databases; J.2 [Computer Appli- cations]: Physical Sciences and Engineering &ndash; Physics </span></p><p class="c4"><span class="c34">Keywords </span><span class="c1">scientific databases, data-intensive computing, threshold queries, turbulence </span></p><p class="c22"><span class="c1">c </span><span class="c152">2015, Copyright is with the authors. Published in Proc. 18th Inter- national Conference on Extending Database Technology (EDBT), March 23-27, 2015, Brussels, Belgium: ISBN 978-3-89318-067-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c4"><span class="c34">1. INTRODUCTION </span></p><p class="c22"><span class="c1">Better instruments, faster and bigger supercomputers and easier collaboration and sharing of data in the sciences have introduced the need to manage increasingly large datasets. Data-intensive systems and architectures have been devel- oped with the goal of storing and providing fast access to such datasets. Examples of such analysis environments in- clude the GrayWulf and Data-Scope clusters [31, 10] at Johns Hopkins, which have capacity of 1.1PB and 11PB respec- tively. One of their missions is to provide persistent storage and public access to world-class numerical simulation data. These systems differ from the traditional HPC environments in that they aim to achieve high aggregate throughput by balancing computation capabilities with I/O and network bandwidth. The computing systems and services developed on top of these platforms are more than pure storage engines and usually have complex analysis routines built-in, which has largely been driven by the &ldquo;move the computation to the data&rdquo; paradigm [14]. These built-in analysis routines are most often not novel themselves. They implement core scientific functionality for the study of the particular scien- tific phenomena, which was observed or simulated in the first place. The analysis routines however require novel evalua- tion strategies and methods for their execution. They have to operate on large array datasets distributed across multiple nodes of a cluster of relational databases. In order to reduce their running times, they have to make efficient use of the cluster resources and incorporate leading data management techniques. </span></p><p class="c22"><span class="c1">Finding the locations or regions of highest vorticity or those with the largest norms of the velocity or other fields of interest enables new insights in the study of fluid dynam- ics. Analysis of this kind coupled with the ability to ana- lyze time-series datasets both forward and backward in time has transformed our understanding of turbulence [12]. Fur- thermore, threshold, top-k queries and similarity search in general are important in many different disciplines. We in- troduce an efficient evaluation strategy for threshold queries over time-series datasets stored in a cluster of relational databases. Our method evaluates not only threshold queries of the vector or scalar field data stored in the database, but also performs thresholding of derived fields. </span></p><p class="c22"><span class="c1">The main challenge that our approach tackles is that the data-intensive computation of derived fields has to be car- ried out on-demand for extremely large array datasets stored in an analysis cluster environment comprised of multiple </span></p><p class="c4"><span class="c28">301 10.5441/002/edbt.2015.27 </span></p><p class="c22"><span class="c1">database nodes. We focus on the evaluation of threshold queries of fields derived from the data stored in the cluster as these queries are the most interesting scientifically. How- ever, our approach applies to the evaluation of top-k queries, rollup queries and data-reducing queries in general. The es- tablished data management techniques that our approach combines make the approach easy to understand. It can be applied to other scientific analysis environments, which manage large datasets in a database management system. Examples include the Sloan Digital Sky Survey [28], the Mil- lennium Simulation [23] and the Open Connectome Project [6].</span><span class="c24">Evaluating threshold queries within the database cluster </span><span class="c1">allows scientists with modest computational and network capability to narrow down on and examine some of the most interesting regions and features in the dataset and focus on the subsequent analysis needed to understand these events. It is impractical to materialize all possible derived fields and store them alongside the raw data due to the large size of the datasets and the limits of available storage. Obtaining the derived field and thresholding locally by the user requires not only the computation of the derived field over an entire time-step server-side but also the transfer of a large amount of data over the network, most of which are subsequently discarded. One of our collaborators reported that such a local evaluation of a threshold query over an entire time-step took over 20 hours. It would take months to iterate over the entire dataset. This highlighted the need for providing the capability through an integrated approach, which performs the evaluation server-side. </span></p><p class="c22"><span class="c1">Database, operating and file system caches are effective at speeding up access to the large amounts of data stored on disk. However, this might not be sufficient for some applica- tions, because these application-independent caches cannot exploit dataset-specific structure and application-level infor- mation [20]. Moreover, even if the data are available in one or more of these application-independent caches the com- putation associated with the derived field still needs to be performed for each point on the grid, because results of pre- vious computations are not cached. We will demonstrate that an integrated approach, which computes the derived fields on-demand in a data-parallel manner, performs the evaluation over an entire time-step in a few minutes. Stor- ing the query results in an application-aware semantic cache further reduces the running times to several seconds. </span></p><p class="c22"><span class="c1">Thresholding allows scientists to obtain and examine the regions containing the most intense events and features in the dataset in the case of turbulence. These are often the locations that have the largest vorticity norms and have in- tense vortices or reconnection events. In magnetohydrody- namics, the locations of largest electric current are of great interest for similar reasons. It is important that threshold queries are evaluated in an efficient manner, because often further subsequent examination and analysis is required to understand the physics that drive these intense events. </span></p><p class="c22"><span class="c1">There are several challenges that arise during the eval- uation of threshold queries of derived fields in an analysis database cluster. The field variables have to be evaluated on-demand from the array data stored in the database clus- ter. The evaluations are data-intensive as they perform ker- nel computations on extremely large multidimensional ar- ray datasets. A kernel computation computes the value at a grid location using the data points at a set of neighbor- </span></p><p class="c4"><span class="c3">Client program 1 </span><span class="c39">K </span><span class="c3">Client program </span><span class="c87">K </span><span class="c3">Web-server / mediator </span><span class="c126">Asynchronous query </span></p><p class="c4"><span class="c3">scheduling </span></p><p class="c4"><span class="c21">0 1 8 </span></p><p class="c56"><span class="c3">Web-services (SOAP) </span></p><p class="c4"><span class="c43">DB</span><span class="c68">1 </span></p><p class="c4"><span class="c43">DB</span><span class="c68">N </span></p><p class="c4"><span class="c25">Data </span></p><p class="c4"><span class="c54">Computational module: </span></p><p class="c4"><span class="c54">Computational module: </span></p><p class="c4"><span class="c54">&#9679; Stored procedures </span></p><p class="c4"><span class="c54">&#9679; UDFs </span></p><p class="c4"><span class="c25">Data </span></p><p class="c4"><span class="c54">&#9679; Stored procedures </span></p><p class="c4"><span class="c54">&#9679; UDFs </span><span class="c21">4 4 4 5 5 5 12 </span></p><p class="c4"><span class="c21">12 </span></p><p class="c4"><span class="c21">12 </span></p><p class="c4"><span class="c78">12 </span></p><p class="c4"><span class="c78">12 </span></p><p class="c4"><span class="c78">12 </span></p><p class="c4"><span class="c25">N </span></p><p class="c4"><span class="c17">0 </span><span class="c21">0 0 </span><span class="c17">1 </span><span class="c21">1 1 </span><span class="c17">8 </span></p><p class="c4"><span class="c21">8 </span></p><p class="c4"><span class="c21">8 </span></p><p class="c4"><span class="c21">8884 </span><span class="c17">36 </span><span class="c21">4 </span><span class="c17">32 </span><span class="c21">0 4 0 </span><span class="c17">37 </span><span class="c21">5 </span><span class="c17">33 </span><span class="c21">1 5 1 5 </span><span class="c17">44 </span><span class="c21">12 </span></p><p class="c4"><span class="c17">40 </span><span class="c21">8 </span></p><p class="c4"><span class="c21">12 </span></p><p class="c4"><span class="c21">8 </span></p><p class="c4"><span class="c21">12 </span></p><p class="c4"><span class="c73">45 </span></p><p class="c18"><span class="c78">12 </span><span class="c17">41</span><span class="c21">8</span><span class="c78">12 </span><span class="c21">8</span><span class="c78">12 </span><span class="c21">8</span><span class="c1">Figure 1: Architecture of the JHTDB. </span></p><p class="c22"><span class="c1">ing locations. Kernel computations have to be performed at each location on the grid as opposed to at a particular number of target locations. The evaluation needs to be dis- tributed across the nodes of the database cluster to avoid the unnecessary movement of data over the network and to achieve scalability. Techniques that target the traditional supercomputing environments do not translate directly to the distributed database setting of an analysis cluster envi- ronment. </span></p><p class="c22"><span class="c1">We present a method for the efficient evaluation of thresh- old queries over fields derived from the raw vector or scalar fields of the numerical simulation stored in the database. Our method makes effective use of the cluster resources and achieves high throughput and scalability. We exploit the parallelism available in the cluster by means of data-parallel execution of the computations. We extend the database management system with an application-aware cache for query results. We build on the idea of an application-aware cache introduced by Lopez et al. [20] and more broadly on the concept of semantic caching [9]. Rather than caching just data as is the case in system caches and the tree-cache described by Lopez et al., we cache query results along with query metadata and subsequent queries are evaluated against the cache. This leads to query performance improve- ment of over an order of magnitude. </span></p><p class="c4"><span class="c1">The contributions of this paper are the following: </span></p><p class="c22"><span class="c86">&bull; </span><span class="c1">Computing derived fields of large simulation data on- demand and evaluating threshold queries on them at extreme scale. This provides large data analytics ca- pabilities that examine entire time-steps of the simula- tion transparently to the user in a production analysis environment. </span></p><p class="c22"><span class="c86">&bull; </span><span class="c1">Achieving this through the combination of existing data management techniques such as data parallelism and semantic caching as well as taking advantage of heterogeneous scientific cluster architectures (sharded relational DBMS with several SSDs per node). </span></p><p class="c4"><span class="c86">&bull; </span><span class="c1">Evaluating the proposed method on data-intensive work- loads in a live production environment and showing scalability results on datasets hundreds of terabytes in size. </span></p><p class="c4"><span class="c28">302 </span></p><p class="c4"><span class="c17">4 5 12 </span></p><p class="c4"><span class="c73">13 </span><span class="c21">0 1 8 </span></p><p class="c4"><span class="c17">9</span></p><p class="c4"><span class="c43">1.00E+09&amp; </span></p><p class="c4"><span class="c43">PDF&amp;of&amp;Vor9city&amp; </span></p><p class="c4"><span class="c118">&#39; stniop&#39;fo&#39;rebmu</span><span class="c45">N</span><span class="c43">1.00E+07&amp; 1.00E+05&amp; </span></p><p class="c4"><span class="c43">1.00E+03&amp; </span></p><p class="c4"><span class="c43">1.00E+01&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">0,10)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">10,20)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">20,30)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">30,40)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">40,50)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">50,60)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">60,70)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">70,80)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">80,90)&amp; </span></p><p class="c4"><span class="c43">[</span><span class="c41">90,..)&amp; </span></p><p class="c4"><span class="c45">Vor0city&#39;norm&#39; </span></p><p class="c22"><span class="c1">Figure 2: Probability density function of the norm of the vorticity field for a representative time-step for the MHD dataset. </span></p><p class="c4"><span class="c34">2. JOHNS HOPKINS TURBULENCE </span></p><p class="c4"><span class="c34">DATABASES </span><span class="c1">Data-intensive architectures and compute clusters built from commodity hardware rely on parallel I/O to multiple disks and high network bandwidth to achieve high through- put. Such systems have only recently been deployed for the storage of large numerical simulation datasets. The virtual laboratories built on these systems make use of relational database system technology to store and manage large ar- ray datasets. Relational database systems however often do not support all of the functionality that scientists are inter- ested in out of the box. It is either up to the user to develop more sophisticated analysis routines locally or such capabil- ities have to be built into the database through user-defined functions or stored procedures. </span></p><p class="c4"><span class="c1">The method that we have developed for the evaluation of threshold queries of derived fields was deployed and inte- grated into the Johns Hopkins Turbulence Databases (JHTDB) [19, 26]. It solves a pressing problem in a production scien- tific analysis environment, which differs from the traditional supercomputing environments and provides large data ana- lytics capabilities transparently to the public. The JHTDB, built on top of the GrayWulf and Data-Scope clusters, serves as a public virtual laboratory for the study of turbulent phe- nomena. The JHTDB stores several datasets, which are the output of high-resolution numerical simulations of turbu- lence. The 3d time-series data are partitioned into small sub- cubes and stored in relational databases distributed across the nodes of the cluster. Access to the data is provided by means of Web-services and a variety of analysis func- tions have been implemented and can be executed through Web-service calls (Fig. 1). At present the service hosts four datasets, which are available publicly. The data are the output of numerical simulations of forced isotropic tur- bulence, magnetohydrodynamics (MHD), channel flow tur- bulence and homogenous buoyancy driven turbulence. The total amount of space occupied by the datasets is over 230 TB.</span><span class="c24">The database nodes are part of the GrayWulf [31] and </span><span class="c1">Data-Scope [10] clusters. Each node is running Windows Server 2008 and SQL Server 2008 R2. The data for each dataset reside on a regular three-dimensional spatial grid with the exception of the channel flow data, which has an </span></p><p class="c22"><span class="c1">irregular y dimension. The data are partitioned spatially across 4 to 8 database nodes, and each database node hosts one or more databases. We use the Morton z-order space- filling curve to distribute the data across nodes and databases [26]. Each time-step is spatially subdivided into database atoms, which are of size 8</span><span class="c19">3</span><span class="c1">. Each such atom is indexed by the time-step, which it belongs to and by the Morton code of it&rsquo;s lower left corner. This combination of index and data forms a record in the database. Queries to the data and derived fields, such as derivatives and filtered quanti- ties are evaluated through stored procedures or user-defined functions implemented in the Common Language Runtime (CLR) framework. </span></p><p class="c22"><span class="c1">The Web-services are hosted on a front-end Web-server, which handles user requests and hosts the main Web-page portal. The Web-server acts as a mediator sending the users&rsquo; requests to the database nodes and initiating their dis- tributed evaluation. Each request is broken down into mul- tiple parts based on the spatial layout of the data. Each part is asynchronously submitted for evaluation to the database which stores the data needed for the evaluation. The Web- server assembles the results from the distributed computa- tion and sends them back to the client. </span></p><p class="c22"><span class="c1">The JHTDB provides a variety of data-intensive analysis routines that are executed on the database nodes. These include interpolation, differentiation, particle tracking and spatial filtering. These tasks are often data-intensive and in order to leverage the capabilities of the cluster we have developed data-driven batch processing techniques for their evaluation [17, 16]. Most of these tasks usually operate on subsets of the space or a collection of individual target loca- tions within a time-step. </span></p><p class="c22"><span class="c1">In contrast, threshold and top-k queries usually have to examine the entire data volume of a time-step or a significa- tion portion of it. Furthermore, the data product of thresh- old queries is much smaller in relation to the amount of data that need to be examined. This fact combined with the fact that subsequent queries can reuse previously computed re- sults makes the query results suitable to caching. </span></p><p class="c4"><span class="c34">3. SCIENTIFIC USE CASES </span></p><p class="c22"><span class="c1">One of the applications of thresholding in turbulence is to find the locations of maximum vorticity in a particular time-step or the dataset as a whole. The locations of maxi- mum vorticity are usually associated with the most intense vortices in the dataset and often have interesting and com- plex reconnection events associated with them. Once ob- tained from the service, these locations can be clustered in both 3d and 4d. This allows scientists to examine their evo- lution with the flow and make subsequent analysis queries as needed in order to study these events. The relationship between different &ldquo;worms&rdquo; (see Figure 3) that connect and reconnect at those locations is of the most interest. </span></p><p class="c4"><span class="c1">The vorticity is computed from the velocity field by taking its curl:</span><span class="c24">d! = r </span><span class="c1">d</span><span class="c24">&#8677; dv = </span></p><p class="c4"><span class="c1">&#10003; </span><span class="c24">&part;&part;x</span><span class="c1">, &part;y</span><span class="c53">&part;, </span><span class="c1">&part;z </span></p><p class="c4"><span class="c53">&part;</span><span class="c1">&#9670; </span></p><p class="c4"><span class="c1">&#8677; (v</span><span class="c25">x</span><span class="c1">,v</span><span class="c25">y</span><span class="c1">,v</span><span class="c25">z</span><span class="c1">) </span></p><p class="c4"><span class="c1">= </span></p><p class="c4"><span class="c1">&#10003;</span><span class="c24">&part;v</span><span class="c70">z </span><span class="c1">&part;y </span></p><p class="c4"><span class="c1">&#9670; </span></p><p class="c4"><span class="c1">. (1) </span></p><p class="c4"><span class="c1">We use finite differencing methods of different orders for the evaluation of the curl. For example, with 4th-order centered </span></p><p class="c4"><span class="c28">303 </span></p><p class="c56"><span class="c1">&part;v</span><span class="c25">y </span><span class="c1">&part;z </span><span class="c53">, &part;v</span><span class="c19">x </span><span class="c1">&part;z </span></p><p class="c56"><span class="c1">&part;v</span><span class="c25">z </span><span class="c1">&part;x </span><span class="c53">, &part;v</span><span class="c19">y </span><span class="c1">&part;x </span></p><p class="c56"><span class="c1">&part;v</span><span class="c25">x </span><span class="c1">&part;y </span></p><p class="c4"><span class="c116">z </span><span class="c103">1.6 </span></p><p class="c4"><span class="c103">1.51.41.31.2</span><span class="c116">1.12.2 </span><span class="c35">2.4 2.6 2.8 3.0 </span><span class="c116">x </span></p><p class="c4"><span class="c35">3.2 3.4 3.6 3.8 4.0 </span></p><p class="c4"><span class="c116">3.8 </span><span class="c103">4.0 4.2 4.4 4.6 </span><span class="c116">y </span></p><p class="c4"><span class="c1">Figure 3: 3D (single time-step) cut through the 4D cluster containing the most intense event. </span></p><p class="c4"><span class="c1">finite differencing each partial derivative is evaluated from the 4 adjacent grid node values as follows: </span></p><p class="c4"><span class="c1">df</span><span class="c24">dx </span><span class="c70">x</span><span class="c137">n </span></p><p class="c4"><span class="c103">4.8 5.0 5.2 </span></p><p class="c4"><span class="c1">topology of the flow and the rates of vortex stretching and rotation. In MHD, finding the locations with largest val- </span></p><p class="c4"><span class="c1">= 3&#8710;x</span><span class="c53">2 </span></p><p class="c4"><span class="c53">[f(x</span><span class="c19">n+1</span><span class="c53">) f(x</span><span class="c19">n 1</span><span class="c53">)] </span></p><p class="c4"><span class="c1">ues for the electric current can lead to new insights into the development of the most intense reconnection events of magnetic field sheets in the simulated plasma. Similarly to 1 12&#8710;x</span><span class="c53">[f(x</span><span class="c25">n+2</span><span class="c1">) f(x</span><span class="c70">n 2</span><span class="c24">)], (2) </span></p><p class="c18"><span class="c1">the vorticity, the electric current is derived from the mag- netic field by taking its curl. The list of fields of interest, on which scientists would like to perform threshold queries where f denotes any one of the three components of the </span></p><p class="c4"><span class="c1">certainly does not stop here and is indicative of how valu- velocity and &#8710;x is the width of the grid in the x direction. </span></p><p class="c4"><span class="c1">able this functionality is in the study of turbulence and fluid The partial derivatives along y and z are computed in the </span></p><p class="c4"><span class="c1">dynamics. same fashion. Figure 2 shows the distribution of the values of the norm of the vorticity field in the MHD dataset for a representative time-step. This is indicative of how the values </span></p><p class="c4"><span class="c34">4. THRESHOLD QUERY EVALUATION </span><span class="c1">are distributed in the dataset as a whole. This coarse view </span></p><p class="c4"><span class="c1">Threshold queries of derived fields submitted to the JHTDB of the data can be used by scientists to guide the selection </span></p><p class="c4"><span class="c1">are evaluated using a data-parallel execution strategy and of threshold values. </span></p><p class="c4"><span class="c1">the query results are cached in an application-aware seman- Figure 3 shows the most intense event observed in the </span></p><p class="c4"><span class="c1">tic cache. In addition to query results, the cache stores their forced isotropic turbulence dataset. The locations of maxi- </span></p><p class="c4"><span class="c1">semantic descriptions and query metadata and parameters mum vorticity in the dataset were clustered in this case in </span></p><p class="c4"><span class="c1">used to obtain them. The evaluation strategy for queries 4d using a friends-of-friends algorithm. It is interesting to </span></p><p class="c4"><span class="c1">that do not hit the cache is driven by the spatial partition- note that the cluster containing the most intense event in </span></p><p class="c4"><span class="c1">ing of the data across the nodes of the cluster. the entire dataset develops from nothing (i.e. it does not </span></p><p class="c4"><span class="c1">Derived fields computation: The databases store only appear in the first few time-steps) and it takes less than the </span></p><p class="c4"><span class="c1">the raw field data from the simulation (e.g. velocity, pres- timespan stored in the database for it to develop. Figure </span></p><p class="c4"><span class="c1">sure, magnetic field etc.). However, the threshold queries of 3 also shows that most interactions between worms are not </span></p><p class="c4"><span class="c1">most interest to science users produce all locations where the simple. There are several worms interacting in a complex </span></p><p class="c4"><span class="c1">values of a derived field are above a given threshold. Thus, way at the same time. Similar type of analysis and the fact </span></p><p class="c4"><span class="c1">the derived field in question has to be computed from the that the entire time history of the simulation is available </span></p><p class="c4"><span class="c1">raw data first. For most derived fields of interest, this com- in a database cluster, which provides built-in sophisticated </span></p><p class="c4"><span class="c1">putation has local support. It has an associated localized analysis routines revealed flux-freezing breakdown in MHD </span></p><p class="c4"><span class="c1">kernel of computation around each grid node. Therefore, turbulence [12], showing why solar flares last minutes rather </span></p><p class="c4"><span class="c1">the value of the derived field at each grid node depends on than the millions of years that conventional theory would </span></p><p class="c4"><span class="c1">the value of the stored field at all of the grid locations, which predict. </span></p><p class="c4"><span class="c1">are part of the kernel of computation. In addition to obtaining the regions of largest vorticity, </span></p><p class="c4"><span class="c1">Distributed data-parallel execution: In most cases there is substantial interest in studying the regions with </span></p><p class="c4"><span class="c1">threshold queries operate over an entire time-step. Each highest values for other fields, such as the second and third </span></p><p class="c4"><span class="c1">such query is subdivided by the mediator into queries sub- velocity gradient invariants (Q and R). These invariants are </span></p><p class="c4"><span class="c1">mitted to each of the database nodes. Each node evaluates scalar quantities whose values contain information about the </span></p><p class="c4"><span class="c1">the query over the data that it has stored locally. Only a </span></p><p class="c4"><span class="c28">304 </span></p><p class="c22"><span class="c1">Figure 4: Points with values above 7 times the root mean square value of the vorticity for a single time- step. </span></p><p class="c22"><span class="c1">small amount of data along the boundary need to be re- quested from adjacent nodes. The size of the band of data that may not be available locally is equal to a kernel half- width. Such a band is needed on each of the sides of the box forming the domain of the computation. The data are read into memory and the particular field requested is com- puted at each of the locations on the grid. The same strat- egy applies when utilizing multiple processes per node. The norm or absolute value of the derived field at each location is compared against the specified threshold and if the value is higher, it is maintained along with the spatial coordinates of the location in a list. </span></p><p class="c22"><span class="c1">We impose a limit on the maximum number of locations that can be returned as a result of a threshold query in order to prevent having to return the entire time-step or a significant fraction of it for queries with thresholds that are set too low. Currently this limit is set conservatively to 10</span><span class="c19">6 </span><span class="c1">locations, which is sufficient to examine a time-step in detail. In the case of the vorticity, the values above 8 times the root mean square value, which is about 25% of the maximum, are contained within 2.6&#8677;10</span><span class="c19">5 </span><span class="c1">points in each time-step. Figure 4 shows all the points in a single time-step with values above 7 times the root mean square value. There are 2.4&#8677;10</span><span class="c19">5 </span><span class="c1">points in the figure. Given that we are interested in extreme events, obtaining the locations with values even within 50% of the maximum would be sufficient. At the same time this also limits the amount of data that have to be returned to the user over the network as well as the amount of data that have to be cached. Users receive an error message notifying them if their request has a threshold that is set too low. If a user is interested in obtaining more data he or she can request the values of the derived field directly. Alternatively, if they are interested in the density distribution of values they can examine the probability density function (e.g. Fig. 2), which is computed using a similar strategy to threshold queries. </span></p><p class="c4"><span class="c3">Web-server mediator / </span></p><p class="c56"><span class="c29">Asynchronous query </span><span class="c3">scheduling </span></p><p class="c4"><span class="c43">DB</span><span class="c68">1 </span><span class="c54">Computational </span></p><p class="c4"><span class="c54">module: </span></p><p class="c4"><span class="c54">&#9679; GetThreshold </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">P </span></p><p class="c4"><span class="c43">DB</span><span class="c68">N </span><span class="c54">Computational </span></p><p class="c4"><span class="c54">module: </span></p><p class="c4"><span class="c54">&#9679; GetThreshold </span></p><p class="c4"><span class="c3">Local cache tables </span><span class="c29">Data tables </span></p><p class="c4"><span class="c54">SSD</span><span class="c2">1 </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">P </span></p><p class="c22"><span class="c1">Figure 5: Distributed evaluation of threshold queries and architecture of the application-aware cache. Each database node has local cache tables, which reside on solid-state drives attached to the node. </span></p><p class="c22"><span class="c1">Application-aware cache for query results: A cen- tral part of the evaluation strategy for threshold queries that we have developed is the introduction of an application- aware cache for query results (Fig. 5). The results of these queries are small compared to the amount of data that need to be examined and the results can be used to answer subse- quent queries as long as they are within the same region and specify the same or higher threshold. Each database node has a local cache. Cache entries are indexed by the field, time-step, spatial region and the threshold requested. We use a least recently used cache replacement policy. All mod- ifications of and queries to the cache are executed within a transaction with snapshot isolation level to avoid dirty-reads or an inconsistent view of the cache. </span></p><p class="c22"><span class="c1">Caching the query results preserves the computational ef- fort in addition to substantially reducing I/O. The cached data are for the particular derived field that was queried and not the raw data of the simulation fields. Thus, we do not have to derive the requested field from the raw data for queries that hit the cache. This results in a substantial im- provement in query performance as we only have to scan a small set of data and do not need to perform any additional computation. </span></p><p class="c22"><span class="c1">Not all query results are suitable to caching. Most of the queries submitted to the JHTDB other than thresh- old queries request data at a collection of target locations. Given that there are 1024</span><span class="c19">4 </span><span class="c1">possible locations for three of the datasets and 6&#8676;1024</span><span class="c19">4 </span><span class="c1">locations for the channel-flow dataset the chance of reuse for the results of these queries is ex- tremely small. This is why the cache currently stores only the results of threshold queries. Nevertheless, it can easily be extended to cache the results of other query types as well if that becomes advantageous. </span></p><p class="c22"><span class="c1">The cached query results are stored in a table in the database and the overall size of the cache is limited by the amount of available SSD disk space, not memory. Given a limit of &#8672;10</span><span class="c19">6 </span><span class="c1">points per time-step for a threshold query, the space required to cache the maximum number of points in- </span></p><p class="c4"><span class="c28">305 </span></p><p class="c4"><span class="c3">Local cache tables </span><span class="c29">Data tables </span></p><p class="c4"><span class="c54">SSD</span><span class="c2">1 </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">1 </span></p><p class="c4"><span class="c25">N </span></p><p class="c4"><span class="c54">SSD</span><span class="c2">S </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">1 </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">2 </span></p><p class="c4"><span class="c54">SSD</span><span class="c2">S </span></p><p class="c4"><span class="c54">HDD</span><span class="c2">2 </span></p><p class="c4"><span class="c1">threshold cluding the index space and database overhead is &#8672;40MB. </span></p><p class="c4"><span class="c1">value used. The cacheData table stores the loca- Therefore for a dataset containing 1024 time-steps, as is the </span></p><p class="c4"><span class="c1">tions of all of the grid points, for which the field queried case for the isotropic turbulence and MHD datasets part of </span></p><p class="c4"><span class="c1">has a norm higher than the specified threshold. The cache- the JHTDB, a cache size of 40GB is sufficient to cache the </span></p><p class="c4"><span class="c1">Data table is foreign key constrained with the ordinal of the query results for threshold queries of a derived field over </span></p><p class="c4"><span class="c1">cacheInfo table. This allows us to quickly find a record in the the entire dataset. The currently available SSD disk space </span></p><p class="c4"><span class="c1">cacheInfo table and retrieve all of the cached entries using per node is &#8672;200GB, which will be sufficient to maintain </span></p><p class="c4"><span class="c1">an index lookup. the threshold results for nearly five derived fields over the </span></p><p class="c4"><span class="c1">Overall execution of threshold queries: Algorithm 1 entire dataset. In contrast, computing and materializing </span></p><p class="c4"><span class="c1">illustrates the process of obtaining all points with norms a scalar derived field for the entire dataset would require </span></p><p class="c4"><span class="c1">of the specified field above the given threshold from the &#8672;5TB (15TB for vector fields). </span></p><p class="c18"><span class="c1">database in the presence of a cache. The mediator sub- mits a query to each of the database nodes storing the raw Algorithm 1 Get points above threshold using cache </span></p><p class="c4"><span class="c1">data asynchronously. Each node begins evaluation of the Require: Dataset d, Field f, Timestep t, Threshold k, </span></p><p class="c4"><span class="c1">Query box q = [x</span><span class="c70">l</span><span class="c24">,y</span><span class="c70">l</span><span class="c24">,z</span><span class="c70">l</span><span class="c24">,x</span><span class="c70">u</span><span class="c24">,y</span><span class="c70">u</span><span class="c24">,z</span><span class="c70">u</span><span class="c24">] </span><span class="c1">1: procedure GetThreshold 2: points List() 3: updateCache false 4: query SELECT * FROM cachedb..cacheInfo </span></p><p class="c4"><span class="c1">WHERE dataset = d AND field = f AND timestep = t 5: command SqlCommand(query) 6: reader command.ExecuteReader() 7: if reader.HasRows() then 8: k</span><span class="c70">s </span><span class="c24">reader[&ldquo;threshold&rdquo;] &gt; Stored threshold </span><span class="c1">9: start reader[&ldquo;startIndex&rdquo;] 10: end reader[&ldquo;endIndex&rdquo;] 11: ordinal reader[&ldquo;ordinal&rdquo;] 12: if k k</span><span class="c70">s </span><span class="c24">&amp; q 2 [start, end] then </span><span class="c1">13: query SELECT * FROM cachedb..cacheData </span></p><p class="c4"><span class="c1">WHERE cacheInfoOrdinal = ordinal 14: command SqlCommand(query) 15: reader command.ExecuteReader() 16: while reader.Read() do 17: location reader[&ldquo;zindex&rdquo;] 18: norm reader[&ldquo;dataV alue&rdquo;] 19: if norm k &amp; location 2 q then 20: points.Add(new Point(location, norm)) 21: end if </span></p><p class="c4"><span class="c1">query by executing Algorithm 1. First a cache lookup is performed. If the data for the requested field, time-step and spatial region are available in the cache and if the spec- ified threshold is higher than the one stored in the cache the query can be answered from there. The records are re- trieved from the cache and the ones that have a higher value are returned to the mediator and subsequently back to the user. If the data stored in the cache have a higher thresh- old than the one requested the cache needs to be updated. Similarly, if the cache does not have an entry for the spec- ified parameters the query needs to be evaluated from the raw data. In those cases the raw data are read into mem- ory with data along the boundary requested from adjacent nodes as needed. The specified field is derived at each loca- tion on the grid and the norm or absolute value of the field is compared against the threshold. The locations where the values are higher than the threshold need to then be stored in the cache. If the cache does not have enough space for the new records, space is freed up by removing the least recently used data across all quantities. Reading from, up- dating or modifying the cache is done within a transaction with snapshot isolation level. Snapshot isolation allows us to avoid locking the tables that serve as the cache for each transaction. This provides for a higher degree of parallelism and avoids any potential deadlocks from queries running in parallel. 22: end while 23: else </span></p><p class="c4"><span class="c34">5. EXPERIMENTAL RESULTS </span><span class="c1">24: updateCache true 25: end if 26: else 27: updateCache true 28: end if 29: if updateCache then 30: Retrieve data covering q from DB. 31: for all p 2 q do 32: Compute f at p. 33: if kf(p)k k then 34: points.Add(new Point(p, kf(p)k)) </span></p><p class="c4"><span class="c1">We evaluate the developed method for the execution of threshold queries to large numerical simulation datasets with the goal of analyzing the benefits and overhead from the introduction of the application-aware cache. We also analyze the scaling properties of the method. Finally, we show that an integrated method that performs the evaluation on the database nodes near the data is several orders of magnitude faster than the user requesting the derived filed of interest from the database and evaluating the threshold locally. </span><span class="c34">5.1 Experimental Setup </span><span class="c1">35: end if 36: end for 37: Update cacheInfo and cacheData tables. 38: end if 39: return points 40: end procedure </span></p><p class="c18"><span class="c1">The experiments were run on the production database nodes of the JHTDB through a development Web-server hosting the Web-services. We used the MHD dataset (Sec. 2) for the experimental runs. This dataset is partitioned across 4 database nodes according to spatial regions in the Morton z-order. The database nodes are 2.66 GHz dual quad-core Windows 2008 servers with SQL Server 2008 R2 The entire cache is comprised of two database tables. The </span></p><p class="c4"><span class="c1">and 24 GB of memory. Each node has 24 2TB SATA disks cacheInfo table stores metadata for the cached entries. It </span></p><p class="c4"><span class="c1">arranged as a set of four RAID-5 arrays. The database files stores information about the dataset, field, time-step, start </span></p><p class="c4"><span class="c1">are striped across the nodes and their associated disk arrays. and end coordinates of the spatial region examined and the </span></p><p class="c4"><span class="c1">The tables storing the data are partitioned spatially along </span></p><p class="c4"><span class="c28">306 </span></p><p class="c4"><span class="c75">1000$ </span></p><p class="c4"><span class="c75">Cache$miss$ No$cache$ Cache$hit$ </span><span class="c148">) ).s()em&amp;)no&amp;ucex</span><span class="c32">E</span><span class="c75">100$ 10$ </span></p><p class="c4"><span class="c52">1$ </span></p><p class="c4"><span class="c75">0.1$4247$ 86580$ 909274$ </span></p><p class="c4"><span class="c32">Number)of)points)above)threshold) </span></p><p class="c22"><span class="c1">Figure 6: Execution time for threshold queries at di</span><span class="c86">ff</span><span class="c1">erent threshold levels compared with the execu- tion time of the same queries in the absence of a cache. </span></p><p class="c4"><span class="c1">contiguous ranges of the Morton z-curve and the data for each partition reside in one database file. </span></p><p class="c22"><span class="c1">For this evaluation we looked at the performance of thresh- old queries to the vorticity field. The vorticity field is rep- resentative of derived fields that have to be computed from the stored data. It is defined as the curl of the velocity field. As described in section 3 thresholding the vorticity field is important in the study of fluid dynamics and obtaining the locations of maximum vorticity can lead to new insights into the development of the most intense vortices observed in the dataset. </span></p><p class="c4"><span class="c34">5.2 Evaluation of cache effectiveness </span></p><p class="c22"><span class="c1">The central part of the strategy that we have developed for the evaluation of threshold queries of derived fields is the application-aware cache, which stores the results of these queries. We first evaluate the overhead associated with the introduction and maintenance of the cache. Figure 6 com- pares the execution time of queries in the absence of a cache with the execution time of the same queries, which interro- gate the cache first (blue and red bars in the figure). The execution times are also shown in Table 1. For these experi- ments we requested the locations with norms of the vorticity above thresholds at different levels. We refer the reader to Figure 2, which shows the distribution of values of the norm of the vorticity field in the MHD dataset to get an appre- ciation of the different threshold values used in the exper- iments. For the first set the threshold was set high (80.0) and only &#8672;4,300 points (or 0.0004% of all points) were above the threshold. For the second set a medium threshold (60.0) was chosen and &#8672;87,000 points (or 0.0081% of all points) were above the threshold. Finally, a low threshold (44.0) was chosen for the last set and there were &#8672;900,000 points (or 0.0847% of all points) above the threshold. For each set a random time-step was chosen and the queries were run against that time-step. The measurements were taken from the point of view of the end user. </span></p><p class="c22"><span class="c1">As we can see from the results shown in Figure 6 the overhead associated with querying the cache first is minimal, less than 3% and within the margin of error. The cache was initially populated by executing several hundred unrelated queries and contained several million entries. During the </span></p><p class="c22"><span class="c1">&ldquo;cache-miss&rdquo; runs cache entries for the particular time-step queried were dropped before each run, making sure that each query would produce a cache miss and would have to be evaluated from the raw data. The execution times were averaged over 10 runs. We utilized 4 processes per database node for the evaluation of each query. The method shows stable running time across different time-steps and threshold levels in the absence of a cache and during cache misses. The running time increases slightly only because of the larger result set that has to be returned to the user. </span></p><p class="c4"><span class="c1">Vorticity threshold </span></p><p class="c4"><span class="c1">Points above threshold </span></p><p class="c56"><span class="c1">Average Running time (s.) No cache With cache (miss) </span></p><p class="c18"><span class="c1">With cache (hit) 80.0 4247 97.1 100.2 0.5 60.0 86580 113.7 115.9 1.2 44.0 909274 111.6 115.0 9.1 </span></p><p class="c4"><span class="c1">Table 1: E</span><span class="c86">ff</span><span class="c1">ectiveness of caching. </span></p><p class="c22"><span class="c1">Cache hits reduce the running time of threshold queries by over an order of magnitude as shown in Figure 6 and Table 1. This is because we do not have to compute the requested derived field from the raw data, which eliminates the associated I/O. Only the cache entries need to be looked- up, which is substantially less data than the raw vector or scalar field data. For the queries with large result sets it is actually the network time taken to transfer the results to the user that dominates the overall execution as opposed to the I/O or computation time as we show later. Cache hits are evaluated by first warming up the cache by submitting the same set of threshold queries of the vorticity field as before. We then submit several more unrelated queries with different time-steps and threshold values in order to pollute the cache. Finally, we issue the original set of queries and measure their running times. Let us focus on the query with low threshold, which returns &#8672;900,000 points. Given that valid threshold values are limited to those that result in no more than 1,000,000 points it is likely that all subsequent queries to this time-step will result in a cache hit as their threshold is likely to be equal or higher than the cached one. Currently we observe fairly high cache-hit ratios as the workload is very structured and queries tend to examine the same regions in space and time. </span></p><p class="c4"><span class="c34">5.3 Scaling and Distributed Evaluation </span></p><p class="c22"><span class="c1">The evaluation of threshold queries of derived fields from the raw data is both I/O and computationally bound. These queries examine the entire data volume of a simulation time- step and are, therefore, good candidates for a data-parallel distributed evaluation. Our data-parallel implementation exhibits good vertical and nearly ideal horizontal scaling as shown in Figure 7. For the scale-up experiments (Fig. 7(a)), we used the same queries and threshold values as for the runs shown in Figure 6 and Table 1 but with varying number of processes per node. Cache entries for the time-step queried were again dropped before each run in order to evaluate the scaling properties of the computation of the derived field from the stored data. The computations for all of the de- rived fields of interest (such as the vorticity) at each grid point need data from adjacent grid points only. Therefore, each node of the cluster is able to compute the derived field </span></p><p class="c4"><span class="c28">307 </span></p><p class="c4"><span class="c98">Low&quot;Threshold&quot;(44.0)&quot; Medium&quot;Threshold&quot;(60.0)&quot; High&quot;Threshold&quot;(80.0)&quot; Linear&quot;Speedup&quot; </span></p><p class="c4"><span class="c1">(a) Scale-up with multiple processes per node </span><span class="c57">8&quot; </span></p><p class="c56"><span class="c98">Low&quot;Threshold&quot;(44.0)&quot; Medium&quot;Threshold&quot;(60.0)&quot; High&quot;Threshold&quot;(80.0)&quot; Linear&quot;Speedup&quot; </span><span class="c59">&amp; pudeep</span><span class="c37">S</span><span class="c57">4&quot;2&quot;</span><span class="c98">1&quot;1&quot; 2&quot; 4&quot; 8&quot; </span><span class="c37">Number&amp;of&amp;processes&amp;per&amp;node&amp;(4&amp;node&amp;cluster)&amp; </span></p><p class="c4"><span class="c1">(b) Scale-out to multiple nodes </span></p><p class="c22"><span class="c1">Figure 7: Execution time for threshold queries at di</span><span class="c86">ff</span><span class="c1">erent threshold levels &ndash; high, medium and low. The scale-up evaluation was performed utilizing 1-8 processes per server on a 4-node cluster. The scale-out evaluation was performed on 1 through 8 nodes. </span></p><p class="c18"><span class="c1">from data available locally with only a small amount along the boundary of each region having to be retrieved from adjacent nodes. Each computation is independent and em- barrassingly parallel. This allows us to make use of multiple processes per node and scale out to multiple database nodes. We observe nearly a two times speedup when going from a single process per node to two processes per node (Fig. 7(a)). The speedup diminishes to 1.4 times when going to 4 processes and little speedup is observed with 8 processes per node. While the computation time scales with increased process count, the time to perform I/O does not as the data on each node reside in the same database table and on the same set of disks. Additionally, I/O redundancy increases as the process count increases as data along the boundary of each region are requested by multiple processes. SQL Server already utilizes parallelism to perform the I/O even when data are retrieved utilizing a single query. Finally, the experiments were run on the live production database nodes, which were also servicing other user queries in addition to operating system and other SQL Server processes. Never- theless, running with 4 processes per node is nearly 2.6 times faster when compared to running with a single process. </span></p><p class="c22"><span class="c1">The scale-out experiments show a nearly perfect linear speedup as the evaluation is distributed to an increasing number of database nodes (Fig. 7(b)). For these experi- ments we issued queries with the same threshold levels as before to a cold cache. We utilized a single process per database node to evaluate the horizontal scaling of the com- putation. The evaluation benefits not only from the addi- tional computational resources with the addition of database nodes to the cluster but also from the increased memory size. The data needed for the computation of each derived field are read into memory and the larger memory size means that there is less contention with other system and applica- tion processes and it is less likely that virtual memory needs to be used. SQL Server also benefits from a larger buffer pool, which reduces the I/O time. </span></p><p class="c22"><span class="c1">As expected, we observe even weaker speedup when the queries perform nothing but I/O and the number of pro- cesses per node is increased. Figure 8 compares the running time of the queries with a medium threshold and executed </span></p><p class="c4"><span class="c59">&amp; pudeep</span><span class="c37">SNumber&amp;of&amp;nodes&amp; </span></p><p class="c4"><span class="c26">E</span><span class="c133">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4"><span class="c26">Number)of)processes)</span><span class="c167">Total&quot;running&quot;3me&quot; </span></p><p class="c4"><span class="c72">I/O&quot;Only&quot; </span></p><p class="c22"><span class="c1">Figure 8: Execution time for threshold queries eval- uated utilizing di</span><span class="c86">ff</span><span class="c1">erent number of processes per server compared with the time taken to perform the I/O only. </span></p><p class="c22"><span class="c1">with varying number of processes per node with the time taken to perform the I/O only. The I/O time is about half of the total running time for these queries. SQL Server al- ready makes use of parallelism internally and the data have to be retrieved from the same set of disks. Nevertheless, the I/O time does decrease with additional processes, this is be- cause the data reside in a partitioned table and the data in each partition are placed in a separate file on one of the disk arrays. Depending on how the data requests are scheduled in SQL Server this allows for the disks arrays to be driven in parallel. Additionally, with more processes per node the data can also be consumed faster. It is worth noting that the total running time for the queries evaluated with 4 or 8 processes is about the same as the time it takes to perform the I/O only with a single process. </span></p><p class="c22"><span class="c1">So far we have presented the effectiveness of evaluating threshold queries of derived fields on the database cluster storing the raw simulation data. The data-parallel compu- tation of the derived fields allows us to evaluate a threshold </span></p><p class="c4"><span class="c28">308 </span></p><p class="c4"><span class="c98">1&quot;</span><span class="c57">2&quot;4&quot;8&quot; </span></p><p class="c4"><span class="c98">1&quot; 2&quot; 4&quot; 8&quot; </span></p><p class="c4"><span class="c72">300&quot; </span></p><p class="c4"><span class="c72">250&quot; </span></p><p class="c4"><span class="c72">200&quot; </span></p><p class="c4"><span class="c72">150&quot; </span></p><p class="c4"><span class="c72">100&quot; </span></p><p class="c4"><span class="c72">50&quot; </span></p><p class="c4"><span class="c72">0&quot; </span></p><p class="c4"><span class="c72">1&quot; 2&quot; 4&quot; 8&quot; </span></p><p class="c84"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c60 c127"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c136"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c100"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c22 c63"><span class="c3">10&quot; </span><span class="c12">9&quot; 8&quot;7&quot;6&quot;5&quot;4&quot;3&quot;2&quot;1&quot;</span><span class="c3">0&quot;4247&quot; 86580&quot; 909274&quot; </span></p><p class="c22 c63"><span class="c3">10&quot; </span><span class="c12">9&quot; 8&quot;7&quot;6&quot;5&quot;4&quot;3&quot;2&quot;1&quot;</span><span class="c3">0&quot;4247&quot; 86580&quot; 909274&quot; </span></p><p class="c22 c63"><span class="c3">10&quot; </span><span class="c12">9&quot; 8&quot;7&quot;6&quot;5&quot;4&quot;3&quot;2&quot;1&quot;</span><span class="c3">0&quot;4247&quot; 86580&quot; 909274&quot; </span></p><p class="c22 c63"><span class="c3">10&quot; </span><span class="c12">9&quot; 8&quot;7&quot;6&quot;5&quot;4&quot;3&quot;2&quot;1&quot;</span><span class="c3">0&quot;4247&quot; 86580&quot; 909274&quot; </span></p><p class="c4 c47"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c47"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c47"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c60 c47"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c47"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c47"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c156 c161"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c161"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c161"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c114"><span class="c3">10&quot; </span></p><p class="c113"><span class="c3">3801&quot; 75062&quot; 809735&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c46"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator4user&quot; communica:on&quot; </span></p><p class="c30 c60"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c4 c30"><span class="c3">Mediator&quot;+&quot;DB&quot; communica:on&quot; </span></p><p class="c36 c156"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c36"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c36"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c36"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c36"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c36"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c14"><span class="c3">10&quot; </span></p><p class="c4 c14"><span class="c3">10&quot; </span></p><p class="c92"><span class="c3">1452&quot; 11195&quot; 939716&quot; </span></p><p class="c4 c150"><span class="c3">1452&quot; 11195&quot; 939716&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c4 c15"><span class="c3">0&quot;</span><span class="c12">1&quot;2&quot;3&quot;4&quot;5&quot;6&quot;7&quot;8&quot;9&quot; </span></p><p class="c110 c132"><span class="c1">(f) Magnetic field (cache hit) </span></p><p class="c4 c131"><span class="c1">(d) Vorticity (cache hit) </span></p><p class="c4 c107"><span class="c1">(e) Q-criterion (cache hit) </span></p><p class="c4 c107"><span class="c1">(e) Q-criterion (cache hit) </span></p><p class="c23"><span class="c1">Figure 9: Breakdown of the execution time for threshold queries requesting di</span><span class="c86">ff</span><span class="c1">erent fields and at di</span><span class="c86">ff</span><span class="c1">erent threshold levels &ndash; high, medium and low. </span></p><p class="c139"><span class="c1">query over an entire 1024</span><span class="c19">3 </span><span class="c1">time-step part of a 20TB dataset in less than two minutes. The introduction of an application- aware cache for the query results of these queries reduces this time to several seconds when there is a cache hit. In contrast, one of our science collaborators reported that his evaluation of this functionality performed locally would take over 20 hours to complete. To perform the evaluation lo- cally the user requests the derived field of interest from the database by submitting multiple queries over subregions of a time-step. This is necessary as requesting a derived field over an entire time-step will overload the network. Derived fields may have even more components than the scalar or vector field stored in the database. For example, the veloc- ity gradient (needed for the computation of the vorticity) has 9 components compared with the 3 components of the velocity. Given a single-precision floating-point representa- tion, this makes the velocity gradient of an entire time-step at least 36GB in size. A Web-service request will be much larger due to the overhead of wrapping the data in an xml format. After the field of interest is obtained locally the user has to threshold it to get the final result, which is reasonably fast, but discards most of the data that have been requested to yield a small in size result. </span></p><p class="c119"><span class="c34">5.4 Evaluation of Additional Fields </span></p><p class="c69"><span class="c1">The data-parallel evaluation of threshold queries shows stable execution time for different derived fields in addi- tion to the different threshold levels and time-steps queried. The execution times depend on the complexity of the com- putation needed to evaluate the particular derived field re- quested. Figures 9(a), 9(b) and 9(c) show a breakdown of the execution time of threshold queries of different derived fields, which are evaluated from the raw data and a cold cache using 4 processes per node on a 4 node cluster. Almost the entire time is spent performing the I/O and computation </span></p><p class="c4 c162"><span class="c1">associated with the derived field requested. </span></p><p class="c85"><span class="c1">The vorticity field and the Q-criterion have similar I/O requirements as they have the same kernels of computation and are both derived from the velocity gradient. The vor- ticity has 3 components and its computation only examines 6 of the 9 components of the velocity gradient, which are also examined in pairs (see Eq. 1). On the other hand, even though the Q-criterion is a scalar value, it is computed through a non-linear combination of all 9 of the components of the velocity gradient. This means that the velocity gra- dient has to be computed at each grid location before the Q-criterion is evaluated, which is reflected in the increased computation time that we observe for the Q-criterion. The magnetic field is one of the raw fields of the magnetohydro- dynamics dataset that are stored in the database. Therefore, there is no additional computation needed to derive it from the data, every data point has to be simply compared with the threshold level specified. This is why the computation time is much smaller compared to the queries for the vortic- ity and the Q-criterion. The I/O time for the magnetic field is also smaller. This is because its kernel of computation is a single point and therefore there are no additional data along the boundary that have to be requested from adja- cent nodes. In that case all of the data needed are available locally for each database node. </span></p><p class="c83"><span class="c1">In all of these cases, the time taken to interrogate the cache is negligible. The mediator time to distribute the queries and assemble the results as well as the time to trans- fer them to the user are also substantially smaller than the I/O and computation times. As expected they increase pro- portionally to the number of points in the result set. </span></p><p class="c99"><span class="c1">It is interesting to note that the time taken to perform a cache lookup is relatively small even in the case of a cache hit as can be seen in Figures 9(d), 9(e) and 9(f). This is because the cache tables reside on SSDs attached to each </span></p><p class="c124"><span class="c28">309 </span></p><p class="c4 c100"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c91"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c160"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c0"><span class="c3">100&quot; </span></p><p class="c105 c141"><span class="c3">80&quot; </span></p><p class="c96 c141"><span class="c3">60&quot; </span></p><p class="c105 c141"><span class="c3">40&quot; </span></p><p class="c90"><span class="c3">20&quot; </span></p><p class="c4 c33"><span class="c3">Mediator3user&quot; communica9on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica9on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c33"><span class="c3">Mediator3user&quot; communica9on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica9on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c33"><span class="c3">Mediator3user&quot; communica9on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica9on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c94"><span class="c3">I/O&quot; </span></p><p class="c4 c165"><span class="c3">I/O&quot; </span></p><p class="c66"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c6"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c121"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c135"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c4 c77"><span class="c3">100&quot; </span></p><p class="c4 c77"><span class="c3">100&quot; </span></p><p class="c50"><span class="c3">80&quot; </span></p><p class="c4 c61"><span class="c3">80&quot; </span></p><p class="c4 c61"><span class="c3">80&quot; </span></p><p class="c4 c61"><span class="c3">80&quot; </span></p><p class="c96 c61"><span class="c3">60&quot; </span></p><p class="c4 c61"><span class="c3">60&quot; </span></p><p class="c4 c61"><span class="c3">60&quot; </span></p><p class="c4 c61"><span class="c3">60&quot; </span></p><p class="c50"><span class="c3">40&quot; </span></p><p class="c4 c61"><span class="c3">40&quot; </span></p><p class="c4 c61"><span class="c3">40&quot; </span></p><p class="c4 c61"><span class="c3">40&quot; </span></p><p class="c50"><span class="c3">20&quot; </span></p><p class="c4 c61"><span class="c3">20&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c64"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c31 c164"><span class="c3">I/O&quot; </span></p><p class="c4 c31"><span class="c3">I/O&quot; </span></p><p class="c4 c31"><span class="c3">I/O&quot; </span></p><p class="c4 c31"><span class="c3">I/O&quot; </span></p><p class="c4 c31"><span class="c3">I/O&quot; </span></p><p class="c164 c101"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c101"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c101"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c101"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c101"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c4 c11"><span class="c10">E</span><span class="c5">xecu&amp;on)&amp;me)(s.)) </span></p><p class="c74"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c4 c79"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c88"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c4 c168"><span class="c10">Number)of)points)above)threshold) </span></p><p class="c4 c13"><span class="c3">100&quot; </span></p><p class="c4 c13"><span class="c3">100&quot; </span></p><p class="c4 c13"><span class="c3">100&quot; </span></p><p class="c4 c13"><span class="c3">100&quot; </span></p><p class="c14 c105"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c4 c14"><span class="c3">80&quot; </span></p><p class="c14 c96"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c4 c14"><span class="c3">60&quot; </span></p><p class="c105 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c4 c14"><span class="c3">40&quot; </span></p><p class="c105 c14"><span class="c3">20&quot; </span></p><p class="c4 c14"><span class="c3">20&quot; </span></p><p class="c4 c14"><span class="c3">20&quot; </span></p><p class="c4 c14"><span class="c3">20&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c4 c8"><span class="c3">Mediator4user&quot; communica:on&quot; </span><span class="c7">Mediator&quot;+&quot;DB&quot; </span><span class="c3">communica:on&quot; </span><span class="c7">Compute&quot; </span></p><p class="c58 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c4 c9"><span class="c3">I/O&quot; </span></p><p class="c20 c58"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c4 c20"><span class="c3">Cache&quot;lookup&quot; </span></p><p class="c0"><span class="c3">120&quot; </span></p><p class="c145"><span class="c3">0&quot; </span></p><p class="c71"><span class="c3">4247&quot; 86580&quot; 909274&quot; </span></p><p class="c147"><span class="c1">(a) Vorticity </span></p><p class="c4 c77"><span class="c3">120&quot; </span></p><p class="c157"><span class="c3">3801&quot; 75062&quot; 809735&quot; </span></p><p class="c4 c46"><span class="c3">0&quot; </span></p><p class="c110 c169"><span class="c1">(b) Q-criterion </span></p><p class="c4 c13"><span class="c3">120&quot; </span></p><p class="c4 c13"><span class="c3">120&quot; </span></p><p class="c97"><span class="c3">1452&quot; 11195&quot; 939716&quot; </span></p><p class="c4 c140"><span class="c3">1452&quot; 11195&quot; 939716&quot; </span></p><p class="c4 c15"><span class="c3">0&quot; </span></p><p class="c4 c15"><span class="c3">0&quot; </span></p><p class="c76 c110"><span class="c1">(c) Magnetic field </span></p><p class="c4 c76"><span class="c1">(c) Magnetic field </span></p><p class="c49"><span class="c1">database node (see Fig. 5) and retrieving the data is always done through a clustered index lookup. In the cases of a cache hit, the majority of the time is spent simply trans- ferring the results from the database nodes to the mediator and then back to the user. These times remain more or less constant between the cases of cache misses and cache hits (top row and bottom row of Fig. 9). Caching the results of threshold queries effectively preserves the I/O and computa- tional effort spent during their initial evaluation and results in over an order of magnitude speedup for all the different fields requested as we can see in Figure 9. </span></p><p class="c81"><span class="c34">6. RELATED WORK </span></p><p class="c69"><span class="c1">Only select few database systems offer support for arrays as first-class citizens. Even fewer provide the fault-tolerance, scalability and availability guarantees necessary for a system managing multi-terabyte datasets in a production setting. This is part of the reason why we have chosen to repre- sent the array data in the JHTDB as a collection of binary large objects in a relational DBMS and perform the array manipulation tasks necessary at the application level. The systems that provide support for arrays and aim to handle large array data efficiently are RasDaMan [5], SciDB [30] and MonetDB/SciQL [34]. RasDaMan partitions raster ob- jects into tiles, which are stored in a traditional relational database system. This approach is similar to how the nu- merical simulation data are handled in the JHTDB. Ras- DaMan provides RasQL [4], which is a SQL-92 based query language for the manipulation of raster images. SciDB is an array database system build from the ground up. Array attributes are partitioned vertically and each attribute ar- ray is decomposed into overlapping chunks. SciDB provides a declarative Array Query Language (AQL) and an Array Functional Language (AFL). Users can create arrays with named dimensions with AQL and make use of the functional operators defined in AFL, such as SLICE, SUBSAMPLE, SJOIN, FILTER and APPLY. SciQL&rsquo;s focus is on language design and integration with SQL:2003 syntax and semantics. It is implemented within the MonetDB framework [24]. </span></p><p class="c112"><span class="c1">Database systems support rollup queries, including top-k queries, but in most cases these queries apply only simple linear score functions on the attribute values of individual records. Additionally, many top-k query evaluation tech- niques rely on the score functions being monotone in order to perform early pruning (see [15] for a survey of top-k evalua- tion strategies). This is an assumption that we cannot make for the functions used to compute all the different possible derived fields of interest in fluid mechanics. Even approaches that aim to work with general score functions [11, 33] as- sume that the function operates on the attributes of a single record. In contrast, our approach performs a kernel com- putation at each grid location in order to obtain the value of a derived field at that location and examines the vector or scalar array data at all neighboring locations, which are within the kernel of the computation. The functions used to derive the field may even be non-linear. Finally, a top-k approach may not be suitable in the cases where scientists are interested in performing threshold queries at different time-steps as the same threshold level will produce different number of points in the result set for different time-steps. </span></p><p class="c151"><span class="c1">The processing of top-k queries has been studied exten- sively in the context of distributed and relational database systems. A survey of different techniques in the case of cen- </span></p><p class="c22 c93"><span class="c1">tralized processing is given in [15]. In the case of distributed processing different approaches focus on horizontally [3, 32] or vertically [7, 8, 13, 21, 22] distributed data. None of these approaches deal with array data stored in a relational database system. Zhao et al. propose an algorithm for the processing of top-k queries in large-scale distributed envi- ronments called BRANCA [35]. They build on the idea of semantic caching [27] and make use of branch caches, which store results of previous top-k queries with respect to the data stored on each server. The caching mechanism that we use is similar in that regard, but the queries that are evaluated in our system operate on derived fields, which are computed at each location by accessing data from a sur- rounding region. The queries described in [35] operate over the attributes of individual records only using simple linear score functions. </span></p><p class="c85"><span class="c1">A&szlig;falg et al. introduce the concept of threshold queries in time-series databases [2]. Their definition of threshold queries differs from the threshold queries described in this paper. They are concerned with determining the time-series, which exceed a user-defined threshold at time frames similar to the time-series specified in the query. Thus, their defi- nition of threshold queries is concerned with the temporal relationship between the time-series stored in the database (usually one dimensional sequence of measurements) and the time-series given in the query. In contrast, our approach fo- cuses on reporting all of the spatial locations of a multidi- mensional field where the norm or absolute value of the field exceeds a user prescribed threshold. </span></p><p class="c85"><span class="c1">In a system called the tree cache, Lopez et al. [20] make use of a small application-aware cache to reduce access time to large datasets stored on disk. The tree cache stores in- dividual octants of octree datasets and exploits application- specific information to determine which octants to cache and to perform query reordering. This work has inspired the use of an application-aware cache for the evaluation of threshold queries. In contrast to the tree cache, we do not cache raw data objects, but rather query results. Caching query results preserves the computational effort in addition to reducing I/O, which has a much bigger impact on query performance and substantially reduces the size of the cache. Additionally, the cache that we introduce resides on disk rather than in memory, which greatly increases its potential size. Lopez et al. also explore approximate querying through aggregation, which can be fairly easily supported by our system but is of limited use as scientists performing threshold queries are usually interested in obtaining the exact locations where a field is at its highest values. </span></p><p class="c83"><span class="c1">Sampling approaches [29, 25] offer an alternative to the on-demand computation of derived fields and the evaluation of threshold queries on them. The goal of both techniques is to not return large data volumes, but focus on the most intense events and interesting regions in the dataset. The computation of derived fields is carried out on the nodes of the database cluster and takes a look at the dataset as a whole, while the user obtains only a small subset of the data, where the derived field in question is above the prescribed threshold. Sampling approaches can potentially omit some locations and while useful for generating initial impressions may not be suitable if the exact locations where a field is at its highest values are desired. </span></p><p class="c106"><span class="c1">Andrade et al. [1] describe a database system and an optimization framework build on the concept of active se- </span></p><p class="c48"><span class="c28">310 </span></p><p class="c49"><span class="c1">mantic caching. An active semantic cache aims to fully or partially reuse cached query results or aggregates through automated transformations of these aggregates. Similarly to our work they focus on real scientific data-analysis appli- cations. The method that we have developed for the eval- uation of threshold queries complements the active seman- tic caching approach and could be used in that framework. Our work has focused on extending a relational database system (Microsoft&rsquo;s SQL Server) as opposed to designing a new database system from the ground up as described by Andrade et al. [1]. </span></p><p class="c155"><span class="c34">7. CONCLUSIONS AND FUTURE WORK </span></p><p class="c69"><span class="c1">We have presented an efficient strategy for the evaluation of threshold queries of derived fields in large numerical simu- lation datasets. The thresholded fields are derived from the stored simulation data in a distributed data-parallel man- ner. The computations scale with the cluster resources and are performed on the database nodes, where the data are stored. This new capability allows researches to quickly ob- tain and focus on regions of special interest even if they lack the computing capabilities or data transfer rates neces- sary to examine entire time-steps or large parts of the entire dataset. </span></p><p class="c112"><span class="c1">We have introduced an application-aware cache for the query results of threshold queries. Cache hits reduce query running times by over an order of magnitude. The cache adds minimal overhead during the evaluation of queries even if there is a cache miss and has modest storage requirements. The cache is represented as a set of database tables and resides on disk rather than in memory. Each database node has local cache tables, which allows the cache to scale-out as the cluster grows. </span></p><p class="c102"><span class="c1">The introduction of an application-aware cache for query results lays the groundwork for the creation of a landmark database. Such a database can store the locations of the highest vorticity regions in the dataset or more broadly re- gions of interest and their associated statistics. </span></p><p class="c102"><span class="c1">The Web-services approach to archived numerical simu- lation datasets provides public access to high quality sim- ulation data to anyone with an internet connection. The Web-services methods can be called from any modern pro- gramming language and we provide C, Fortran and Matlab client libraries for the JHTDB. The evaluation of each query submitted through a Web-service call is carried out on the nodes of the database cluster by means of a stored proce- dure or a user-defined function that has been implemented and deployed to handle these requests. This allows us to fine-tune the execution of these procedures and handle all requests transparently to the user. However, this approach also has drawbacks. Adding new functionality means adding to a long list of Web-service calls and requires substantial implementation effort. In the case of threshold queries the stored procedure performing the evaluation must have an implementation for each derived field of interest even though the execution is handled by the same Web-service call. </span></p><p class="c138"><span class="c1">In the future, we plan to develop declarative and graph- ical user interfaces that will allow users to combine exist- ing building blocks and perform computations that have not been explicitly implemented. Additionally, we plan on de- ploying a server-side computing environment for users simi- lar to the CasJobs service for the Sloan Digital Sky Survery [18]. In such an environment users can run queries in batch </span></p><p class="c22 c122"><span class="c1">mode and save their results in a personal database called MyDB, which resides on the servers near the data. This will allow for much greater flexibility in the type of compu- tations that can be performed in addition to substantially decreasing the network overhead. </span></p><p class="c111"><span class="c34">8. ACKNOWLEDGMENTS </span></p><p class="c60 c149"><span class="c1">The authors would like to thank the Turbulence Database Group at Johns Hopkins University as well as three anony- mous reviewers for their insightful comments and sugges- tions. This work is supported in part by the National Science Foundation under Grants CMMI-0941530, ACI-1261715, OCI- 1244820 and AST-0939767 and Johns Hopkins University&rsquo;s Institute for Data Intensive Engineering &amp; Science. </span></p><p class="c16"><span class="c34">9. REFERENCES </span></p><p class="c65"><span class="c1">[1] H. Andrade, T. Kurc, A. Sussman, and J. Saltz. </span></p><p class="c125 c142"><span class="c1">Active semantic caching to optimize multidimensional data analysis in parallel and distributed environments. Parallel Computing, 33(7-8):497&ndash;520, Aug. 2007. [2] J. A&szlig;falg, H.-P. Kriegel, P. Kr&ouml;ger, P. Kunath, </span></p><p class="c129"><span class="c1">A. Pryakhin, and M. Renz. Similarity Search on Time Series based on Threshold Queries. In EDBT, 2006. [3] W.-T. Balke, W. Nejdl, W. Siberski, and U. Thaden. </span></p><p class="c104"><span class="c1">Progressive Distributed Top-k Retrieval in Peer-to-Peer Networks. In ICDE, 2005. [4] P. Baumann. A Database Array Algebra for </span></p><p class="c146"><span class="c1">Spatio-Temporal Data and Beyond. In Proceedings of the 4th International Workshop on Next Generation Information Technologies and Systems, NGIT &rsquo;99, 1999. [5] P. Baumann, A. Dehmel, P. Furtado, R. Ritsch, and </span></p><p class="c153"><span class="c1">N. Widmann. The Multidimensional Database System RasDaMan. In SIGMOD, 1998. [6] R. Burns, K. Lillaney, D. R. Berger, L. Grosenick, </span></p><p class="c67"><span class="c1">K. Deisseroth, R. C. Reid, W. G. Roncal, P. Manavalan, D. D. Bock, N. Kasthuri, M. Kazhdan, S. J. Smith, D. Kleissas, E. Perlman, K. Chung, N. C. Weiler, J. Lichtman, A. S. Szalay, J. T. Vogelstein, and R. J. Vogelstein. The open connectome project data cluster: Scalable analysis and vision for high-throughput neuroscience. In SSDBM, 2013. [7] P. Cao and Z. Wang. Efficient top-K Query </span></p><p class="c109"><span class="c1">Calculation in Distributed Networks. In PODC, 2004. [8] S. Chaudhuri, L. Gravano, and A. Marian. Optimizing Top-k Selection Queries over Multimedia Repositories. IEEE Trans. on Knowl. and Data Eng., 16(8):992&ndash;1009, Aug. 2004. [9] S. Dar, M. J. Franklin, B. T. J&oacute;nsson, D. Srivastava, </span></p><p class="c122 c125"><span class="c1">and M. Tan. Semantic Data Caching and Replacement. In VLDB, 1996. [10] DataScope. http://idies.jhu.edu/datascope. [11] P. M. Deshpande, D. P, and K. Kummamuru. Efficient </span></p><p class="c44"><span class="c1">Online top-K Retrieval with Arbitrary Similarity Measures. In EDBT, 2008. [12] G. Eyink, E. Vishniac, C. Lalescu, H. Aluie, </span></p><p class="c89"><span class="c1">K. Kanov, K. B&uuml;rger, R. Burns, C. Meneveau, and A. Szalay. Flux-freezing breakdown in high-conductivity magnetohydrodynamic turbulence. Nature, 497(7450):466&ndash;9, 2013. </span></p><p class="c159"><span class="c28">311 </span></p><p class="c130"><span class="c1">[13] U. G&uuml;ntzer, W.-T. Balke, and W. Kie&szlig;ling. </span></p><p class="c143"><span class="c1">Optimizing Multi-Feature Queries for Image Databases. In VLDB, 2000. [14] A. J. G. Hey, S. Tansley, and K. M. Tolle. The Fourth </span></p><p class="c123"><span class="c1">Paradigm: Data-Intensive Scientific Discovery. Microsoft Research, 2009. [15] I. F. Ilyas, G. Beskales, and M. A. Soliman. A Survey </span></p><p class="c144"><span class="c1">of Top-k Query Processing Techniques in Relational Database Systems. ACM Comput. Surv., 40(4):11:1&ndash;11:58, Oct. 2008. [16] K. Kanov, R. Burns, G. Eyink, C. Meneveau, and </span></p><p class="c82"><span class="c1">A. Szalay. Data-intensive Spatial Filtering in Large Numerical Simulation Datasets. In Supercomputing, 2012. [17] K. Kanov, E. Perlman, R. Burns, Y. Ahmad, and </span></p><p class="c95"><span class="c1">A. Szalay. I/O Streaming Evaluation of Batch Queries for Data-intensive Computational Turbulence. In Supercomputing, 2011. [18] N. Li and A. R. Thakar. CasJobs and MyDB: A Batch </span></p><p class="c166"><span class="c1">Query Workbench. Computing in Science and Engineering, 10(1):18&ndash;29, 2008. [19] Y. Li, E. Perlman, M. Wan, Y. Yang, C. Meneveau, </span></p><p class="c108"><span class="c1">R. Burns, S. Chen, A. Szalay, and G. Eyink. A public turbulence database cluster and applications to study Lagrangian evolution of velocity increments in turbulence. Journal of Turbulence, page N31, 2008. [20] J. C. Lopez, D. R. O&rsquo;Hallaron, and T. Tu. Big Wins </span></p><p class="c40"><span class="c1">With Small Application-aware Caches . In Supercomputing, 2004. [21] A. Marian, N. Bruno, and L. Gravano. Evaluating </span></p><p class="c55"><span class="c1">Top-k Queries over Web-accessible Databases. ACM Trans. Database Syst., 29(2):319&ndash;362, June 2004. [22] S. Michel, P. Triantafillou, and G. Weikum. KLEE: A </span></p><p class="c51"><span class="c1">Framework for Distributed Top-k Query Algorithms. In VLDB, 2005. [23] The Millennium Simulation. </span></p><p class="c80"><span class="c1">http://www.mpa-garching.mpg.de/millennium/. [24] MonetDB. http://monetdb.cwi.nl/. [25] S. Nirkhiwale, A. Dobra, and C. Jermaine. A sampling algebra for aggregate estimation. Proc. VLDB Endow., 6(14):1798&ndash;1809, Sept. 2013. [26] E. Perlman, R. Burns, Y. Li, and C. Meneveau. Data </span></p><p class="c154"><span class="c1">Exploration of Turbulence Simulations Using a Database Cluster. In Supercomputing, 2007. [27] Q. Ren, M. H. Dunham, and V. Kumar. Semantic </span></p><p class="c38"><span class="c1">Caching and Query Processing. IEEE Trans. on Knowl. and Data Eng., 15(1):192&ndash;210, Jan. 2003. [28] The Sloan Digital Sky Survey. http://www.sdss.org/. [29] L. Sidirourgos, M. L. Kersten, and P. A. Boncz. </span></p><p class="c27"><span class="c1">Sciborq: Scientific data management with bounds on runtime and quality. In CIDR, 2011. [30] M. Stonebraker, J. Becla, D. J. DeWitt, K. Lim, </span></p><p class="c115"><span class="c1">D. Maier, O. Ratzesberger, and S. B. Zdonik. Requirements for Science Data Bases and SciDB. In CIDR, 2009. [31] A. S. Szalay, G. Bell, J. Vandenberg, A. Wonders, </span></p><p class="c125 c170"><span class="c1">R. Burns, D. Fay, J. Heasley, T. Hey, M. Nieto-Santisteban, A. Thakar, C. van Ingen, and R. Wilton. GrayWulf: Scalable Clustered Architecture for Data Intensive Computing. In HICSS, 2009. [32] A. Vlachou, C. Doulkeridis, K. N&oslash;rv&aring;g, and </span></p><p class="c4 c163"><span class="c1">M. Vazirgiannis. On Efficient Top-k Query Processing in Highly Distributed Environments. In SIGMOD, 2008. [33] D. Xin, J. Han, and K. C. Chang. Progressive and </span></p><p class="c42"><span class="c1">Selective Merge: Computing Top-k with Ad-hoc Ranking Functions. In SIGMOD, 2007. [34] Y. Zhang, M. Kersten, M. Ivanova, and N. Nes. </span></p><p class="c134"><span class="c1">SciQL: Bridging the Gap Between Science and Relational DBMS. In IDEAS, 2011. [35] K. Zhao, Y. Tao, and S. Zhou. Efficient Top-k </span></p><p class="c117"><span class="c1">Processing in Large-scaled Distributed Environments. Data Knowl. Eng., 63(2):315&ndash;335, Nov. 2007. </span></p><p class="c158"><span class="c28">312 </span></p></body></html>