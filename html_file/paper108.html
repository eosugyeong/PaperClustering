<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c107{margin-left:-16.9pt;padding-top:14.2pt;text-indent:27pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.2pt}.c68{margin-left:-16.9pt;padding-top:18.2pt;text-indent:27pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c26{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Arial";font-style:normal}.c73{color:#ec008c;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c44{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:5.9pt;font-family:"Arial";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c53{margin-left:-16.9pt;padding-top:1.4pt;text-indent:26pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.1pt}.c87{margin-left:-15.6pt;padding-top:1.4pt;text-indent:24.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.2pt}.c34{margin-left:-6.5pt;padding-top:1.7pt;text-indent:20.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:44.8pt}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.6pt;font-family:"Courier New";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c70{margin-left:-16.9pt;padding-top:9.6pt;text-indent:26pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.1pt}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.8pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8pt;font-family:"Arial";font-style:normal}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Courier New";font-style:normal}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:5.9pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.8pt;font-family:"Arial";font-style:normal}.c48{margin-left:-15.6pt;padding-top:13.2pt;text-indent:25.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.2pt}.c29{margin-left:-15.6pt;padding-top:3.8pt;text-indent:24.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.2pt}.c89{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.6pt;font-family:"Courier New";font-style:normal}.c38{margin-left:-15.6pt;padding-top:4.1pt;text-indent:24.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.2pt}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.6pt;font-family:"Arial";font-style:normal}.c8{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c32{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.8pt;font-family:"Courier New";font-style:normal}.c65{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c55{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c16{margin-left:-15.6pt;padding-top:1.7pt;text-indent:24.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.8pt}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c24{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Arial";font-style:normal}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c57{margin-left:21.1pt;padding-top:1.7pt;text-indent:35pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c90{margin-left:-16.9pt;padding-top:1.7pt;text-indent:26pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.9pt}.c37{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c56{margin-left:-16.9pt;padding-top:9.4pt;text-indent:27pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.1pt}.c52{margin-left:-16.9pt;padding-top:3.8pt;text-indent:26pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.1pt}.c28{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c79{margin-left:-6.5pt;padding-top:1.4pt;text-indent:20.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-4.4pt}.c86{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:5.3pt}.c112{margin-left:-16.9pt;padding-top:11.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:43.9pt}.c77{margin-left:-11pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.4pt}.c78{margin-left:7.4pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:119.9pt}.c71{margin-left:7.4pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-0.1pt}.c85{margin-left:21.1pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:27.5pt}.c25{margin-left:-15.6pt;padding-top:24.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11.4pt}.c75{margin-left:-15.6pt;padding-top:28.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:93.3pt}.c64{margin-left:-11pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.2pt}.c31{margin-left:-15.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:19.4pt}.c72{margin-left:-6.5pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:96.6pt}.c106{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-7pt}.c121{margin-left:-11pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-7.5pt}.c59{margin-left:30.5pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:29.9pt}.c105{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.2pt}.c66{margin-left:-16.9pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:157.7pt}.c113{margin-left:-6.5pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-13.5pt}.c40{margin-left:-15.6pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:110.8pt}.c84{margin-left:21.5pt;padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:23.3pt}.c60{margin-left:-15.6pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c51{margin-left:7.4pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:91.4pt}.c74{margin-left:-11pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.6pt}.c50{margin-left:2.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13pt}.c116{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-14.6pt}.c104{margin-left:-6.5pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:72.2pt}.c17{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-4.3pt}.c5{margin-left:218.2pt;padding-top:52.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c92{margin-left:218.2pt;padding-top:52.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c39{margin-left:74.3pt;padding-top:10.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:76.1pt}.c62{margin-left:-16.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.2pt}.c91{margin-left:3.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-0.3pt}.c3{margin-left:-15.6pt;padding-top:22.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c93{margin-left:-16.9pt;padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:8.4pt}.c41{margin-left:-6.5pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:26.8pt}.c69{margin-left:10pt;padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:11.8pt}.c58{margin-left:74.3pt;padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:76.1pt}.c42{margin-left:-6.5pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:77.9pt}.c21{margin-left:-15.6pt;padding-top:14.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1.5pt}.c122{margin-left:-16.9pt;padding-top:10.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.7pt}.c82{margin-left:218.2pt;padding-top:51.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c81{margin-left:-16.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:3.6pt}.c67{margin-left:-15.6pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c49{margin-left:-13pt;padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:84.9pt}.c97{margin-left:-11pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-14.5pt}.c123{margin-left:-14pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:81.4pt}.c108{margin-left:-11pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c83{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.8pt}.c110{margin-left:7.4pt;padding-top:3.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:83.9pt}.c61{margin-left:-16.9pt;padding-top:7.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.1pt}.c35{margin-left:-11pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-4.9pt}.c88{margin-left:-16.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-12.5pt}.c46{margin-left:-15.6pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.2pt}.c47{margin-left:-16.9pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:112.1pt}.c98{margin-left:-15.6pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c118{margin-left:1.4pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:0.9pt}.c114{margin-left:7.4pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:129.8pt}.c103{margin-left:-6.5pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c33{margin-left:218.2pt;padding-top:60.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c76{margin-left:21.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:7.4pt}.c119{padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c101{padding-top:11.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c100{padding-top:13pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c94{padding-top:8.4pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c102{padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c115{padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c27{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c109{padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c111{padding-top:11.3pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c95{margin-left:-15.6pt;text-indent:25.4pt;margin-right:-16.2pt}.c96{margin-left:-16.9pt;text-indent:26pt;margin-right:-14.9pt}.c124{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c120{margin-left:-16.9pt;margin-right:-8.9pt}.c54{margin-left:-16.9pt;margin-right:-12.7pt}.c99{margin-left:-15.6pt;margin-right:-16.2pt}.c117{margin-left:21.1pt;margin-right:2.6pt}.c80{margin-left:-16.9pt;margin-right:-15.1pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c124"><p class="c4"><span class="c19">Series ISSN: 2367-2005 270 </span><span class="c65">10.5441/002/edbt.2017.25 </span></p><p class="c4"><span class="c55">Information Propagation in Interaction Networks </span></p><p class="c4"><span class="c15">Rohit Kumar </span><span class="c20">Department of Computer and Decision Engineering Universit&eacute; Libre de Bruxelles, Belgium Department of Service and Information System Engineering Universitat </span><span class="c43">rohit.kumar@ulb.ac.be </span></p><p class="c4"><span class="c20">Polit&eacute;cnica de Catalunya, Spain </span><span class="c15">Toon Calders </span><span class="c20">Department of Computer and Decision Engineering Universit&eacute; Libre de Bruxelles, Belgium Department of Mathematics and Computer Science </span><span class="c43">Toon.Calders@uantwerpen.be </span><span class="c20">Universiteit Antwerpen, Belgium </span><span class="c15">ABSTRACT </span><span class="c0">We study the potential flow of information in interaction networks, that is, networks in which the interactions be- tween the nodes are being recorded. The central notion in our study is that of an information channel. An informa- tion channel is a sequence of interactions between nodes forming a path in the network which respects the time or- der. As such, an information channel represents a poten- tial way information could have flown in the interaction network. We propose algorithms to estimate information channels of limited time span from every node to other nodes in the network. We present one exact and one more efficient approximate algorithm. Both algorithms are one- pass algorithms. The approximation algorithm is based on an adaptation of the HyperLogLog sketch, which al- lows easily combining the sketches of individual nodes in order to get estimates of how many unique nodes can be reached from groups of nodes as well. We show how the results of our algorithm can be used to build efficient influ- ence oracles for solving the Influence maximization prob- lem which deals with finding top k seed nodes such that the information spread from these nodes is maximized. Experiments show that the use of information channels is an interesting data-driven and model-independent way to find top k influential nodes in interaction networks. </span></p><p class="c4"><span class="c15">Keywords </span><span class="c0">Influence Maximization, Influence estimation, Informa- tion flow mining </span></p><p class="c4"><span class="c15">1. INTRODUCTION </span></p><p class="c14"><span class="c0">In this paper, we study information propagation by identifying potential &ldquo;information channels&rdquo; based on in- teractions in a dynamic network. Studying the propa- gation of information through a network is a fundamen- tal and well-studied problem. Most of the works in this area, however, studied the information propagation prob- lem in static networks or graphs only. Nevertheless, with the recent advancement in data storage and processing, </span></p><p class="c14"><span class="c36">c 2017, Copyright is with the authors. Published in Proc. 20th Inter- national Conference on Extending Database Technology (EDBT), March 21-24, 2017 - Venice, Italy: ISBN 978-3-89318-073-8, on OpenProceed- ings.org. Distribution of this paper is permitted under the terms of the Cre- ative Commons license CC-by-nc-nd 4.0 </span></p><p class="c4"><span class="c23">3</span><span class="c0">src. dst. time </span></p><p class="c4"><span class="c0">b c 8 e c 7 </span></p><p class="c4"><span class="c63">4 </span><span class="c23">5 </span><span class="c0">de</span><span class="c23">1 2 </span></p><p class="c4"><span class="c0">a </span></p><p class="c4"><span class="c23">6 </span><span class="c63">7 </span></p><p class="c4"><span class="c0">f </span></p><p class="c4"><span class="c0">b e 6 . .. .. </span></p><p class="c4"><span class="c10">b </span></p><p class="c4"><span class="c23">8</span><span class="c10">c </span></p><p class="c12"><span class="c0">e f 2 a d 1 </span><span class="c10">(a) </span></p><p class="c4"><span class="c0">(b) </span></p><p class="c4"><span class="c0">Figure 1: (a) An example Interaction graph. (b) The interaction in reverse order of time. </span></p><p class="c14"><span class="c0">it is becoming increasingly interesting to store and ana- lyze not only the connections in a network but the com- plete set of interactions as well. In many networks not only the connections between the nodes in the network are important, but also and foremost, how the connected nodes interact with each other. Examples of such net- works include email networks, in which not only the fact that two users are connected because they once exchanged emails is important, but also how often and with whom they interact. Another example is that of social networks where people become friends once, but may interact many times afterward, intensify their interactions over time, or completely stop interacting. The static network of inter- actions does not take these differences into account, even though these interactions are very informative for how in- formation spreads. To illustrate the importance of taking the interactions into account, Kempe et al. [</span><span class="c8">12</span><span class="c0">] showed how the temporal aspects of networks affect the properties of the graph. </span></p><p class="c14"><span class="c0">Figure </span><span class="c28">1a </span><span class="c0">gives an example of a toy interaction network. As can be seen, an interaction network is abstracted as a sequence of timestamped edges. A central notion in our study is that of an information channel; that is, a path consisting of edges that are increasing in time. For in- stance, in Figure </span><span class="c28">1a</span><span class="c0">, there is an information channel from a to e, but not from a to f. This notion of an informa- tion channel is not new, and was already studied under the name time-respecting path [</span><span class="c8">12</span><span class="c0">] and is a special case of temporal paths [</span><span class="c8">26</span><span class="c0">].In contrast to earlier work on informa- tion channels we additionally impose a constraint on the total duration of the information channel, thus reflecting the fact that in influence propagation the relevance of the message being propagated may deteriorate over time. To the best of our knowledge, our paper is the first one to study the notion of temporal paths with time constraints in influence propagation on interaction networks. </span></p><p class="c4"><span class="c23">2 </span><span class="c0">We propose a method to identify the most influential nodes in the network based on how many other nodes they could potentially reach through an information channel of </span></p><p class="c4"><span class="c23">6 </span></p><p class="c14"><span class="c0">limited timespan. As such, the information channels form an implicit propagation model learned from data. Most of the related work in the area of information propaga- tion in interaction or dynamic networks uses probabilis- </span></p><p class="c4"><span class="c23">4 </span></p><p class="c4"><span class="c23">3 </span></p><p class="c14"><span class="c0">tic models like the independent cascade(IC) model or the Linear Threshold(LT) model, and tries to learn the influ- ence probabilities that are assumed to be given by these models [</span><span class="c8">13</span><span class="c0">, </span><span class="c8">4</span><span class="c0">, </span><span class="c8">3</span><span class="c0">, </span><span class="c8">6</span><span class="c0">]. Another set of recent work focuses on deriving the hidden diffusion network by studying the cascade information of actions [</span><span class="c8">10</span><span class="c0">, </span><span class="c8">11</span><span class="c0">] or cascade of in- fection times [</span><span class="c8">8</span><span class="c0">, </span><span class="c8">24</span><span class="c0">]. These paper, however, use a very different model of interactions. For example, the work by Goyal et al. [</span><span class="c8">10</span><span class="c0">, </span><span class="c8">11</span><span class="c0">], every time an activity of a node a is repeated within a certain time span by a node b that is connected to a in the social graph, this is recorded as an interaction. Each user can execute each activity only once, and the strength of influence of one user over the other is expressed as the number of different activities that are repeated. While this model is very natural for certain social network settings, we believe that our model is much more natural for networks in which messages are exchanged, such as for instance email networks because activities such as sending an email can be executed repeat- edly and already include the interaction in itself. Further- more, [</span><span class="c8">11</span><span class="c0">] is not based on information channels, but on the notion of credit-distribution, and [</span><span class="c8">10</span><span class="c0">] does not include the time-respecting constraint for paths. </span></p><p class="c14"><span class="c0">One of the key differentiators of the techniques intro- duced here and earlier work is that next to an exact algo- rithm, we also propose an efficient one-pass algorithm for building an approximate influence oracle that can be used to identify top-k maximal influencers. Our algorithm is based on the same notion as shown in so-called sliding window HyperLogLog sketch [</span><span class="c8">15</span><span class="c0">] leading to an efficient, yet approximate solution. Experiments on various inter- action networks with our algorithm show the accuracy and scalability of our approximate algorithm, as well as how it outperforms algorithms that only take into account the static graph formed by the connected nodes. </span></p><p class="c4"><span class="c0">The contribution of this paper are as follows. </span></p><p class="c14"><span class="c0">&bull; Based on the notion of an Information Channel, we introduce the Influence Reachability Set of a node in a interaction network. </span></p><p class="c14"><span class="c0">&bull; We propose an exact but memory inefficient algo- rithm which calculates the Influence Reachability Set of every node in the network in one pass over the list of interactions. </span></p><p class="c14"><span class="c0">&bull; Next to the exact algorithm, an approximate sketch- based extension is made using a versioned Hyper- LogLog sketch. </span></p><p class="c14"><span class="c0">&bull; With the influence reachability sets of the nodes in our interaction network, we identify top-k influ- encers in a model-independent way. </span></p><p class="c14"><span class="c0">&bull; We propose a new Time Constrained Information Cascade Model for interaction networks derived from the Independent Cascade Model for static networks. </span></p><p class="c4"><span class="c0">&bull; We present the results of extensive experiments on six real world interaction network datasets and demon- strate the effectiveness of the time window based in- </span></p><p class="c4"><span class="c89">8 </span><span class="c23">5 </span><span class="c0">Figure 2: Interaction network example with mul- tiple information channels between node c and f </span></p><p class="c4"><span class="c0">fluence spread maximization over static graph based influence maximization. </span></p><p class="c4"><span class="c15">2. PRELIMINARIES </span></p><p class="c4"><span class="c0">Let V be a set of nodes. An interaction between nodes from V is defined as a triplet (u, v, t), where u, v &isin; V , and t is a natural number representing a time stamp. The interaction (u, v, t) indicates that node u interacted with node v at time t. Interactions are directed and could denote, for instance, the sending of a message. For a directed edge u &rarr; v, u is the source node and v is the destination node. An interaction network G(V,E) is a set of nodes V , together with a set E of interactions. We assume that every interaction has a different time stamp. We will use n = |V | to denote the number of nodes in the interaction network, and m = |E| to denote the total number of interactions. Time Constrained Information Cascade Model: For interaction networks, influence models such as the Inde- pendent Cascade Model or Linear Threshold Model no longer suffice as they do not take the temporal aspect into account and are meant for static networks. To ad- dress this shortcoming, we introduce a new model of Infor- mation Cascade for Interaction networks. The Time Con- strained Information Cascade Model (TCIC) is a variation of the famous Independent Cascade Model. This model forms the basis of our comparison with other baselines SKIM [</span><span class="c8">6</span><span class="c0">], PageRank and High Degree. We say a node is infected if it is influenced. For a given set of seed nodes we start by infecting the seed nodes at their first inter- action in the network and then start to spread influence to their neighbors with a fixed probability. The influence spread is constrained by the time window(&omega;) specified; i.e, once a seed node is infected at time stamp t it can spread the infection to another node via a temporal path only if the interaction on that path happens between time t and t + &omega;. For sake of simplicity we use a fixed infec- tion probability in our algorithms to simulate the spread nevertheless node specific probabilities or random proba- bilities could easily be used as well. In Algorithm </span><span class="c28">1 </span><span class="c0">we present the algorithm for the TCIC model. </span></p><p class="c4"><span class="c0">In order to Find highly influential nodes under the TCIC model we introduce the notion of Information Channel. </span></p><p class="c4"><span class="c0">Definition 1. (Information Channel) Information Chan- nel ic between nodes u and v in an interaction network G(V,E), is defined as a series of time increasing inter- actions from E satisfying the following conditions: ic = (u, n</span><span class="c7">1</span><span class="c0">,t</span><span class="c7">1</span><span class="c0">),(n</span><span class="c7">1</span><span class="c0">,n</span><span class="c7">2</span><span class="c0">,t</span><span class="c7">2</span><span class="c0">), ...(n</span><span class="c1">k</span><span class="c10">, v, t</span><span class="c1">k</span><span class="c10">) where t</span><span class="c1">1 </span><span class="c10">&lt; t</span><span class="c1">2 </span><span class="c10">&lt; .. &lt; </span><span class="c0">t</span><span class="c1">k</span><span class="c10">. The duration of the information channel ic is dur(ic) := </span><span class="c0">t</span><span class="c1">k </span><span class="c10">&minus; t</span><span class="c1">1 </span><span class="c10">+ 1 and the end time of the information channel </span><span class="c0">ic is end(ic) := t</span><span class="c1">k</span><span class="c10">. We denote the set of all information </span><span class="c0">channels between u and v as IC(u, v), and the set of all </span></p><p class="c4"><span class="c19">271 </span></p><p class="c4"><span class="c0">bd</span><span class="c23">1 </span></p><p class="c4"><span class="c10">c </span></p><p class="c4"><span class="c10">e </span><span class="c0">a </span></p><p class="c4"><span class="c0">f </span></p><p class="c4 c99"><span class="c0">Algorithm 1 Simulation with a given seed set and win- dow</span><span class="c10">Input: G(V,E) the interaction graph given as a time- </span><span class="c0">ordered list l</span><span class="c1">G </span><span class="c10">of (u, v, t), &omega;, and S the seed set. p is </span><span class="c0">the probability of infection spread on interaction. Output: Number of nodes influenced by the seed. Initially all nodes are inactive and for all activateTime is set to -1. for all (u, v, t) &isin; l</span><span class="c1">G </span><span class="c10">do </span></p><p class="c114"><span class="c0">if u &isin; S then </span></p><p class="c71"><span class="c0">u.isActive=true u.activateTime=t end if if u.isActive &amp; (t &minus; u.activateT ime) &le; &omega; then </span></p><p class="c109 c117"><span class="c0">With probability p v.isActive=true if u.activateTime &gt; v.activateTime then </span></p><p class="c79"><span class="c0">v.activateTime=u.activateTime end if end if end for Return: Count of nodes for which isActive is true. </span></p><p class="c25"><span class="c0">information channels of duration &omega; or less as IC</span><span class="c7">&omega;</span><span class="c0">(u, v). </span></p><p class="c46"><span class="c0">Notice that there can exist multiple information channels between two nodes u and v. For example, in Fig </span><span class="c28">2 </span><span class="c0">there are 2 information channels from a to f. The intuition of the information channel notion is that node u could only have sent information to node v if there exists a time respecting series of interactions connecting these two nodes. Therefore, nodes that can reach many other nodes through information channels are more likely to influence other nodes than nodes that have information channels to only few nodes. This notion is captured by the influence reachability set. </span></p><p class="c48"><span class="c0">Definition 2. (Influence reachability set) The Influence reachability set (IRS) &sigma;(u) of a node u in a network G(V,E) is defined as the set of all the nodes to which u has an information channel: </span></p><p class="c59"><span class="c0">&sigma;(u) := {v &isin; V | IC(u, v) = &empty;} . </span></p><p class="c99 c115"><span class="c0">Similarly, the influence set for a given maximal duration &omega; is defined as </span></p><p class="c118"><span class="c0">&sigma;</span><span class="c1">&omega;</span><span class="c10">(u) = {v &isin; V | &exist;ic &isin; IC(u, v) : dur(ic) &le; &omega;} . </span></p><p class="c99 c101"><span class="c0">The IRS of a node may change depending on the maximal duration &omega;. For example, in Figure </span><span class="c28">2 </span><span class="c0">&sigma;</span><span class="c1">3</span><span class="c10">(a) = {b, c, d} and </span><span class="c0">&sigma;</span><span class="c7">5</span><span class="c0">(a) = {b, c, d, f}. This is quite intuitive because as the maximal duration increases, longer paths become valid, hence increasing the size of the influence reachability set. Once we have the IRS for all nodes in a interaction net- work for a given window we can efficiently answer many interesting queries, such as finding top k influential nodes. Formally, the algorithms we will show in the next section solve the following problem: </span></p><p class="c95 c100"><span class="c0">Definition 3. (IRS-based Oracle Problem) Given an in- teraction network G(V,E), and a duration threshold &omega;, construct a data structure that allows to efficiently an- swer the following type of queries: given a set of nodes V &sube; V , what is the cardinality of the combined influence reachability sets of the nodes in V ; that is: </span><span class="c9">&#8739;</span><span class="c0">&#8739;</span><span class="c9">&#8899;</span><span class="c7">v&isin;V </span><span class="c9">&sigma;</span><span class="c22">&omega;</span><span class="c9">(v)&#8739;</span><span class="c0">&#8739;</span><span class="c10">. </span></p><p class="c14 c80"><span class="c0">First we will present an exact but memory inefficient so- lution that will maintain the sets &sigma;</span><span class="c1">&omega;</span><span class="c10">(v) for all nodes v. </span><span class="c0">Clearly this data structure will allow to get the exact car- dinality of the exact influence reachability sets, by tak- ing the unions of the individual influence reachability sets and discarding duplicate elements. The approximate al- gorithm on it&rsquo;s turn will maintain a much more memory efficient sketch of the sets &sigma;</span><span class="c7">&omega;</span><span class="c0">(v) that allows to take unions and estimate cardinalities. </span></p><p class="c112"><span class="c15">3. SOLUTION FRAMEWORK </span></p><p class="c52"><span class="c0">In this section, we present an algorithm to compute the IRS for all nodes in an interaction network in one pass over all interactions. In the following all definitions assume that an interaction network G(V,E) and a thresh- old &omega; have been given. We furthermore assume that the edges are ordered by time stamp, and will iterate over the interactions in reverse order of time stamp. As such, our algorithm is a one-pass algorithm, as it treats every in- teraction exactly once and, as we will see, the time spent per processed interaction is very low. It is not a streaming algorithm because it can not process interactions as they arrive. The reverse processing order of the edges is essen- tial in our algorithm, because of the following observation. </span></p><p class="c68"><span class="c0">Lemma 1. Let G(V, E) be an interaction network, and let (u, v, t) be an interaction with a time stamp before any time stamp in E; i.e., for all interactions (u ,v ,t ) &isin; E, t &gt; t. G (V,E&cup;{(u, v, t)}) denotes the interaction network that is obtained by adding interaction (u, v, t) to G. Then, for all w &isin; V \ {u}, IRS</span><span class="c1">&omega;</span><span class="c10">(w) is equal in G and </span><span class="c0">G .</span><span class="c10">Proof. Suppose that IRS</span><span class="c1">&omega;</span><span class="c10">(w) changes by adding (u, v, t) </span><span class="c0">to E. This means that there must exist an information channel ic from w to another node in G that did not yet exist in G. This information channel hence necessar- ily contains the interaction (u, v, t). As t was the earliest time in the interaction network G , (u, v, t) has to be the first interaction in this information channel. Therefore w must be u and thus w &isin; V \ {u}. </span></p><p class="c70"><span class="c0">This straightforward observation logically leads to the strategy of reversely scanning the list of interactions. Ev- ery time a new interaction (u, v, t) is added, only the IRS of the source node u needs to be updated. Notice that there is no symmetric definition for the forward scan of a list of interactions; if a new interaction arrives with a time stamp later than any other time stamp in the interaction network, potentially the IRS of every node in the network changes, leading to an unpredictable and potentially un- acceptable update time per interaction. </span></p><p class="c90"><span class="c0">In order to exploit the observation of Lemma </span><span class="c28">1</span><span class="c0">, we keep a summary of the interactions processed so far. </span></p><p class="c56"><span class="c0">Definition 4. (IRS Summary) For each pair u, v &isin; V , such that IC</span><span class="c1">&omega;</span><span class="c10">(u, v) = &empty;, &lambda;(u, v) is defined as the end time </span><span class="c0">of the earliest information channel of length &omega; or less from u to v. That is: </span></p><p class="c69"><span class="c0">&lambda;(u, v) := min({end(ic) | ic &isin; IC</span><span class="c7">&omega;</span><span class="c0">(u, v)}) </span></p><p class="c93"><span class="c0">The IRS summary &phi;</span><span class="c1">&omega;</span><span class="c10">(u) is now defined as follows: </span></p><p class="c84"><span class="c0">&phi;</span><span class="c7">&omega;</span><span class="c0">(u) = {(v, &lambda;(u, v)) | v &isin; IRS</span><span class="c7">&omega;</span><span class="c0">(u)} . </span></p><p class="c80 c94"><span class="c0">That is, we will be keeping for every node u the list of all other nodes that are reachable by an information </span></p><p class="c92"><span class="c19">272 </span></p><p class="c14"><span class="c0">channel of duration at most &omega;. Furthermore, for ev- ery such reachable node v, we keep the earliest time it can be reached from u by an information channel. The IRS of a node u can easily be computed from &phi;</span><span class="c1">&omega;</span><span class="c10">(u) as </span><span class="c0">&sigma;</span><span class="c7">&omega;</span><span class="c0">(u) = {v | &exist;t : (v, t) &isin; &phi;(u)}. On the other hand, the information stored in the summary consisting of &phi;(u) for every u is sufficient to efficiently update it whenever we process the next edge in the reverse order as we shall see. </span></p><p class="c14"><span class="c0">Example 1. In Figure </span><span class="c28">2</span><span class="c0">, &phi;</span><span class="c1">3</span><span class="c10">(a) = {(b,1),(d,2),(c, 4)} </span><span class="c0">and &phi;</span><span class="c7">3</span><span class="c0">(c) = {(f,5),(e,3)}. There are 2 information chan- nels between c and f, one with dur(ic) = 1 and end(ic) = 8 and another with dur(ic) = 3 and end(ic) = 5 and hence &lambda;(c, f) = 5. </span></p><p class="c4"><span class="c15">3.1 The Exact algorithm </span></p><p class="c14"><span class="c0">We illustrate our algorithm using the running example in Figure </span><span class="c28">1a</span><span class="c0">. Table </span><span class="c28">1b </span><span class="c0">shows all the interactions for the graph reverse ordered by time stamp. Recall that we pro- cess the edges in time decreasing order. The algorithm is detailed in Algorithm </span><span class="c28">2</span><span class="c0">. First, we initialize all &phi;(u) to the empty set. Then, whenever we process an interaction (u, v, t), we know from Lemma </span><span class="c28">1 </span><span class="c0">that only the summary &phi;(u) may change. The following lemma explains how the summary &phi;(u) changes: </span></p><p class="c14"><span class="c0">Lemma 2. Let G(V,E) be an interaction network, and let (u, v, t) be an interaction with a time stamp before any time stamp in E; i.e., for all interactions (u ,v ,t ) &isin; E, t &gt; t. G (V,E&cup;{(u, v, t)}) denotes the interaction network that is obtained by adding the interaction (u, v, t) to G. Let &phi; (u) denote the summary of u in G and &phi;(u) that in G. Then, &phi; (u) =&darr; ({(v, t)} &cup; &phi;(u) &cup; {(z,t ) &isin; &phi;(v) | t &minus; t + 1 &le; &omega;}), where &darr; (A) denotes A \ {(v, t) &isin; A | &exist;(v, t ) &isin; A : t &lt; t}. </span></p><p class="c4"><span class="c0">Proof. Let ic be an information channel of duration maximally &omega; from u to z in G that minimizes end(ic). Then there are three options: (1) ic is the information channel from u to v formed by the single interaction (u, v, t) that was added. The end time of this information chan- nel is t. (2) ic was already present in G, and hence (z,end(ic)) &isin; &phi;(u), or (3) ic is a new information channel. Using similar arguments as in the proof of Lemma </span><span class="c28">1</span><span class="c0">, we can show that ic needs to start with the new interaction and that the remainder of ic forms an information channel ic from v to z in G with end(ic ) = end(ic). In that case (z,end(ic)) &isin; &phi;(v). Given the constraint on duration we furthermore need to have end(ic) &minus; t + 1 &le; &omega;. Hence, &phi; (u) needs to be a subset of {(v, t)} &cup; &phi;(u) &cup; {(z,t ) &isin; &phi;(v) | t &minus; t + 1 &le; &omega;}, and we can obtain &phi; (u) by only keeping those pairs that are not dominated. </span></p><p class="c4"><span class="c0">Example 2. Figure </span><span class="c28">1a </span><span class="c0">represents a small interaction net- work and Table </span><span class="c28">1b </span><span class="c0">shows the edges in order of time. For &omega; = 3 the Influence Summary Set will update as follows: </span></p><p class="c12"><span class="c7">a b c d e f </span><span class="c0">&phi; {} {} {} {} {} {} </span><span class="c7">(b,c,8) </span><span class="c10">&minus;&rarr; </span><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; {} (c,8) {} {} {} {} </span><span class="c7">(e,c,7) </span><span class="c10">&minus;&rarr; </span><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; {} (c,8) {} {} (c,7) {} </span></p><p class="c4"><span class="c7">(b,e,6) </span><span class="c10">&minus;&rarr; </span><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; {} (c,7)(e,6) {} {} (c,7) {} </span></p><p class="c4"><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; </span><span class="c7">(a,b,5) </span><span class="c10">&minus;&rarr; </span></p><p class="c14"><span class="c0">(b,5) (c,7) (e,6) </span></p><p class="c4"><span class="c0">(c,7) (e,6) </span><span class="c9">{} {} (c,7) {} </span></p><p class="c4"><span class="c7">(e,b,4) </span><span class="c10">&minus;&rarr; </span></p><p class="c4"><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; </span></p><p class="c14"><span class="c0">(b,5) (c,7) (e,6) </span></p><p class="c4"><span class="c0">(c,7) (e,6) </span><span class="c9">{} {} (c,7) </span></p><p class="c4"><span class="c0">(b,4) </span><span class="c9">{} </span></p><p class="c4"><span class="c7">(d,e,3) </span><span class="c10">&minus;&rarr; </span></p><p class="c4"><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; </span></p><p class="c14"><span class="c0">(b,5) (c,7) (e,6) </span></p><p class="c27"><span class="c0">(c,7) (e,6) </span><span class="c9">{} (e, 3) </span><span class="c0">(b,4) </span></p><p class="c4"><span class="c0">(c,7) (b,4) </span><span class="c9">{} </span></p><p class="c4"><span class="c7">(e,f,2) </span><span class="c10">&minus;&rarr; </span></p><p class="c4"><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; </span></p><p class="c14"><span class="c0">(b,5) (c,7) (e,6) </span></p><p class="c27"><span class="c0">(c,7) (e,6) </span><span class="c9">{} (e,3) </span><span class="c0">(b,4) </span></p><p class="c4"><span class="c0">(c,7) (b,4) </span></p><p class="c4"><span class="c0">{} (f,2) </span></p><p class="c4"><span class="c7">(a,d,1) </span><span class="c10">&minus;&rarr; </span></p><p class="c4"><span class="c7">a b c d e f </span></p><p class="c4"><span class="c0">&phi; </span></p><p class="c4"><span class="c0">(b,5) (c,7) (e,3) (d,1) </span></p><p class="c27"><span class="c0">(c,7) (e,6) </span><span class="c9">{} (e,3) </span><span class="c0">(b,4) </span></p><p class="c14"><span class="c0">(c,7) (b,4) (f,2) </span></p><p class="c4"><span class="c0">{} </span></p><p class="c14"><span class="c0">While processing the edge (b, e,6), first we add (e,6) in the summary of d and then add (c,7) from the summary of e in summary of b. As the summary of b already had (c,8), the value will be updated. Next, during the processing of edge (a, b,5) the summary of a is updated first by adding (b,5) then while merging the summary of b in a we will ignore (e,8) because the duration of the channel is 4 and the permitted window length is 3. The only addition is hence (c,7). </span></p><p class="c4"><span class="c0">Theorem 1. Algorithm </span><span class="c28">2 </span><span class="c0">updates the IRS summary correctly. </span></p><p class="c14"><span class="c0">Proof. This proof follows by induction. For the empty list of transactions, the algorithm produced the empty summary. This is our base case. Then, for every in- teraction that is added in the for loop, it follows from Lemma </span><span class="c28">1 </span><span class="c0">and Lemma </span><span class="c28">2 </span><span class="c0">that the summaries are correctly updated to form the summary of the interaction graph with one more (earlier) interaction. After all interactions have been processed, the summary is hence that of the complete interaction graph. </span></p><p class="c4"><span class="c0">Lemma 3. Algorithm </span><span class="c28">2 </span><span class="c0">runs in time O(mn) and space O(n</span><span class="c22">2</span><span class="c0">), where n = |V | and m = |E|. </span></p><p class="c14"><span class="c0">Proof. Each edge in E is processed exactly once and for each edge, both Add and Merge are called once. We assume that the summary sets &phi;(u) are implemented with hash tables such that looking up the element (v, t) for a given v takes constant time only. Under this assumption, the Add function has constant complexity. The Merge function calls Add for every item in &phi;(v) at least once. The number of items in &phi;(v) is upper bounded by n and hence the time complexity of one merge operation is at most O(n). This leads to the upper bound O(mn) in total. </span></p><p class="c14"><span class="c0">For the space complexity, note that in the worst case for each node there is an information channel to every other node of duration at most &omega;. In that case, the size of the individual summary &phi;(v) of every node v is O(n) which leads to a space complexity of O(n</span><span class="c22">2</span><span class="c0">) in total. </span></p><p class="c4"><span class="c0">As we can see from Lemma </span><span class="c28">3 </span><span class="c0">the memory requirements for the exact algorithm is in worst case quadratic in the </span></p><p class="c4"><span class="c19">273 </span></p><p class="c4 c99"><span class="c0">Algorithm 2 Influence set with Exact algorithm Input: Interaction graph G(V,E). l</span><span class="c1">G </span><span class="c10">is the list of inter- </span></p><p class="c67"><span class="c0">actions reversely ordered by time stamp Threshold &omega; (maximum allowed duration of an influ- ence channel) Output: &phi;(u) for all u &isin; V </span></p><p class="c72"><span class="c0">function Add(&phi;(u),(v, t)) </span></p><p class="c110"><span class="c0">if &exist;t : (v, t ) &isin; &phi;(u) then </span></p><p class="c57"><span class="c0">&#8883; There is at most one such entry if t&lt;t then </span></p><p class="c34"><span class="c0">&phi;(u)=(&phi;(u) \ (v, t )) &cup; (v, t) end if else</span><span class="c10">&phi;(u) = &phi;(u) &cup; {(v, t)} </span><span class="c0">end if end function </span></p><p class="c104"><span class="c0">function Merge(&phi;(u),&phi;(v),t,&omega;) </span></p><p class="c51"><span class="c0">for all (x, t</span><span class="c1">x</span><span class="c10">) &isin; &phi;(v) do </span></p><p class="c41"><span class="c0">if t</span><span class="c7">x </span><span class="c0">&minus; t&lt;&omega; then Add(&phi;(u),(x, t</span><span class="c7">x</span><span class="c0">)) end if end for end function </span></p><p class="c42"><span class="c0">Initialize: &phi;(u) &larr; &empty; &forall;u &isin; V for all (u, v, t) &isin; l</span><span class="c1">G </span><span class="c10">do </span><span class="c0">Add(&phi;(u),(v, t)) Merge(&phi;(u),&phi;(v),t,&omega;) end for </span></p><p class="c3"><span class="c0">number of nodes of the graph. This will not scale well for large graphs as we want to keep this data structure in memory for efficient querying. Hence in the next section we will present an approximate but more memory and time efficient version of the algorithm. </span><span class="c15">3.2 Approximate Algorithm </span></p><p class="c29"><span class="c0">Algorithm presented in the previous section computes the IRS exactly, albeit at the cost of high space com- plexity and update time. In this section, we describe an approximate algorithm which is much more efficient in terms of memory requirements and update time. The approximate algorithm is based on an adaptation of the HyperLogLog sketch [</span><span class="c8">9</span><span class="c0">]. </span></p><p class="c49"><span class="c45">3.2.1 HyperLogLog Sketch </span></p><p class="c29"><span class="c0">A HyperLogLog (HLL) sketch [</span><span class="c8">9</span><span class="c0">] is a probabilistic data structure for approximately counting the number of dis- tinct items in a stream. Any exact solution for counting the number of distinct items in a stream would require O(N) space with N the cardinality of the set. The HLL sketch, however, approximates this cardinality with no more than O(log(log(N))) bits. The HLL sketch is an array with &beta; = 2</span><span class="c22">k </span><span class="c0">cells (c</span><span class="c1">1</span><span class="c10">,...,c</span><span class="c1">&beta;</span><span class="c10">), where k is a constant </span><span class="c0">that controls the accuracy of the approximation. Initially all cells are 0. Every time an item x in the stream ar- rives, the HLL sketch is updated as follows: the item x is hashed deterministically to a positive number h(x). The first k bits of this number determines the 0-based index of the cell in the HLL sketch that will be updated. We de- note this number &iota;(x). For the remaining bits in h(x), the position of the least significant bit that is 1 is computed. This number is denoted &rho;(x). If &rho;(x) is larger than c</span><span class="c1">&iota;(x)</span><span class="c0">, c</span><span class="c1">&iota;(x) </span><span class="c10">will be overwritten with &rho;(x). </span></p><p class="c4 c96"><span class="c0">For example, suppose that we use a HLL sketch with &beta; = 2</span><span class="c22">2 </span><span class="c0">= 4 cells. Initially the sketch is empty: </span></p><p class="c39"><span class="c0">0 0 0 0 </span></p><p class="c122"><span class="c0">Suppose now item a arrives with h(a) = 1110100110010110</span><span class="c1">b</span><span class="c10">. </span><span class="c0">The first 2 bits are used to determine &iota;(a) = 11</span><span class="c7">&beta; </span><span class="c0">= 3. The rightmost 1 in the binary representation of h(a) is in posi- tion 2, and hence c</span><span class="c7">3 </span><span class="c0">becomes 2. Suppose that next items arrive in the stream with (c</span><span class="c1">&iota;(x)</span><span class="c0">,&rho;(x)) equal to: (c</span><span class="c1">1</span><span class="c10">,3), </span><span class="c0">(c</span><span class="c1">0</span><span class="c10">,7), (c</span><span class="c1">2</span><span class="c10">,2), and (c</span><span class="c1">1</span><span class="c10">,2), then the content of the sketch </span><span class="c0">becomes: </span></p><p class="c58"><span class="c0">7 3 2 2 </span></p><p class="c61"><span class="c0">It is clear that duplicate items will not change the sum- mary. Furthermore, for a random element x, P(&rho;(x) &ge; l) = 2</span><span class="c22">&minus;l</span><span class="c0">. Hence, if d different items have been hashed into cell c</span><span class="c1">&iota;</span><span class="c10">, then P(c</span><span class="c1">&iota; </span><span class="c10">&ge; l)=1 &minus; (1 &minus; 2</span><span class="c7">&minus;l</span><span class="c10">)</span><span class="c7">d</span><span class="c10">. This prob- </span><span class="c0">ability depends on d, and all c</span><span class="c7">i </span><span class="c0">are independent. Based on a clever exploitation of these observations, Flajolet et al. [</span><span class="c8">9</span><span class="c0">] showed how the number of distinct items in a stream can be approximated from the HLL sketch. Last but not least, two HLL sketches can easily be combined into a sin- gle sketch by taking for each index the maximum of the values in that index of both sketches. </span></p><p class="c123"><span class="c45">3.2.2 Versioned HLL Sketch </span></p><p class="c52"><span class="c0">The HLL sketch is an excellent tool for our purpose; ev- ery time an edge (a, b) needs to be processed (recall that we process the edges in reverse chronological order), all nodes reachable by an information channel from b, are also reachable by an information channel from a. Therefore, if we keep the list of reachable nodes as a HLL sketch, we can update the reachable nodes from a by unioning in the HLL sketch of the reachable nodes from b into the HLL sketch of those reachable from a. One aspect, how- ever, that is not taken into account here is that we only consider information channels of length &omega;. Hence, only those nodes reachable from b by an information channel that ends within time window &omega; should be considered. Therefore, we developed a so-called versioned HLL sketch vHLL. The vHLL maintains for each cell c</span><span class="c7">i </span><span class="c0">of the HLL a list L</span><span class="c1">i </span><span class="c10">of &rho;(x)-values together with a timestamp and is </span><span class="c0">updated as follows: let t</span><span class="c7">current </span><span class="c0">be the current time; peri- odically entries (r, t) with t&minus;t</span><span class="c1">current</span><span class="c10">+1 &gt; &omega; are removed </span><span class="c0">from vHLL. Whenever an item x arrives, &rho;(x) and &iota;(x) are computed, and the pair (&rho;(x),t</span><span class="c7">current</span><span class="c0">) is added to the list L</span><span class="c1">&iota;(x)</span><span class="c10">. Furthermore, all pairs (r, t) such that r &le; &rho;(x) </span><span class="c0">are removed from L</span><span class="c1">&iota;(x)</span><span class="c10">. The rationale behind the update </span><span class="c0">procedure is as follows: at any point in time t</span><span class="c1">current </span><span class="c10">we </span><span class="c0">need to be able to estimate the number of elements x that arrived within the time interval [t</span><span class="c7">current</span><span class="c0">,t</span><span class="c7">current</span><span class="c0">+&omega;&minus;1]. Therefore it is essential to know the maximal &rho;(x) of all x that arrived within this interval. We keep those pairs (r, t) in L</span><span class="c1">&iota; </span><span class="c10">such that r may, at some point, become the maxi- </span><span class="c0">mal value as we shift the window further back in time. It is easy to see that any pair (r, t) such that r &le; &rho;(x) for a newly arrived x at t</span><span class="c1">current </span><span class="c10">will always be dominated by </span><span class="c0">(&rho;(x),t</span><span class="c7">current</span><span class="c0">). On the other hand, if &rho;(x) &lt; r we still do have to store (&rho;(x),t</span><span class="c1">current</span><span class="c10">) as (r, t) will leave the window </span><span class="c0">before (&rho;(x),t</span><span class="c7">current</span><span class="c0">) will. </span></p><p class="c107"><span class="c0">Example 3. Suppose that the elements e, d, c, a, b, a have to be added to the vHLL. Recall that we process the stream in reverse order, hence the updates are processed in the following order: (a, t</span><span class="c7">6</span><span class="c0">), (b, t</span><span class="c7">5</span><span class="c0">), (a, t</span><span class="c7">4</span><span class="c0">), (c, t</span><span class="c7">3</span><span class="c0">), (d, t</span><span class="c7">2</span><span class="c0">), </span></p><p class="c82"><span class="c19">274 </span></p><p class="c4"><span class="c0">Algorithm (e, t</span><span class="c7">1</span><span class="c0">). Let &iota; and &rho; be as follows for the elements in V : </span></p><p class="c4"><span class="c0">3 Approximate Algorithm for IRS </span></p><p class="c14"><span class="c0">item a b c d e &iota; 1 3 3 2 2 &rho; 3 1 2 2 1 </span></p><p class="c4"><span class="c0">The subsequent vHLL sketches are respectively lowing: </span></p><p class="c4"><span class="c0">function ApproxAdd(&phi;(u),(&rho;(v),t),&iota;(v)) </span></p><p class="c4"><span class="c0">if &exist;(&rho;, t ) &isin; L</span><span class="c7">&iota; </span><span class="c0">: (&rho;, t ) dominates (&rho;(v),t) then </span></p><p class="c4"><span class="c0">Ignore (&rho;(v),t) </span></p><p class="c4"><span class="c0">the fol- </span></p><p class="c4"><span class="c0">else</span><span class="c10">if &exist;(&rho;, t ) &isin; L</span><span class="c1">&iota; </span><span class="c10">: (&rho;(v),t) dominates (&rho;, t ) then </span></p><p class="c4"><span class="c0">remove (&rho;, t ) from L</span><span class="c7">&iota; </span><span class="c0">{} {} {} {} </span><span class="c7">(a,t</span><span class="c10">&minus;&rarr; </span><span class="c37">6</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">6</span><span class="c10">) {} {} </span><span class="c7">(b,t</span><span class="c10">&minus;&rarr; </span><span class="c37">5</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">6</span><span class="c10">) {} (1,t</span><span class="c1">5</span><span class="c10">) </span></p><p class="c12"><span class="c0">end if Append (&rho;(v),t) in L</span><span class="c7">&iota; </span><span class="c0">end if end function </span><span class="c7">(a,t</span><span class="c10">&minus;&rarr; </span><span class="c37">4</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">4</span><span class="c10">) {} (1,t</span><span class="c1">5</span><span class="c10">) </span><span class="c7">(c,t</span><span class="c10">&minus;&rarr; </span><span class="c37">3</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">4</span><span class="c10">) {} (2,t</span><span class="c1">3</span><span class="c10">) </span></p><p class="c4"><span class="c0">function ApproxMerge(&phi;(u),&phi;(v),t,&omega;) </span></p><p class="c4"><span class="c0">while i&lt;&beta; do </span></p><p class="c4"><span class="c0">for all (x, t</span><span class="c7">x</span><span class="c0">) &isin; L</span><span class="c7">i </span><span class="c0">do &#8883; Iterate over &phi;(v) </span><span class="c7">(d,t</span><span class="c10">&minus;&rarr; </span><span class="c37">2</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">4</span><span class="c10">) (2,t</span><span class="c1">2</span><span class="c10">) (2,t</span><span class="c1">3</span><span class="c10">) </span><span class="c7">(e,t</span><span class="c10">&minus;&rarr; </span><span class="c37">1</span><span class="c7">) </span><span class="c10">{} (3,t</span><span class="c1">4</span><span class="c10">) (2,t</span><span class="c1">2</span><span class="c10">),(1,t</span><span class="c1">1</span><span class="c10">) (2,t</span><span class="c1">3</span><span class="c10">) </span></p><p class="c4"><span class="c0">if t</span><span class="c1">x </span><span class="c10">&minus; t&lt;&omega; then </span></p><p class="c4"><span class="c0">ApproxAdd(&phi;(u),(x, t</span><span class="c1">x</span><span class="c10">),i) </span><span class="c0">end if </span></p><p class="c14"><span class="c0">Notice that also two vHLL sketches can be easily com- bined by merging them. For each cell &iota;, we take the union of the respective in the result that lists are L</span><span class="c7">&iota; </span><span class="c0">dominated and L </span><span class="c1">&iota; </span><span class="c0">and by remove a end for </span></p><p class="c27"><span class="c0">i + + end while end function </span></p><p class="c14"><span class="c0">Proof. In the ApproxMerge function the while loop will run for &beta; iterations and the inner for loop will run for an expected of log(&omega;) items(from Lemma </span><span class="c28">4</span><span class="c0">). Hence time complexity would be O(&beta; log(&omega;)O(ApproxAdd)). </span></p><p class="c14"><span class="c0">Now in the ApproxAdd function there are at-most log(&omega;) comparisons, hence O(ApproxAdd) = O(log(&omega;)). For each edge ApproxAdd and ApproxMerge are called only once. Hence O(m&beta;(log(&omega;))</span><span class="c22">2</span><span class="c0">) is the expected time complexity. </span></p><p class="c4"><span class="c0">Lemma 6. The expected space complexity for the Al- gorithm </span><span class="c28">3 </span><span class="c0">is O(n&beta;(log(&omega;))</span><span class="c22">2</span><span class="c0">), where n = |V | and m = |E|. </span></p><p class="c14"><span class="c0">Proof. From Lemma </span><span class="c28">4 </span><span class="c0">the expected size of one vHLL sketch is O(&beta;(log(&omega;))</span><span class="c22">2</span><span class="c0">). There will be only one vHLL sketch for each node, hence, expected space complexity is O(n&beta;(log(&omega;))</span><span class="c22">2</span><span class="c0">). </span></p><p class="c4"><span class="c15">4. APPLICATIONS </span></p><p class="c4"><span class="c15">4.1 Influence Oracle: </span></p><p class="c14"><span class="c0">Given the Influence Reachability Set of an interaction network computing the influence spread of a given seed set, S &sube; V is straightforward. The influence spread for seed set S is computed as: </span></p><p class="c12"><span class="c0">Inf (S) = </span><span class="c9">&#8899;</span><span class="c7">u&isin;S </span><span class="c0">all pairs (r, t) pair (r ,t ) that came from the other list with t &lt; t and r &ge; r. If the lists are stored in order of time, this merge operation can be executed in time linear in the length of the lists. </span></p><p class="c4"><span class="c0">Example 4. Consider the following two vHLL sketches: </span></p><p class="c4"><span class="c0">{} (3,t</span><span class="c1">4</span><span class="c10">) (1,t</span><span class="c1">1</span><span class="c10">),(2,t</span><span class="c1">2</span><span class="c10">) (2,t</span><span class="c1">3</span><span class="c10">) </span></p><p class="c4"><span class="c0">{(5,t</span><span class="c1">1</span><span class="c10">)} (3,t</span><span class="c1">2</span><span class="c10">) (4,t</span><span class="c1">3</span><span class="c10">) (1,t</span><span class="c1">4</span><span class="c10">) </span><span class="c0">The result of merging them is: </span></p><p class="c4"><span class="c0">{(5,t</span><span class="c7">1</span><span class="c0">)} (3,t</span><span class="c7">2</span><span class="c0">) (1,t</span><span class="c7">1</span><span class="c0">),(2,t</span><span class="c7">2</span><span class="c0">),(4,t</span><span class="c7">3</span><span class="c0">) (2,t</span><span class="c7">3</span><span class="c0">) </span></p><p class="c4"><span class="c0">Note that adding versioning to the HLL sketch comes at a price. </span></p><p class="c4"><span class="c0">Lemma 4. The expected space for storing a vHLL sketch for a window length &omega; is O(&beta;(log(&omega;)</span><span class="c22">2</span><span class="c0">)). </span></p><p class="c14"><span class="c0">Proof. The size of each pair (r, t) stored in a list L</span><span class="c1">&iota; </span><span class="c10">is </span><span class="c0">dominated by t and takes space O(log(&omega;)). In worst case, all elements in the window x</span><span class="c1">current</span><span class="c10">,...,x</span><span class="c1">current+&omega;&minus;1 </span><span class="c10">are </span><span class="c0">different and all arrive into the same cell c</span><span class="c7">&iota;</span><span class="c0">. In that case, the expected number of pairs in L&iota; is E[X</span><span class="c1">1 </span><span class="c10">+ X</span><span class="c1">2 </span><span class="c10">+ ... + </span><span class="c0">X</span><span class="c1">&omega;&minus;1</span><span class="c10">] where X</span><span class="c1">i </span><span class="c10">denotes the following statistical vari- </span><span class="c0">able: X</span><span class="c7">i </span><span class="c0">equals 1 if (&rho;(x</span><span class="c7">i</span><span class="c0">),t</span><span class="c7">current+i&minus;1</span><span class="c0">) is in L&iota; and 0 otherwise. This means that X</span><span class="c1">i </span><span class="c10">= 1 if and only if </span><span class="c0">&rho;(x</span><span class="c7">i</span><span class="c0">) &gt; max{&rho;(x</span><span class="c7">1</span><span class="c0">),...,&rho;(x</span><span class="c7">i&minus;1</span><span class="c0">))}. As each &rho;(x</span><span class="c7">j</span><span class="c0">), j &le; i has the same chance to be the largest, P(X</span><span class="c1">i </span><span class="c10">= 1) &le; </span><span class="c0">Hence we get: </span></p><p class="c4"><span class="c7">1</span><span class="c1">i </span><span class="c0">. </span></p><p class="c4"><span class="c0">E[|L</span><span class="c7">&iota;</span><span class="c0">|] &le; E[X</span><span class="c7">1 </span><span class="c0">+ ... + X</span><span class="c7">&omega;&minus;1</span><span class="c0">] &le; </span></p><p class="c4"><span class="c10">&sum;</span><span class="c7">&omega;</span><span class="c1">i=1 </span></p><p class="c4"><span class="c0">1</span><span class="c10">i </span><span class="c0">= O(log(&omega;)) . </span></p><p class="c4"><span class="c0">&sigma;(u) (1) </span></p><p class="c12"><span class="c0">HyperLogLog sketch union requires taking the maximum at each bucket index &iota; which is very efficient, so the the time complexity would be O(|S|l). </span><span class="c45">3.2.3 vHLL-Based Algorithm </span></p><p class="c14"><span class="c0">The approximate algorithm is very similar to the ex- act algorithm </span><span class="c28">2</span><span class="c0">; instead of using exact sets we use the more compact versioned HyperLogLog sketch. Add and Merge are the only functions which need to be updated as per the new sketch everything else will remain the same as shown in algorithm </span><span class="c28">2</span><span class="c0">. We will just present the ApproxAdd and ApproxMerge functions in Algorithm </span><span class="c28">3</span><span class="c0">. </span></p><p class="c4"><span class="c15">4.2 Influence Maximization: </span></p><p class="c12"><span class="c0">Influence Maximization deals with the problem of find- ing top k seed nodes which will maximize the influence spread. After the pre processing stage of computing IRS we can use a greedy approach to find the top-k seed nodes by using the Influence oracle. First we show the complex- ity of the top-k most influential nodes problem is NP- hard and then show that the Influence oracle function is Lemma 5. The expected time complexity for Algorithm </span><span class="c28">3 </span></p><p class="c4"><span class="c0">monotone and submodular. Hence we can use a greedy is O(m&beta;(log(&omega;))</span><span class="c22">2</span><span class="c0">), where n = |V | and m = |E|. </span></p><p class="c4"><span class="c0">approximation approach. </span></p><p class="c4"><span class="c19">275 </span></p><p class="c4 c95"><span class="c0">Lemma 7. Influence maximization under the Influence Reachability Set model is NP-hard. </span></p><p class="c119 c95"><span class="c0">Proof. Given the Influence Reachability Set for all the nodes the problem of finding a subset of k nodes such that the union is maximum is a problem which is similar to the problem of maximum coverage problem. As the later is a NP-hard problem we deduce that the given problem is NP-hard. </span></p><p class="c95 c111"><span class="c0">Lemma 8. The influence function &sigma;(S) is submodular and monotone. </span></p><p class="c95 c119"><span class="c0">Proof. First we will prove that Inf (S) is a submodu- lar function. Let S and T be two sets of seed nodes such that S &sub; T. Let x be another node not in T. Now, let the marginal gain of adding x in S, i.e., Inf(S + x) &minus; Inf(S) = P. P is the set of those nodes for which there is no path from S and hence these should belong to Inf(x). Let the marginal gain of adding x in T,i.e., Inf(T +x)&minus;Inf(T) = P . It is clear that P &sube; P, as oth- erwise there will be a node u for which there is a path from S but not from T and this is not possible given S &sub; T. Hence Inf(S + x) &minus; Inf(S) &ge; Inf(T + x) &minus; Inf(T). </span></p><p class="c87"><span class="c0">It is obvious to see the that Inf is monotone as it is a increasing function, adding a new node in the seed set will never decrease the influence, and hence if S &sub; T then Inf (S) &le; Inf (T) </span></p><p class="c21"><span class="c0">Greedy Approach for Influence Maximization: </span></p><p class="c16"><span class="c0">Algorithm </span><span class="c28">4 </span><span class="c0">outlines the details for the greedy approach. We start by first sorting the nodes based on the size of the Influence Reachability Set. The node with maximum IRS set size becomes the most influential node and is taken as the first node in seed set. Next at each stage we iterate through the sorted list and check the gain by using in- fluence oracle of the already selected nodes and the new node. The node which results in maximum gain is added into the seed set. </span></p><p class="c60"><span class="c0">Algorithm 4 Influence Maximization using IRS Input: The Influence set &sigma;</span><span class="c1">u</span><span class="c10">&forall;u &isin; V and the number of </span></p><p class="c103"><span class="c0">seed nodes to find is k initialize selected &larr;&empty;&and; covered &larr; &empty; Sort u &isin; V descending with respect to |&sigma;</span><span class="c1">u</span><span class="c10">|. Save this </span><span class="c0">sorted list as l while selected &lt; k do </span></p><p class="c78"><span class="c0">gain =0; u</span><span class="c7">s </span><span class="c0">= &empty; for all u &isin; l do </span></p><p class="c76"><span class="c0">if |covered &cup; &sigma;</span><span class="c1">u</span><span class="c10">|&minus;|covered| &gt; gain then </span></p><p class="c85"><span class="c0">gain = |covered &cup; &sigma;</span><span class="c7">u</span><span class="c0">|&minus;|covered| u</span><span class="c1">s </span><span class="c10">= {u} </span><span class="c0">end if if gain &gt; &sigma;</span><span class="c1">u </span><span class="c10">then </span></p><p class="c113"><span class="c0">break; end if end for selected &larr; selected &cup; u</span><span class="c7">s</span><span class="c0">; covered &larr; covered &cup; &sigma;</span><span class="c7">u</span><span class="c37">s </span><span class="c10">end while </span></p><p class="c75"><span class="c15">5. RELATED WORK </span></p><p class="c29"><span class="c0">The problem of Influence Maximization and Influence spread prediction is a well know problem. Broadly, the work in this area can be categorized into two main cate- gories. The first category is based on static graphs [</span><span class="c8">7</span><span class="c0">, </span><span class="c8">23</span><span class="c0">, </span></p><p class="c14 c80"><span class="c8">13</span><span class="c0">, </span><span class="c8">6</span><span class="c0">] where the underlying graph is already given and the probability of a node getting influenced is derived from probabilistic simulations. The second category is data driven, where the underlying influence graph is de- rived based on a relationship such as friendship between two users or common action within a specified time [</span><span class="c8">24</span><span class="c0">, </span><span class="c8">8</span><span class="c0">, </span><span class="c8">11</span><span class="c0">, </span><span class="c8">10</span><span class="c0">]. The static graph approaches do not capture the dynamics of real networks such as social media and hence the data driven approaches are more suitable. </span></p><p class="c66"><span class="c45">Static graph. </span></p><p class="c53"><span class="c0">The Influence Maximization problem in social network was first studied by Richardson et al. [</span><span class="c8">7</span><span class="c0">, </span><span class="c8">23</span><span class="c0">] where they formalized the problem with a probabilistic model. Later Kempe et al. [</span><span class="c8">13</span><span class="c0">] proposed a solution using discrete op- timization. They proved that the Influence Maximiza- tion problem is NP-hard and provided a greedy algo- rithm to select seed sets using maximum marginal gain. As the model is based on Monte Carlo simulations, it is not scalable for large graphs. Later improvements were proposed by Chen et al. [</span><span class="c8">4</span><span class="c0">] using the DegreeDiscoun- tand prefix excluding maximum influence in-arborescence (PMIA) [</span><span class="c8">3</span><span class="c0">] algorithms. Both algorithms are heuristic- based. Leskovec et al. proposed the Cost-Effective Lazy Forward (CELF) [</span><span class="c8">17</span><span class="c0">] mechanism to reduce the number of simulations required to select seeds. All of the above- mentioned studies focus on static graph and do not take the temporal nature of the interactions between different nodes into consideration. The latest work on the static graph Influence Maximization problem by Cohen et al. [</span><span class="c8">6</span><span class="c0">] is the fastest we have come across which scales to very large graphs. We compare our seed sets and their in- fluence spread with the seeds selected by their algorithm SKIM. Related work on information flow mining on static graph may be found in [</span><span class="c8">14</span><span class="c0">, </span><span class="c8">17</span><span class="c0">, </span><span class="c8">19</span><span class="c0">, </span><span class="c8">22</span><span class="c0">, </span><span class="c8">21</span><span class="c0">]. Lie et al. in [</span><span class="c8">20</span><span class="c0">] and Chen et al. in [</span><span class="c8">2</span><span class="c0">] independently proposed the first time constrained Influence Maximization solu- tions for static graph. Their work considers the concept of time delay in information flow. They assign this delay at individual node level based on different probabilistic models and not the information channels or pathways be- tween the nodes. </span></p><p class="c47"><span class="c45">Data Driven approach. </span></p><p class="c53"><span class="c0">There are a few recent work which consider the tempo- ral aspect of the graph and are based on real interaction data. Goyal et al. [</span><span class="c8">11</span><span class="c0">] proposed the first data based ap- proach to find influential users in a social network by con- sidering the temporal aspect in the cascade of common actions performed by users, instead of using just static simulation of the friendship network. However, their work does not consider the time constraint in the information flow. In [</span><span class="c8">10</span><span class="c0">] they do use a time window based approach to determine true leaders in the network. However, the time window they consider is for direct influence only, i.e., once a user performs an action how many of his/her friends repeat that action in that time window. They have some additional assumptions like information prop- agation is non-cyclic and if one user performs an action more then once, they use only the time stamp of the first action. Our approach does not make such assumptions and identifies influential nodes without any constraints on the number of times a user performs an action or that the propagation graph needs to be a DAG. The time con- straints we impose are on the path of information flow from the start of the action. Also, our proposed solu- </span></p><p class="c5"><span class="c19">276 </span></p><p class="c4"><span class="c0">Table 1: Comparison of related work on different parameters </span></p><p class="c4"><span class="c26">Gomez- Rodriguez [</span><span class="c24">24</span><span class="c26">] </span></p><p class="c4"><span class="c26">Cohen </span></p><p class="c4"><span class="c26">Du,N </span></p><p class="c4"><span class="c26">Tang </span></p><p class="c4"><span class="c26">Goyal </span></p><p class="c4"><span class="c26">Lei [</span><span class="c24">6</span><span class="c26">] </span></p><p class="c4"><span class="c26">[</span><span class="c24">8</span><span class="c26">] </span></p><p class="c4"><span class="c26">[</span><span class="c24">25</span><span class="c26">] </span></p><p class="c4"><span class="c26">[</span><span class="c24">11</span><span class="c26">, </span></p><p class="c4"><span class="c26">[</span><span class="c24">20</span><span class="c26">] </span><span class="c24">10</span><span class="c26">] </span></p><p class="c4"><span class="c26">IRS </span></p><p class="c4"><span class="c26">Static Graph(S), Data or Cascade (C), Interaction Network (I) </span></p><p class="c12"><span class="c26">Kempe [</span><span class="c24">13</span><span class="c26">] C S C S C S S I </span></p><p class="c4"><span class="c26">Considers information channel or path- ways? </span></p><p class="c4"><span class="c26">Yes No Yes No Yes No No Yes </span></p><p class="c14"><span class="c26">Time window constrained Yes No Yes No Yes No No Yes Approx sketching or sampling Yes Yes Yes Yes No No Yes Yes One Pass algorithm No Yes No No Yes No Yes Yes </span></p><p class="c14"><span class="c0">tion just needs a single pass over the propagation graph whereas Goyal&rsquo;s work do a single pass over the action log but multiple passes on the social network to find the child nodes. Our sketch based approximation further improves the time and space complexity. </span></p><p class="c14"><span class="c0">There are a few more recent works on data driven ap- proach by Gomez-Rodriguez et al. [</span><span class="c8">24</span><span class="c0">] and Du et al. [</span><span class="c8">8</span><span class="c0">]. These works try to derive the underlying hidden influence network and the influence diffusion probabilities along ev- ery edge from a given cascade of infection times for each node in the network. Du et al. [</span><span class="c8">8</span><span class="c0">] proposed a scalable algorithm called ConTinEst, which finds most influential nodes from the derived influence network. ConTinEst uses an adaption of a randomized neighborhood estima- tion algorithm [</span><span class="c8">5</span><span class="c0">] to find the most influential node in the network. But getting the cascade data of infection times for every network is not always possible. For example in an email or a messaging network, we may have access only to interactions between the users and not to the actual in- dividual infection time. To the best of our knowledge our work is the first to try to predict and maximize influence in a network in which only the interaction data is avail- able and no other action cascade or relationship between users is provided. </span></p><p class="c14"><span class="c0">In Table </span><span class="c28">1 </span><span class="c0">we give a brief comparison matrix of our IRS approach with some of the other works in Influence Max- imization. We compare against the type of input each approach considers; i.e, a static graph (S), action cascade or infection time based event cascades (C) or interaction network based (I). We also compare if in the modeling of the information propagation in the approach considers information pathways or channels to do influence max- imization and if the pathways have time window based constrains. For performance comparison, we see if they do use some sampling or sketching techniques to improve performance and if the algorithm is a one pass algorithm. </span></p><p class="c4"><span class="c15">6. EXPERIMENTAL EVALUATION </span></p><p class="c4"><span class="c0">In this section, we address the following questions: Accuracy of Approximation. How accurate is the approximation algorithm for the Oracle problem? In other words, how well can we estimate the size of the IRS set based on the versionned HLL sketch? </span></p><p class="c14"><span class="c0">Efficiency. How efficient is the approximate algorithm in terms of processing time per activity, and how does the window length &omega; impact the efficiency? How long does it take to evaluate an Oracle query based on the IRS summary? </span></p><p class="c14"><span class="c0">Effectiveness. How effective is the identification of in- fluential nodes using IRS to maximize the influence spread under the Time-Constrained Information Cascade Model? To this end, we compare our algorithm to a number of </span></p><p class="c4"><span class="c0">competitors: </span></p><p class="c14"><span class="c0">&bull; SKIM is the only algorithm which scale to large datasets in few minutes time. We ran SKIM us- ing the same parameters Cohen et al. [</span><span class="c8">6</span><span class="c0">] use in their paper for all the experiments. SKIM is from the cat- egory of algorithms which considers a static graph and takes input in the form of a DIAMICS format graph. Hence we convert the interaction network data into the required static graph format by re- moving repeated interactions and the time stamp of every interaction. </span></p><p class="c14"><span class="c0">&bull; ConTinEst(CTE) [</span><span class="c8">8</span><span class="c0">] is the latest data driven al- gorithm which works on static networks where the edge weights corresponds to the associated trans- mission times. The edge weight is obtained from a transmission function which in turn is derived from an cascade of infection time of every node. As we assume that only the interaction between different nodes of a network is being observed and no other in- formation such as the Infection time cascade is avail- able, we transform the interactions into a static net- work with edge weights as required by ConTinEst. The first time a node u appears as the source of an interaction we assign the infection time u</span><span class="c1">i </span><span class="c10">for </span><span class="c0">the source node as the interaction time. Then each interaction (u, v, t) is transformed into an weighted edge (u, v) with the edge weight as the difference of the interaction time and the time when the source gets infected, i.e, t &minus; u</span><span class="c1">i</span><span class="c10">. We ran the same code as </span><span class="c0">published by the authors with the default settings on the transformed data. </span></p><p class="c14"><span class="c0">&bull; The popular baselines PageRank(PR) and High De- gree(HD)[</span><span class="c8">13</span><span class="c0">]. Here we select the k nodes with re- spectively the highest PageRank and out-degree. No- tice that for PageRank we reversed the direction of the interaction edges, as PageRank measures incom- ing &ldquo;importance&rdquo; whereas we need outgoing &ldquo;influ- ence.&rdquo; By reversing the edges this aspect is cap- tured. To make a fair comparison with our algo- rithm that takes into account the overlap of the in- fluence of the selected top-influencers, we developed a version of HD that takes into account overlap. That is, we select a set of nodes that together have maximal outdegree. In our experiments we call this method the Smart High Degree approach (SHD). Notice that SHD is actually a special case of our IRS algorithm, where we set &omega; = 0. </span></p><p class="c14"><span class="c0">We also ran some performance experiments comparing the competitors to our IRS algorithm. In the interpre- tation of these results, however, we need to take into ac- </span></p><p class="c4"><span class="c19">277 </span></p><p class="c14"><span class="c0">Table 2: Characteristics of interaction network along with the time span of the interactions as number of days. </span></p><p class="c14"><span class="c0">Dataset |V|[.10</span><span class="c22">3</span><span class="c0">] |E|[.10</span><span class="c22">3</span><span class="c0">] Days </span><span class="c13">Enron </span><span class="c0">87.3 1,148.1 8,767 </span><span class="c13">Lkml </span><span class="c0">27.4 1,048.6 2,923 </span><span class="c13">Facebook </span><span class="c0">46.9 877.0 1,592 </span><span class="c13">Higgs </span><span class="c0">304.7 526.2 7 </span><span class="c13">Slashdot </span><span class="c0">51.1 140.8 978 </span><span class="c13">US-2016 </span><span class="c0">4,468 44,638 16 </span></p><p class="c14"><span class="c0">count that the static methods require the graph to be pre- processed and takes as input the flattened non-temporal graph, which is in some cases significantly smaller as it does not take repetitions of activities into account. </span></p><p class="c4"><span class="c15">6.1 Datasets and Setup </span></p><p class="c14"><span class="c0">We ran our experiments on real-world datasets obtained from the SNAP repository [</span><span class="c8">18</span><span class="c0">] and the koblenx network collection [</span><span class="c8">16</span><span class="c0">]. We tested with social (</span><span class="c13">Slashdot</span><span class="c0">, </span><span class="c13">Higgs</span><span class="c0">, </span><span class="c13">Facebook</span><span class="c0">) and email (</span><span class="c13">Enron</span><span class="c0">, </span><span class="c13">Lkml</span><span class="c0">) networks. As the real world interaction networks available from previous works were not large enough to test the scalability of our al- gorithm, we created another dataset by tracking tweets related to the US Election 2016. We follow the same technique used to create the </span><span class="c13">Higgs </span><span class="c0">data set of the SNAP repository. Statistics of these data sets are reported in Table </span><span class="c28">2</span><span class="c0">. These datasets are available online, sorted by time of interaction. We kept the datasets in this order, as our algorithm assumes that the interactions are ordered by time. This assumption is reasonable in real scenarios because the interactions will always arrive in increasing order of time and it is hence plausible that they are stored as such. The overall time span of the interactions varies from few days to many years in the data sets. There- fore, in our experiments we express the window length as a percentage of the total time span of the interaction network. </span></p><p class="c14"><span class="c0">The performance results presented in this section are for the C++ implementation of our algorithm. All ex- periments were run on a simple desktop machine with an Intel Core i5-4590 CPU @3.33GHz CPU and 16 GB of RAM, running the Windows 10 operating system. For the larger dataset </span><span class="c13">US-2016 </span><span class="c0">the memory required was more than 16 GB. hence, we ran the experiments for the </span><span class="c13">US- 2016 </span><span class="c0">dataset on a Linux system with 64 GB of RAM. </span></p><p class="c4"><span class="c15">6.2 Accuracy of the Approximation </span></p><p class="c14"><span class="c0">In order to test the accuracy of the approximate algo- rithm, we compared the algorithm with the exact version. We compute the average relative error in the estimation of the IRS size for all the nodes, in function of the num- ber of buckets (&beta; = 2</span><span class="c22">k</span><span class="c0">). Running the exact algorithm is infeasible for the large datasets due to the memory re- quirements, and hence, we test only on the </span><span class="c13">Slashdot </span><span class="c0">and </span><span class="c13">Higgs </span><span class="c0">datasets to measure accuracy. We tested accuracy at different window lengths. The results are reported in Table </span><span class="c28">3</span><span class="c0">. As expected from previous studies, the accuracy increases with &beta;. There is a decrease in accuracy with increasing window length because as the window length increases, the number of nodes with larger IRS increases as well, resulting in a higher average error. &beta; values be- yond 512 yield only modest further improvement in the </span></p><p class="c14"><span class="c0">Table 3: Average relative error in the estimation of the IRS size for all the nodes as a function of b for different window length. </span></p><p class="c4"><span class="c0">Dataset &beta; </span><span class="c9">window % </span></p><p class="c4"><span class="c0">1 10 20 </span></p><p class="c4"><span class="c13">Higgs </span></p><p class="c14"><span class="c0">16 0.075 0.116 0.113 32 0.044 0.081 0.053 64 0.026 0.056 0.046 128 0.008 0.015 0.017 256 0.005 0.008 0.009 512 0.002 0.006 0.007 </span></p><p class="c4"><span class="c13">Slashdot </span></p><p class="c14"><span class="c0">16 0.048 0.055 0.105 32 0.023 0.044 0.042 64 0.013 0.022 0.33 128 0.011 0.04 0.05 256 0.01 0.026 0.025 512 0.005 0.019 0.02 </span></p><p class="c27"><span class="c0">Table 4: Memory used in MB to process all the interactions at different window length &omega; Datasets &omega; = 1 &omega; = 10 &omega; = 20 </span></p><p class="c14"><span class="c13">Slashdot </span><span class="c0">194.9 385.4 431.5 </span><span class="c13">Higgs </span><span class="c0">1008.6 1138.3 1229.8 </span><span class="c13">Enron </span><span class="c0">416.3 426 426.3 </span><span class="c13">Facebook </span><span class="c0">247.4 470 496.2 </span><span class="c13">Lkml </span><span class="c0">228.5 282.5 295.2 </span><span class="c13">US-2016 </span><span class="c0">50,449 56,829 59,104 </span></p><p class="c4"><span class="c0">accuracy. Therefore, we used &beta; = 512 as default for all of the next experiments. </span><span class="c15">6.3 Runtime </span><span class="c43">proximation </span><span class="c15">and </span><span class="c43">Algorithm </span></p><p class="c14"><span class="c15">Memory usage of the Ap- </span><span class="c0">We study the runtime of the approximation algorithm on all the datasets for different window lengths &omega;. The runtime increases with the increasing window length, as expected given that the number of nodes in the IRS in- creases, resulting in more elements in the vHLL to be merged. We study the processing time in function of the time window &omega;. Here we vary &omega; from 1% to 100%. The results are reported in Figure </span><span class="c28">3</span><span class="c0">. It is interesting to see in Figure </span><span class="c28">3 </span><span class="c0">that the processing time becomes almost con- stant as soon as the window length reaches 10%. This is because the IRS does not change much once the time window is large enough. This behavior indicates that at higher window lengths the analysis of the interaction net- work becomes similar to that of the underlying static net- work. As the algorithm is one pass it scales linearly with the input size. For the largest data set </span><span class="c13">US-2016 </span><span class="c0">with approx 45 million interactions the algorithm was able to parse all the interactions in just 8 min. </span></p><p class="c14"><span class="c0">As shown in Table </span><span class="c28">4</span><span class="c0">, we observe that the space con- sumption is essentially dependent on the number of nodes and not on the number of interactions on the network. For example, on </span><span class="c13">Enron </span><span class="c0">dataset the total space requirement is just 295 MB for &omega; = 20%, whereas for </span><span class="c13">Higgs </span><span class="c0">the mem- ory requirement is 1229 MB, as the number of nodes for this data set is 4 times that of </span><span class="c13">Enron</span><span class="c0">. It is natural to see a slight increase in the space requirement with window length &omega; as the lists in the vHLL sketches become larger. </span></p><p class="c4"><span class="c15">6.4 Influence Oracle Query Efficiency </span></p><p class="c4"><span class="c19">278 </span></p><p class="c4"><span class="c30">1 </span><span class="c6">10000 1000 ) emiT(g o</span><span class="c30">L</span><span class="c6">100 10 </span><span class="c30">0 10 20 30 40 50 60 70 80 90 100 </span></p><p class="c4"><span class="c30">Window (%) </span></p><p class="c12"><span class="c30">Slashdot Higgs Facebook Enron Lkml US-2016 </span></p><p class="c4"><span class="c0">Figure 3: Log of the time to process all the in- teractions as a function of time window &omega; </span></p><p class="c12"><span class="c6">60 </span><span class="c30">Slashdot Higgs </span><span class="c6">50 </span><span class="c30">Facebook Enron Lkml </span></p><p class="c4"><span class="c6">) ces40 </span><span class="c30">US-2016 </span><span class="c6">m(e30 mi</span><span class="c30">T</span><span class="c6">20 10 </span><span class="c30">0 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 </span></p><p class="c4"><span class="c30">Seeds </span></p><p class="c14"><span class="c0">Figure 4: Influence spread prediction query time in milliseconds for window length, &omega; = 20% as a function of the seed set size. </span></p><p class="c14"><span class="c0">Now, we present the query time for the Influence Oracle using IRS. After the pre-processing step of computing the IRS for all nodes, querying the data structure is very efficient. We pick seed nodes randomly and query the data structure to calculate their combined influence spread. In Figure </span><span class="c28">4 </span><span class="c0">we report the average query time for randomly selected seeds. We observe that, irrespective of the graph size the query time is mostly the same for all graphs. This is because the complexity of the versionned HyperLogLog union is independent of the set size. As expected, query time increases with the number of seed nodes. Even for numbers of seed nodes as large as 10,000, the query time is just few milliseconds. </span></p><p class="c4"><span class="c15">6.5 Influence Maximization </span></p><p class="c4"><span class="c0">Our next goal is to study how the Influence Reachability Set could be used to solve the problem of Influence Max- imization. First we do an effectiveness analysis and then an efficiency comparison with the baseline approaches. Effectiveness analysis: </span></p><p class="c14"><span class="c0">We compare the influence spread by running the Time Constrained Information Cascade Model with infection probabilities of 50% and 100%. We compare our sketch based algorithm with the latest sketch based probabilis- tic approach SKIM [</span><span class="c8">6</span><span class="c0">] and ConTinEst(CTE) [</span><span class="c8">8</span><span class="c0">]. As Both SKIM and ConTinEst require a specific input format of the underlying static graph we ran a pre-processing phase to generate the required graph data from the interac- tion network. We ran both SKIM and ConTinEst using the code published by the respective authors. We also </span></p><p class="c4"><span class="c0">Table 5: Common seeds between different win- dow length for top 10 seeds </span></p><p class="c4"><span class="c0">Datasets 1% - 10% 1% - 20% 10% - 20% </span></p><p class="c14"><span class="c13">Slashdot </span><span class="c0">0 0 7 </span><span class="c13">Higgs </span><span class="c0">3 1 3 </span><span class="c13">Enron </span><span class="c0">0 0 6 </span><span class="c13">Facebook </span><span class="c0">4 4 9 </span><span class="c13">Lkml </span><span class="c0">1 0 5 </span><span class="c13">US-2016 </span><span class="c0">6 6 10 </span></p><p class="c14"><span class="c0">compare with other popular baselines PageRank(PR) and High Degree(HD)[</span><span class="c8">13</span><span class="c0">] by selecting top k nodes with high- est page rank and highest out degree. We used 0.15 as the restart probability and a difference of 10</span><span class="c22">&minus;4 </span><span class="c0">in the L1 norm between two successive iterations as the stopping criterion. We also introduced a variation of High Degree called Smart High Degree(SHD) in which instead of select- ing top k nodes with highest degree we select nodes using a greedy approach to maximize the distinct neighbors. </span></p><p class="c14"><span class="c0">The results of our comparison are reported in Figure </span><span class="c28">5</span><span class="c0">. We observe that in all the datasets the influence spread by simulation through the seed nodes selected by our IRS exact algorithm is consistently better than that of other baselines. The IRS approx approach results in lesser spread but still it is best for </span><span class="c13">Lkml </span><span class="c0">dataset and is close to other baselines in other datasets. In other datasets like </span><span class="c13">Enron </span><span class="c0">or </span><span class="c13">Facebook </span><span class="c0">the nodes with highest degree are the same node for which the longer temporal paths ex- ists hence the spread is similar. SKIM and ConTinEst both perform worst at smaller windows but with higher window lengths their performance increases; this is be- cause for higher window lengths there is less pruning of the information channels resulting in a very small change in the Influence reachability set size. Hence, the behav- ior is the same as the analysis of the static graph and the time window does not have much effect on the Influ- ence Reachability Set. The Smart High Degree approach out-performs High Degree in all of the cases. For smaller values of k the spread is very similar because of common seeds, for example 4 out of 5 seeds are common in </span><span class="c13">Slash- dot </span><span class="c0">as nodes with highest page Rank is the also the node with highest degree and highest IRS set size at &omega; = 1%. But as k increases IRS performs much better. </span></p><p class="c4"><span class="c0">Efficiency analysis: </span></p><p class="c14"><span class="c0">Next, we compared the time required to find the top 50 seeds. The results are reported in Table </span><span class="c28">6</span><span class="c0">. For IRS we report time taken by the more efficient IRS approx approach. The IRS approach takes more time for </span><span class="c13">Enron </span><span class="c0">and </span><span class="c13">Lkml </span><span class="c0">as compare to other baselines because the IRS approach depends on the number of interactions. While IRS is slower than Page Rank and Smart High Degree for smaller datasets it scales linearly with the size and takes 8 times less time for the </span><span class="c13">US-2016 </span><span class="c0">dataset with millions of nodes and interactions. For SKIM the time required to find top k seeds is quite low. However, it requires preprocessed data in the DIMACS graph format [</span><span class="c8">1</span><span class="c0">] and the pre-processing step takes up to 10 hours for the </span><span class="c13">US- 2016 </span><span class="c0">dataset. ConTinEst does not scale so well for large graphs and is the slowest in all dataseta. For the </span><span class="c13">US- 2016 </span><span class="c0">dataset the memory requirements were so high that it could not even finish the processing. IRS provides a promising tradeoff between efficiency and effectiveness, especially for smaller window lengths when the tempo- </span></p><p class="c4"><span class="c19">279 </span></p><p class="c4"><span class="c2">0 </span><span class="c18">10000 45000 6000 </span><span class="c2">PR</span><span class="c18">9000 40000 </span><span class="c44">HD </span></p><p class="c27"><span class="c2">SHD SKIM </span><span class="c18">5000 8000 35000 </span><span class="c2">IRS(Approx) </span><span class="c18">7000 </span><span class="c2">IRS(Exact) </span><span class="c18">30000 </span><span class="c2">ConTinEst </span><span class="c18">4000 6000 25000 3000 5000 20000 2000 4000 15000 3000 10000 1000 </span><span class="c2">2000 5000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c0">(b) </span><span class="c13">Enron </span><span class="c0">(&omega; = 1%) </span></p><p class="c12"><span class="c2">PR</span><span class="c44">HD </span><span class="c2">SHD SKIM IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c0">(c) </span><span class="c13">Facebook </span><span class="c0">(&omega; = 1%) </span></p><p class="c4"><span class="c18">11000 10000 9000 8000 7000 </span><span class="c2">6000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span></p><p class="c4"><span class="c18">20000 </span><span class="c2">PR</span><span class="c44">HD </span><span class="c2">SHD SKIM </span><span class="c18">19000 </span><span class="c2">IRS(Approx) </span></p><p class="c4"><span class="c2">IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c18">18000 17000 16000 </span><span class="c2">15000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c0">(e) </span><span class="c13">Enron </span><span class="c0">(&omega; = 20%) </span></p><p class="c12"><span class="c2">PR</span><span class="c44">HD </span><span class="c2">SHD SKIM IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c0">(f) </span><span class="c13">Facebook </span><span class="c0">(&omega; = 20%) </span></p><p class="c4"><span class="c18">17000 16000 15000 14000 13000 </span><span class="c2">12000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c18">35000 d aerp</span><span class="c2">S</span><span class="c18">30000 25000 </span><span class="c2">20000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">top k </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span></p><p class="c27"><span class="c18">50000 12000 </span><span class="c2">PRPRPR</span><span class="c44">HD HD </span></p><p class="c4"><span class="c44">HD </span><span class="c2">SHD SKIM </span></p><p class="c4"><span class="c18">45000 </span><span class="c2">SHD SKIM </span></p><p class="c12"><span class="c18">10000 </span><span class="c2">SHD SKIM IRS(Approx) </span></p><p class="c4"><span class="c2">IRS(Approx) </span></p><p class="c4"><span class="c2">IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c18">40000 </span><span class="c2">IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c18">8000 </span><span class="c2">IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">S</span><span class="c18">35000 6000 30000 4000 25000 2000 </span><span class="c2">20000 0 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c0">(h) </span><span class="c13">Enron </span><span class="c0">(&omega; = 1%) </span></p><p class="c4"><span class="c0">(i) </span><span class="c13">Facebook </span><span class="c0">(&omega; = 1%) </span></p><p class="c4"><span class="c18">20000 19500 19000 18500 18000 17500 17000 16500 </span><span class="c2">16000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span><span class="c18">d aerp</span><span class="c2">SPR</span><span class="c44">HD </span><span class="c2">SHD SKIM IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c27"><span class="c2">top k </span><span class="c0">(a) </span><span class="c13">Lkml </span><span class="c0">(&omega; = 1%) </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">SPR</span><span class="c44">HD </span><span class="c2">SHD SKIM IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c27"><span class="c2">top k </span><span class="c0">(d) </span><span class="c13">Lkml </span><span class="c0">(&omega; = 20%) </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span></p><p class="c4"><span class="c2">top k </span><span class="c0">(g) </span><span class="c13">Lkml </span><span class="c0">(&omega; = 1%) </span></p><p class="c4"><span class="c18">55000 28000 </span><span class="c2">PRPR</span><span class="c44">HD </span><span class="c2">SHD </span></p><p class="c12"><span class="c44">HD </span><span class="c2">SHD </span><span class="c18">27000 </span><span class="c2">SKIM </span><span class="c18">50000 </span><span class="c2">SKIM IRS(Approx) </span></p><p class="c27"><span class="c2">IRS(Approx) </span><span class="c18">26000 </span><span class="c2">IRS(Exact) </span></p><p class="c4"><span class="c2">IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c2">ConTinEst </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">S</span><span class="c18">d </span></p><p class="c4"><span class="c18">aerp</span><span class="c2">S</span><span class="c18">45000 40000 25000 24000 23000 22000 35000 21000 </span><span class="c2">30000 20000 5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">5 10 15 20 25 30 35 40 45 50 </span></p><p class="c4"><span class="c2">top k </span></p><p class="c4"><span class="c2">top k </span><span class="c0">(j) </span><span class="c13">Lkml </span><span class="c0">(&omega; = 20%) </span></p><p class="c4"><span class="c0">(k) </span><span class="c13">Enron </span><span class="c0">(&omega; = 20%) </span></p><p class="c12"><span class="c2">PR</span><span class="c44">HD </span><span class="c2">SHD SKIM IRS(Approx) IRS(Exact) ConTinEst </span></p><p class="c4"><span class="c0">(l) </span><span class="c13">Facebook </span><span class="c0">(&omega; = 20%) </span></p><p class="c4"><span class="c0">Figure 5: Comparing the spread of the influence of top k seeds using Simulation Algorithm for different seed size at different window length &omega; at Infection probability 50%(a-f) and 100%(g-l) respectively. </span></p><p class="c4"><span class="c11">Table 6: Time in seconds to find top 50 seeds by IRS(approx) and all other baseline approach. </span></p><p class="c4"><span class="c11">Datasets IRS SKIM PR HD SHD CTE </span></p><p class="c14"><span class="c32">Slashdot </span><span class="c11">1.1 1.2 21.9 0.9 2.1 694 </span><span class="c32">Higgs </span><span class="c11">2.2 4.3 29.8 0.7 1.5 3,802 </span><span class="c32">Enron </span><span class="c11">93.7 2.2 49.4 0.4 8.1 1,349 </span><span class="c32">Facebook </span><span class="c11">10.3 1.1 35.6 0.5 2.9 790 </span><span class="c32">Lkml </span><span class="c11">117.9 1.7 29.8 0.5 22.9 733 </span><span class="c32">US-2016 </span><span class="c11">498 23.6 4,261 47.4 3,338.4 - </span></p><p class="c4"><span class="c0">ral nature of the graph has a higher role in determining the influential nodes. Effect of window on top k seeds: </span></p><p class="c4"><span class="c18">d aerp</span><span class="c2">Stop k </span></p><p class="c14"><span class="c0">To see the effect of the time window on the most in- fluential nodes we study the common seeds between dif- ferent window lengths. We observed that the top k seeds change drastically as we change the window length, espe- cially when the window length is small. But for window lengths greater than 10% the top k seeds do not change much. For </span><span class="c13">US-2016 </span><span class="c0">the top 10 seeds are exactly the same for the 10% and 20% window. In Table </span><span class="c28">5 </span><span class="c0">we have re- ported the common seeds among different top 10 seeds at different window lengths. There are no common seeds between the top 10 seeds found for window lengths of 1% and 10% for </span><span class="c13">Slashdot </span><span class="c0">and </span><span class="c13">Enron </span><span class="c0">and only 3 &minus;4 common seeds for </span><span class="c13">Higgs</span><span class="c0">, </span><span class="c13">Facebook </span><span class="c0">and </span><span class="c13">Lkml</span><span class="c0">. This shows that for different window lengths there are different nodes which become most influential and hence it is necessary to con- </span></p><p class="c4"><span class="c19">280 </span></p><p class="c4 c99"><span class="c0">sider window length while doing Influence maximization. </span></p><p class="c40"><span class="c15">7. CONCLUSION </span></p><p class="c38"><span class="c0">We studied the problem of information propagation in an interaction network&mdash;a graph with a sequence of time stamped interactions. We presented a new time con- strained influence channel based approach for Influence Maximization and Information Spread Prediction. We presented an exact algorithm, which is memory inefficient, but it set the stage for our main technique, an approxi- mate algorithm based on a modified version of Hyper- LogLog sketches, which requires logarithmic memory per network node, and has fast update time. One interesting property of our sketch is that the query time of the Influ- ence Oracle is almost independent of the network size. We showed that the time taken to do influence maximization by a greedy approach on our sketch is very time efficient. We also showed the effect of the time window on the in- fluence spread. We conclude that smaller window lengths have very high impact on the Information propagation and hence it is important to consider the spread window to do Influence maximization. </span></p><p class="c98"><span class="c15">8. REFERENCES </span><span class="c10">[1] 9th DIMACS Implementation Challenge - Shortest </span><span class="c0">Paths. </span><span class="c73">http://www.dis.uniroma1.it/challenge9/ format.shtml#graph</span><span class="c0">, [Online; accessed 12-Sep-2016] [2] Chen, W., Lu, W., Zhang, N.: Time-critical </span></p><p class="c77"><span class="c0">influence maximization in social networks with time-delayed diffusion process. arXiv:1204.3074 (2012) [3] Chen, W., Wang, C., Wang, Y.: Scalable influence </span></p><p class="c121"><span class="c0">maximization for prevalent viral marketing in large-scale social networks. In: Proceedings of the 16th ACM SIGKDD. pp. 1029&ndash;1038. ACM (2010) [4] Chen, W., Wang, Y., Yang, S.: Efficient influence </span></p><p class="c97"><span class="c0">maximization in social networks. In: Proceedings of the 15th ACM SIGKDD. pp. 199&ndash;208. ACM (2009) [5] Cohen, E.: Size-estimation framework with </span></p><p class="c74"><span class="c0">applications to transitive closure and reachability. Journal of Computer and System Sciences 55(3), 441&ndash;453 (1997) [6] Cohen, E., Delling, D., Pajor, T., Werneck, R.F.: </span></p><p class="c108"><span class="c0">Sketch-based influence maximization and computation: Scaling up with guarantees. In: Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. pp. 629&ndash;638. ACM (2014) [7] Domingos, P., Richardson, M.: Mining the network </span></p><p class="c64"><span class="c0">value of customers. In: Proceedings of the seventh ACM SIGKDD. pp. 57&ndash;66. ACM (2001) [8] Du, N., Song, L., Gomez-Rodriguez, M., Zha, H.: </span></p><p class="c35"><span class="c0">Scalable influence estimation in continuous-time diffusion networks. In: Advances in neural information processing systems. pp. 3147&ndash;3155 (2013) [9] Flajolet, P., Fusy, </span><span class="c9">&nbsp;&#769;</span><span class="c0">E., Gandouet, O., Meunier, F.: </span></p><p class="c31"><span class="c0">Hyperloglog: the analysis of a near-optimal cardinality estimation algorithm. DMTCS Proceedings (2008) [10] Goyal, A., Bonchi, F., Lakshmanan, L.V.: </span></p><p class="c91"><span class="c0">Discovering leaders from community actions. In: Proceedings of the 17th ACM conference on Information and knowledge management. pp. 499&ndash;508. ACM (2008) </span></p><p class="c4 c54"><span class="c0">[11] Goyal, A., Bonchi, F., Lakshmanan, L.V.: A data-based approach to social influence maximization. Proceedings of the VLDB Endowment 5(1), 73&ndash;84 (2012) [12] Kempe, D., Kleinberg, J., Kumar, A.: Connectivity </span></p><p class="c106"><span class="c0">and inference problems for temporal networks. In: Proceedings of the thirty-second annual ACM symposium on Theory of computing. pp. 504&ndash;513. ACM (2000) [13] Kempe, D., Kleinberg, J., Tardos, </span><span class="c9">&nbsp;&#769;</span><span class="c0">E.: Maximizing </span></p><p class="c80 c109"><span class="c0">the spread of influence through a social network. In: Proceedings of the ninth ACM SIGKDD. pp. 137&ndash;146. ACM (2003) [14] Kleinberg, J.: The flow of on-line information in </span></p><p class="c109 c120"><span class="c0">global networks. In: Proceedings of the 2010 ACM SIGMOD. pp. 1&ndash;2. ACM (2010) [15] Kumar, R., Calders, T., Gionis, A., Tatti, N.: </span></p><p class="c105"><span class="c0">Maintaining sliding-window neighborhood profiles in interaction networks. In: Machine Learning and Knowledge Discovery in Databases, pp. 719&ndash;735. Springer (2015) [16] Kunegis, J.: Konect: the koblenz network </span></p><p class="c116"><span class="c0">collection. In: Proceedings of the 22nd international conference on World Wide Web companion. pp. 1343&ndash;1350. International World Wide Web Conferences Steering Committee (2013) [17] Leskovec, J., Krause, A., Guestrin, C., Faloutsos, C., VanBriesen, J., Glance, N.: Cost-effective outbreak detection in networks. In: Proceedings of the 13th ACM SIGKDD. pp. 420&ndash;429. ACM (2007) [18] Leskovec, J., Krevl, A.: SNAP Datasets: Stanford </span></p><p class="c83"><span class="c0">large network dataset collection. </span><span class="c73">http://snap.stanford.edu/data </span><span class="c0">(Jun 2014) [19] Leskovec, J., McGlohon, M., Faloutsos, C., Glance, </span></p><p class="c62"><span class="c0">N.S., Hurst, M.: Patterns of cascading behavior in large blog graphs. In: SDM. vol. 7, pp. 551&ndash;556. SIAM (2007) [20] Liu, B., Cong, G., Xu, D., Zeng, Y.: Time </span></p><p class="c17"><span class="c0">constrained influence maximization in social networks. In: Data Mining (ICDM). pp. 439&ndash;448. IEEE (2012) [21] Mohammadi, A., Saraee, M., Mirzaei, A.: </span></p><p class="c81"><span class="c0">Time-sensitive influence maximization in social networks. Journal of Information Science 41(6), 765&ndash;778 (2015) [22] Prakash, B.A., Chakrabarti, D., Valler, N.C., </span></p><p class="c88"><span class="c0">Faloutsos, M., Faloutsos, C.: Threshold conditions for arbitrary cascade models on arbitrary networks. Knowledge and information systems 33(3), 549&ndash;575 (2012) [23] Richardson, M., Domingos, P.: Mining </span></p><p class="c86"><span class="c0">knowledge-sharing sites for viral marketing. In: Proceedings of the eighth ACM SIGKDD. pp. 61&ndash;70. ACM (2002) [24] Rodriguez, M.G., Sch&ouml;lkopf, B.: Influence </span></p><p class="c80 c102"><span class="c0">maximization in continuous time diffusion networks. arXiv:1205.1682 (2012) [25] Tang, Y., Shi, Y., Xiao, X.: Influence maximization in near-linear time: A martingale approach. In: Proceedings of the 2015 ACM SIGMOD. pp. 1539&ndash;1554. ACM (2015) [26] Wu, H., Cheng, J., Huang, S., Ke, Y., Lu, Y., Xu, </span></p><p class="c50"><span class="c0">Y.: Path problems in temporal graphs. Proceedings of the VLDB Endowment 7(9), 721&ndash;732 (2014) </span></p><p class="c33"><span class="c19">281 </span></p></body></html>