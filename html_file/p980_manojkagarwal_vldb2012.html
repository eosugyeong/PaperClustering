<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c84{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.7pt;font-family:"Arial";font-style:normal}.c103{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.7pt;font-family:"Arial";font-style:normal}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.4pt;font-family:"Times New Roman";font-style:normal}.c79{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.7pt;font-family:"Arial";font-style:normal}.c71{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c109{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.8pt;font-family:"Times New Roman";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15pt;font-family:"Times New Roman";font-style:italic}.c99{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:1.4pt;font-family:"Arial";font-style:normal}.c120{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.8pt;font-family:"Times New Roman";font-style:italic}.c61{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Times New Roman";font-style:italic}.c55{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c47{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.9pt;font-family:"Times New Roman";font-style:normal}.c122{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.4pt;font-family:"Times New Roman";font-style:normal}.c106{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.7pt;font-family:"Times New Roman";font-style:italic}.c135{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.8pt;font-family:"Times New Roman";font-style:normal}.c132{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c89{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11.1pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c51{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.4pt;font-family:"Times New Roman";font-style:italic}.c67{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Times New Roman";font-style:normal}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:italic}.c14{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c64{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Times New Roman";font-style:italic}.c59{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Times New Roman";font-style:normal}.c83{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11.8pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c88{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Times New Roman";font-style:italic}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:1.4pt;font-family:"Times New Roman";font-style:italic}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.7pt;font-family:"Times New Roman";font-style:italic}.c40{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.2pt;font-family:"Times New Roman";font-style:normal}.c53{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:7.6pt;font-family:"Times New Roman";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c75{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.7pt;font-family:"Times New Roman";font-style:normal}.c110{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Times New Roman";font-style:italic}.c68{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.7pt;font-family:"Times New Roman";font-style:italic}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.4pt;font-family:"Times New Roman";font-style:normal}.c46{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.7pt;font-family:"Times New Roman";font-style:normal}.c131{margin-left:-8.4pt;padding-top:5.5pt;text-indent:26.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:7.4pt}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c57{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.6pt;font-family:"Times New Roman";font-style:normal}.c92{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Arial";font-style:normal}.c107{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.4pt;font-family:"Arial";font-style:normal}.c117{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Times New Roman";font-style:normal}.c26{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Times New Roman";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c80{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:19.7pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15pt;font-family:"Times New Roman";font-style:normal}.c111{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.8pt;font-family:"Times New Roman";font-style:italic}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Times New Roman";font-style:normal}.c33{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Times New Roman";font-style:italic}.c85{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Times New Roman";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Arial";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12.1pt;font-family:"Arial";font-style:normal}.c115{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.6pt;font-family:"Times New Roman";font-style:normal}.c54{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15pt;font-family:"Arial";font-style:normal}.c127{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.2pt;font-family:"Times New Roman";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c32{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:15pt;font-family:"Times New Roman";font-style:normal}.c123{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.4pt;font-family:"Times New Roman";font-style:italic}.c95{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Times New Roman";font-style:normal}.c119{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:18.9pt;font-family:"Arial";font-style:normal}.c44{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Times New Roman";font-style:normal}.c93{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.7pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.4pt;font-family:"Arial";font-style:normal}.c101{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.7pt;font-family:"Courier New";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c116{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.7pt;font-family:"Times New Roman";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Times New Roman";font-style:normal}.c49{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:1.4pt;font-family:"Times New Roman";font-style:normal}.c87{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.7pt;font-family:"Times New Roman";font-style:normal}.c60{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c50{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.4pt;font-family:"Times New Roman";font-style:normal}.c133{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13.6pt;font-family:"Arial";font-style:normal}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Times New Roman";font-style:normal}.c130{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.6pt;font-family:"Times New Roman";font-style:italic}.c129{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15.8pt;font-family:"Arial";font-style:normal}.c94{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c121{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c128{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.2pt;font-family:"Times New Roman";font-style:italic}.c37{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c90{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Times New Roman";font-style:italic}.c58{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.5pt;font-family:"Times New Roman";font-style:italic}.c125{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.1pt;font-family:"Arial";font-style:normal}.c124{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c134{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.2pt;font-family:"Arial";font-style:normal}.c74{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.4pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Times New Roman";font-style:italic}.c104{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.6pt;font-family:"Times New Roman";font-style:italic}.c72{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c108{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.7pt;font-family:"Times New Roman";font-style:italic}.c73{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.7pt;font-family:"Times New Roman";font-style:normal}.c62{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.2pt;font-family:"Times New Roman";font-style:italic}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c77{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.5pt;font-family:"Arial";font-style:normal}.c65{margin-left:-8pt;padding-top:1.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-18.2pt}.c18{margin-left:-8pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.2pt}.c69{margin-left:-12.5pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-0.3pt}.c9{margin-left:-8pt;padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-18.2pt}.c1{margin-left:-8pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-18.2pt}.c52{margin-left:-18pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.5pt}.c136{margin-left:226.6pt;padding-top:121.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.4pt}.c31{margin-left:-18pt;padding-top:6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.2pt}.c118{margin-left:-12.5pt;padding-top:14.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:10.7pt}.c91{margin-left:-8pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:59.5pt}.c100{margin-left:226.6pt;padding-top:41.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.4pt}.c66{margin-left:226.6pt;padding-top:50.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.4pt}.c34{margin-left:-12.5pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:8.1pt}.c48{margin-left:-12.5pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:2.3pt}.c19{margin-left:-18pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.5pt}.c105{margin-left:226.6pt;padding-top:37.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.4pt}.c96{margin-left:226.6pt;padding-top:40.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.4pt}.c35{margin-left:-8pt;padding-top:2.2pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-18.2pt}.c81{margin-left:41.4pt;padding-top:105.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:31.4pt}.c98{margin-left:-18pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.5pt}.c6{margin-left:24.9pt;padding-top:333.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:15.1pt}.c102{padding-top:1.7pt;text-indent:12.6pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c97{padding-top:2.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c38{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c82{padding-top:2.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c78{padding-top:7.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c45{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c24{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c56{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c28{margin-left:-8pt;text-indent:47.6pt;margin-right:-18.2pt}.c86{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c126{margin-left:30.2pt;margin-right:20.2pt}.c112{margin-left:-149.6pt;margin-right:269.5pt}.c114{margin-left:-12.5pt;margin-right:120.2pt}.c70{margin-left:-8pt;margin-right:-18.2pt}.c113{margin-left:-18pt;margin-right:-8.2pt}.c43{margin-left:-12.5pt;margin-right:120.4pt}.c76{margin-left:-149.6pt;margin-right:299.3pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c86"><p class="c24"><span class="c60">Real Time Discovery of Dense Clusters in Highly Dynamic Graphs</span><span class="c133">: </span></p><p class="c24"><span class="c60">Identifying </span><span class="c36">Manoj K Agarwal</span><span class="c60">Real </span><span class="c107">* </span></p><p class="c24"><span class="c60">World Events in Highly Dynamic Environments </span></p><p class="c45"><span class="c72">IBM Research-India, New Delhi manojkag@in.ibm.com </span></p><p class="c45"><span class="c36">Krithi Ramamritham </span><span class="c72">IIT-Bombay, Mumbai, India krithi@cse.iitb.ac.in </span></p><p class="c45"><span class="c36">Manish Bhide </span><span class="c72">IBM India Software Labs, Hyderabad abmanish@in.ibm.com </span></p><p class="c24"><span class="c21">ABSTRACT </span><span class="c0">Due to their </span><span class="c2">real time </span><span class="c0">nature, microblog streams are a rich source of dynamic information, for example, about </span><span class="c2">emerging events</span><span class="c0">. Existing techniques for discovering such events from a microblog stream in real time (such as Twitter trending topics), have several lacunae when used for discovering emerging events; extant graph based event detection techniques are not practical in microblog settings due to their complexity; and conventional techniques, which have been developed for blogs, web-pages, etc., involving the use of keyword search, are only useful for finding information about </span><span class="c2">known </span><span class="c0">events. Hence, in this paper, we present techniques to discover events that are unraveling in microblog message streams in real time so that such events can be reported as soon as they occur. We model the problem as discovering dense clusters in highly dynamic graphs. Despite many recent advances in graph analysis, ours is the first technique to identify dense clusters in massive and highly dynamic graphs in real time. Given the characteristics of microblog streams, in order to find clusters without missing any events, we propose and exploit a novel graph property which we call </span><span class="c2">short-cycle property</span><span class="c0">. Our algorithms find these clusters efficiently in spite of rapid changes to the microblog streams. Further we present a novel ranking function to identify the important events. Besides proving the correctness of our algorithms we show their practical utility by evaluating them using real world microblog data. These demonstrate our technique&rsquo;s ability to discover, with high precision and recall, emerging events in high intensity data streams in real time. Many recent web applications create data which can be represented as massive dynamic graphs. Our technique can be easily extended to discover, in real time, interesting patterns in such graphs. </span></p><p class="c24"><span class="c21">1. INTRODUCTION and MOTIVATION </span><span class="c0">Microblogging sites such as </span><span class="c37">twitter.com </span><span class="c0">have become a rich source of information about any &ldquo;event&rdquo;, ranging from breaking news stories to earthquakes or information about local concerts. Empirical studies [10] [11] show that (i) Twitter is often the first medium to break important events such as earthquakes, often in a matter of seconds after they occur and more importantly (ii) they highlight the need to discover all such events (and not just events related to earthquakes [10]) in real time from microblog streams. Note that by &lsquo;real time&rsquo; we mean that events need to be discovered as early as possible after they start unraveling in the microblog stream. Such information about emerging events can be immensely valuable if it is discovered </span><span class="c2">timely </span><span class="c0">and made available. _____________________________ </span></p><p class="c24"><span class="c57">* This work is done as part of the PhD at IIT-Bombay, India. </span></p><p class="c24"><span class="c0">One obvious way to find information on microblogging sites is to use keyword search. There are many microblog search engines which allow users to find real-time microblogs relevant to a keyword query (e.g., twitter search). These search engines allow users to register their (continuous) keyword queries and return a stream of events, trends or news items relevant to the query. However, these search techniques do not help the user to &ldquo;discover&rdquo; the event but can be used to gather follow up information about the event. One could argue that the event could have been discovered by a continuous query with a keyword, say, &ldquo;earthquake&rdquo;. However, note that a user would have to register a large number of such keyword queries to discover all possible types of events, something that is clearly not feasible. The major challenge in achieving the goal of building a real time event discovery and tracking system lies in correlating the right microblog messages, among the hundreds of thousands of messages that are continuously being generated. The problem is exacerbated by the fact that the keywords used to describe the event might vary from one user to another and could also change over time due to the evolving nature of real time events. Hence classifier [10] or keyword search techniques may not be practical. This paper addresses these problems and presents a technique for discovering events in a microblog stream in real time. Whenever an event happens, there will be a few keywords which will show burstiness (display a sudden jump in frequency). Hence a simple and obvious way to discover events is to keep track of the most popular words, something that is already done by twitter, and displayed as trending topics. A keyword (or a pair of consecutively occurring words) is recognized as a trending topic by Twitter if it is popular over a period of time. However, as reported in </span><span class="c37">whatthetrend.com</span><span class="c0">, several thousand tweets over a relatively short period of time are needed to identify an event as trending topic. Therefore, (1) using keywords appearing in &lsquo;trending topics&rsquo; does not serve the purpose of discovering events in &lsquo;real time&rsquo; (as by then the event would no longer be an emerging event) and (2) it is not necessary that all important events do become trending topics. Further, once a set of keywords becomes popular, they would remain so for a long time thereby overshadowing any new emerging events. Moreover, rather than reporting individual keywords or a pair of consecutive keywords it might be more meaningful and insightful to identify a set of correlated keywords (not necessarily occurring consecutively). In order to identify an emerging topic, we need to identify a set of keywords which are </span><span class="c2">temporally correlated</span><span class="c0">, i.e., they show burstiness at the same time and are </span><span class="c2">spatially correlated, </span><span class="c0">i.e., they co-occur in temporally correlated messages from the same user. In order to capture these characteristics we use a dynamic graph </span></p><p class="c56"><span class="c3">Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific </span></p><p class="c38"><span class="c0">model which uses the moving window paradigm and is constructed using the most recent messages present in the message stream. An edge between two nodes -- representing two keywords -- indicates that messages from a user within the recent sliding window involve the respective keywords. We use these properties </span><span class="c3">permission and/or a fee. Articles from this volume were invited to present </span></p><p class="c24"><span class="c0">to formulate our problem as that of cluster discovery in a dynamic </span><span class="c3">their results at The 38th International Conference on Very Large Data Bases, August 27th - 31st 2012, Istanbul, Turkey. Proceedings of the VLDB Endowment, Vol. 5, No. 10 Copyright 2012 VLDB Endowment 2150-8097/12/06... </span><span class="c132">$ </span><span class="c3">10.00. </span></p><p class="c56"><span class="c0">graph. Figure 1 shows a partial graph induced by 6 real twitter messages (comprising 12 keywords). 6 of these keywords show burstiness (e.g., at least 2 occurrences). Keywords co-occurring </span></p><p class="c24"><span class="c25">980 </span></p><p class="c56"><span class="c0">together in messages from a user (within 6 messages) share an edge. We discover the cluster &ldquo;earthquake struck eastern Turkey&rdquo; in the graph, denoting an event. Two other keywords (&ldquo;massive&rdquo; and &ldquo;moderate&rdquo;) were also bursty within the graph but they are not part of cluster (due to weak spatial correlation). When the window is moved at a fixed rate (oldest 2 messages expire and 2 most recent messages are added), a new keyword (&ldquo;5.9&rdquo;) gets added to the cluster (denoting the intensity of earthquake). </span></p><p class="c24"><span class="c85">earthquake </span></p><p class="c24"><span class="c85">struck </span></p><p class="c24"><span class="c85">Turkey </span><span class="c115">5.9 </span></p><p class="c38"><span class="c26">Figure 1</span><span class="c20">: </span><span class="c26">Event cluster embedded in a graph drawn on Twitter data </span><span class="c0">The example above highlights several issues central to our problem, specifically a) the cluster definition should be able to capture the imperfect correlation among keywords belonging to an event. Not all keywords are used by all the users (there is no edge between &lsquo;eastern&rsquo; and &lsquo;struck&rsquo;); b) we should be able to capture the evolving nature of events in a highly dynamic environment (&lsquo;5.9&rsquo; joined the cluster later); and, c) the identified events should truly be categorizable as emerging real-world events by filtering out spurious and unimportant events. The graph is highly dynamic and complex, i.e., keywords (and associated edges) present in the graph get added and deleted at a fast pace; (Twitter reports more than 2300 tweets/sec [12] with potentially multiple simultaneous events present); the technique to identify the emerging events needs to be highly scalable. Specifically, it should be able to identify and maintain the events in a massive and highly dynamic graph. </span><span class="c21">1.1 Problem Formulation, Solution Ingredients </span><span class="c0">Let multiple </span><span class="c2">S</span><span class="c4">i </span><span class="c11">represent a set </span><span class="c0">messages) from </span><span class="c11">of keywords (potentially spread over </span><span class="c0">a unique user </span><span class="c2">i </span><span class="c0">in a time window that spans from time </span><span class="c2">(t - </span><span class="c8">&delta;</span><span class="c2">.w) </span><span class="c0">to current time t, where </span><span class="c8">&delta; </span><span class="c0">represents unit time called </span><span class="c2">quantum </span><span class="c0">and </span><span class="c8">&delta;</span><span class="c2">.w </span><span class="c0">is the length of the time window. Let </span><span class="c2">S</span><span class="c0">microblog </span><span class="c4">w</span><span class="c61">t</span><span class="c12">={S</span><span class="c4">1</span><span class="c12">...S</span><span class="c0">stream </span><span class="c4">m</span><span class="c11">} be a set of keywords sent by </span><span class="c12">m </span><span class="c11">unique users in the </span><span class="c0">in a given time window. As we are interested in discovering emerging events, sliding window (of size </span><span class="c8">&delta;</span><span class="c2">.w</span><span class="c0">) over </span><span class="c2">S</span><span class="c4">w</span><span class="c61">t </span><span class="c0">the </span><span class="c11">contains </span><span class="c0">message </span><span class="c11">the </span><span class="c0">stream. </span><span class="c11">messages </span><span class="c0">Time </span><span class="c11">from </span><span class="c0">unit </span><span class="c11">a </span><span class="c8">&delta; </span><span class="c0">denotes the fixed rate at which the window is moved. </span><span class="c14">Correlated Keyword Graph </span><span class="c0">(</span><span class="c14">CKG) captures the properties of microblog contents. </span><span class="c0">We represent all the keywords, after removing stop words, appearing in the messages in the current window as nodes in an undirected graph, CKG (we use the terms </span><span class="c2">node </span><span class="c0">and </span><span class="c2">keyword </span><span class="c0">interchangeably in this paper). CKG </span><span class="c2">is a dynamic graph whose state at time t, is G</span><span class="c13">t </span><span class="c2">= (V</span><span class="c13">t</span><span class="c2">, E</span><span class="c13">t</span><span class="c2">) where V</span><span class="c13">t </span><span class="c2">is the subset of </span><span class="c0">keywords are </span><span class="c85">eastern </span></p><p class="c24"><span class="c85">massive </span><span class="c2">keywords appearing </span><span class="c0">said to be temporally </span><span class="c85">moderate </span></p><p class="c38"><span class="c2">in </span><span class="c0">correlated </span><span class="c2">message iff set </span><span class="c0">they </span><span class="c2">S</span><span class="c4">w</span><span class="c61">t</span><span class="c0">appear </span><span class="c12">. </span><span class="c11">Thus, two </span><span class="c0">in </span><span class="c2">V</span><span class="c13">t </span><span class="c0">and are said to be spatially correlated if they have an edge between them in </span><span class="c2">E</span><span class="c13">t</span><span class="c0">. An edge links two keywords </span><span class="c2">iff </span><span class="c0">they both appear in a keyword set </span><span class="c2">S</span><span class="c4">i </span><span class="c11">belonging to a user </span><span class="c12">i. </span><span class="c0">Thus using the sliding window paradigm, a keyword is present in CKG if the keyword appears in at least one message in the current window. Since the window moves forward with time, CKG is highly dynamic where nodes and edges appear and disappear in real time. Further, a node in CKG can be either in a &ldquo;high&rdquo; state or a &ldquo;low&rdquo; state. A node moves into high state if there is a sudden increase in the frequency of its occurrence in the message stream. </span></p><p class="c24"><span class="c25">981 </span></p><p class="c24"><span class="c0">Each edge in CKG is associated with a weight which signifies the probability of the words associated with the edge appearing in temporally correlated messages from a set of users. One of the challenges in working with highly dynamic microblog data is the size of the generated CKG. We overcome this challenge by constructing a much smaller Active CKG (AKG) from the original CKG such that (1) the clusters discovered in AKG are no different from those discovered in the CKG and (2) it is orders of magnitude smaller than the original CKG. </span><span class="c14">Emerging events are identified by discovering clusters in CKG. </span><span class="c0">Given CKG, our problem of discovering emerging events can be mapped to identifying significant properties of the graph. For example, the burstiness of the keywords is captured by the state associated with a node. Temporal correlation can be captured by the moving window and spatial correlation can be identified by the weight associated with the edges. Using these properties, at a high level, our problem of event identification is similar to discovering a &ldquo;cluster&rdquo; within CKG. The cluster would consist of a set of keywords (e.g., &ldquo;earthquake&rdquo;, &ldquo;struck&rdquo;, &ldquo;Turkey&rdquo;) where each keyword would be bursty and would exhibit temporal and spatial correlation with the other words in the cluster. CKG is an undirected graph, i.e., is a tree of its biconnected components. A graph is said to be biconnected if for any pair of nodes in the graph there are at least two independent paths between them. Two paths are independent if they do not have any nodes in common except the end points. In a connected graph, two biconnected clusters can be connected with each other with just one path (had there been more paths between two clusters, they will merge into one cluster). We assume that nodes within biconnected components are more likely to be associated with the same event compared to nodes across components. Biconnected components are the most encompassing forms of clusters in an undirected graph, next only to a connected graph itself being considered to be a cluster. However, if we choose to consider all biconnected components as our clusters, we may end up discovering massive and more often meaningless clusters in a large and dynamic graph. The other option is to consider only complete cliques, wherein each node is connected with all the other nodes in the clique, as clusters of interest to us. Complete cliques are more likely to represent interesting real world events but considering only complete cliques as clusters does not suit our scenario because a) different users may use different sets of keywords to describe the same event and b) keywords associated with an event change rapidly in the microblogging stream due to the evolving nature of real time events. </span><span class="c14">Considering 1&frasl;2-quasi cliques (MQCs) as clusters of interest contributes to good precision and recall of discovered events</span><span class="c0">. As noted above, identifying events from the biconnected components in a CKG is likely to result in high recall (i.e., identify more real world events) but low precision (i.e., identify many non events as real-world events); the opposite is likely to be true for complete cliques. Therefore instead of finding either complete cliques or just biconnected components, we focus on 1&frasl;2-quasi cliques as our clusters of interest. A cluster is a </span><span class="c8">&sigma;</span><span class="c0">-quasi clique if each node in the cluster is adjacent to at least </span><span class="c8">&sigma;</span><span class="c0">.</span><span class="c2">(N-1) </span><span class="c0">nodes in the cluster where </span><span class="c8">&sigma; </span><span class="c0">is a number between 0 and 1 and </span><span class="c2">N </span><span class="c0">is the cluster size. When </span><span class="c8">&sigma; </span><span class="c0">is 1, the cluster is a complete clique. A biconnected component has </span><span class="c8">&sigma;</span><span class="c0">=2/N-1. For a connected graph, the minimum value of </span><span class="c8">&sigma; </span><span class="c0">can be 1/N-1. As explained above, none of the two extreme values of </span><span class="c8">&sigma; </span><span class="c0">is suitable in our environment. Therefore a natural choice is to set </span><span class="c8">&sigma; </span><span class="c0">to their mean in order to balance precision and recall. Hence, in order to discover meaningful clusters in a dynamic environment, we identify those components of a graph as clusters that have &gt; </span></p><p class="c19"><span class="c2">(1/2+1/N-1) </span><span class="c0">or </span><span class="c8">&ge;</span><span class="c0">1/2. We call these cliques </span><span class="c2">majority quasi cliques (MQCs) </span><span class="c0">since each node of the cluster is connected with a majority of the remaining nodes in the cluster. </span><span class="c14">Exploiting </span><span class="c15">short cycle property </span><span class="c14">(SCP) of MQCs makes event discovery a tractable and local problem. </span><span class="c0">It has been shown [14] that discovering 1&frasl;2 -quasi cliques is an NP-complete problem even for static graphs. Fortunately, we are able to show that 1&frasl;2-quasi cliques possess a unique property which we call </span><span class="c2">short cycle property (</span><span class="c14">SCP</span><span class="c2">)</span><span class="c14">: </span><span class="c0">any edge in the cluster has at least one cycle of length at most 4 within the cluster. (In Section 4, we define the </span><span class="c2">short-cycle property </span><span class="c0">formally and show that (1) </span><span class="c2">SCP </span><span class="c0">is a necessary but not sufficient condition for </span><span class="c2">MQC, </span><span class="c0">(2) </span><span class="c2">SCP </span><span class="c0">is a sufficient but not necessary condition for bi-connected components, and, (3) </span><span class="c2">SCP </span><span class="c0">can be exploited to identify events by discovering clusters which possess the short cycle property (called </span><span class="c2">approximate MQCs </span><span class="c0">(</span><span class="c2">aMQC</span><span class="c0">s)). The key advantage of using </span><span class="c2">SCP </span><span class="c0">for defining clusters is that we can discover dense clusters (</span><span class="c2">aMQCs</span><span class="c0">) efficiently and </span><span class="c2">locally </span><span class="c0">without using any global state information. For a dynamic graph, a cluster is said to be </span><span class="c14">locally </span><span class="c0">processable if for each incoming or departing node (or edge) to the graph, the cluster can be discovered by processing only its adjacent edges and nodes. Since these computations are </span><span class="c2">local </span><span class="c0">in nature</span><span class="c2">, </span><span class="c0">they are efficient, a pre- condition for discovering clusters in a highly dynamic graph. Further, multiple independent additions and deletions are allowed simultaneously on the graph. On the other hand, any processing which needs the graph to be stable (i.e., no addition or deletion is allowed in the graph during the course of computation) is called </span><span class="c14">global </span><span class="c0">processing. We believe that ours is the very first attempt to develop a technique to discover dense clusters in a highly dynamic graph. We propose efficient algorithms for discovering and maintaining the clusters in a dynamic graph as nodes and edges get added and deleted due to the moving window. We prove the correctness of our algorithms and experimentally show that our use of </span><span class="c2">aMQC </span><span class="c0">to define clusters helps us to discover emerging events correctly and efficiently. </span><span class="c14">Globally consistent ranking of events can be achieved by exploiting local properties of clusters</span><span class="c0">. In order to consume events, a ranking function is needed such that important events are ranked higher compared to spurious or less important news. However, due to the highly dynamic environment and real time considerations, no ranking function which needs any global information can be used. We present a novel and highly efficient ranking function that ranks events by just exploiting the local cluster properties corresponding to each event, yet delivers a globally consistent ranking in a best effort manner. Suppose two clusters discovered by us pertain to the same event but they could not get merged into a single event because (1) users used synonymous keywords to describe the event; (2) users indeed used different keywords, providing different perspectives about the same event; (3) the messages are posted in different languages. All these cases can be addressed by pre-processing the messages or post-processing the discovered clusters. For instance, one can use dictionary/thesaurus to address issues (1) and (3). For (2), clusters pointing to the same event should show temporal correlation. Therefore, one can post-process the discovered clusters (within a given time window) to correlate such clusters. Further, suppose there is an ongoing discussion among tweeters about a controversial topic (resulting in many messages) but it is not a real world event. Typically, such &ldquo;events&rdquo; are ranked low compared to real world events due to their slow rate of spread. We may want to report even those events if they are ranked sufficiently high, but often one may want to ignore such events by </span></p><p class="c24 c70"><span class="c0">post-processing the discovered clusters to identify such events. Post/pre-processing of keywords and discovered clusters and event categorization are orthogonal to the technique presented in this paper. It can be used to further enhance our technique and is part of our future work. </span><span class="c21">1.2 Research Contributions </span></p><p class="c70 c82"><span class="c8">&bull; </span><span class="c0">We present a new technique to discover and maintain dense clusters in massive and highly dynamic graphs in real time. In contrast, other clustering techniques, such as those based on data mining, are not only inherently slow in such environments they are also not suitable (details in Section 2). </span></p><p class="c65"><span class="c8">&bull; </span><span class="c0">In Section 3 we present our strategy to construct a much smaller Active CKG (AKG) from the original CKG to help us efficiently discover and maintain the clusters, which is imperative in a dynamic environment. </span></p><p class="c65"><span class="c8">&bull; </span><span class="c0">We model the problem of discovering the emerging events in real time in microblog streams as discovering approximate 1&frasl;2-quasi cliques, which possess the </span><span class="c2">short-cycle property. </span><span class="c0">This property is especially useful in highly dynamic microblog environments as it helps us maintain the clusters </span><span class="c2">locally </span><span class="c0">without using any </span><span class="c2">global </span><span class="c0">state information. We also prove the correctness of the algorithms (Section 4). </span></p><p class="c97 c70"><span class="c8">&bull; </span><span class="c0">We propose efficient algorithms for maintaining the clusters locally even under numerous additions and deletions of nodes and edges (Section 5). </span></p><p class="c70 c97"><span class="c8">&bull; </span><span class="c0">In Section 6, we present our ranking function such that more important events are highly likely to be ranked higher by just using local cluster properties. </span></p><p class="c35"><span class="c8">&bull; </span><span class="c0">Through an experimental study of our technique using real twitter data, we demonstrate its ability to (1) discover the emerging events in real time -- with high precision and recall; (2) process at almost double the rate of current Twitter intensity on a machine of moderate configuration; (3) discover emerging events around the same time or much before it is seen on Google headlines; (4) discover additional events which do not appear in Google headlines (Section 7). Discovering dense clusters in highly dynamic graphs efficiently and in real time has many applications in social networks, IP networks, telecommunication networks and for real time business analytics. Extant algorithms to discover dense clusters in dynamic graphs work on snapshot based techniques [2] and have severe limitations with regard to real time analytics. Our technique to discover clusters in massive and highly dynamic graphs in real time improves upon the state-of-the-art and can be easily extended for many such applications. </span></p><p class="c18"><span class="c21">2. RELATED WORK </span><span class="c0">The notion of time evolving graphs where some communities show a burst in their behavior at certain points in time was first developed in [1]. This work, done in the context of blogs, developed techniques to study the evolution of connected component structures in time evolving graphs. A technique to find proximity between two nodes in time evolving bipartite graphs is proposed in [3]. </span></p><p class="c9"><span class="c0">In [2], authors propose a technique to discover keyword clusters in blogs [2] to identify a topic. The key difference between [2] and our work is that we discover keyword clusters in microblog streams which are very dynamic and under stringent real time constraints. The technique presented in [2] requires global computation of clusters in the graph where graphs are updated not in real time but on a daily basis. Similarly, there is a large body </span></p><p class="c100"><span class="c25">982 </span></p><p class="c19"><span class="c0">of work on analyzing the structure of communities and their evolutions in social networks [4] [5]. These communities comprise humans (and not keywords), hence the real time constraint in this body of work is at a totally different scale compared to our problem setting. Hence our problem warrants a new approach. Recent work on identifying </span><span class="c2">emerging topics </span><span class="c0">on Twitter data [13] [17] [18] has a problem statement similar to ours. These techniques use &lsquo;bursty keywords&rsquo; in recent set of messages as </span><span class="c2">seeds </span><span class="c0">to identify emerging events. In [18] the authors describe a series of heuristics to identify &lsquo;emerging terms&rsquo;. The technique is computationally expensive for real time analysis due to the iterative method that is employed to compute an &lsquo;authority score&rsquo;. Further, the concept of user&#39;s authority to identify emerging terms may not be applicable in most real world situations. [13] reports a </span><span class="c2">pair of keywords </span><span class="c0">(based on correlation) as an emerging topic. At least one of these two keywords should be among the &lsquo;bursty keywords&rsquo;. [17] reports a cluster of keywords (at least one of them has to be &lsquo;bursty&rsquo;). However, both the techniques suffer from multiple limitations; 1) the performance is highly sensitive to the value of keyword burstiness threshold; 2) in the presence of multiple events, identifying co-occurring disjoint subsets from all the bursty keywords [17] or identifying co-occurring pairs based on time series analysis [13] are computationally expensive techniques. Events are not ranked in [17] therefore making the consumption of events untenable in the presence of multiple events. Further, the methods in [13] [17] [18] are not able to capture the evolution of an event as all these techniques use </span><span class="c2">seed </span><span class="c0">keywords to identify events. These techniques are essentially based on post-hoc analysis but they highlight the importance of identifying keywords (nodes) and their correlation (edges among keywords) as the basis for identifying an emerging topic. </span></p><p class="c52"><span class="c21">3. REDUCING GRAPH SIZE: CKG to AKG </span><span class="c0">Due to the high rate of arrival of messages in microblogs, the CKG generated from the microblog stream can quickly become very large. Hence we first generate a manageable sub-graph, AKG, from the original CKG so that our cluster discovery problem becomes tractable. </span><span class="c21">3.1 Identifying AKG Nodes </span><span class="c0">We use a &lsquo;hysteresis&rsquo; based approach. Let the CKG be denoted by </span><span class="c2">G</span><span class="c13">o</span><span class="c0">. Each node in this graph represents a keyword in the data stream (after removal of stop words). As we are interested in finding the emerging events, a natural way is to pick only </span><span class="c2">active </span><span class="c0">keywords in </span><span class="c2">G</span><span class="c13">o </span><span class="c0">which show an upward trend in their burstiness, i.e., frequency of their occurrence across different messages during a quantum, crosses a given threshold. Towards that end, we construct a subgraph, called AKG using only the active keywords and ignoring all the other keywords and their associated edges. Let </span><span class="c2">G </span><span class="c0">be the AKG induced by </span><span class="c2">G</span><span class="c13">o </span><span class="c0">after removing the non- bursty keywords. Notice that threshold in our case is set to identify keywords that need to be </span><span class="c2">excluded </span><span class="c0">from </span><span class="c2">G </span><span class="c0">and hence it is significantly low. However, given a properly set threshold, </span><span class="c2">G </span><span class="c0">will still be significantly smaller in size as compared to </span><span class="c2">G</span><span class="c13">o</span><span class="c0">, since only a small number of keywords would show burstiness. Because the burstiness threshold is low, the graph </span><span class="c2">G </span><span class="c0">contains all the keywords associated with an </span><span class="c2">emerging </span><span class="c0">event. We can subsequently use </span><span class="c2">G </span><span class="c0">to identify the events without impacting precision and recall. In order to identify bursty keywords, we use a two-state automaton where each keyword is either in a </span><span class="c2">low </span><span class="c0">state or a </span><span class="c2">high </span><span class="c0">state. A keyword moves from </span><span class="c2">low </span><span class="c0">state to </span><span class="c2">high </span><span class="c0">state (i.e., added in AKG) if during a quantum it shows burstiness, i.e., it appears in more than </span><span class="c8">&gamma; </span><span class="c0">different users&rsquo; messages. We call </span><span class="c8">&gamma; </span><span class="c0">the </span><span class="c2">high state threshold (HST). </span><span class="c0">All other keywords are in </span><span class="c2">low </span><span class="c0">state. A keyword </span></p><p class="c24 c70"><span class="c0">in </span><span class="c2">high state </span><span class="c0">may remain bursty or may become non-bursty in subsequent quanta. As we are interested in finding emerging events, we are specifically interested in finding keywords which are moving from </span><span class="c2">low </span><span class="c0">to </span><span class="c2">high </span><span class="c0">state. In order to discover meaningful clusters in </span><span class="c2">G</span><span class="c0">, we need relative stability in the graph. Hence, a keyword which has moved to AKG remains in AKG as long as it is part of an event cluster irrespective of its frequency of occurrence in subsequent quanta However, as we maintain the graph over a sliding window, we remove all the stale keywords, i.e., those keywords which have not occurred in any of the last </span><span class="c2">w </span><span class="c0">quanta, from AKG. For the keywords present in AKG, we update their status (i.e., remove them from AKG) using a </span><span class="c2">lazy update </span><span class="c0">principle, if needed, for only those nodes which are (1) in AKG and also occur in the messages present in the current quantum and (2) nodes adjacent to nodes identified in (1), as their correlation can change. One can see that in a given quantum only these nodes can be removed from a cluster (due to change in correlation). A departing keyword from a cluster is removed from the AKG if it is not part of any other event cluster. Notice that, as we explain in Section 3.2, a keyword which is not part of any cluster cannot become part of another cluster unless it exhibits a high frequency behavior. At that point, the keyword is moved into AKG anyway. The above technique helps us to smooth the movement of keywords from </span><span class="c2">high </span><span class="c0">to </span><span class="c2">low </span><span class="c0">state or vice-versa and is more efficient and scalable compared to the time series analysis as required in [13]. We can compute the state of each arriving keyword at the end of the quantum in </span><span class="c2">O(1) </span><span class="c0">time. Once the nodes in the sub-graph have been identified, the next step is to find the edges between these nodes. </span><span class="c21">3.2 Identifying AKG Edges </span><span class="c0">The guiding principle for creating an edge between two nodes in the sub-graph </span><span class="c2">G </span><span class="c0">is that</span><span class="c2">, in the current time window, messages from a significant number of users should have both the keywords</span><span class="c0">. Therefore, we associate a correlation measure with the edge connecting the two nodes and place an edge between the two keywords (present in AKG) if the correlation between them is above a threshold. The correlation is computed by associating a set of user ids with each keyword. This set U</span><span class="c5">1 </span><span class="c11">(called the </span><span class="c12">id set</span><span class="c11">) </span><span class="c0">associated with a keyword </span><span class="c2">n</span><span class="c4">1</span><span class="c11">, contains the ids of all those users </span><span class="c0">who used this word in the current window. Given sets U</span><span class="c5">1 </span><span class="c11">and U</span><span class="c5">2 </span><span class="c11">for a pair of nodes n</span><span class="c5">1 </span><span class="c11">and n</span><span class="c5">2</span><span class="c11">, we can find their correlation by </span><span class="c0">using the </span><span class="c2">Jaccard coefficient, </span><span class="c0">which is defined as the size of the intersection divided by the size of the union of the two sets: |</span><span class="c2">U</span><span class="c4">1 </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|/|</span><span class="c12">U</span><span class="c4">1 </span><span class="c11">U </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|. We call it </span><span class="c12">edge correlation </span><span class="c11">(</span><span class="c12">EC</span><span class="c11">). Notice that </span><span class="c0">a high value of the </span><span class="c2">EC </span><span class="c0">would imply that the two keywords have been used together by a large proportion of users and would hence imply a strong correlation. We use user ids as opposed to message ids so as to avoid the case of a single user flooding the same message multiple times leading to high correlation between nodes of the message. However, if we use user id, the strict message based spatiality is not valid (it is not necessary for a user to mention all the keywords in the same message). Hence, spatial correlation is not confined to a message but to a user and keywords from a user may be spread over multiple messages albeit within a given quantum of size </span><span class="c8">&delta;</span><span class="c0">. Since AKG contains all the keywords in the </span><span class="c2">high state</span><span class="c0">, it would be costly to compute the correlation of all pairs of nodes in AKG. Hence, we next address the following challenges: (1) Identify those pairs of nodes whose correlation is likely to be above the threshold and; (2) Find the correlation of the selected nodes. </span></p><p class="c66"><span class="c25">983 </span></p><p class="c19"><span class="c39">3.2.1 Identifying node pairs for EC Computation </span><span class="c0">As mentioned earlier, each keyword is associated with an </span><span class="c2">id set</span><span class="c0">. For keywords appearing in the </span><span class="c2">last </span><span class="c0">quantum, we construct two sets with the aid of </span><span class="c2">id set; </span><span class="c0">(1) Keywords that are in the high state (the size of the associated </span><span class="c2">id set </span><span class="c0">is </span><span class="c8">&ge; &gamma;</span><span class="c0">) and (2) keywords that were already in AKG and have also appeared in at least one of the messages that arrived in the last quantum. Note that a keyword may appear in both the sets. For all the keywords in set (1), we compute the correlation only among them. If the </span><span class="c2">EC threshold </span><span class="c0">is </span><span class="c8">&lambda; </span><span class="c0">and if the </span><span class="c2">correlation </span><span class="c0">between two keywords is above </span><span class="c8">&lambda; </span><span class="c0">we place an edge between them. It is intuitive to see that </span><span class="c2">new </span><span class="c0">keywords, entering into AKG do not have temporal and spatial correlation with any other keyword present in the AKG except those in set (1). For all the keywords identified in set (2), we update their correlation with their neighbors. Any other pairs of keywords would not have their correlation changed. Thus, using this mechanism we drastically reduce the number of </span><span class="c2">EC </span><span class="c0">computations that we need to do at the end of each quantum. As described next, we use the Min-Hashing scheme [6] to compute the </span><span class="c2">EC </span><span class="c0">efficiently. </span><span class="c39">3.2.2 Efficient computation of EC </span><span class="c0">We assign a hash value to each unique user in a quantum. Assuming that the number of unique users per quantum is no more than 2</span><span class="c94">n</span><span class="c0">, we choose the hash value for each message independently and uniformly from a range (0, 2</span><span class="c94">2n</span><span class="c0">) so as to avoid the birthday paradox (hash collision) [8]. For each keyword, we then keep track of the minimum hash value (</span><span class="c2">Min-Hash</span><span class="c0">) among all the user ids present in its </span><span class="c2">id set</span><span class="c0">. Now, for each pair of nodes </span><span class="c2">n</span><span class="c4">1 </span><span class="c11">and </span><span class="c12">n</span><span class="c4">2</span><span class="c11">, the probability of both </span><span class="c12">n</span><span class="c4">1 </span><span class="c11">and </span><span class="c12">n</span><span class="c4">2 </span><span class="c11">having the same </span><span class="c12">Min- </span><span class="c2">Hash </span><span class="c0">value is exactly equal to their </span><span class="c2">Jaccard similarity coefficient </span><span class="c0">[7] or </span><span class="c2">EC. </span><span class="c0">The reasoning is as follows: The </span><span class="c2">Min-hash </span><span class="c0">value will be the same if the </span><span class="c2">id </span><span class="c0">with minimum hash value is common to both the </span><span class="c2">id set </span><span class="c0">nodes, i.e., it belongs to the set |</span><span class="c2">U</span><span class="c4">1 </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|. Since the </span><span class="c0">total size of both the sets is |</span><span class="c2">U</span><span class="c4">1 </span><span class="c11">U </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|, the probability of having </span><span class="c0">the same </span><span class="c2">min-hash </span><span class="c0">value is |</span><span class="c2">U</span><span class="c4">1 </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|/|</span><span class="c12">U</span><span class="c4">1 </span><span class="c11">U </span><span class="c12">U</span><span class="c4">2 </span><span class="c11">|. However, in </span><span class="c0">order to avoid false negatives, instead of keeping track of only a single </span><span class="c2">Min-Hash </span><span class="c0">value for a node, we keep track of </span><span class="c2">p Min-Hash </span><span class="c0">values (i.e., the </span><span class="c2">p </span><span class="c0">minimum hash values amongst all the user ids in the union of </span><span class="c2">id set</span><span class="c0">). We add an edge between two keywords in </span><span class="c2">G </span><span class="c0">if there is at least one common entry in their </span><span class="c2">p Min-Hash </span><span class="c0">values. The value of </span><span class="c2">p </span><span class="c0">depends on the </span><span class="c2">EC </span><span class="c0">threshold </span><span class="c8">&lambda; </span><span class="c0">and </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">; for a uniform distribution, the expected number of trials before a match occurs is </span><span class="c2">1/p.</span><span class="c8">&lambda;</span><span class="c0">. Value of </span><span class="c2">p </span><span class="c0">is set to </span><span class="c2">min(</span><span class="c8">&gamma;</span><span class="c2">/2,1/</span><span class="c8">&lambda;</span><span class="c0">). Due to this mechanism, we can compute the correlation between two nodes in an efficient manner with a very small probability of false negatives and false positives [7]</span><span class="c2">. </span><span class="c0">In summary, we first significantly reduce the number of pairs of nodes whose correlation needs to be computed and then for the identified pairs we find their </span><span class="c2">Jaccard coefficient </span><span class="c0">efficiently in O</span><span class="c2">(p.log(p)) </span><span class="c0">time where </span><span class="c2">p </span><span class="c0">is a constant. Thus, the tunable parameters and thresholds affecting the AKG are </span><span class="c8">&gamma;</span><span class="c0">, </span><span class="c8">&lambda;</span><span class="c0">, </span><span class="c8">&delta; </span><span class="c0">and </span><span class="c2">w</span><span class="c0">* </span><span class="c8">&delta;</span><span class="c0">. One can argue that it is imperative to set the thresholds ( and </span><span class="c8">&gamma;</span><span class="c0">) correctly to include an edge and a node in the AKG. The discovery of an event ultimately depends on what nodes and edges are present in the graph, which in turn depends on these threshold values. For timely discovery of events these thresholds are kept low and they are just the qualifying thresholds for any edge or node to be in the AKG. If the </span><span class="c3">&gamma; </span><span class="c0">is high, only very popular keywords reach the high state. It compromises our ability to identify the emerging events in a timely manner. Further, since not all keywords are used by all the users, the threshold for each individual keyword has to be low. For the same reason, </span><span class="c3">&lambda; </span><span class="c0">has to be </span></p><p class="c1"><span class="c0">relatively low. Therefore, thresholds are set such that they just filter out completely unwarranted nodes and edges and not tuned such that nodes and edges left in the graph automatically result in events. However, with low threshold, many more keywords move into high state. Therefore, the events are identified by discovering a particular class of clusters (aMQC</span><span class="c2">s</span><span class="c0">) as explained in Section 4. </span></p><p class="c18"><span class="c21">4. CLUSTER DISCOVERY </span><span class="c0">Once the graph is in place, we can use many standard cluster finding algorithms [2] to find a cluster of keywords corresponding to an emerging event. However, approximation algorithms for finding dense clusters in a graph operate on the entire graph (i.e., graph needs to be stable during the computation) and are not efficient [2]. We hence propose the novel </span><span class="c2">short cycle property </span><span class="c0">(SCP) in Section 4.1 which helps us discover dense clusters (i.e., aMQC cliques in our case) efficiently and in real time. In Figure 1, a cluster with 4 keywords (&ldquo;earthquake&rdquo;, &ldquo;struck&rdquo;, &ldquo;eastern&rdquo;, &ldquo;turkey&rdquo;) exists at time </span><span class="c2">t. </span><span class="c0">At time </span><span class="c2">t+</span><span class="c8">&delta;</span><span class="c2">, </span><span class="c0">we could update the cluster </span><span class="c2">with </span><span class="c0">keyword &ldquo;5.9&rdquo; since it was forming a cycle of length 3 with nodes (&ldquo;earthquake&rdquo;, &ldquo;turkey&rdquo;). If the edge between &ldquo;earthquake&rdquo; and &ldquo;turkey&rdquo; would not have existed, even then keyword &ldquo;5.9&rdquo; would have joined the cluster due to the formation of cycle of length 4, via keywords &ldquo;eastern&rdquo; or &ldquo;struck&rdquo;. Hence, due to the existence of a </span><span class="c2">short cycle </span><span class="c0">within the nodes of the cluster</span><span class="c2">, </span><span class="c0">we could update the cluster without re-computing it on the entire graph. As the graph changes, </span><span class="c2">SCP </span><span class="c0">ensures that only incremental computations are performed for those nodes and edges which need to be updated, while simultaneously ensuring the correctness of result. We provide the analysis and correctness of our approach in Section 4.2 and Section 4.3 respectively. </span><span class="c21">4.1 Short-cycle property </span><span class="c0">A graph is said to possess the short-cycle property if for any two adjacent nodes n</span><span class="c5">1 </span><span class="c11">and n</span><span class="c5">2 </span><span class="c11">in the graph, in addition to the direct </span><span class="c0">edge between n</span><span class="c5">1 </span><span class="c11">and n</span><span class="c5">2</span><span class="c11">, there exists at least one more path of </span><span class="c0">length at most 3 between n</span><span class="c5">1 </span><span class="c11">and n</span><span class="c5">2</span><span class="c11">, i.e., n</span><span class="c5">1 </span><span class="c11">and n</span><span class="c5">2 </span><span class="c11">are part of a </span><span class="c0">cycle of length at most 4. More formally, </span><span class="c2">short-cycle property </span><span class="c0">in a cluster </span><span class="c2">C(V,E) </span><span class="c0">in graph </span><span class="c2">G </span><span class="c0">is defined as follows: if </span><span class="c20">)(},{ </span><span class="c33">CVvv </span><span class="c68">ji </span><span class="c3">&isin; </span><span class="c0">and </span><span class="c20">)(),( </span><span class="c33">CEvv </span><span class="c68">ji </span><span class="c3">&isin; </span><span class="c0">then </span><span class="c20">) ( </span><span class="c68">j i </span><span class="c33">vv </span><span class="c3">&rarr;&exist; </span><span class="c0">s.t., </span><span class="c20">3| |1 </span><span class="c3">&le;&rarr;&lt; </span><span class="c68">j i </span><span class="c33">vv </span><span class="c0">. </span></p><p class="c78 c70"><span class="c14">Definition 1: </span><span class="c0">The diameter of a graph </span><span class="c2">G(V, E) </span><span class="c0">is defined as </span><span class="c2">D(G)= </span><span class="c135">)},({ max </span><span class="c30">)(, </span><span class="c111">vud </span><span class="c51">GVvu </span><span class="c27">&isin; </span><span class="c0">where </span><span class="c2">d(u,v) </span><span class="c0">is the distance between any two nodes </span><span class="c2">u, v</span><span class="c0">, belonging to the graph. The diameter of a complete clique is 1. Theorem 1 states that </span><span class="c2">SCP </span><span class="c0">is a necessary property for </span><span class="c2">MQC</span><span class="c0">s. </span><span class="c14">Theorem 1: </span><span class="c0">For a majority quasi clique </span><span class="c2">G(V,E) </span><span class="c0">with </span><span class="c8">&ge; </span><span class="c0">1&frasl;2 , </span><span class="c7">)(</span><span class="c55">GVv</span><span class="c72">&isin;&forall; </span><span class="c0">, </span><span class="c2">v </span><span class="c0">participates in a cycle of length at most 4. </span><span class="c14">Proof: </span><span class="c0">Let us denote the neighbor set of node </span><span class="c2">u </span><span class="c0">as </span><span class="c2">A(u). u </span><span class="c63">&isin; </span><span class="c110">G</span><span class="c58">MQC </span><span class="c63">&rArr;</span><span class="c23">| </span><span class="c110">A</span><span class="c23">(</span><span class="c110">u</span><span class="c23">)|</span><span class="c63">&ge; </span><span class="c23">(</span><span class="c110">N </span><span class="c63">&minus;</span><span class="c23">1) / 2 </span><span class="c63">&lceil;</span><span class="c44">&#9474; </span><span class="c63">&rceil;</span><span class="c44">&#9474;</span><span class="c0">where </span><span class="c2">|V(G)| = N. </span><span class="c0">For a graph </span><span class="c2">G(V,E) </span><span class="c0">with </span><span class="c8">&ge;</span><span class="c0">1&frasl;2, </span><span class="c2">D(G)=2 </span><span class="c0">[15]</span><span class="c2">. </span><span class="c0">Hence </span><span class="c7">2)},({ </span><span class="c46">),(, </span><span class="c72">&le; &forall; </span><span class="c79">&isin; </span><span class="c55">vud </span><span class="c68">GVvu </span><span class="c0">. </span><span class="c15">Case1: </span><span class="c2">d(u,v)=2; </span><span class="c0">u,v </span><span class="c20">) ( </span><span class="c68">MQC </span><span class="c33">GV</span><span class="c3">&isin; </span><span class="c20">) (),(&amp;),(| </span><span class="c46">0 0 0 </span><span class="c68">MQC </span><span class="c33">GEvn nun </span><span class="c3">&isin; &exist; &rArr; </span><span class="c0">. We claim that for pair of nodes </span><span class="c2">{u,v}, </span><span class="c0">there is at least one more common neighbor apart from node </span><span class="c46">0</span><span class="c55">n </span><span class="c0">. Let us define </span><span class="c108">i vui </span><span class="c22">SniniA S </span><span class="c93">&notin; &minus;= </span><span class="c103">&isin; </span><span class="c73">},{;)( </span><span class="c87">00 },{ </span><span class="c67">3| | </span><span class="c124">&minus;&le;&cup; &rArr; </span><span class="c90">NSS </span><span class="c128">vu </span><span class="c11">(1). </span><span class="c0">Eqn (1) holds since nodes </span><span class="c2">u, v </span><span class="c0">and </span><span class="c2">n</span><span class="c4">0 </span><span class="c11">are not part of </span><span class="c59">| | </span><span class="c104">vu </span><span class="c33">SS </span><span class="c3">&cup; </span><span class="c0">. Since </span><span class="c2">|V(G</span><span class="c4">MQC</span><span class="c12">)| = N </span><span class="c11">and, | | </span><span class="c46">},{ </span><span class="c68">vui</span><span class="c2">S </span><span class="c79">&isin; </span><span class="c8">&ge;</span><span class="c0">1&frasl;2 </span><span class="c125">&lceil; &rceil; </span><span class="c116">| |11 </span><span class="c4">v u </span><span class="c106">SS N </span><span class="c101">1 </span><span class="c84">&rArr; &minus;&minus; </span><span class="c8">&ge; </span><span class="c0">1, otherwise Eqn (1) will not hold. In other words, </span><span class="c2">u </span><span class="c0">and </span><span class="c2">v </span><span class="c0">have at </span></p><p class="c105"><span class="c25">984 </span></p><p class="c24"><span class="c0">least one more neighbor apart from node </span><span class="c2">n</span><span class="c4">0</span><span class="c11">. Hence, there exists a </span><span class="c0">cycle of length 4 between any pair of nodes </span><span class="c2">{u,v} </span><span class="c20">) ( </span><span class="c68">MQC </span><span class="c33">GV</span><span class="c3">&isin; </span><span class="c0">. </span><span class="c15">Case 2: </span><span class="c2">d (u,v) = 1; u,v </span><span class="c20">) ( </span><span class="c68">MQC </span><span class="c33">GV</span><span class="c3">&isin; </span><span class="c0">i.e. u and v have an edge between themselves. In this case, without loss of generality, for any neighbor </span><span class="c2">n</span><span class="c4">0 </span><span class="c11">of node </span><span class="c12">u, </span><span class="c20">2),( </span><span class="c30">0 </span><span class="c3">&le; </span><span class="c33">vnd </span><span class="c0">. Hence </span><span class="c2">{u,v} </span><span class="c20">) ( </span><span class="c68">MQC </span><span class="c33">GV</span><span class="c3">&isin; </span><span class="c0">are part of cycle of length 4. Hence in both these cases, node </span><span class="c2">v (u) </span><span class="c0">is part of a cycle of length at most 4 or, in other words, for any </span><span class="c2">(u, v) </span><span class="c20">) ( </span><span class="c68">MQC </span><span class="c33">GE </span><span class="c3">&isin; </span><span class="c0">, there exists another path between them of length at most 3 within the cluster. The </span><span class="c2">short cycle property (SCP) </span><span class="c0">of MQCs, as we explain next, radically simplifies the cluster discovery problem. Capitalizing on the </span><span class="c2">SCP </span><span class="c0">we can add a new node to the existing clusters </span><span class="c2">locally </span><span class="c0">(i.e., by just processing the edges adjacent to it) as follows. For each new keyword </span><span class="c2">n </span><span class="c0">that is moving into </span><span class="c2">high </span><span class="c0">state, if it shows a correlation with n</span><span class="c5">1</span><span class="c11">, n</span><span class="c5">2</span><span class="c11">....n</span><span class="c5">k </span><span class="c11">(</span><span class="c12">k </span><span class="c11">&gt;1) keywords (nodes) in graph G, </span><span class="c0">we check if each node pair </span><span class="c2">n</span><span class="c4">i</span><span class="c12">, n</span><span class="c4">j </span><span class="c12">(1</span><span class="c54">&le;</span><span class="c12">i , j</span><span class="c54">&le;</span><span class="c12">k)</span><span class="c11">: </span><span class="c2">Rule R1</span><span class="c0">: Has at least one more common neighbor OR </span><span class="c2">Rule R2</span><span class="c0">: Has an edge between them. In either case, we add the new node to the cluster that both these nodes are already part of. If these two nodes (</span><span class="c2">n</span><span class="c4">i</span><span class="c12">, n</span><span class="c4">j</span><span class="c11">) are not part of </span><span class="c0">any cluster, we initialize a cluster with four nodes if it satisfies (</span><span class="c2">R1</span><span class="c0">) or three nodes if it satisfies (</span><span class="c2">R2</span><span class="c0">). For </span><span class="c2">k=2, </span><span class="c0">as shown in Figure 2</span><span class="c2">, </span><span class="c0">an incoming node </span><span class="c2">n, </span><span class="c0">forms a cluster (a) as </span><span class="c2">n1 and n2 </span><span class="c0">have a common neighbor </span><span class="c2">n</span><span class="c4">c </span><span class="c12">(R1) </span><span class="c11">or cluster (b) as </span><span class="c12">n</span><span class="c4">1 </span><span class="c11">and </span><span class="c12">n</span><span class="c4">2 </span><span class="c11">have </span><span class="c0">an edge between them (</span><span class="c2">R2</span><span class="c0">). If the incoming node shows correlation with zero or one node, we simply add that node (and edge) in </span><span class="c2">G </span><span class="c0">and do nothing. </span></p><p class="c24"><span class="c0">We check </span><span class="c2">R1 </span><span class="c0">and </span><span class="c2">R2</span><span class="c0">, for each departing node (node which moves from </span><span class="c2">high </span><span class="c0">state to </span><span class="c2">low </span><span class="c0">state), where existing clusters can be either re-clustered into smaller clusters or dissolved (Section 5.3). For all edges adjacent to the arriving or departing node, we consider two adjacent edges at a time (total O (</span><span class="c2">k</span><span class="c13">2</span><span class="c0">) pairs of edges if there are </span><span class="c2">k </span><span class="c0">adjacent edges to that node). We check if nodes which these two edges are adjacent to, satisfy either </span><span class="c2">R1 </span><span class="c0">or </span><span class="c2">R2</span><span class="c0">. Therefore without processing any other nodes and edges in the graph, except the pairs of edges adjacent to the node under consideration, we can discover a cluster that satisfies </span><span class="c2">SCP </span><span class="c0">and thus an </span><span class="c2">aMQC</span><span class="c0">. Thus, due to this special property, we can discover the approximate 1/2-quasi cliques in the dynamic graph AKG by performing just local computations. At each time quantum, we do a total of O(k</span><span class="c94">2</span><span class="c0">NC) computations where </span><span class="c2">N </span><span class="c0">is the total number of nodes changing their status (to </span><span class="c2">high </span><span class="c0">or </span><span class="c2">low</span><span class="c0">), </span><span class="c2">k </span><span class="c0">is the average number of edges adjacent to these nodes and C is the average cluster size a node (among N nodes) is participating in. Now, by our definition, both </span><span class="c2">k </span><span class="c0">and </span><span class="c2">N </span><span class="c0">are fairly small compared to the number of keywords present in the message stream in a given time window. Further, as shown by our experiments, the average cluster size is very small compared to the size of the graph (less than 7 keywords/cluster). For MQC, short cycle property is a necessary but not sufficient condition. For the cluster in Figure 3(b) (including new edges), each edge participates in a cycle of length 4 within the cluster but the cluster is not MQC. If we identify the cliques based on the short-cycle property, while we will not miss any MQC, we may collect some extra clusters which are not MQCs. As shown in </span></p><p class="c24"><span class="c0">[14], discovering MQC is NP-hard even for static graphs. Therefore, discovering clusters based on SCP discovers the MQCs not only with a good approximation bound, but also very fast and we can discover dense clusters with just </span><span class="c2">local </span><span class="c0">computation. </span><span class="c21">4.2 Analysis of Approximate MQCs </span><span class="c0">As we proved in Section 4.1, SCP is a necessary condition for </span><span class="c2">MQCs</span><span class="c0">. Once an aMQC is discovered based on SCP, one can efficiently identify if it is MQC in </span><span class="c2">O(N</span><span class="c13">2</span><span class="c2">) </span><span class="c0">time where N is the number of nodes in the discovered cluster. We check if each node belonging to the cluster has edges with at least </span><span class="c2">(N-1)/2 </span><span class="c0">nodes in the cluster. However, with dynamic graphs, we face challenges which are different from stable graphs as depicted below. </span><span class="c15">Example 1: </span><span class="c0">Let us consider a MQC of size 7 as in Fig 3(a) which is reported as a cluster. Since the clique size is 7, each node has to be connected with at least </span><span class="c89">&lceil; &rceil; </span><span class="c0">32/6 </span><span class="c8">= </span><span class="c0">of the nodes in the clique. Now, if a 8</span><span class="c94">th </span><span class="c0">node joins the clique (due to the existence of </span><span class="c2">short cycle </span><span class="c0">with nodes in the cluster), for the original cluster to be continued to be considered MQC, each node should have connection with </span><span class="c119">&lceil; &rceil; </span><span class="c127">42/7 </span><span class="c134">= </span><span class="c0">nodes. Hence, the new node should a) have edges to at least 6 of the existing nodes in the cluster or b) have connection with any of the 4 nodes in the cluster along with at least 1 more </span><span class="c2">new </span><span class="c0">edge among already existing nodes in the cluster. Point (b) not only makes the computation of MQC exponential, it is also an unnecessary requirement since the cluster with existing 7 nodes is already reported. On the other hand, the requirement to have an edge with almost all the other existing nodes is too stringent for admitting any node in the cluster as the keywords belonging to an event may keep on changing. This example shows that since real time events evolve continuously, using MQC as our cluster definition restricts our capability to capture dynamic events. </span><span class="c15">Example 2: </span><span class="c0">We show two separate clusters (MQC clusters) in Figure 3(b), both discovered based on </span><span class="c2">SCP. </span><span class="c0">Now assume that two new edges emerge among two clusters, as shown in Figure 3(b), forming a short cycle between the nodes belonging to separate clusters therefore, due to </span><span class="c2">SCP, </span><span class="c0">merging these two clusters into one. Now a) either we stop reporting both of these earlier clusters as events since the merged cluster is no longer an MQC or b) we keep on reporting earlier clusters as separate clusters. </span></p><p class="c24"><span class="c26">Figure 3: Clusters discovered based on </span><span class="c88">SCP </span><span class="c0">Both of these scenarios point out the following issues: In case of (a) we stop reporting the events already reported, the basis for which is still intact. The nodes in the event continue to show correlation with the same set of nodes as in the erstwhile clusters (one may, however, stop reporting the event if any node/edge disappears); In case of (b) maintaining such distinction will not only be computationally expensive in a dynamic environment (we need to identify all sub-cliques in a discovered cluster such that these sub-cliques are MQCs), it will be erroneous also (nodes n</span><span class="c5">1</span><span class="c0">, n</span><span class="c5">2</span><span class="c0">, n</span><span class="c5">3</span><span class="c0">, n</span><span class="c5">4 </span><span class="c0">would be reported as a separate cluster). On the other hand, emergence of new edges among the nodes belonging to two events, both discovered close to each other in real world time, points to a strong temporal and spatial correlation. However, if we relax the requirement of having MQC and instead consider </span><span class="c2">aMQC </span><span class="c0">based on </span><span class="c2">SCP</span><span class="c0">, as our clusters of interest, we not </span></p><p class="c24"><span class="c33">n</span><span class="c62">1 </span><span class="c33">n</span><span class="c62">2 </span></p><p class="c24"><span class="c33">n </span></p><p class="c45"><span class="c33">n</span><span class="c62">c </span><span class="c33">(a) </span></p><p class="c24"><span class="c33">(b) </span></p><p class="c24"><span class="c20">New Edges </span></p><p class="c24"><span class="c47">n</span><span class="c53">1 </span></p><p class="c24"><span class="c33">n</span><span class="c64">1 </span><span class="c33">n</span><span class="c64">2 </span></p><p class="c24"><span class="c33">n </span></p><p class="c24"><span class="c26">Figure 2: Clusters formed due to short-cycle property </span></p><p class="c24"><span class="c25">985 </span></p><p class="c24"><span class="c57">Clusters 1 Cluster 2 </span></p><p class="c24"><span class="c47">n</span><span class="c53">2 </span><span class="c47">n</span><span class="c53">3 </span><span class="c47">n</span><span class="c53">4 </span></p><p class="c24"><span class="c57">(a) MQC of size 7 (b) Clusters formed due to </span><span class="c130">SCP </span></p><p class="c24"><span class="c0">only capture the evolving nature of real time events in a fast moving environment, we discover the clusters more efficiently. </span><span class="c2">aMQC </span><span class="c0">cliques allow incremental evolution of clusters therefore capturing the evolving nature of the real time events. Hence, in Example 1, a new node is able to join the cluster due to </span><span class="c2">SCP </span><span class="c0">indicating the continuous evolution of the real time events. Similarly, in Example 2, two clusters exhibiting strong temporal and spatial correlation are allowed to merge into one event. However, if the evolved cluster is sparse, it is more likely to be ranked lower due to its inherent sparse nature. Our ranking function (Section 6) ensures the quality of discovered events by ranking more dense clusters higher. Hence, the </span><span class="c2">SCP </span><span class="c0">helps discovering dense clusters in a scalable and efficient manner. Therefore, even though one can efficiently identify MQC from an aMQC, due to the dynamic nature of the graph and the evolving nature of the events, </span><span class="c2">SCP </span><span class="c0">is the only cluster property that we enforce while discovering clusters in a dynamic graph. The aMQCs based on </span><span class="c2">SCP </span><span class="c0">ensure that no MQC based clique is missed. At the same time, the clusters thus discovered are biconnected components as </span><span class="c2">SCP </span><span class="c0">is a sufficient (but not a necessary) condition for biconnected components as shown in Section 4.3. The bi-connected property of clusters is helpful in maintaining the events efficiently in a highly dynamic graph as explained in Section 5. </span><span class="c21">4.3 Correctness of our Approach </span><span class="c0">We next present the main properties of our clusters (aMQCs) and give a correctness proof for our approach. We first prove that clusters discovered by us are bi-connected. Thereafter we give a proof of correctness of our approach, i.e., the clusters discovered based on </span><span class="c2">local </span><span class="c0">processing of nodes and edges are unique and consistent with similar clusters discovered on a time invariant instance of the same graph. </span><span class="c14">Theorem 2</span><span class="c2">: If we discover the clusters based on SCP, the resulting clusters will be bi-connected. </span><span class="c14">Proof</span><span class="c2">: </span><span class="c0">The proof is by induction and is based on </span><span class="c2">Lemma 1</span><span class="c0">. </span></p><p class="c24"><span class="c20">p</span><span class="c40">1 </span><span class="c20">p</span><span class="c40">2 </span><span class="c57">n</span><span class="c16">1 </span></p><p class="c24"><span class="c20">p</span><span class="c40">3 </span></p><p class="c24"><span class="c20">p</span><span class="c40">4 </span></p><p class="c24"><span class="c20">I</span><span class="c40">1 </span></p><p class="c45"><span class="c20">n</span><span class="c40">2 </span><span class="c20">I</span><span class="c40">2 </span><span class="c59">n</span><span class="c40">3 </span><span class="c26">Figure 4</span><span class="c20">: </span><span class="c26">Independent path examples </span><span class="c14">Lemma </span><span class="c2">cluster, two, n</span><span class="c4">1 </span><span class="c12">to </span><span class="c2">i.e., </span><span class="c12">n</span><span class="c4">3 </span><span class="c12">which </span><span class="c2">there </span><span class="c14">1</span><span class="c0">: </span><span class="c2">there Given </span><span class="c12">are </span><span class="c2">exist exit </span><span class="c12">independent </span><span class="c2">any two two three paths, independent nodes one </span><span class="c12">from </span><span class="c2">from n</span><span class="c12">each </span><span class="c4">1</span><span class="c12">, </span><span class="c2">paths </span><span class="c12">n</span><span class="c2">n</span><span class="c4">2 1 </span><span class="c12">other. </span></p><p class="c38"><span class="c12">and to </span><span class="c2">from </span><span class="c12">n</span><span class="c4">2 </span><span class="c12">nand </span><span class="c4">3 </span><span class="c2">n</span><span class="c12">belonging </span><span class="c4">1 </span><span class="c12">another to to a the other from </span></p><p class="c38"><span class="c14">Proof Sketch</span><span class="c15">: </span><span class="c0">As the cluster is bi-connected, there exist two independent Figure 4, those from paths and let paths the two from paths n</span><span class="c5">1 </span><span class="c0">hence n</span><span class="c5">1 </span><span class="c0">to ndo </span><span class="c5">3 </span><span class="c0">be not named intersect from to pn</span><span class="c5">3 2 </span><span class="c0">and with nand </span><span class="c5">1 </span><span class="c0">to peach from </span><span class="c5">4</span><span class="c0">n. </span><span class="c5">2 </span><span class="c0">p</span><span class="c5">1 </span><span class="c0">be and other. nnamed </span><span class="c5">1 </span><span class="c0">to p</span><span class="c5">2 </span><span class="c0">nare The </span><span class="c5">3</span><span class="c0">. pAs </span><span class="c5">1 </span><span class="c0">independent same and shown pholds </span><span class="c5">2 </span><span class="c0">in and </span></p><p class="c24"><span class="c0">for C1: paths None pof </span><span class="c5">3 </span><span class="c0">Hence there and exist these p</span><span class="c5">4</span><span class="c0">2 . 4 Now, independent paths there (</span><span class="c2">p</span><span class="c4">1</span><span class="c12">, </span><span class="c0">C2: Only one pair of paths intersects are three cases: </span></p><p class="c24"><span class="c12">p</span><span class="c4">2, </span><span class="c0">paths </span><span class="c12">p</span><span class="c4">3</span><span class="c12">, p</span><span class="c0">from </span><span class="c4">4</span><span class="c0">) each intersect with each other. </span></p><p class="c24"><span class="c2">n</span><span class="c0">other. </span><span class="c4">1</span><span class="c12">-n</span><span class="c4">2 </span><span class="c0">and Without </span><span class="c2">n</span><span class="c4">1</span><span class="c12">-n</span><span class="c4">3</span><span class="c0">. </span></p><p class="c24"><span class="c0">loss of generality, there C3: say paths exist 2 independent </span><span class="c2">p</span><span class="c4">1 </span><span class="c0">Both of these pairs and paths of </span><span class="c2">p</span><span class="c4">3 </span><span class="c0">from paths intersect </span><span class="c2">n</span><span class="c4">1</span><span class="c12">-n</span><span class="c0">intersect </span><span class="c4">2 </span><span class="c0">with </span><span class="c12">(p</span><span class="c4">2</span><span class="c12">) </span><span class="c17">and </span><span class="c0">each with </span><span class="c12">n</span><span class="c4">1</span><span class="c12">-n</span><span class="c0">other. each </span><span class="c4">3 </span><span class="c12">(p</span><span class="c4">4</span><span class="c12">). </span></p><p class="c24"><span class="c0">Hence, </span></p><p class="c56"><span class="c0">other. Therefore, there must exist at least 2 intersection points. Let&rsquo;s call them </span><span class="c2">I</span><span class="c4">1 </span><span class="c0">and </span><span class="c2">I</span><span class="c4">2</span><span class="c0">. We can always construct two independent paths </span></p><p class="c24"><span class="c25">986 </span></p><p class="c24"><span class="c0">from </span><span class="c2">n</span><span class="c4">1 </span><span class="c0">to </span><span class="c2">n</span><span class="c4">2 </span><span class="c0">and </span><span class="c2">n</span><span class="c4">1 </span><span class="c0">to </span><span class="c2">n</span><span class="c4">3 </span><span class="c0">as follows: </span><span class="c2">n</span><span class="c4">1</span><span class="c12">-I</span><span class="c4">1</span><span class="c12">-n</span><span class="c4">2 </span><span class="c0">and </span><span class="c2">n</span><span class="c4">1</span><span class="c12">-I</span><span class="c4">2</span><span class="c12">-n</span><span class="c4">3</span><span class="c0">. Independent paths can be constructed even if </span><span class="c2">I</span><span class="c4">1 </span><span class="c0">and/or </span><span class="c2">I</span><span class="c4">2 </span><span class="c17">themselves are a sequence of nodes by extending the same </span><span class="c0">argument. The detailed proof is omitted in the interest of space. </span><span class="c15">Correctness of Local Computation</span><span class="c0">: We now prove that our cluster computation is correct, unique and consistent. </span><span class="c14">Lemma 2: </span><span class="c2">The locally discovered clusters are consistent with any global computation of clusters on the same graph. </span><span class="c14">Proof</span><span class="c2">: </span><span class="c0">The proof is by induction. As we see above, node </span><span class="c2">n </span><span class="c0">need not be present in the graph at the time of computation of cluster </span><span class="c2">C, </span><span class="c0">and as and when it arrives, by just processing its adjacent edges, we update the cluster. Now, suppose, an incoming (or departing) node </span><span class="c2">n </span><span class="c0">is adjacent to nodes </span><span class="c2">n</span><span class="c4">1</span><span class="c12">,..n</span><span class="c4">k. </span><span class="c12">e</span><span class="c4">i </span><span class="c0">is an edge from node </span><span class="c2">n </span><span class="c0">to node </span><span class="c2">n</span><span class="c4">i </span><span class="c14">Lemma 3: </span><span class="c2">Each pair of edges (ei, ej), 1</span><span class="c8">&le;</span><span class="c2">i,j</span><span class="c8">&le;</span><span class="c2">k, i</span><span class="c8">&ne;</span><span class="c2">j will merge at most two clusters (for incoming node). </span><span class="c14">Lemma 4: </span><span class="c2">Each pair of edges (ei, ej), 1</span><span class="c8">&le;</span><span class="c2">i,j</span><span class="c8">&le;</span><span class="c2">k, i</span><span class="c8">&ne;</span><span class="c2">j will break the cluster into at most two clusters(for departing node). </span><span class="c0">However, it may be the case that one or more of the resulting sub clusters no longer remain aMQC as </span><span class="c2">SCP </span><span class="c0">may no longer hold for the cluster. The process to check this is described in Section 5.3. </span><span class="c14">Lemma 5</span><span class="c2">: For all pairs of edges (ei, ej), 1</span><span class="c8">&le;</span><span class="c2">i,j</span><span class="c8">&le;</span><span class="c2">k, i</span><span class="c8">&ne;</span><span class="c2">j adjacent to node n, the final cluster(s) do not depend on the order in which each of these pairs is considered. </span><span class="c0">Similarly, for an incoming/departing edge </span><span class="c2">e</span><span class="c0">, adjacent to nodes </span><span class="c2">n</span><span class="c4">1 </span><span class="c17">and </span><span class="c12">n</span><span class="c4">2</span><span class="c0">, clusters are maintained by considering all pairs of edges (</span><span class="c2">e, e</span><span class="c4">i</span><span class="c0">) where </span><span class="c2">e</span><span class="c4">i </span><span class="c0">(</span><span class="c8">&ne;</span><span class="c2">e</span><span class="c0">) is an edge adjacent to either node </span><span class="c2">n</span><span class="c4">1 </span><span class="c0">or </span><span class="c2">n</span><span class="c4">2 </span><span class="c0">(as outlined in Section 5). Therefore, Lemmas 3, 4 and 5 are applicable for edge addition/deletion as well. </span></p><p class="c24"><span class="c14">Theorem 3: </span><span class="c2">The locally discovered clusters result in the unique clustering for a given graph. </span><span class="c14">Proof</span><span class="c2">: </span><span class="c0">Follows as a corollary of Lemmas 2, 3, 4 and 5. In summary, the properties of a </span><span class="c2">cluster C </span><span class="c0">discovered based on SCP are: </span><span class="c2">P1</span><span class="c0">: </span><span class="c2">C </span><span class="c0">is an a</span><span class="c2">MQC </span><span class="c0">as </span><span class="c2">SCP </span><span class="c0">is a necessary (but not sufficient) condition for MQC. </span><span class="c2">P2: C </span><span class="c0">is a bi-connected cluster as </span><span class="c2">SCP </span><span class="c0">is sufficient (but not necessary) condition for bi-connected clusters. </span><span class="c2">P3: C, discovered locally </span><span class="c0">with the aid of </span><span class="c2">SCP, </span><span class="c0">is consistent with global computation on the same graph, is correct and unique. </span></p><p class="c24"><span class="c21">5. CLUSTER MAINTENANCE </span><span class="c0">We now present the details of the algorithms for node/edge addition/deletion. These operations do not require any global computation. We first prove a property of aMQCs below. </span><span class="c14">Lemma 6</span><span class="c0">: Two aMQCs which share an edge are merged to form a single aMQC </span><span class="c14">Proof Sketch</span><span class="c15">: </span><span class="c0">Consider two aMQC clusters C</span><span class="c5">1</span><span class="c0">(V</span><span class="c5">1</span><span class="c0">,E</span><span class="c5">1</span><span class="c0">) and C</span><span class="c5">2</span><span class="c0">(V</span><span class="c5">2</span><span class="c0">,E</span><span class="c5">2</span><span class="c0">). Let edge e</span><span class="c5">1 </span><span class="c0">between nodes n</span><span class="c5">1 </span><span class="c0">and n</span><span class="c5">2 </span><span class="c0">be common between C</span><span class="c5">1 </span><span class="c0">and C</span><span class="c5">2</span><span class="c0">, i.e., e</span><span class="c5">1 </span><span class="c42">&isin;</span><span class="c17">E</span><span class="c5">1 </span><span class="c0">and e</span><span class="c5">1</span><span class="c42">&isin;</span><span class="c17">E</span><span class="c5">2</span><span class="c0">. If C</span><span class="c5">1 </span><span class="c0">and C</span><span class="c5">2 </span><span class="c0">are merged to form a single cluster C(V,E) then the merged cluster will be an aMQC and satisfy all our cluster properties (</span><span class="c2">P1,P2 P3</span><span class="c0">). As explained next, we use this property to merge clusters as new nodes and edges are added to the graph. </span><span class="c21">5.1 Node Addition </span><span class="c0">The node addition algorithm is based on the </span><span class="c2">SCP</span><span class="c0">. Hence for a new node n</span><span class="c5">1 </span><span class="c0">to be made a part of cluster c</span><span class="c5">1</span><span class="c0">, it should have </span><span class="c2">edges </span><span class="c0">to at least two nodes n</span><span class="c5">2 </span><span class="c0">and n</span><span class="c5">3 </span><span class="c0">within the cluster. In order to </span></p><p class="c45"><span class="c0">satisfy other two. the </span><span class="c2">SCP</span><span class="c0">, either or The (b) node n</span><span class="c5">2 </span><span class="c0">addition and n</span><span class="c5">3 </span><span class="c0">(a) should n</span><span class="c5">3 </span><span class="c0">or be nconnected </span><span class="c5">2 </span><span class="c0">should be neighbors of each by a path of length algorithm can be stated as follows: </span><span class="c15">Algorithm</span><span class="c0">: NodeAddition Let V&rsquo; be the set of node if Find (nn</span><span class="c5">12</span><span class="c0">. , all For n</span><span class="c5">3</span><span class="c0">)nodes </span><span class="c80">&isin;</span><span class="c0">all E, pairs form N Form a new cluster Merge the clusters nodes which are of nodes (n</span><span class="c5">2</span><span class="c0">, n</span><span class="c5">3</span><span class="c0">) incident </span><span class="c83">&isin;</span><span class="c17">V&rsquo;, </span></p><p class="c24"><span class="c0">on the newly added </span></p><p class="c24"><span class="c0">which a new are cluster adjacent from to both n</span><span class="c5">1</span><span class="c0">using from the the cluster nodes nmerging </span><span class="c5">1</span><span class="c0">, n</span><span class="c5">2</span><span class="c0">, , nn</span><span class="c5">3 2 </span><span class="c0">nand and </span><span class="c5">2 </span><span class="c0">algorithm and </span><span class="c74">&forall; </span><span class="c0">n</span><span class="c5">3</span><span class="c0">n. n</span><span class="c5">3</span><span class="c0">. </span></p><p class="c24"><span class="c5">4</span><span class="c83">&isin;</span><span class="c0">till </span><span class="c17">N. </span></p><p class="c38"><span class="c0">no more merging is possible. In Figure 5(b), when a new node </span><span class="c2">n </span><span class="c0">arrives, it has edges to node </span><span class="c2">1 </span><span class="c0">and </span><span class="c2">2. </span><span class="c0">These two nodes have a common neighbor (node </span><span class="c2">4</span><span class="c0">). Hence, a new cluster (</span><span class="c2">1, 2, 4, n</span><span class="c0">) is formed due to presence of </span><span class="c2">SCP</span><span class="c0">. Since this new cluster shares an edge (</span><span class="c2">1, 4</span><span class="c0">) again merged Being based with on with </span><span class="c2">SCP, C</span><span class="c4">1</span><span class="c12">, </span><span class="c0">C</span><span class="c17">it </span><span class="c5">2 </span><span class="c0">we due </span><span class="c17">is merged </span><span class="c0">to can edge see </span><span class="c17">with </span><span class="c0">(</span><span class="c2">2, </span><span class="c0">that </span><span class="c12">C</span><span class="c0">the </span><span class="c2">4</span><span class="c0">) </span><span class="c4">1</span><span class="c12">. </span><span class="c0">resulting </span><span class="c17">This </span><span class="c0">newly </span><span class="c17">merged </span><span class="c0">formed in cluster </span><span class="c17">cluster </span><span class="c0">clusters </span><span class="c2">C</span><span class="c17">is </span><span class="c4">4</span><span class="c12">. </span></p><p class="c24"><span class="c0">will satisfy </span><span class="c2">P1, P2 and P3</span><span class="c0">. </span></p><p class="c24"><span class="c47">C</span><span class="c53">1 </span><span class="c30">C</span><span class="c53">2 </span><span class="c47">Articulation </span></p><p class="c24"><span class="c47">Point </span></p><p class="c24"><span class="c47">Node </span><span class="c41">n </span><span class="c47">arrives </span></p><p class="c24"><span class="c41">n </span></p><p class="c24"><span class="c26">Figure 5</span><span class="c20">: </span><span class="c26">Node/edge addition and deletion examples </span><span class="c21">5.2 Edge Addition </span><span class="c0">The edge addition algorithm also tries to ensure that the fresh clusters formed due to the new edge satisfy the </span><span class="c2">short-cycle property</span><span class="c0">. We present the algorithm and then prove its correctness. Let a new edge the nodes n</span><span class="c5">1 </span><span class="c0">and e</span><span class="c5">1 </span><span class="c0">n</span><span class="c5">2 </span><span class="c0">(nalready </span><span class="c5">1</span><span class="c0">, n2) be added to the graph. Notice that both </span></p><p class="c24"><span class="c0">existed in the graph G(V,E). </span><span class="c15">Algorithm</span><span class="c0">: </span><span class="c74">&forall; &forall; </span><span class="c0">n</span><span class="c5">3</span><span class="c42">&isin;</span><span class="c0">n</span><span class="c5">4</span><span class="c42">&isin;</span><span class="c0">V </span><span class="c17">V </span><span class="c0">EdgeAddition </span><span class="c17">| (n</span><span class="c5">1</span><span class="c0">, n| (n</span><span class="c5">2</span><span class="c0">Merge if the n</span><span class="c5">3</span><span class="c0">= clusters n</span><span class="c5">4 </span><span class="c0">or </span><span class="c5">3</span><span class="c0">, </span><span class="c61">5 4 </span><span class="c0">) n</span><span class="c42">&isin;</span><span class="c5">4</span><span class="c0">)</span><span class="c42">&isin;</span><span class="c0">E </span><span class="c17">E </span><span class="c0">(nusing </span><span class="c5">3</span><span class="c0">, n</span><span class="c5">4</span><span class="c0">) </span><span class="c61">3 </span></p><p class="c24"><span class="c4">1 </span></p><p class="c24"><span class="c61">5 </span></p><p class="c24"><span class="c41">n </span><span class="c61">4 </span></p><p class="c24"><span class="c50">Edge 1-2 </span><span class="c47">arrives </span></p><p class="c24"><span class="c61">1 </span></p><p class="c24"><span class="c61">2 </span></p><p class="c24"><span class="c61">5 5 </span></p><p class="c24"><span class="c30">C</span><span class="c53">3 </span></p><p class="c24"><span class="c61">2 </span></p><p class="c24"><span class="c17">do </span><span class="c0">the </span><span class="c42">&isin;</span><span class="c0">do </span></p><p class="c24"><span class="c17">E, </span><span class="c0">cluster </span><span class="c17">form </span><span class="c0">merging </span><span class="c17">a cluster </span><span class="c0">algorithm. </span></p><p class="c24"><span class="c17">of n</span><span class="c5">1</span><span class="c0">, n</span><span class="c5">2</span><span class="c0">, n</span><span class="c5">3</span><span class="c0">, n</span><span class="c5">4</span><span class="c0">. </span></p><p class="c24"><span class="c0">The EdgeAddition algorithm works in two phases. In the first phase it forms all those clusters which satisfy the </span><span class="c2">short-cycle property </span><span class="c0">with the newly added edge. Once it has formed these clusters, it merges them using the cluster merging algorithm. The clusters formed during the first phase satisfy the </span><span class="c2">short-cycle property </span><span class="c0">and hence satisfy all our cluster properties. As per </span><span class="c2">Lemma 6</span><span class="c0">, the clusters discovered during the second phase would also satisfy our cluster properties. Hence the edge addition algorithm discovers correct clusters. In Figure 5(a), a new edge (</span><span class="c2">1,2</span><span class="c0">) arrives. In phase 1, we create three clusters namely (</span><span class="c2">1,2,4</span><span class="c0">), (</span><span class="c2">1,2,4,5</span><span class="c0">) and </span><span class="c2">(1,2,3,4,). </span><span class="c0">In phase 2, these aMQCs are merged (</span><span class="c2">Lemma 6</span><span class="c0">) to form the cluster C</span><span class="c5">3</span><span class="c0">. </span><span class="c21">5.3 Node Deletion </span><span class="c0">When a node is deleted from the graph all the incident edges on that node also get deleted. As a result of this the clusters in which the node participates could get split into one or more smaller clusters. Due to </span><span class="c2">short-cycle property, </span><span class="c0">standard depth first search based techniques to partition a biconnected component do not work in our environment. Thus the major task associated with the deletion of a node is to ensure that the correctness of the clusters </span></p><p class="c24"><span class="c47">Node </span><span class="c41">n </span><span class="c47">departs </span><span class="c61">2 </span><span class="c4">5 4 </span><span class="c47">Edge </span><span class="c41">n-1 </span></p><p class="c24"><span class="c47">departs </span><span class="c4">5 </span><span class="c61">1 </span></p><p class="c24"><span class="c47">(a) (b) C</span><span class="c53">4 </span></p><p class="c38"><span class="c4">2 </span><span class="c30">(c) </span><span class="c61">3 1 </span></p><p class="c24"><span class="c13">4 </span></p><p class="c24"><span class="c61">2 3 4 3 </span></p><p class="c24"><span class="c61">1 </span><span class="c4">1 </span></p><p class="c24"><span class="c104">n </span><span class="c61">4 </span><span class="c4">3 2 </span></p><p class="c24"><span class="c30">(d) </span><span class="c61">3 </span><span class="c25">987 </span></p><p class="c24"><span class="c0">is maintained post the deletion of the node. This implies that the partitioned clusters satisfy the </span><span class="c2">short-cycle property</span><span class="c0">. Thus a cluster will not get dissolved/split if (1) each edge in the cluster is part of a </span><span class="c2">short-cycle </span><span class="c0">within the cluster and (2) if the cluster does not have an articulation point. Notice that after the deletion of a node, a cluster could satisfy (1) and still have an articulation point as shown by the example in Figure 6. In the figure, initially the graph consists of a single cluster consisting of all the nodes. When node 9 gets deleted, the cluster gets split into two as node 3 now becomes an articulation point (Cluster 1 &ndash; nodes 0,1,11,10,2,3 and Cluster 2 &ndash; nodes 4,5,8,7,6,3). Hence whenever a node gets deleted, we need to perform two checks: </span></p><p class="c24"><span class="c2">Cycle Check</span><span class="c0">: find the edges which do not participate in a </span><span class="c2">short-cycle, </span><span class="c0">i.e., a cycle of maximum length four; and </span></p><p class="c24"><span class="c2">Articulation Check</span><span class="c0">: find if any articulation points are generated in the cluster. Before we explain the algorithm for dissolving clusters, we first present a property satisfied by the set of nodes that can become articulation points due to the deletion of a node and its incident edges. Once we identify this set we can restrict the articulation check to the nodes in this set thereby improving our efficiency. </span></p><p class="c24"><span class="c8">&bull; </span><span class="c122">10 </span></p><p class="c24"><span class="c44">&bull; </span><span class="c16">1 </span></p><p class="c24"><span class="c71">&bull; </span></p><p class="c24"><span class="c8">&bull; </span><span class="c16">2 </span></p><p class="c45"><span class="c71">&bull; </span><span class="c16">0 9 </span><span class="c8">&bull; </span><span class="c71">&bull; </span><span class="c16">3 </span><span class="c8">&bull; </span><span class="c71">&bull; </span><span class="c29">6 </span><span class="c122">4 </span></p><p class="c24"><span class="c44">&bull; </span><span class="c71">&bull; </span><span class="c16">5 </span><span class="c8">&bull; </span><span class="c16">8 </span></p><p class="c24"><span class="c16">0 </span></p><p class="c24"><span class="c26">Figure 6: Breaking of cluster due to node deletion </span><span class="c14">Lemma 7</span><span class="c15">: </span><span class="c0">Figure 2(a)). Let n has nodes </span><span class="c2">only </span><span class="c0">n</span><span class="c5">1</span><span class="c0">two , nits articulation </span><span class="c5">1 </span><span class="c0">and edges n</span><span class="c5">2 </span><span class="c0">ehave </span><span class="c5">1 </span><span class="c0">point. </span></p><p class="c38"><span class="c0">and a ecommon </span><span class="c5">2 </span><span class="c0">be deleted. neighbor n</span><span class="c5">2</span><span class="c0">, incident n No and other nn</span><span class="c5">c</span><span class="c0">edges . </span><span class="c5">c </span><span class="c0">Let node belong the e</span><span class="c5">1</span><span class="c0">(n, except node to n</span><span class="c5">1</span><span class="c0">cluster ) C (See and n along e</span><span class="c5">2</span><span class="c0">(n, with n</span><span class="c5">2</span><span class="c0">). </span></p><p class="c24"><span class="c0">n</span><span class="c5">c </span><span class="c0">can be the </span></p><p class="c38"><span class="c14">Proof Sketch</span><span class="c15">: </span><span class="c0">Let the articulation point in the cluster be a node n</span><span class="c2">short-cycle. </span><span class="c0">node </span><span class="c5">a</span><span class="c54">&ne;</span><span class="c17">n</span><span class="c5">c</span><span class="c0">. n Since would That n</span><span class="c5">a </span><span class="c0">have is </span><span class="c2">short-cycle </span><span class="c0">part had of at an least cannot aMQC one have cluster, more either edge it </span><span class="c2">e</span><span class="c4">1 </span><span class="c0">participates or adjacent </span><span class="c2">e</span><span class="c4">2 </span><span class="c0">in a (otherwise to it). Therefore, articulation npoint. </span></p><p class="c24"><span class="c5">a </span><span class="c0">continues to be the part of a cycle and cannot be an </span></p><p class="c38"><span class="c0">In case a direct </span><span class="c17">and </span><span class="c0">This </span><span class="c17">n</span><span class="c0">can </span><span class="c5">3 </span><span class="c0">there is no node adjacent will edge become between the n</span><span class="c5">2 </span><span class="c0">articulation and n</span><span class="c5">3 </span><span class="c0">be proved using arguments to both then it points similar can n</span><span class="c5">2 </span><span class="c0">and be shown n</span><span class="c5">3 </span><span class="c0">after the to those but there exists that both removal of given above. nn</span><span class="c5">12 </span><span class="c0">. </span></p><p class="c45"><span class="c0">It is important to note that the node(s) suggested by </span><span class="c2">Lemma 7 </span><span class="c0">will be an articulation point if there are no alternate paths between </span><span class="c17">and </span><span class="c0">edge </span><span class="c17">n</span><span class="c0">between </span><span class="c5">2 </span><span class="c0">except nfrom </span><span class="c5">1 </span><span class="c0">and the n</span><span class="c5">2 </span><span class="c0">above then the nn</span><span class="c5">1 </span><span class="c0">and </span><span class="c5">c </span><span class="c16">11 </span><span class="c0">and cannot one n</span><span class="c5">2 </span><span class="c0">via or be if nan </span><span class="c5">c</span><span class="c0">there . In articulation other words if there is a direct n</span><span class="c5">1 </span><span class="c0">are multiple nodes neighboring point. This is intuitive hence the proof is omitted. The articulation check is performed for each pair of edges adjacent to node </span><span class="c2">n, </span><span class="c0">which participate in a </span><span class="c2">short-cycle. </span><span class="c0">The node removal algorithm uses the </span><span class="c2">Lemma 7 </span><span class="c0">to restrict the articulation check to a small set of nodes. We now explain the details of this algorithm. Let the graph G(V,E) consist of a cluster C having nodes V(C) and edges E(C). </span><span class="c15">Algorithm</span><span class="c0">: Let Delete V</span><span class="c5">I</span><span class="c36">&sube; </span><span class="c0">node </span><span class="c17">V </span><span class="c15">Cycle </span><span class="c77">&forall; </span><span class="c0">n</span><span class="c77">&forall; </span><span class="c5">2</span><span class="c42">&isin;</span><span class="c0">V(n</span><span class="c15">Check </span><span class="c5">2</span><span class="c0">,n</span><span class="c5">I 3</span><span class="c0">do ) </span><span class="c16">7 </span></p><p class="c24"><span class="c47">Delete Node 9 </span></p><p class="c24"><span class="c16">11 </span></p><p class="c45"><span class="c8">&bull; </span><span class="c44">&bull; </span><span class="c16">10 1 </span></p><p class="c24"><span class="c8">&bull; &bull; </span><span class="c16">2 </span></p><p class="c24"><span class="c8">&bull; &bull; </span><span class="c16">3 </span><span class="c8">&bull; &bull; </span><span class="c29">6 </span><span class="c122">4 </span></p><p class="c45"><span class="c44">&bull; </span><span class="c16">7 </span></p><p class="c24"><span class="c44">&bull; </span><span class="c16">5 </span><span class="c8">&bull; </span><span class="c16">8 </span></p><p class="c24"><span class="c0">NodeDeletion </span><span class="c17">s.t. </span><span class="c0">n</span><span class="c5">1 </span><span class="c0">and </span><span class="c129">&forall; </span><span class="c17">n</span><span class="c5">2</span><span class="c0">all </span><span class="c42">&isin;</span><span class="c0">Vits </span><span class="c5">I </span><span class="c0">incident | (n</span><span class="c5">1</span><span class="c0">, n</span><span class="c5">2</span><span class="c0">) edges </span></p><p class="c24"><span class="c42">&isin;</span><span class="c0">E(C) </span></p><p class="c24"><span class="c42">&isin;</span><span class="c0">E(C) check if the edge (n</span><span class="c5">2</span><span class="c0">,n</span><span class="c5">3</span><span class="c0">) has a path of length </span></p><p class="c24"><span class="c0">at most 3 within the cluster If not remove edge from cluster and add n</span><span class="c5">3 </span><span class="c0">to V</span><span class="c5">I </span><span class="c17">If yes, check if at least one edge of the cycle is shared with </span><span class="c0">another cycle of the original cluster of length at most 3. If not, create an independent cluster from this cycle. </span><span class="c15">Articulation Check</span><span class="c0">: </span><span class="c77">&forall; </span><span class="c0">n</span><span class="c5">2 </span><span class="c0">and n</span><span class="c5">3</span><span class="c42">&isin;</span><span class="c17">V</span><span class="c5">I </span><span class="c0">do </span></p><p class="c45"><span class="c0">if (n</span><span class="c5">2</span><span class="c0">, n</span><span class="c5">3</span><span class="c0">)</span><span class="c36">&notin;</span><span class="c17">E(C) and there exists exactly one common neighbor </span><span class="c0">of n</span><span class="c5">2 </span><span class="c0">and n</span><span class="c5">3 </span><span class="c0">then check if there is any path from n</span><span class="c5">2 </span><span class="c0">to n</span><span class="c5">3 </span><span class="c17">if not, split C into two clusters &ndash; one consisting of node n</span><span class="c5">2 </span><span class="c0">and </span></p><p class="c24"><span class="c0">nodes in V(C) reachable from n</span><span class="c5">2 </span><span class="c0">except via n</span><span class="c5">3</span><span class="c0">. The remaining nodes will be part of another cluster. if (n</span><span class="c5">2</span><span class="c0">,n</span><span class="c5">3</span><span class="c0">) </span><span class="c42">&isin;</span><span class="c0">E(C) and there is no other path from n</span><span class="c5">2 </span><span class="c0">to n</span><span class="c5">3 </span><span class="c0">of </span></p><p class="c24"><span class="c0">length at most 3, then check if there is any path from n</span><span class="c5">2 </span><span class="c0">to n</span><span class="c5">3 </span><span class="c17">if not, split C into two clusters &ndash; one consisting of node n</span><span class="c5">2 </span><span class="c0">and </span></p><p class="c24"><span class="c0">nodes in V(C) reachable from n</span><span class="c5">2 </span><span class="c0">except via n</span><span class="c5">3</span><span class="c0">. The remaining nodes will be part of another cluster. In Figure 5(c), node </span><span class="c2">n </span><span class="c0">is removed. Set V</span><span class="c5">1 </span><span class="c0">contains nodes 1, 3 and 4 in the beginning. Node 2 and 5 are also added to set V</span><span class="c5">1 </span><span class="c0">as described in </span><span class="c2">cycle-check</span><span class="c0">. Since none of the nodes participates in a </span><span class="c2">short-cycle, </span><span class="c0">the cluster is no longer an </span><span class="c2">aMQC </span><span class="c0">and is discarded</span><span class="c2">. </span><span class="c0">In Figure 6, when node 9 is deleted, it generates an articulation node (node 3), and gets split into two clusters as described above. Articulation check is done for smaller set of nodes selected based on </span><span class="c2">Lemma 7. </span><span class="c0">If we find an articulation point then we split the original cluster around the articulation point. Thus the above algorithm helps to finds the new clusters locally by only focusing on the nodes taking part in the original cluster. Further, the algorithm needs to evaluate all the nodes of the original cluster if and only if we find some articulation point. Articulation points are used to discover bi-connected components in static graphs. We present algorithms such that we use articulation points to efficiently maintain the clusters </span><span class="c2">locally </span><span class="c0">as described above. Articulation points could be efficiently exploited due to the bi-connected property of aMQCs. In most of the cases the algorithm is able to discover the new clusters by visiting a fraction of the nodes of the original cluster. </span><span class="c21">5.4 Edge Deletion </span><span class="c0">The edge deletion algorithm is very similar to that of node deletion. When an edge e</span><span class="c5">1</span><span class="c0">(n</span><span class="c5">1</span><span class="c0">, n</span><span class="c5">2</span><span class="c0">) is deleted, we need to perform a cycle check to find all the cycles of length at most 4 that could have been broken due to the deletion of this edge. In Figure 5(d), edge (n, 1) is deleted. Set V</span><span class="c5">1 </span><span class="c0">(in NodeDeletion algorithm) is initialized with nodes {1,n}. In </span><span class="c2">cycle-check </span><span class="c0">phase, a smaller cluster with nodes (3, 4, n) is created since nodes 1, 2 and 5 are no longer part of a </span><span class="c2">short-cycle. </span></p><p class="c24"><span class="c21">6. RANKING EMERGING EVENTS </span><span class="c0">We discover emerging events in real time in a microblog stream. It is important to rank these discovered events in order to present these events to users in a comprehensible manner such that relatively more important events are ranked higher. Further, due to overwhelming pace at which the messages are generated in a microblog stream, it is entirely possible that some spurious events may get discovered due to accidental formation of a cluster, for instance because of presence of some popular keywords in the graph. Hence, our goal is to not only identify </span><span class="c2">real </span><span class="c0">events but to rank relatively more important events higher. We compute the relative ranking of events (or clusters) by utilizing only the local parameters of a cluster without resorting to any global data structure or entity; since our objective is to discover events in real time any global computation (for instance, </span></p><p class="c24"><span class="c0">relative ranking of events by considering all the events in the current time window) for ranking is simply not scalable. Therefore, for efficient ranking of the clusters, we take into account </span><span class="c2">local </span><span class="c0">cluster properties, namely: a) Correlation coefficient of edges present in a cluster. b) Density of cluster (number of edges present in a cluster). c) Support of the cluster, i.e., the number of independent user </span></p><p class="c24"><span class="c0">ids associated with the cluster keywords. A natural way to think about these parameters is that a strongly correlated dense cluster with high support should be ranked higher. Hence, a set of messages due to a real event is more likely to be ranked higher than an accidental cluster formation as accidental clusters are likely to possess low correlation, low density, or low support. Let </span><span class="c2">C= (V,E) </span><span class="c0">is a cluster discovered by our algorithm. </span><span class="c2">V </span><span class="c0">is the set of nodes in C, </span><span class="c2">|V| = n</span><span class="c0">. </span><span class="c2">E </span><span class="c0">is set of edges in </span><span class="c2">C</span><span class="c0">. We compute the rank of the cluster as </span><span class="c109">.</span><span class="c75">1</span><span class="c120">n </span><span class="c32">W.C </span><span class="c95">where </span><span class="c32">W </span><span class="c95">is the weight matrix of </span><span class="c0">size </span><span class="c15">1-by-n </span><span class="c0">where </span><span class="c14">w</span><span class="c121">i, </span><span class="c0">is the weight of a node </span><span class="c14">i</span><span class="c0">, i.e., the number of user ids associated with it. </span><span class="c15">C </span><span class="c0">is edge correlation coefficient matrix of size </span><span class="c15">n-by-n. </span></p><p class="c56"><span class="c10">iCii</span><span class="c99">&forall;=</span><span class="c49">;1 </span><span class="c123">Eji Ci C </span><span class="c41">ij ii </span><span class="c92">&notin; = &forall;= </span><span class="c117">),(;0 ,;1 </span><span class="c32">. </span><span class="c95">We normalize the </span><span class="c0">cluster rank with its size so that the rank of a cluster is not a monotonically increasing function of cluster size. Hence, a strongly connected cluster will result in higher rank as there would be many non-zero entries in </span><span class="c15">C</span><span class="c0">. Secondly, higher correlation coefficient values will result in higher cluster rank. Finally, higher support to cluster will result in higher value of weight matrix, </span><span class="c15">W, </span><span class="c0">resulting in higher rank. </span></p><p class="c24"><span class="c21">7. EXPERIMENTAL EVALUATION </span><span class="c0">Our goal in Section 7.1 is to compare and contrast our SCP based technique, designed to extract, in real-time, emerging events from microblog messages, with ground truth regarding real-world events, as manifested in Google news headlines. The above study establishes that our technique is capable of identifying real-world events, as they occur, with high precision and recall. In the experiment reported in Section 7.2 we present the results of a detailed precision and recall study using Twitter traces. In Section 7.3, we compare the performance of our </span><span class="c2">SCP </span><span class="c0">based clustering algorithm with an offline method [2]. </span></p><p class="c24"><span class="c21">7.1 Evaluation against Ground Truth </span><span class="c0">Using an RSS feed reader we collected a total of 473 Google news headlines over a period of 18 hours on 29</span><span class="c94">th </span><span class="c0">Feb 2012. 255 of these headlines related to USA specific real time events (for example, we did not consider news analysis related headlines among our events of interest). These headlines were found to be related to 60 unique real-world events. We concurrently ran a twitter downloader to obtain more than 1.3 million tweets generated within the USA (by providing longitude and latitude range). Tweet download rate was close to 21/sec. We set =800 tweets/quantum, and </span><span class="c2">w=30 quanta, </span><span class="c0">representing a history of 20 minutes. Note that </span><span class="c8">&delta; </span><span class="c0">is defined in terms of number of messages in our experiments. First we identified all the bursty keywords in the twitter trace; a keyword is bursty if in at least one quantum in the trace, the keyword is used by </span><span class="c8">&ge; </span><span class="c0">4 users. That is, </span><span class="c8">&gamma;</span><span class="c33">=4. </span><span class="c3">&lambda;</span><span class="c0">=0.1. A keyword in a given Google news headline, (after removing stop words), must be present in the bursty keyword list in order to be identified as pertaining to an event. For instance, corresponding to the headline &ldquo;Body of missing Florida firefighter found&rdquo;, there was only one tweet present in the entire trace. </span><span class="c8">&gamma;</span><span class="c0">=4 implies that the event represented by the lone tweet need not be </span></p><p class="c24"><span class="c25">988 </span></p><p class="c24 c113"><span class="c0">considered as an emerging event. Of the 60 news events, there were 27 such events (with very few related tweets) including, &ldquo;Egypt lifts travel ban on 7 US pro-democracy workers&rdquo;, &ldquo;Rep. David Drier decides against seeking reelection&rdquo;, etc. Of the remaining 33 emerging real-world event related headlines our technique identified 31 events. Other two headlines were ((&ldquo;Obama, Congress leaders seek cooperation on jobs&rdquo;, &ldquo;Obama praises Snowe&rdquo;). Of the keywords occurring in these headlines, only &ldquo;Obama&rdquo; exceeded the burstiness threshold. Upon investigation, we found that considered w.r.t. each headline, &ldquo;Obama&rdquo; could not be characterized as being bursty. Hence our technique did not report these two events. In the table below, we list a subset of the identified events. Events with real time implications such as weather warning (Tornado in MidWest) were up to 6 hours ahead of their Google News counterpart. Some events, like &lsquo;Apple&rsquo;, were concurrent with the source of Google news (USA Today). </span></p><p class="c69"><span class="c15">Table 1: </span><span class="c14">SCP </span><span class="c15">technique w.r.t. ground truth Google News HeadLine Event Discovered Using </span><span class="c14">SCP </span></p><p class="c34"><span class="c20">Davy Jones of Monkees dead Davy Jones Monkees Dead RIP </span></p><p class="c48"><span class="c20">Tornado pounds MidWest Watch awesome Tornado outside </span></p><p class="c1"><span class="c0">larger the </span><span class="c8">&delta;</span><span class="c0">, the less bursty an event needs to be and vice versa; 2) </span><span class="c2">Edge Correlation threshold </span><span class="c0">(</span><span class="c8">&lambda;</span><span class="c0">). We report the results obtained by varying the quantum size instead of </span><span class="c2">high state threshold </span><span class="c0">(</span><span class="c8">&gamma;</span><span class="c0">) as, if we vary </span><span class="c8">&gamma; </span><span class="c0">the set of events itself changes. It is important to point out that varying shows similar trends. </span></p><p class="c70 c78"><span class="c39">7.2.2 Measuring Recall and Precision </span><span class="c0">If a trace contains messages pertaining to an event but we do not discover the event, </span><span class="c2">loss of recall </span><span class="c0">occurs. We may miss the event due to (1) non-formation of the corresponding cluster (i.e., only 1 or 2 words from the event showed burstiness) (2) the cluster formed does not satisfy the </span><span class="c2">SCP</span><span class="c0">. Therefore, we compute recall as follows: First we collect all the keywords, after removing stop words, which are either bursty (based on the </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">) or are already present in the current sliding window. An event in the current window can comprise of only these keywords. Keywords which are bursty but not present in any of the chronologically correlated event clusters discovered in offline manner indicate potentially missed events. Once we collect all such </span><span class="c2">noun </span><span class="c0">words (we use Stanford POS Tagger [16]), we manually check in the trace if they indeed belong to any real event or not. To make this check manageable, given the size of the data, we randomly pick a fraction of missing noun keywords. The probability of them belonging to a real event is extrapolated to estimate the number of missing events. The maximum number of events (by adding both events identified and events missed by our algorithm) discovered in a run is considered to be the sum total of all the events present in the trace. We use this number to compute recall across different runs. Once the maximum number of real events is estimated, the same number is used to compute recall across all the runs. Therefore, our objective of studying the impact of parameter tuning on recall is not affected because of &lsquo;estimation&rsquo; inaccuracy, if any. Precision is defined as &lsquo;How many of the events identified by us are real and important events?&rsquo; A spurious event reported by our system leads to </span><span class="c2">loss of precision. </span><span class="c0">However, for an event, classification of it as real or spurious can be subjective. Therefore, to identify spurious events, we employ the following approach: 1) We ignore an event if its rank is below a threshold which is a function of the minimum rank that a cluster of size </span><span class="c2">N </span><span class="c0">can have (for given correlation and burstiness thresholds); 2) we ignore the clusters with all non-noun words. Our premise is that there must be at least one noun keyword in real world events. However, there may still be spurious event clusters (such as advertisements or rumors). As noticed in our evaluation, real world events typically have a build-up and wind-down phase. Therefore, the clusters belonging to such events are evolving and/or their rank scores keep on changing in a non-monotonic manner. On the other hand, spurious events have a sudden burst and thereafter they die. Hence, events which do not evolve and have monotonically decreasing rank scores are considered spurious events in our analysis. We cannot suppress these events from being reported as we cannot determine their future behavior. However, for an event, we can analyze its behavior in a post-hoc manner. Precision for events is computed as the percentage of real events among all the events that are reported. </span></p><p class="c24 c114"><span class="c20">Nebraska senator Bob Kerrey reverses decision not to run </span></p><p class="c24 c76"><span class="c20">Bob Kerrey will run </span></p><p class="c118"><span class="c20">Apple market value hits $500B Apple worth more than Poland </span></p><p class="c98"><span class="c0">It is important to point out that we identified almost 6 times more events (e.g., &ldquo;Forecast 29</span><span class="c94">th </span><span class="c0">Feb Snow Rain Today&rdquo;, &ldquo;advisory high wind warning issued surf&rdquo;) which were not present in Google news headline but were important in the local context (see Table 3). These included local job openings such as &ldquo;#jobs alert ca #job #retail store #accounting manager #tweetmyjobs&rdquo;. </span><span class="c21">7.2 Precision and Recall </span><span class="c39">7.2.1 Experimental Setup </span><span class="c0">For a more detailed study of our technique and to understand its sensitivity to various parameters, we used 2 different data sets, 1) Event Specific (</span><span class="c2">ES</span><span class="c0">), (comprising a total of 8 million tweets) containing tweets corresponding to specific topics such as the Japan earthquake, Apple, etc. 2) Time Window (</span><span class="c2">TW</span><span class="c0">), (comprising a total of 10 million tweets) contains tweets, generated during a particular time window, not specific to any event or location. Tweets appear in chronological sequence w.r.t. their time of generation. The tunable parameters are listed in Table 2. </span></p><p class="c131"><span class="c15">Table 2: Nominal values used in the experiments </span><span class="c26">Parameter Name Nominal Value Tunable Range </span><span class="c33">Quantum size </span><span class="c3">&delta; </span><span class="c20">160 tweets 80-240 tweets </span><span class="c33">HighStateThreshold </span><span class="c3">&gamma; </span><span class="c20">4 user ids/quantum NA </span><span class="c33">EC Threshold </span><span class="c3">&lambda; </span><span class="c20">0.20 0.1-0.25 </span><span class="c33">Window Length w.</span><span class="c3">&delta; </span><span class="c20">30 quanta 20-40 quanta </span></p><p class="c31"><span class="c0">Window length is 30 quanta, comprising a total of 4800 most recent tweets. The events in our case comprise global news such as &ldquo;Plane crash in Iran kills 150 passengers&rdquo; to more specific or local events such as &ldquo;Now milk products in Fukushima are contaminated&rdquo;. Many a times events may not be breaking news for world media but important in the local context. Identification of an event depends on the nodes and edges that constitute the graph. Therefore, in our experiments, we have varied two parameters to test our algorithm&rsquo;s performance; 1) Quantum size (</span><span class="c8">&delta;</span><span class="c0">). </span><span class="c8">&delta; </span><span class="c0">is related to the burstiness of keywords. The </span></p><p class="c24 c70"><span class="c39">7.2.2 Measuring Recall and Precision </span><span class="c0">If a trace contains messages pertaining to an event but we do not discover the event, </span><span class="c2">loss of recall </span><span class="c0">occurs. We may miss the event due to (1) non-formation of the corresponding cluster (i.e., only 1 or 2 words from the event showed burstiness) (2) the cluster formed does not satisfy the </span><span class="c2">SCP</span><span class="c0">. Therefore, we compute recall as follows: First we collect all the keywords, after removing stop words, which are either bursty (based on the </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">) or are already present in the current sliding window. An event in the current window can comprise of only these keywords. Keywords which are bursty but not present in any of the chronologically correlated event clusters discovered in offline manner indicate potentially missed events. Once we collect all such </span><span class="c2">noun </span><span class="c0">words (we use Stanford POS Tagger [16]), we manually check in the trace if they indeed belong to any real event or not. To make this check manageable, given the size of the data, we randomly pick a fraction of missing noun keywords. The probability of them belonging to a real event is extrapolated to estimate the number of missing events. The maximum number of events (by adding both events identified and events missed by our algorithm) discovered in a run is considered to be the sum total of all the events present in the trace. We use this number to compute recall across different runs. Once the maximum number of real events is estimated, the same number is used to compute recall across all the runs. Therefore, our objective of studying the impact of parameter tuning on recall is not affected because of &lsquo;estimation&rsquo; inaccuracy, if any. Precision is defined as &lsquo;How many of the events identified by us are real and important events?&rsquo; A spurious event reported by our system leads to </span><span class="c2">loss of precision. </span><span class="c0">However, for an event, classification of it as real or spurious can be subjective. Therefore, to identify spurious events, we employ the following approach: 1) We ignore an event if its rank is below a threshold which is a function of the minimum rank that a cluster of size </span><span class="c2">N </span><span class="c0">can have (for given correlation and burstiness thresholds); 2) we ignore the clusters with all non-noun words. Our premise is that there must be at least one noun keyword in real world events. However, there may still be spurious event clusters (such as advertisements or rumors). As noticed in our evaluation, real world events typically have a build-up and wind-down phase. Therefore, the clusters belonging to such events are evolving and/or their rank scores keep on changing in a non-monotonic manner. On the other hand, spurious events have a sudden burst and thereafter they die. Hence, events which do not evolve and have monotonically decreasing rank scores are considered spurious events in our analysis. We cannot suppress these events from being reported as we cannot determine their future behavior. However, for an event, we can analyze its behavior in a post-hoc manner. Precision for events is computed as the percentage of real events among all the events that are reported. </span></p><p class="c24 c70"><span class="c39">7.2.2 Measuring Recall and Precision </span><span class="c0">If a trace contains messages pertaining to an event but we do not discover the event, </span><span class="c2">loss of recall </span><span class="c0">occurs. We may miss the event due to (1) non-formation of the corresponding cluster (i.e., only 1 or 2 words from the event showed burstiness) (2) the cluster formed does not satisfy the </span><span class="c2">SCP</span><span class="c0">. Therefore, we compute recall as follows: First we collect all the keywords, after removing stop words, which are either bursty (based on the </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">) or are already present in the current sliding window. An event in the current window can comprise of only these keywords. Keywords which are bursty but not present in any of the chronologically correlated event clusters discovered in offline manner indicate potentially missed events. Once we collect all such </span><span class="c2">noun </span><span class="c0">words (we use Stanford POS Tagger [16]), we manually check in the trace if they indeed belong to any real event or not. To make this check manageable, given the size of the data, we randomly pick a fraction of missing noun keywords. The probability of them belonging to a real event is extrapolated to estimate the number of missing events. The maximum number of events (by adding both events identified and events missed by our algorithm) discovered in a run is considered to be the sum total of all the events present in the trace. We use this number to compute recall across different runs. Once the maximum number of real events is estimated, the same number is used to compute recall across all the runs. Therefore, our objective of studying the impact of parameter tuning on recall is not affected because of &lsquo;estimation&rsquo; inaccuracy, if any. Precision is defined as &lsquo;How many of the events identified by us are real and important events?&rsquo; A spurious event reported by our system leads to </span><span class="c2">loss of precision. </span><span class="c0">However, for an event, classification of it as real or spurious can be subjective. Therefore, to identify spurious events, we employ the following approach: 1) We ignore an event if its rank is below a threshold which is a function of the minimum rank that a cluster of size </span><span class="c2">N </span><span class="c0">can have (for given correlation and burstiness thresholds); 2) we ignore the clusters with all non-noun words. Our premise is that there must be at least one noun keyword in real world events. However, there may still be spurious event clusters (such as advertisements or rumors). As noticed in our evaluation, real world events typically have a build-up and wind-down phase. Therefore, the clusters belonging to such events are evolving and/or their rank scores keep on changing in a non-monotonic manner. On the other hand, spurious events have a sudden burst and thereafter they die. Hence, events which do not evolve and have monotonically decreasing rank scores are considered spurious events in our analysis. We cannot suppress these events from being reported as we cannot determine their future behavior. However, for an event, we can analyze its behavior in a post-hoc manner. Precision for events is computed as the percentage of real events among all the events that are reported. </span></p><p class="c91"><span class="c39">7.2.3 Observed Precision and Recall </span></p><p class="c70 c102"><span class="c0">The event density (events/unit length of trace) in ES set is found to be approximately 3 times that in TW set. Recall and Precision results are shown in Figures 7 to 10. In general with increasing and decreasing </span><span class="c8">&lambda;</span><span class="c2">, </span><span class="c0">recall increases as more nodes and edges move into AKG due to the less stringent requirement on the burstiness. Similarly, precision tends to improve with increasing and </span></p><p class="c24 c43"><span class="c20">A dead body found by Miami police on Rick Ross&rsquo;s House </span></p><p class="c24 c112"><span class="c20">Dead body found Rick house </span></p><p class="c24 c70"><span class="c39">7.2.2 Measuring Recall and Precision </span><span class="c0">If a trace contains messages pertaining to an event but we do not discover the event, </span><span class="c2">loss of recall </span><span class="c0">occurs. We may miss the event due to (1) non-formation of the corresponding cluster (i.e., only 1 or 2 words from the event showed burstiness) (2) the cluster formed does not satisfy the </span><span class="c2">SCP</span><span class="c0">. Therefore, we compute recall as follows: First we collect all the keywords, after removing stop words, which are either bursty (based on the </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">) or are already present in the current sliding window. An event in the current window can comprise of only these keywords. Keywords which are bursty but not present in any of the chronologically correlated event clusters discovered in offline manner indicate potentially missed events. Once we collect all such </span><span class="c2">noun </span><span class="c0">words (we use Stanford POS Tagger [16]), we manually check in the trace if they indeed belong to any real event or not. To make this check manageable, given the size of the data, we randomly pick a fraction of missing noun keywords. The probability of them belonging to a real event is extrapolated to estimate the number of missing events. The maximum number of events (by adding both events identified and events missed by our algorithm) discovered in a run is considered to be the sum total of all the events present in the trace. We use this number to compute recall across different runs. Once the maximum number of real events is estimated, the same number is used to compute recall across all the runs. Therefore, our objective of studying the impact of parameter tuning on recall is not affected because of &lsquo;estimation&rsquo; inaccuracy, if any. Precision is defined as &lsquo;How many of the events identified by us are real and important events?&rsquo; A spurious event reported by our system leads to </span><span class="c2">loss of precision. </span><span class="c0">However, for an event, classification of it as real or spurious can be subjective. Therefore, to identify spurious events, we employ the following approach: 1) We ignore an event if its rank is below a threshold which is a function of the minimum rank that a cluster of size </span><span class="c2">N </span><span class="c0">can have (for given correlation and burstiness thresholds); 2) we ignore the clusters with all non-noun words. Our premise is that there must be at least one noun keyword in real world events. However, there may still be spurious event clusters (such as advertisements or rumors). As noticed in our evaluation, real world events typically have a build-up and wind-down phase. Therefore, the clusters belonging to such events are evolving and/or their rank scores keep on changing in a non-monotonic manner. On the other hand, spurious events have a sudden burst and thereafter they die. Hence, events which do not evolve and have monotonically decreasing rank scores are considered spurious events in our analysis. We cannot suppress these events from being reported as we cannot determine their future behavior. However, for an event, we can analyze its behavior in a post-hoc manner. Precision for events is computed as the percentage of real events among all the events that are reported. </span></p><p class="c24 c70"><span class="c39">7.2.2 Measuring Recall and Precision </span><span class="c0">If a trace contains messages pertaining to an event but we do not discover the event, </span><span class="c2">loss of recall </span><span class="c0">occurs. We may miss the event due to (1) non-formation of the corresponding cluster (i.e., only 1 or 2 words from the event showed burstiness) (2) the cluster formed does not satisfy the </span><span class="c2">SCP</span><span class="c0">. Therefore, we compute recall as follows: First we collect all the keywords, after removing stop words, which are either bursty (based on the </span><span class="c2">high state </span><span class="c0">threshold </span><span class="c8">&gamma;</span><span class="c0">) or are already present in the current sliding window. An event in the current window can comprise of only these keywords. Keywords which are bursty but not present in any of the chronologically correlated event clusters discovered in offline manner indicate potentially missed events. Once we collect all such </span><span class="c2">noun </span><span class="c0">words (we use Stanford POS Tagger [16]), we manually check in the trace if they indeed belong to any real event or not. To make this check manageable, given the size of the data, we randomly pick a fraction of missing noun keywords. The probability of them belonging to a real event is extrapolated to estimate the number of missing events. The maximum number of events (by adding both events identified and events missed by our algorithm) discovered in a run is considered to be the sum total of all the events present in the trace. We use this number to compute recall across different runs. Once the maximum number of real events is estimated, the same number is used to compute recall across all the runs. Therefore, our objective of studying the impact of parameter tuning on recall is not affected because of &lsquo;estimation&rsquo; inaccuracy, if any. Precision is defined as &lsquo;How many of the events identified by us are real and important events?&rsquo; A spurious event reported by our system leads to </span><span class="c2">loss of precision. </span><span class="c0">However, for an event, classification of it as real or spurious can be subjective. Therefore, to identify spurious events, we employ the following approach: 1) We ignore an event if its rank is below a threshold which is a function of the minimum rank that a cluster of size </span><span class="c2">N </span><span class="c0">can have (for given correlation and burstiness thresholds); 2) we ignore the clusters with all non-noun words. Our premise is that there must be at least one noun keyword in real world events. However, there may still be spurious event clusters (such as advertisements or rumors). As noticed in our evaluation, real world events typically have a build-up and wind-down phase. Therefore, the clusters belonging to such events are evolving and/or their rank scores keep on changing in a non-monotonic manner. On the other hand, spurious events have a sudden burst and thereafter they die. Hence, events which do not evolve and have monotonically decreasing rank scores are considered spurious events in our analysis. We cannot suppress these events from being reported as we cannot determine their future behavior. However, for an event, we can analyze its behavior in a post-hoc manner. Precision for events is computed as the percentage of real events among all the events that are reported. </span></p><p class="c136"><span class="c25">989 </span></p><p class="c56 c113"><span class="c0">decreasing </span><span class="c8">&lambda; </span><span class="c0">(though not as much as recall) due to the following reason: in our experiments we see that spurious events tend to appear in bursts. Hence, there is practically no effect of parameter tuning on these events due to their strong temporal correlation and they are almost always discovered in each run. However, with more relaxed parameters, majority of the </span><span class="c2">extra </span><span class="c0">events that get discovered are real events. Hence, with more events getting identified and the number of spurious events remaining approximately stable, precision increases. In experiment (run on ES trace) with =800, =0.25 and =4: (i) Recall improves to 0.95; (ii) Precision also improves marginally due to the presence of almost the same number of spurious events. As stated earlier, we varied instead of </span><span class="c8">&gamma; </span><span class="c0">to see the effect of burstiness. Finally, changing </span><span class="c2">w</span><span class="c0">, the number of quanta in a window, did not result in a discernable effect on precision/recall. </span></p><p class="c52"><span class="c39">7.2.4 Analysis of Quality of Discovered Events </span><span class="c0">From our previous experiment, it may appear that one may set the </span><span class="c8">&delta; </span><span class="c0">as large and </span><span class="c8">&lambda; </span><span class="c0">as small as possible to achieve maximum recall and precision. However, another important dimension in our analysis is the quality of the discovered events. With low </span><span class="c8">&lambda; </span><span class="c0">and high </span><span class="c8">&delta;</span><span class="c2">, </span><span class="c0">more and more keywords start merging with event clusters, reducing the quality of event clusters. Similarly, many meaningless (or less interesting) events may get discovered. We use the following two measures to determine the event quality: 1) </span><span class="c2">Average cluster size: </span><span class="c0">We compute the size of average cluster for all the discovered events. The average cluster size across all the runs ranges from 6.16 to 6.88 keywords/event except when </span><span class="c8">&lambda; </span><span class="c0">is reduced to 0.1 when the average cluster size becomes 9.23 and 9.88 for ES and TW data sets respectively indicating an almost 50% increase. As one can see, consuming small and focused event clusters is preferred compared to large clusters. 2) </span><span class="c2">Average Cluster Rank: </span><span class="c0">As explained in Section 6, a high rank score signifies a strong cluster and therefore a better event quality. We notice, with increasing </span><span class="c8">&delta; </span><span class="c0">and reducing </span><span class="c8">&lambda;</span><span class="c2">, </span><span class="c0">average rank score reduces by up to 20% and 30% in TW and ES traces respectively from its peak value. As we see, the average cluster size does not change much across different runs, the reduced rank score implies that most of the additional events that are discovered with more relaxed parameters have fairly low rank score. Further, clusters around real events were almost always ranked higher compared to clusters formed accidentally. </span><span class="c21">7.3 Bi-connected clusters vs. SCP clusters </span><span class="c0">We implemented the algorithm to discover the bi-connected clusters (</span><span class="c2">BCs</span><span class="c0">) on exactly the same graph on which </span><span class="c2">SCP </span><span class="c0">clusters are computed. Similar algorithm is also proposed in [2] to identify events in blogs. After each quantum, the </span><span class="c2">BCs </span><span class="c0">are computed on the entire graph in an offline manner. All the edges (including edges connecting two </span><span class="c2">BCs</span><span class="c0">), which are not part of any bi-connected cluster, are reported as clusters of size 2. All parameters are set to their nominal values (Table 2). We have used the same twitter trace which we used for the ground truth experiment. At the end of each quantum, clusters identified by both the techniques are compared. Since </span><span class="c2">SCP </span><span class="c0">is not a necessary condition for bi- connected clusters, additional clusters are discovered in the offline method. Therefore, we compute: (1) additional clusters (</span><span class="c2">A</span><span class="c4">c</span><span class="c0">) and (2) additional events (</span><span class="c2">A</span><span class="c4">E</span><span class="c0">) discovered in offline method. We get 276% </span><span class="c2">A</span><span class="c4">c </span><span class="c0">and -11.1% </span><span class="c2">A</span><span class="c4">E</span><span class="c0">. If we exclude BCs of size 2 from offline clusters (since </span><span class="c2">SCP </span><span class="c0">based clusters do not include them), </span><span class="c2">A</span><span class="c4">c </span><span class="c17">and </span><span class="c12">A</span><span class="c4">E </span><span class="c0">come down by -5.1% and -17.1%. The additional clusters in the offline method arise from edges being identified as clusters (of size 2). A substantial number of these edges are found to be not related to </span><span class="c2">real </span><span class="c0">events</span><span class="c2">. </span><span class="c0">We further identify that 1) 74.5% of offline event clusters exactly overlap with </span><span class="c2">short-cycle </span><span class="c0">based </span></p><p class="c24 c28"><span class="c26">Figure 10: Precision for </span><span class="c15">Event Specific </span><span class="c26">Trace </span><span class="c0">As is evident from the above discussion, the offline clusters lead to lower precision. However, even recall is lower as in some </span></p><p class="c96"><span class="c25">990 </span></p><p class="c1"><span class="c0">clusters (after excluding edges), 2) no instance of an event cluster is found in the offline method which did not have </span><span class="c2">short-cycle. </span><span class="c0">Both these facts prove (1) the correctness of our method (2) our conjecture that </span><span class="c2">real </span><span class="c0">events have </span><span class="c2">short-cycle </span><span class="c0">within the event cluster. Average size of exactly overlapping clusters was 4.53 (against 5.07 for all the clusters in the </span><span class="c2">SCP </span><span class="c0">method) indicating that mostly small clusters overlap exactly. For the offline event clusters, not overlapping </span><span class="c2">exactly </span><span class="c0">with </span><span class="c2">short-cycle </span><span class="c0">based clusters, we see an increase in average cluster size from 6.83 to 12.72. The average rank of all the </span><span class="c2">BC </span><span class="c0">clusters goes down from 186.4 to 150.9 w.r.t. SCP clusters. Therefore, the quality of offline clusters suffers. Further, our technique computes clusters 46% faster compared to offline method due to the fact that it involved </span><span class="c2">only </span><span class="c0">local computations. Note that the performance of our method can further be improved in a parallel processing environment since multiple simultaneous computations are allowed on the graph in </span><span class="c2">short-cycle </span><span class="c0">based clusters. </span></p><p class="c1"><span class="c0">clusters (after excluding edges), 2) no instance of an event cluster is found in the offline method which did not have </span><span class="c2">short-cycle. </span><span class="c0">Both these facts prove (1) the correctness of our method (2) our conjecture that </span><span class="c2">real </span><span class="c0">events have </span><span class="c2">short-cycle </span><span class="c0">within the event cluster. Average size of exactly overlapping clusters was 4.53 (against 5.07 for all the clusters in the </span><span class="c2">SCP </span><span class="c0">method) indicating that mostly small clusters overlap exactly. For the offline event clusters, not overlapping </span><span class="c2">exactly </span><span class="c0">with </span><span class="c2">short-cycle </span><span class="c0">based clusters, we see an increase in average cluster size from 6.83 to 12.72. The average rank of all the </span><span class="c2">BC </span><span class="c0">clusters goes down from 186.4 to 150.9 w.r.t. SCP clusters. Therefore, the quality of offline clusters suffers. Further, our technique computes clusters 46% faster compared to offline method due to the fact that it involved </span><span class="c2">only </span><span class="c0">local computations. Note that the performance of our method can further be improved in a parallel processing environment since multiple simultaneous computations are allowed on the graph in </span><span class="c2">short-cycle </span><span class="c0">based clusters. </span></p><p class="c6"><span class="c26">Figure 9: Precision for Time Window Based Trace </span></p><p class="c24 c126"><span class="c26">Figure 7: Recall for Time Window Based Trace </span></p><p class="c81"><span class="c26">Figure 8: Recall for Event Specific Trace </span></p><p class="c56"><span class="c0">instances two </span><span class="c2">real </span><span class="c0">events get merged into one offline cluster, leading to loss of recall. In summary, we show that </span><span class="c2">real </span><span class="c0">time events almost invariably have </span><span class="c2">short-cycle </span><span class="c0">within the cluster (except a small number of events which do not form cycles). </span></p><p class="c24"><span class="c15">Table 3: Performance of different clustering schemes </span></p><p class="c24"><span class="c88">SCP Clusters </span></p><p class="c24"><span class="c88">Bi-connected Clusters </span></p><p class="c45"><span class="c88">Bi-connected clusters +Edges </span><span class="c20">Events Discovered 216 179 192 Precision 0.911 0.795 0.216 Recall 0.935 0.775 0.831 Avg. Rank 186.4 150.9 92.1 Avg. Cluster Size 5.07 6.31 3.14 </span><span class="c21">7.4 Impact of using AKG </span><span class="c0">Recall from Section 3 that at the end of each quantum, we do a total of </span><span class="c2">O (k</span><span class="c13">2</span><span class="c2">NC) </span><span class="c0">computations. On average, the number of edges in AKG was less than 2% of CKG (at a given point of time). In our experiments, less than 5% nodes in CKG show burstiness. These reductions demonstrate the efficacy of our technique to reduce the size of graphs used for cluster discovery. Further, the average number of edges attached to a node was less than 6 and the average size of clusters was less than 7 nodes. Hence we can clearly see that the amount of computation that needs to be done at the end of each quantum is significantly reduced due to the use of SCP over AKG. In the table below, we show the message processing rate. We see that on our machine, one with modest configuration, the rate of processing a general twitter trace is beyond 5000 messages/second. On </span><span class="c2">ES </span><span class="c0">trace, with much higher event intensity, the rate of processing comes down. With increasing , the number of low quality clusters increases and only some of them are identified as real events. The system ends up processing many clusters which are discarded later. </span></p><p class="c24"><span class="c15">Table 4: Message processing rate for given quantum sizes </span><span class="c26">Trace Type </span></p><p class="c24"><span class="c26">Msg Processed/Second </span><span class="c20">=120 =160 =200 Time Window Based Trace 5185 4420 4160 </span></p><p class="c24"><span class="c20">Event Specific Trace 1410 1400 1160 </span></p><p class="c24"><span class="c0">In summary, our experiments demonstrate the following: </span></p><p class="c56"><span class="c8">&bull; </span><span class="c0">We see that our algorithm is able to discover interesting events with high precision and recall in a timely manner. Besides &lsquo;important&rsquo; events it also discovers events which may not be &ldquo;captured&rdquo; by headlines reported in news sites. </span></p><p class="c56"><span class="c8">&bull; </span><span class="c0">Our algorithm, by exploiting the SCP, works in real time and outperforms the offline algorithm reported in [2]. Analysis of events identified in offline method also establishes that SCP is almost invariably present in all the event clusters. </span></p><p class="c56"><span class="c8">&bull; </span><span class="c0">Our algorithm is quite resilient to parameter settings as the event set discovered by us is fairly stable across different runs underlining the robustness of our algorithm. Further, we find that the average cluster size is quite stable across runs. </span></p><p class="c24"><span class="c3">&bull; </span><span class="c0">On a modest machine, our algorithm is able to process almost twice the current rate at which messages are added to the Twitter stream underlying our algorithms&rsquo; scalability. </span><span class="c21">8. CONCLUSION </span><span class="c0">In this paper we have addressed the problem of discovering events in a microblog stream. We mapped the problem of finding events to that of finding clusters in a graph. Due to the dynamic nature of the twitter stream, the size of the graph can become extremely large. We hence proposed the use of a technique which allowed us to efficiently find a stable graph which was order of magnitude smaller than the original graph and yet captures all the information about the emerging events. We argued that </span></p><p class="c24"><span class="c0">conventional cluster discovery techniques used for finding events in a microblog stream do not work in our setting. We hence introduced </span><span class="c2">aMQCs</span><span class="c0">, which are bi-connected clusters, satisfying a new </span><span class="c2">short-cycle property </span><span class="c0">which allowed us to find and maintain the clusters locally without affecting the quality of the discovered clusters. To handle the dynamics we also proposed algorithms for handling addition/deletion of a node/edge and proved the correctness of the same. We showed the efficacy of our techniques using real world data &ndash; we were able to find clusters efficiently, in real-time, i.e., keeping pace with the arrival of messages. As part of our future work we plan to build a system that includes the ability to discover and thus discard spurious and malicious events (e.g., rumors). Since many web applications generate data which can be modeled as massive and dynamic graphs, we will also extend and apply our technique to other domains with similar characteristics. Finally, we will explore pre- as well as post- processing techniques to complement the core approach described in this paper. </span><span class="c21">9. REFERENCES </span><span class="c7">[1] </span><span class="c0">Kumar R., Novak J., Raghavan P., Tomkins A. On the Bursty </span></p><p class="c24"><span class="c0">Evaluation of Blogspace. WWW 2003. </span><span class="c7">[2] </span><span class="c0">Bansal N., Chiang F., Koudas N., Tompa F. Seeking Stable </span></p><p class="c24"><span class="c0">Clusters in the Blogosphere, VLDB 2007. </span><span class="c7">[3] </span><span class="c0">Tong H. et al., Proximity Tracking on Time-Evolving </span></p><p class="c24"><span class="c0">Bipartite Graphs. SDM, 2008 </span><span class="c7">[4] </span><span class="c0">Backstrom L., et al. Group Formation in Large Social </span></p><p class="c24"><span class="c0">Networks: Membership, Growth and Evolution. KDD, 2007. </span><span class="c7">[5] </span><span class="c0">Hopcroft J., Khan O., B., Kulis Selman B.. Natural </span></p><p class="c24"><span class="c0">communities in large linked networks, KDD 2003. </span><span class="c7">[6] </span><span class="c0">Cohen E. Size-Estimation Framework with Applications to Transitive Closure and Reachability. J. of Computer and System Sciences 55 (1997): 441&ndash;453. </span><span class="c7">[7] </span><span class="c0">Cohen E. et al. Finding Interesting Associations without </span></p><p class="c24"><span class="c0">Support Pruning, ICDE 2000. </span><span class="c7">[8] </span><span class="c0">Motwani R., and Raghavan P. Randomized Algorithms. </span></p><p class="c24"><span class="c0">Cambridge University Press, 1995. </span><span class="c7">[9] </span><span class="c0">Zvi Galil, Maintaining biconnected components of a dynamic </span></p><p class="c24"><span class="c0">planar graph. ICALP 1991. </span><span class="c7">[10] </span><span class="c0">T. Sakaki, et al. Earthquake Shakes Twitter Users: Real-time </span></p><p class="c45"><span class="c0">Event Detection by Social Sensors, WWW 2010. </span><span class="c7">[11] </span><span class="c0">H. Kwak et al. What is Twitter, a Social Network or a News </span></p><p class="c24"><span class="c0">Media?, WWW 2010. </span><span class="c7">[12] </span><span class="c0">http://blog.seevibes.com/social-media/10-historic-moments- </span></p><p class="c24"><span class="c0">that-broke-records-on-twitter/ </span><span class="c7">[13] </span><span class="c0">F. Alvanaki et al., En Blogue &ndash; Emergent Topic Detection in </span></p><p class="c24"><span class="c0">Web 2.0 Stream, SIGMOD 2011. </span><span class="c7">[14] </span><span class="c0">H. Matsuda, Classifying Molecular Sequences using a </span></p><p class="c24"><span class="c0">Linkage Graph with their Pairwise Similarities. STOC 1999. </span><span class="c7">[15] </span><span class="c0">J. Pei, D. Jiang, A. Zhang, On Mining CrossGraph </span></p><p class="c24"><span class="c0">QuasiCliques. KDD 2005. </span><span class="c7">[16] </span><span class="c0">http://nlp.stanford.edu/software/tagger.shtml </span><span class="c7">[17] </span><span class="c0">M. Mathioudakis, N. Koudas, TwitterMonitor: Trend </span></p><p class="c45"><span class="c0">Detection over the Twitter Stream, SIGMOD 2010. </span><span class="c7">[18] </span><span class="c0">M. Cataldi et al., Emerging Topic Detection on Twitter based on Temporal and Social Terms Evaluation, MDM 2010. </span></p><p class="c24"><span class="c25">991 </span></p></body></html>