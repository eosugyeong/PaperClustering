<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c61{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c112{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.8pt;font-family:"Arial";font-style:normal}.c96{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Arial";font-style:normal}.c54{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:7.4pt;font-family:"Arial";font-style:normal}.c107{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.9pt;font-family:"Arial";font-style:normal}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.8pt;font-family:"Arial";font-style:normal}.c148{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11.8pt;font-family:"Arial";font-style:normal}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.1pt;font-family:"Arial";font-style:normal}.c191{margin-left:-19pt;padding-top:1.2pt;text-indent:36.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.2pt}.c139{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:italic}.c169{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c62{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:normal}.c114{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c60{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.6pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.3pt;font-family:"Arial";font-style:normal}.c121{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.1pt;font-family:"Arial";font-style:normal}.c18{color:#800000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.2pt;font-family:"Arial";font-style:normal}.c145{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:italic}.c105{margin-left:-15pt;padding-top:1pt;text-indent:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.1pt}.c122{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.4pt;font-family:"Arial";font-style:normal}.c99{color:#800000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:normal}.c93{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.1pt;font-family:"Arial";font-style:normal}.c21{margin-left:-28.1pt;padding-top:7.2pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c92{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.9pt;font-family:"Arial";font-style:normal}.c19{color:#ff0000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c79{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.3pt;font-family:"Arial";font-style:normal}.c34{margin-left:-28.1pt;padding-top:1.4pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c197{color:#008000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c102{margin-left:-35.5pt;padding-top:7.2pt;text-indent:43.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.4pt}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c157{margin-left:-19pt;padding-top:1pt;text-indent:36.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:7pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c194{margin-left:-28.1pt;padding-top:1.7pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c57{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.9pt;font-family:"Arial";font-style:normal}.c135{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.6pt;font-family:"Arial";font-style:normal}.c151{color:#800000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.9pt;font-family:"Arial";font-style:normal}.c73{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:7.4pt;font-family:"Arial";font-style:italic}.c38{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:normal}.c133{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:normal}.c186{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.4pt;font-family:"Arial";font-style:normal}.c36{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:7.1pt;font-family:"Arial";font-style:normal}.c119{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Courier New";font-style:normal}.c184{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:8.2pt;font-family:"Arial";font-style:italic}.c163{margin-left:-28.1pt;padding-top:4.1pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c50{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c33{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.6pt;font-family:"Arial";font-style:normal}.c134{color:#800000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c128{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.4pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.4pt;font-family:"Arial";font-style:normal}.c53{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.4pt;font-family:"Arial";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c178{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Courier New";font-style:normal}.c97{margin-left:-28.1pt;padding-top:7.2pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.4pt}.c108{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.8pt;font-family:"Arial";font-style:normal}.c120{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:7.4pt;font-family:"Arial";font-style:italic}.c132{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.9pt;font-family:"Arial";font-style:normal}.c106{margin-left:-19pt;padding-top:1pt;text-indent:36.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:3.1pt}.c109{margin-left:-28.1pt;padding-top:4.3pt;text-indent:36.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c149{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.3pt;font-family:"Arial";font-style:normal}.c68{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c196{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.7pt;font-family:"Arial";font-style:italic}.c162{color:#800000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c24{margin-left:-15pt;padding-top:1.2pt;text-indent:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.9pt}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c70{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.4pt;font-family:"Arial";font-style:normal}.c190{margin-left:-28.1pt;padding-top:4.3pt;text-indent:44.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c64{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.8pt;font-family:"Arial";font-style:normal}.c88{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:italic}.c111{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.6pt;font-family:"Arial";font-style:normal}.c69{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c90{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.3pt;font-family:"Arial";font-style:italic}.c175{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c48{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.6pt;font-family:"Arial";font-style:normal}.c130{margin-left:-28.1pt;padding-top:6pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c138{margin-left:-15pt;padding-top:1pt;text-indent:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6pt}.c37{margin-left:-28.1pt;padding-top:3.8pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c171{color:#800000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:9.9pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.2pt;font-family:"Arial";font-style:normal}.c116{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.8pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:normal}.c154{margin-left:-28.1pt;padding-top:7.2pt;text-indent:35pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c98{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.7pt;font-family:"Arial";font-style:normal}.c75{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.6pt;font-family:"Arial";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.7pt;font-family:"Arial";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c118{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:9pt;font-family:"Arial";font-style:normal}.c82{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Courier New";font-style:normal}.c84{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.2pt;font-family:"Arial";font-style:italic}.c192{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.4pt;font-family:"Arial";font-style:italic}.c94{color:#800000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.9pt;font-family:"Arial";font-style:normal}.c103{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.7pt;font-family:"Arial";font-style:italic}.c158{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:8.2pt;font-family:"Arial";font-style:italic}.c172{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:6.9pt;font-family:"Arial";font-style:italic}.c29{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.8pt;font-family:"Arial";font-style:normal}.c185{margin-left:-19pt;padding-top:1pt;text-indent:36.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.4pt}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.3pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c87{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9pt;font-family:"Arial";font-style:normal}.c58{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:8.2pt;font-family:"Arial";font-style:normal}.c76{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.9pt;font-family:"Arial";font-style:italic}.c55{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.4pt;font-family:"Arial";font-style:italic}.c81{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9pt;font-family:"Arial";font-style:normal}.c74{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:6.6pt;font-family:"Arial";font-style:normal}.c179{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.6pt;font-family:"Arial";font-style:normal}.c46{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.1pt;font-family:"Arial";font-style:normal}.c173{margin-left:0.4pt;padding-top:11.5pt;text-indent:85.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1pt}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c59{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.8pt;font-family:"Arial";font-style:normal}.c113{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:11.3pt;font-family:"Arial";font-style:normal}.c67{margin-left:-28.1pt;padding-top:4.3pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c177{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.9pt;font-family:"Courier New";font-style:normal}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.6pt;font-family:"Arial";font-style:italic}.c32{margin-left:-273.7pt;padding-top:4.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:462.7pt}.c6{margin-left:-22.1pt;padding-top:4.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:208.7pt}.c14{margin-left:-21.4pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:127.1pt}.c164{margin-left:-19pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.8pt}.c100{margin-left:-28.1pt;padding-top:16.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c85{margin-left:220.6pt;padding-top:31.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-33.4pt}.c86{margin-left:-19pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.8pt}.c188{margin-left:-28.1pt;padding-top:16.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c161{margin-left:-19pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:28.3pt}.c147{margin-left:-15pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-7pt}.c41{margin-left:-25.2pt;padding-top:12.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:48.9pt}.c146{margin-left:99.3pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-7.9pt}.c189{margin-left:-1.3pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1.4pt}.c71{margin-left:220.6pt;padding-top:41pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-33.4pt}.c129{margin-left:-28.1pt;padding-top:103.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c144{margin-left:-261.2pt;padding-top:67.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:318.5pt}.c5{margin-left:-33.4pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:166.8pt}.c166{margin-left:-28.1pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:123.3pt}.c176{margin-left:-19pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-10.8pt}.c198{margin-left:-10.2pt;padding-top:4.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:83.8pt}.c89{margin-left:-19pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18pt}.c49{margin-left:-19pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.4pt}.c136{margin-left:-28.1pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:2.6pt}.c159{margin-left:-3.6pt;padding-top:14.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:65.4pt}.c137{margin-left:-15pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-16.3pt}.c80{margin-left:-14.9pt;padding-top:4.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:208.7pt}.c124{margin-left:-2.6pt;padding-top:10.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:69.8pt}.c170{margin-left:-91pt;padding-top:5.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:169.9pt}.c23{margin-left:115.8pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:15.6pt}.c142{margin-left:73.6pt;padding-top:6.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:118.6pt}.c200{margin-left:-16.4pt;padding-top:13.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:31pt}.c65{margin-left:324pt;padding-top:7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-135.4pt}.c131{margin-left:-15pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11pt}.c160{margin-left:-15pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.2pt}.c95{margin-left:220.6pt;padding-top:55.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-33.4pt}.c7{margin-left:-13.9pt;padding-top:5.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:0.4pt}.c127{margin-left:-19pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.7pt}.c77{padding-top:4.8pt;text-indent:114.8pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c104{padding-top:1.4pt;text-indent:23.6pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c152{padding-top:3.8pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c150{padding-top:4.6pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c199{padding-top:4.3pt;text-indent:36.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c167{padding-top:4.1pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c126{padding-top:4.3pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c123{padding-top:4.3pt;text-indent:34.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c101{padding-top:7.2pt;text-indent:25.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c195{padding-top:4.3pt;text-indent:36.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c91{padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c125{padding-top:1.4pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c193{padding-top:4.6pt;text-indent:34.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c110{padding-top:7pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c156{padding-top:6pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c39{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c141{padding-top:6.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c52{padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c83{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c40{margin-left:66.4pt;margin-right:118.6pt}.c51{margin-left:-98.7pt;margin-right:154.8pt}.c182{margin-left:-91pt;margin-right:169.9pt}.c72{margin-left:98.8pt;margin-right:34.3pt}.c168{margin-left:-8.6pt;margin-right:-13.8pt}.c56{margin-left:104.1pt;margin-right:-21.6pt}.c78{margin-left:-33.4pt;margin-right:187.7pt}.c165{margin-left:-276.1pt;margin-right:462.7pt}.c44{margin-left:115.8pt;margin-right:15.6pt}.c187{margin-left:-98.7pt;margin-right:290.6pt}.c66{margin-left:-22.1pt;margin-right:208.7pt}.c42{margin-left:182.4pt;margin-right:-96.8pt}.c153{margin-left:168.4pt;margin-right:-0.5pt}.c117{margin-left:324pt;margin-right:-135.4pt}.c155{margin-left:-19pt;margin-right:-22.8pt}.c43{margin-left:-19pt;margin-right:-23pt}.c180{margin-left:-273.7pt;margin-right:462.7pt}.c181{margin-left:-18.7pt;margin-right:-4.6pt}.c143{margin-left:73.6pt;margin-right:118.6pt}.c47{margin-left:-102.3pt;margin-right:290.6pt}.c140{margin-left:76.7pt;margin-right:-2.2pt}.c174{text-indent:45.1pt}.c115{margin-right:87.8pt}.c183{text-indent:27.9pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c83"><p class="c26"><span class="c169">Elevating Annotation Summaries To First-Class Citizens In InsightNotes </span></p><p class="c11"><span class="c27">Karim Ibrahim, Dongqing Xiao, Mohamed Eltabakh </span></p><p class="c11"><span class="c61">Computer </span><span class="c114">100 </span><span class="c61">Science </span><span class="c114">Institute </span><span class="c61">Department, </span><span class="c114">Rd., </span><span class="c61">Worcester </span><span class="c114">Worcester, </span><span class="c61">Polytechnic </span><span class="c114">MA, USA </span></p><p class="c11"><span class="c61">Institute (WPI) </span><span class="c12">{kaibrahm, dxiao, meltabakh}@cs.wpi.edu </span></p><p class="c11"><span class="c27">ABSTRACT </span><span class="c0">Most scientific and modern applications generate&mdash;in addition to the base data&mdash;valuable annotations and metadata information at unprecedented scale and complexity. Such annotations warrant the need for advanced annotation management techniques that not only propagate the raw annotations to end-users, but also mine, summa- rize, and extract useful knowledge from them. Towards this goal, we proposed the InsightNotes system, the first summary-based an- notation management engine in relational databases [22]. Insight- Notes relies on creating concise representations of the raw anno- tations, called annotation summaries. InsightNotes addresses sev- eral unique challenges related to the maintenance, propagation, and zooming of these summaries. However, a key limitation is that the annotation summaries are treated as propagate-only (report-only) objects that cannot be directly queried or manipulated. This limita- tion hinders higher-level applications from applying complex pro- cessing over both the base data and its attached annotation sum- maries even within a single query. In this paper, we propose new extensions to InsightNotes for treating the annotation summaries as first-class citizens. We address the challenges of: (1) Develop- ing new manipulation functions and query operators specific for the annotation summaries, (2) Designing summary-based index struc- tures and access methods for efficient retrieval and predicate eval- uation, and (3) Extending the query optimizer to optimize queries accessing both the data and the annotation summaries. The pro- posed extensions not only make it feasible to natively query and manipulate the annotation summaries, but also achieve more than two orders of magnitude speedup in query evaluation. </span></p><p class="c11"><span class="c27">1. INTRODUCTION </span></p><p class="c3"><span class="c0">Metadata&mdash;usually referred to as &ldquo;annotations&rdquo;&mdash; is gaining an increasing importance in most modern database applications as a valuable source of information. Applications in many sci- ence domains, e.g., in biology, healthcare, earth sciences, and or- nithology, create and manage annotations and metadata informa- tion in orders of magnitude larger than the base datasets as re- ported in [5, 20, 22]. For example, according to the geneon- tology.org website, several biological databases, e.g., Genobase </span></p><p class="c3"><span class="c0">c </span><span class="c45">2015, Copyright is with the authors. Published in Proc. 18th Inter- national Conference on Extending Database Technology (EDBT), March 23-27, 2015, Brussels, Belgium: ISBN 978-3-89318-067-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c3"><span class="c0">(http://ecoli.naist.jp/GB8/), EcoliHouse (http://www.porteco.org/), and UniProt (http://www.ebi.ac.uk/uniprot), manage annota- tions in a 10x scale compared to the number of genes and proteins in the database. Moreover, in ornithological databases, e.g., DBRC (http://www.dbrc.org.uk/), and AKN (http://www.avianknowledge.net/), the number of annotations col- lected from the bird watchers and scientists all over the world is around 200x larger than the number of birds&rsquo; collection stored in these repositories [1]. </span></p><p class="c3"><span class="c0">It is not only the scale of annotations that poses challenges, but also the need for transparent processing and propagation of anno- tations, and their combinatorial relationship with the data, e.g., an- notations can be attached to single table cells (attributes), rows, columns, arbitrary sets and combinations of them, or even attached to sub-attributes. That is why annotation management has been extensively studied in RDBMSs to address some of these chal- lenges [4, 7, 11, 14, 17, 21]. However, all of the existing techniques have the common limitation of manipulating only the raw annota- tions, and hence reporting back to end-users 100s of annotations attached to each output tuple. Nevertheless, any advanced process- ing of mining, summarizing, and extracting useful knowledge from the annotations is entirely delegated to end-users. </span></p><p class="c11"><span class="c0">As a first step towards addressing the above limitations, we pro- posed the &ldquo;InsightNotes&rdquo; system, a summary-based annotation management engine in relational databases [22]. InsightNotes is based on integrating data mining and summarization techniques with annotation management in novel ways with the objective of creating concise and meaningful representations of the raw anno- tations, called &ldquo;annotation summaries&rdquo;. For example, the R.H.S in Figure 1 illustrates a data tuple with 100s of attached raw anno- tations, while the L.H.S illustrates the tuple with its attached sum- mary objects using InsightNotes. The summary objects include, for example, Classifier-type objects, e.g., ClassBird1 and ClassBird2, that classify the raw annotations into user-defined classes, Snippet- type objects, e.g., TextSummary1, that summarize the attached big articles and report snippets on each, and Cluster-type objects, e.g., SimCluster, that group similar annotations into groups and reports only a representative from each group. An overview on the system will be presented in Section 2. </span><span class="c27">1.1 Case Study: Effectiveness and Motivation </span><span class="c0">We performed a usability case study to demonstrate the effec- tiveness of InsightNotes and motivate the new extensions proposed in this paper. We used a small subset of 100 data tuples from the AKN ornithological database, each has a number of raw annota- tions ranging between 75 to 380. The annotations describe any- thing related to birds, e.g., color, body shape or weight, certain behavior or sound, eating habits, geographic location, or observed diseases. And then, we asked 20 students to query the data, and an- </span></p><p class="c11"><span class="c8">49 10.5441/002/edbt.2015.06 </span></p><p class="c11"><span class="c25">... </span><span class="c145">TextSummary1 </span></p><p class="c11"><span class="c31">... </span><span class="c25">... [&ldquo;Experiment E ... &rdquo;, &ldquo;Wikipedia article ...&ldquo;] </span></p><p class="c11"><span class="c0">Figure 1: Summary-Based Annotation Management in InsightNotes. </span></p><p class="c11"><span class="c9">Query Semantics # Qualifying data tuples </span></p><p class="c11"><span class="c16">[(Behavior, </span><span class="c145">ClassBird1 </span><span class="c16">33), (Disease, 8), (Anatomy, 25), </span></p><p class="c11"><span class="c29">A1: </span><span class="c25">Large one </span></p><p class="c11"><span class="c29">A3: </span><span class="c25">Observed in region ... having size ... </span></p><p class="c11"><span class="c16">(Other, 16)] </span></p><p class="c11"><span class="c16">Swan Goose Anser cygnoides ... </span><span class="c30">SimCluster </span></p><p class="c11"><span class="c29">A2: </span><span class="c25">found eating stonewort and... </span></p><p class="c11"><span class="c29">A6: </span><span class="c25">size seems </span></p><p class="c11"><span class="c25">A4 wrong </span><span class="c16">A1# </span><span class="c64">A2# </span></p><p class="c11"><span class="c25">A5 </span></p><p class="c26"><span class="c113">The same tuple annotated with </span><span class="c29">its summary objects </span></p><p class="c26"><span class="c54">Using&amp;&amp; InsightNotes&amp; </span></p><p class="c11"><span class="c16">Swan Goose Anser cygnoides ... </span></p><p class="c11"><span class="c108">[(Provenance, </span><span class="c145">ClassBird2 </span><span class="c108">11), </span><span class="c16">(Comment, 83), (Question, 7)] </span></p><p class="c11"><span class="c29">Annotated tuple with 100s of attached raw annotations </span><span class="c9">InsightNotes </span></p><p class="c11"><span class="c9">Group </span></p><p class="c26"><span class="c9">Raw-Annotations Group </span></p><p class="c11"><span class="c9">Q1: </span><span class="c38">Report the </span><span class="c139">disease-related </span><span class="c38">annotations attached to birds with name like &ldquo;Swan*&#39;&rsquo;. </span></p><p class="c11"><span class="c0">of treating the annotation summaries as &ldquo;propagate-only objects&rdquo;. </span></p><p class="c11"><span class="c38">5 Time: 47 sec </span></p><p class="c11"><span class="c38">Accuracy: 100% </span></p><p class="c3"><span class="c0">This limitation hinders the applications from mixing operations over both the data content and annotation summaries even within a single query (Refer to Q3 in Figure 2). In this paper, we pro- pose extending the InsightNotes system by elevating the annotation summaries to be first-class citizens, where end-users and applica- tions can manipulate them in various ways, e.g., selecting, join- ing, or ordering the data tuples based on their attached annotation summaries. To build such full-fledged summary-based annotation management engine, we propose the following contributions: </span></p><p class="c3"><span class="c0">&bull; Seamless Manipulation of Diverse Summary Types: In- sightNotes supports three types of summarization techniques, i.e., clustering, classification, and text summarization. And hence, the summary objects attached to the data tuples can have diverse types, structures, and properties (Refer to Figure 1). Therefore, we pro- pose manipulation functions at different granularities, e.g., at the tuple-level to manipulate the entire set of attached summary ob- jects, and at the object-level to manipulate the individual summary objects according to their types. </span></p><p class="c3"><span class="c0">&bull; Summary-Based Query Processing: We propose building an extended query engine, where end-users can process both the data and their attached annotation summaries seamlessly in a single query plan. For example, Q3 in Figure 2 involves a summary-based ordering operation. Another query may be interested in retrieving only the data tuples with zero provenance-related annotations, i.e., </span><span class="c12">ClassBird2.Provenance </span><span class="c0">= 0, which involves a summary- based selection operation. Therefore, we extend the InsightNotes&rsquo;s query engine by introducing new summary-based query operators, e.g., filter, selection, join, and sort, that operate on the summaries&rsquo; content. We define their algebraic semantics and integrate them with the standard operators in a single query plan. </span></p><p class="c3"><span class="c0">&bull; Efficient Access Methods and Retrieval Mechanisms: Applying predicates and operators on top of the annotation summaries warrants the need for efficient retrieval mechanisms and indexing techniques to achieve scalable performance. For example, how could the system efficiently answer the two queries mentioned above, i.e., a selection query based on </span><span class="c12">ClassBird2.Provenance = 0</span><span class="c0">, and an ordering query based on </span><span class="c12">ClassBird1.Disease</span><span class="c0">. We propose summary-based index- ing techniques that achieve efficient execution for the summary- based queries, while retaining the optimal summary-propagation performance. </span></p><p class="c3"><span class="c0">&bull; Extended Summary-Based Query Optimizer: The integra- tion between the summary-based and the standard SQL operators within a single query engine opens several new opportunities for query optimization. For example, one query may now involve joins and selections based on both the data and the summaries, and thus the query optimization becomes even more challenging. Therefore, we introduce several new equivalence and transformation rules as well as an extended cost model that guide the query optimizer in generating efficient execution plans. </span></p><p class="c11"><span class="c8">50 </span><span class="c38">Time: 21 mins False Positives: 17% False Negatives: 25% </span></p><p class="c11"><span class="c9">Q2: </span><span class="c38">Aggregate based on the bird&rsquo;s family column, and report the number of behavior-related information on each group. </span></p><p class="c11"><span class="c38">3 Time: 47 sec </span></p><p class="c11"><span class="c38">Accuracy: 100% </span></p><p class="c11"><span class="c38">Time: 45 mins False Positives: 18% False Negatives: 34% </span></p><p class="c3"><span class="c9">Q3: </span><span class="c38">Report the data tuples sorted based on the number of attached disease-related annotations </span></p><p class="c11"><span class="c38">100 Time: 5.2 mins </span></p><p class="c11"><span class="c38">Accuracy: 100% ----- </span></p><p class="c11"><span class="c0">Figure 2: Usability Case Study using InsightNotes. </span></p><p class="c3"><span class="c0">swer the three questions highlighted in Figure 2. These are simple annotation-based analytical queries that scientists or end-users may ask over their datasets. Half of the students use the InsightNotes en- gine, while the other half uses an existing annotation management engine that reports the raw annotations [11]. We then measured the average time taken by each group (including writing the query) as well as the results&rsquo; accuracy. </span></p><p class="c3"><span class="c0">To answer Q1, the InsightNotes group needs to submit a single SQL query to get the 5 expected data tuples (similar to the L.H.S in Figure 1). And then, they need to issue another follow-up com- mand, i.e., a zoom-in command, to retrieve the raw disease-related annotations over these tuples. In contrast, the Raw-Annotations group will get the 5 tuples along with their raw annotations (similar to the R.H.S in Figure 1). And then, they need to manually read the annotations and extract the desired ones. It took them, on average, 21 minutes and they reported the results with high false-positive and false-negative ratios as indicated in the figure. </span></p><p class="c3"><span class="c0">To answer Q2, the InsightNotes group needs to only retrieve the number of the behavior-related annotations from the answer, i.e., ClassBird1.Behavior. It took them few seconds for writing and ex- ecuting the query. In contract, the other group took very long time and still produced erroneous results&mdash;Notice that Q2 is an aggrega- tion query, and thus each output tuple may have many annotations collected from multiple base tuples. </span></p><p class="c3"><span class="c0">The Q3 query is more challenging because InsightNotes does not provide mechanisms for sorting the data based on their attached summaries. Thus, the InsightNotes group needed to go over the 100 reported tuples, and manually sort them according to the Class- Bird1.Disease field. For the other group, it was not even feasible to analyze 100s of annotations over each of the reported tuples to figure out the number of disease-related annotations, and then sort based on that. </span></p><p class="c11"><span class="c27">1.2 Limitations and Proposed Extensions </span></p><p class="c3"><span class="c0">The results from the our study show that InsightNotes opens a promising direction for better understanding of large-scale an- notations and extracting useful knowledge from them. However, the results also show that InsightNotes has the critical limitation </span></p><p class="c3"><span class="c0">&bull; Realization and Evaluation: We developed the proposed ex- tensions within the InsightNotes prototype engine [22]. The ex- perimental analysis demonstrates the value-added functionalities of directly manipulating and querying the annotation summaries, e.g., enabling a seamless expression of more complex annotation-based analytical queries, and the significant performance gain from the proposed optimizations. </span></p><p class="c3"><span class="c0">The rest of the paper is organized as follows. In Section 2, we overview the InsightNotes system. In Section 3, we present the new summary-based functions and query operators. Sections 4 and 5 introduce the summary-based indexing scheme, and the extended query optimizer, respectively. The experimental evaluation is pre- sented in Section 6, while the related work is presented in Section 7. Finally, the conclusion remarks are included in Section 8. </span></p><p class="c11"><span class="c27">2. OVERVIEW ON InsightNotes SYSTEM </span></p><p class="c11"><span class="c0">InsightNotes addresses several challenges related to managing the annotation summaries, which include: (1) Designing an exten- sible engine where domain experts and database admins can de- fine how to summarize and mine their annotations, (2) Developing efficient and incremental mechanisms for the maintenance of an- notation summaries to scale up with large number of annotations, (3) Extending the query engine and relational algebra to operate on and propagate the annotation summaries along with the queries&rsquo; answers, and (4) Building zoom-in query processing mechanisms that enable end-users to zoom-in and retrieve the raw annotations of specific summaries of interest. In this section, we overview the basic functionalities of InsightNotes needed for this paper. </span><span class="c27">2.1 InsightNotes&rsquo;s Data Model </span></p><p class="c3"><span class="c0">The system supports three widely-used families (types) of min- ing and summarization techniques, which are: Text Summarization, Clustering, and Classification techniques. The system is extensible such that the database admins can customize these techniques&mdash;and instantiate what is called Summary Instances&mdash;to fit their domains and produce the desired summaries. Each user relation R can be linked to as many summary instances as needed. For example, Figure 1 illustrates Table </span><span class="c12">Birds </span><span class="c0">having four summary instances linked to it (2 Classifiers, 1 Snippet, and 1 Cluster). Therefore, the raw annotations attached to each data tuple in this table (the R.H.S) will be summarized according to these four summary in- stances. This will result in creating the Summary Objects, which will be attached back to the corresponding data tuple (the L.H.S). </span></p><p class="c3"><span class="c0">Assume a user&rsquo;s relation R having n data attributes and k sum- mary instances linked to it. Then, each tuple r &isin; R has the following conceptual schema: </span></p><p class="c11"><span class="c0">r =&lt; a</span><span class="c15">1</span><span class="c10">,a</span><span class="c15">2</span><span class="c10">, ..., a</span><span class="c15">n</span><span class="c10">,{s</span><span class="c15">1</span><span class="c10">,s</span><span class="c15">2</span><span class="c10">, ..., s</span><span class="c15">k</span><span class="c10">} &gt; </span><span class="c0">where a</span><span class="c20">1</span><span class="c0">,a</span><span class="c20">2</span><span class="c0">, ..., a</span><span class="c20">n </span><span class="c0">are the data values of r, and s</span><span class="c20">1</span><span class="c0">,s</span><span class="c20">2</span><span class="c0">, ..., s</span><span class="c15">k </span><span class="c10">are </span><span class="c0">the summary objects attached to r. Each summary object con- sists of a five-ary vector {ObjID, InstanceID, TupleID, Rep[], Ele- ments[][]} as depicted in the following figure: </span></p><p class="c11"><span class="c197">Visible </span><span class="c19">Not Visible </span></p><p class="c11"><span class="c30">Type Structure of Representatives (Rep[]) </span></p><p class="c11"><span class="c62">Cluster [(</span><span class="c30">Text </span><span class="c88">annotation</span><span class="c62">, </span><span class="c30">Number </span><span class="c88">groupSize</span><span class="c62">)] </span></p><p class="c11"><span class="c38">InstanceID </span></p><p class="c11"><span class="c62">ObjID </span></p><p class="c11"><span class="c62">TupleID Classifier [(</span><span class="c30">Text </span><span class="c88">classLabel</span><span class="c62">, </span><span class="c30">Numbr </span><span class="c88">annotationCnt</span><span class="c62">)] </span></p><p class="c11"><span class="c62">Snippet [(</span><span class="c30">Text </span><span class="c88">snippetValue</span><span class="c62">)] </span></p><p class="c11"><span class="c62">Rep[] </span></p><p class="c11"><span class="c62">Elements[][] </span></p><p class="c3"><span class="c0">The ObjID is the objects&rsquo;s unique identifier, and the Instan- ceID and TupleID are references for the corresponding summary instance, and the data tuple, respectively. The Rep[] array stores the representatives produced from the summarization algorithm, while Elements[][] is a two-dimensional array storing for each represen- </span></p><p class="c3"><span class="c0">tative, the references (Ids) to its contributing raw annotations. At query time, end-users will see only the InstanceID and Rep[] fields of each propagated summary object as illustrated in Figure 1. </span></p><p class="c3"><span class="c0">For each summary object s</span><span class="c15">i</span><span class="c10">, the structure of its representatives </span><span class="c0">stored in Rep[] depends on s</span><span class="c15">i</span><span class="c10">&rsquo;s type as depicted in the above figure. </span><span class="c0">For example, in the case of the Cluster type, each cluster (group) will report an annotation as its representative as well as the number of annotations in that group. Hence, the Rep[] array consists of a list of representatives in the form of pairs [(Text annotation, Num- ber groupSize)]. In the case of the Classifier type, each represen- tative will have a class label along with the number of annotations assigned to this label. For the Snippet type, each large annotation will have a corresponding short snippet as its representative. </span></p><p class="c39"><span class="c27">2.2 Summary-Aware Query Processing and </span><span class="c114">Propagation </span><span class="c0">InsightNotes&rsquo;s query engine has several extensions that enable efficient and seamless propagation of the summary objects under complex transformations, e.g., projection, join, grouping and ag- gregations, and duplicate elimination. We proposed extensions to the semantics and algebra of each query operator to manipulate the summary objects on-the-fly without the need for accessing the raw annotations. The following example demonstrates a Select-Project- Join (SPJ) query involving summary propagation in InsightNotes. The formal semantics of all query operators can be found in [22]. </span></p><p class="c11"><span class="c0">Example 1: Assume an SQL query </span><span class="c12">&quot;Select r.a, r.b, s.z From R r, S s Where r.a = s.x And r.b = 2&quot; </span><span class="c0">over the two tuples r and s presented in Figure 3. Tuple r has four summary objects attached to it, while tuple s has only two attached summary objects. We proved in [22] in Theorems 1 and 2 that to guarantee identical summary propagation under different&mdash;but equivalent&mdash;query plans, InsightNotes needs to project out the un-needed annotations before any merge operation over the summary objects. Therefore, the projection operator in Step 1 in Figure 3 projects out attributes r.c and r.d and eliminates the effect of their annotations from r&rsquo;s summary objects. For example, the </span><span class="c12">annotationCnt </span><span class="c0">field in the classifier objects is decremented, the wikipedia article in the snippet object is deleted, and the cluster objects are modified, e.g., some annotations are dropped from each cluster, and hence the </span><span class="c12">groupSize </span><span class="c0">field is decremented. Moreover, if a cluster&rsquo;s representative is dropped, then another representative is elected (See A5 representative replacing the dropped A2 representative). The same operation takes place over tuple s, where the effect of all annotations attached to both s.x and s.y is removed from s&rsquo;s summary objects. The only difference is that s.x attribute will not be projected out because it is needed in the subsequent join operator. </span></p><p class="c3"><span class="c0">The next operator in the query plan is the selection operator over r (Step 2). Based on the query&rsquo;s predicate, r will pass the opera- tor and all its summary objects will propagate without any change. Then, the produced tuples will join and their summary objects will be merged (Step 3). According to the merge procedure, r&rsquo;s sum- mary objects </span><span class="c12">ClassBird1 </span><span class="c0">and </span><span class="c12">TextSummary1 </span><span class="c0">will propagate without any change since they do have no counterpart objects over s. Whereas summary objects </span><span class="c12">ClassBird2 </span><span class="c0">and </span><span class="c12">SimCluster </span><span class="c0">will be combined. This action takes into account the case where the same annotation may be attached to both tuples r and s, and hence the annotation&rsquo;s effect on the summary objects should not be double counted. For example, assuming that there are five common annotations on both r and s classified as </span><span class="c12">Comment</span><span class="c0">, then when the two objects are merged the sum of that classifier label will be 22 instead of 27 as illustrated in the figure. The merge of the clus- </span></p><p class="c11"><span class="c8">51 </span></p><p class="c11"><span class="c76">ClassBird2 </span><span class="c107">SimCluster </span><span class="c2">B1&amp; </span><span class="c60">B2&amp; </span></p><p class="c11"><span class="c48">[(Provenance, 5), </span><span class="c2">(Comment, 10), </span></p><p class="c11"><span class="c2">B3&amp;x&amp; </span></p><p class="c11"><span class="c60">x&amp; </span><span class="c48">x&amp;</span><span class="c2">x&amp;(Question, 1)] </span></p><p class="c11"><span class="c35">s.x = 1 s.y </span></p><p class="c11"><span class="c35">s.z </span></p><p class="c11"><span class="c35">r.a = 1 r.b =2 r.c r.d </span><span class="c53">Tuple s </span><span class="c96">&pi;</span><span class="c59">&amp;</span><span class="c96">&amp; </span></p><p class="c26"><span class="c1">1A&amp;Project&amp;on&amp;summary&amp;objects&amp;&amp; (Eliminate&amp;unAneeded&amp;annota,ons)&amp; </span></p><p class="c39"><span class="c76">TextSummary1 </span><span class="c1">[&ldquo;Experiment E ... &rdquo;] </span><span class="c96">&pi;</span><span class="c59">&amp;</span><span class="c96">&amp; </span><span class="c107">SimCluster </span></p><p class="c11"><span class="c2">B5&amp; B7&amp; </span><span class="c48">x&amp; x&amp;</span><span class="c2">x&amp; </span></p><p class="c11"><span class="c48">[(Provenance, </span><span class="c76">ClassBird2 </span><span class="c48">2), </span><span class="c2">(Comment, 7), (Question, 1)] </span></p><p class="c11"><span class="c35">s.x = 1 s.z </span></p><p class="c11"><span class="c177">&sigma; </span><span class="c81">2A&amp;selec,on&amp;operator&amp;&amp; </span></p><p class="c11"><span class="c1">(does&amp;not&amp;change&amp;summaries)&amp; </span></p><p class="c26"><span class="c1">3A&amp;Join&amp;operator&amp;&amp; (Merges&amp;the&amp;annota,on&amp;summaries)&amp; </span></p><p class="c11"><span class="c148">&#8904;&amp;&amp; </span></p><p class="c11"><span class="c107">SimCluster </span></p><p class="c11"><span class="c2">A5&amp; </span></p><p class="c11"><span class="c35">s.x = 1 s.z r.a = 1 r.b =2 </span><span class="c81">4A&amp;Project&amp;out&amp;column&amp;s.x&amp; </span><span class="c1">(does&amp;not&amp;change&amp;summaries)&amp; </span></p><p class="c11"><span class="c96">&pi;</span><span class="c59">&amp;</span><span class="c96">&amp; </span><span class="c0">Figure 3: Example Query in InsightNotes. </span></p><p class="c3"><span class="c0">ter summary objects is slightly more complex. The main idea is that the overlapping groups from both sides, e.g., the groups rep- resented by A1 and B5, will be combined together, whereas the non-overlapping groups, e.g., the groups represented by A5 and B7, will propagate separately as illustrated in the figure. Finally attribute s.x will be projected out before producing the output. </span></p><p class="c11"><span class="c27">3. SUMMARY-BASED FUNCTIONS &amp; OP- </span></p><p class="c11"><span class="c27">ERATORS </span></p><p class="c39"><span class="c27">3.1 Summary-Based Manipulation Functions </span><span class="c0">The first step in treating the annotation summaries as first-class citizens is to design a set of interfaces and manipulation functions on top of them. In the following, we demonstrate few of the devel- oped functions, which we use throughout the paper. We also ex- pect the end-users to leverage these basic functions to create more semantic-rich summary-based UDFs. </span></p><p class="c3"><span class="c0">&bull; Summary Set Functions: We introduce a special variable &ldquo;$&rdquo; for each data tuple that represents the set of summary objects at- tached to this tuple, i.e., r.$ represents the set of summary objects attached to r. Then, we define interface functions over the $ vari- able, which include: </span></p><p class="c3"><span class="c0">&#9702; Int $.getSize(): Returns the number of summary objects within the set. For example, referring to tuple r in Table </span><span class="c12">Birds </span><span class="c0">in Figure 1(c), r.$.getSize() = 4. </span></p><p class="c11"><span class="c0">&#9702; SummaryObj $.getSummaryObject(String InstName): The function takes a summary instance name as in- put, and returns the summary object corresponding to that name, otherwise it returns Null. For exam- ple, r.$.getSummaryObject(&lsquo;ClassBird1 ) and r.$.getSummaryObject(&lsquo;T extSummary1 ) return the Classifier and Snippet summary objects attached to tuple r. </span></p><p class="c3"><span class="c0">&#9702; SummaryObj $.getSummaryObject(Int i ): This function takes a position within the summary set as input, and returns the summary object at that position. Since the objects in the set do not follow a pre-defined order, this function is more useful when used </span></p><p class="c11"><span class="c76">TextSummary1 </span><span class="c1">[&ldquo;Experiment E ... &rdquo;] </span><span class="c2">A1&amp; </span></p><p class="c11"><span class="c2">B7&amp; </span><span class="c48">x&amp; x&amp;</span><span class="c2">x&amp; </span></p><p class="c11"><span class="c48">[(Provenance, </span><span class="c76">ClassBird2 </span><span class="c48">9), </span><span class="c2">(Comment, 22), (Question, 2)] </span></p><p class="c11"><span class="c158">ClassBird1 </span><span class="c48">[(Behavior, 14), </span><span class="c2">(Disease, 2), (Anatomy, 16), (Other, 0)] </span></p><p class="c11"><span class="c0">within UDFs, e.g., to iterate over the objects within a summary set and apply a certain functionality. </span></p><p class="c3"><span class="c0">We then define a set of manipulation functions over each sum- mary object O according to its summary type. Some functions are common to all types. For example, O.getSummaryType() and O.getSummaryName(), return the type of the summary object&mdash; as either &ldquo;Classifier&rdquo;, &ldquo;Snippet&rdquo;, or &ldquo;Cluster&rdquo;&mdash;, and the summary instance name, respectively. Another common function to all types is O.getSize(), which returns the number of representatives within object O, i.e., the size of O.Rep[]. For example, referring to Fig- ure 1, the ClassBird1 classifier object has 4 representatives, while SimCluster cluster object has 2 representatives. Other functions are specific to each summary type. For example: </span></p><p class="c11"><span class="c0">&bull; Classifier Type Functions: For a summary object O of type Classifier, the defined functions include: </span></p><p class="c3"><span class="c0">&#9702; String O.getLabelName(Int i): Returns the class label at po- sition i, i.e., Rep[i].classLabel. The order among the class labels is pre-defined based on the order specified when creating the classifier summary instance in the system. </span></p><p class="c3"><span class="c0">&#9702; Int O.getLabelValue(Int i | String label): This function takes either an index i or a class label label as input, and returns the corresponding value, i.e., Rep[i].annotationCnt (for input i), or Rep[j].annotationCnt, where Rep[j].classLabel = label (for input label). </span></p><p class="c11"><span class="c0">&bull; Snippet Type Functions: For a summary object O of type Snip- pet, the defined functions include: </span></p><p class="c3"><span class="c0">&#9702; String O.getSnippet(Int i): Returns the snippet value at po- sition i. The order among the snippets is arbitrary and does not follow a pre-defined order. </span></p><p class="c3"><span class="c0">&#9702; Boolean O.containsSingle(String kw</span><span class="c20">1 </span><span class="c0">[, String kw</span><span class="c20">2</span><span class="c0">, ...]): Returns True if all of the given keywords kw</span><span class="c15">1</span><span class="c10">, kw</span><span class="c15">2</span><span class="c10">, ... are con- </span><span class="c0">tained within any one of O&rsquo;s snippets or the raw annotations. As we studied in [16], there is a tradeoff&mdash;w.r.t accuracy and performance&mdash;between searching the snippets vs. searching the raw annotations. </span></p><p class="c11"><span class="c8">52 </span></p><p class="c11"><span class="c76">TextSummary1 </span><span class="c87">[&ldquo;Experiment E ... &rdquo;, </span><span class="c1">&ldquo;Wikipedia article ...&ldquo;] </span></p><p class="c39"><span class="c53">Tuple r </span><span class="c184">ClassBird1 </span><span class="c2">[(Behavior, 33), (Disease, 8), (Anatomy, 25), (Other, 16)] </span><span class="c58">SimCluster </span><span class="c2">A1&amp; </span><span class="c60">A2&amp; </span></p><p class="c39"><span class="c76">ClassBird1 </span><span class="c48">[(Behavior, 14), </span><span class="c2">(Disease, 2), (Anatomy, 16), (Other, 0)] </span><span class="c107">SimCluster </span><span class="c2">A1&amp; </span><span class="c60">A5&amp; </span></p><p class="c11"><span class="c48">[(Provenance, </span><span class="c76">ClassBird2 </span><span class="c48">7), </span><span class="c122">r.a = 1 r.b =2 </span></p><p class="c11"><span class="c2">(Comment, 20), (Question, 2)] </span></p><p class="c11"><span class="c76">ClassBird2 </span><span class="c48">[(Provenance, 11), </span><span class="c2">(Comment, 83), (Question, 7)] </span></p><p class="c100 c174"><span class="c0">&#9702; Boolean O.containsUnion(String kw</span><span class="c20">1 </span><span class="c0">[, String kw</span><span class="c20">2</span><span class="c0">, ...]): Returns True if all of the given keywords kw</span><span class="c15">1</span><span class="c10">, kw</span><span class="c15">2</span><span class="c10">, ... are con- </span><span class="c0">tained within the union of O&rsquo;s snippets or O&rsquo;s raw annotations. In this function, the keywords may span multiple annotations attached to the same tuple. </span></p><p class="c67"><span class="c0">Internally, InsightNotes&mdash;which uses PostgreSQL as its underly- ing DBMS&mdash; implements the summary objects as composite data types. On top of these types, the manipulation functions presented above are defined. </span></p><p class="c136"><span class="c27">3.2 Summary-Based Relational Operators </span></p><p class="c37"><span class="c0">We now introduce several summary-based relational operators. Unlike the standard SQL operators, these operators operate on the summary objects attached to each tuple instead of its data content. The summary-based operators can be mixed with other standard relational operators in a single query pipeline for seamless process- ing. The new operators include: </span></p><p class="c109"><span class="c0">&bull; Filter Operator (F</span><span class="c15">p</span><span class="c10">(R)): The filter operator takes a set of </span><span class="c0">summary-based predicates p, and returns each tuple r &isin; R along with only its summary objects satisfying p. The operator is for- mally defined as: </span></p><p class="c110 c181"><span class="c0">F</span><span class="c20">p</span><span class="c0">(r) = {r =&lt; a</span><span class="c20">1</span><span class="c0">,a</span><span class="c20">2</span><span class="c0">, ..., a</span><span class="c20">n</span><span class="c0">,{s</span><span class="c20">i</span><span class="c0">, ...} &gt; | p(s</span><span class="c20">i</span><span class="c0">) = True, </span><span class="c10">where 1 &le; i &le; k } </span></p><p class="c21"><span class="c0">For example, referring to Figure 1(c), the predicate </span><span class="c12">(getSummaryName() = &lsquo;SimCluster&rsquo;) </span><span class="c0">returns r along with only the the specified cluster summary object. In contrast, the predicates </span><span class="c12">(getSummaryType() = &lsquo;Classifier&rsquo;) </span><span class="c0">return r along with only the two classifier summary objects ClassBird1 and ClassBird2. </span></p><p class="c154"><span class="c0">&bull; Selection Operator (S</span><span class="c15">p</span><span class="c10">(R)): The summary-based selection op- </span><span class="c0">erator takes a set of summary-based predicates p, and returns the data tuples r &isin; R having summary objects satisfying p. Other- wise, r is dropped. For qualifying tuples, all their summary objects will pass without change. The algebraic expression of the operator is as follows: </span></p><p class="c7"><span class="c0">S</span><span class="c15">p</span><span class="c10">(R) = {r &isin; R, r =&lt; a</span><span class="c15">1</span><span class="c10">,a</span><span class="c15">2</span><span class="c10">, ..., a</span><span class="c15">n</span><span class="c10">,{s</span><span class="c15">1</span><span class="c10">,s</span><span class="c15">2</span><span class="c10">, ..., s</span><span class="c15">k</span><span class="c10">} &gt; | p(r.$) = True} </span></p><p class="c97"><span class="c0">The summary-based predicates may range from black-box UDFs that take r.$ as a parameter and return a Boolean value, to explicit predicates based on the system-defined manipula- tion functions presented in Section 3.1. In the latter case, the system can reason about and optimize the execution of these predicates as will be presented in Section 4. For example, the pred- icate </span><span class="c12">(r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;ClassBird2&rsquo;). getLabelValue(&lsquo;Provenance&rsquo;) = 0) </span><span class="c0">returns only R&rsquo;s tuples having no provenance-related anno- tations attached to them. In contrast, the predicate </span><span class="c12">(r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;TextSummary1&rsquo;).contains Single(&lsquo;Wikipedia&rsquo;, &lsquo;hormone&rsquo;)) </span><span class="c0">returns R&rsquo;s tuples that have at least one annotation containing both keywords. Such predicates can be efficiently evaluated using the the summary- based indexes presented in Section 4. </span></p><p class="c102"><span class="c0">&bull; Join Operator (J</span><span class="c15">p</span><span class="c10">(R, S)): The summary-based join operator </span><span class="c0">joins two input tuples r &isin; R and s &isin; S iff the summary-based join predicates p evaluate to True over r.$ and s.$. The algebraic expression of the operator is as follows: J</span><span class="c15">p</span><span class="c10">(R, S) = {&lt; r, s &gt;, where r &isin; R &amp; s &isin; S | p(r.$, s.$) = True} </span></p><p class="c130"><span class="c0">For example, referring to Table Birds in Figure 1, assume we have two revisions of this table, V</span><span class="c20">1 </span><span class="c0">(after Revision 1) and V</span><span class="c20">2 </span><span class="c0">(af- </span></p><p class="c3 c43"><span class="c0">ter Revision 2). Then, reporting the data tuples whose number of provenance annotations has changed between the two revisions would involve the following expression: </span></p><p class="c173"><span class="c135">Data-based join </span><span class="c13">&lsquo;&lsquo;v</span><span class="c73">1</span><span class="c13">.ID = v</span><span class="c73">2</span><span class="c13">.ID &amp; v</span><span class="c73">1</span><span class="c13">.$.getSummaryObject(&lsquo;ClassBird1&rsquo;).getLabelValue(&lsquo;Provenance&rsquo;) &lt;&gt; v</span><span class="c73">2</span><span class="c13">.$.getSummaryObject(&lsquo;ClassBird1&rsquo;).getLabelValue (&lsquo;Provenance&rsquo;)&rsquo;&rsquo; </span></p><p class="c43 c77"><span class="c135">Summary-based join </span><span class="c0">The expression combines both data- and summary-based join op- erators. As will be discussed in Section 5 and based on the available indexes and statistics, the query optimizer may decide to join the tuples based on the data values and then applies a summary-based selection operator, i.e., (S(R 1 S)). Alternatively, it may join the tuples based on the summary objects and then applies a standard selection operator (&rho;(J (R, S))). </span></p><p class="c43 c101"><span class="c0">&bull; Sort Operator (O</span><span class="c15">f[,direction]</span><span class="c0">(R)): The summary-based sort op- erator orders the data tuples in R according to the summary-based function f(r.$). Function f must return values of a data type hav- ing a full-ordering property, e.g., number, string, and Boolean. Us- ing the O sort operator, the Q3 query in the case study (Figure 2) can now be fully automated and answered in few seconds. </span></p><p class="c43 c150"><span class="c0">It is worth highlighting that these summary-based operators are new physical operators introduced to the InsightNotes engine. They are not implemented as UDFs within PostgreSQL DBMSs for the following fundamental reasons: (1) If the summary-based opera- tors are implemented as UDFs, then their execution will be carried out and encapsulated within the standard SQL operators. As a re- sult, none of the summary-based optimizations proposed in Sec- tion 5 would have been possible. (2) The annotation summaries are not like any other user-defined data types created through Post- greSQL extensibility. They are special tuple-based metadata infor- mation that requires extending the semantics of the core query op- erators [22]. That is why the core operators of InsightNotes in [22] do not manipulate the summaries through UDFs, and consequently, the newly proposed operators cannot be implemented as UDFs. And (3) The design choice of implementing the summary-based operators as new physical operators does not limit the extensibility of InsightNotes because the operators are defined at the summary- type level, i.e., Classifier, Snippet, and Cluster types. And thus, they apply to any driven instance under those types. </span></p><p class="c127"><span class="c27">4. SUMMARY-BASED INDEX SCHEME </span></p><p class="c43 c167"><span class="c0">To enable efficient execution of the summary-based relational operators, we need to build a summary-based indexing scheme over the summary objects. In this paper, we will focus only on the Classifier-Type indexing scheme. The InsightNotes system will not automatically index all summary instances defined in the database. Instead, this process is triggered by DB admins using the following command: </span></p><p class="c198"><span class="c12">Alter Table &lt;tableName&gt; </span></p><p class="c43 c104"><span class="c12">[Add [Indexable] | Drop] &lt;InstanceName&gt;; </span><span class="c0">This extended SQL command is used in InsightNotes to link a Summary Instance SI to a given user&rsquo;s relation R (Refer to Sec- tion 2.1). The newly added optional clause </span><span class="c12">Indexable </span><span class="c0">will in- form the system to build an index on SI&rsquo;s summary objects created over R&rsquo;s tuples. </span></p><p class="c43 c125"><span class="c0">Before we investigate possible indexing scheme, we briefly ex- plain how the summary objects are currently stored in Insight- Notes to optimize their propagation at query time. Referring to Figure 4(a), given a user&rsquo;s relation R, each tuple in R may have one or more summary objects attached to it according to number </span></p><p class="c85"><span class="c8">53 </span></p><p class="c188"><span class="c0">of summary instances linked to R. To optimize the propagation of the annotation summaries at query time, R&rsquo;s summary objects are stored in a de-normalized form in a corresponding catalog ta- ble R_SummaryStorage, as illustrated in Figure 4(b). Each tuple in R has a corresponding unique tuple in R_SummaryStorage linked together through unique tuple identifiers (OIDs). This scheme has two main advantages: (1) Since the summary objects are stored in tables separate from the data tables, there is no I/O or CPU over- heads added to users&rsquo; relations when queried in isolation, i.e., when the data is queried without annotation propagation, and (2) Since the summary objects are stored in a de-normalized form, there is no additional I/O or CPU overheads at query time to re-construct them from their primitive components. Thus, their propagations becomes more efficient as studied in [22]. </span><span class="c27">4.1 Classifier-Type Indexing Scheme </span></p><p class="c163"><span class="c0">Target Query: The index will speedup summary-based selection operators in the form of </span><span class="c12">&quot;classLabel &lt;Op&gt; constant&quot;</span><span class="c0">, where </span><span class="c12">classLabel </span><span class="c0">is a classifier label within a classifier sum- mary object, and Op is a comparison operator including {=, &gt;, &lt;, &le;, &ge;}. The output are the data tuples whose classifier summary objects satisfy the given predicates. The index will also speedup summary-based join and sorting operators involving the indexed classifier column. </span></p><p class="c67"><span class="c0">Example 2: Referring to Figure 4(a), assume we want to retrieve the data tuples having more than 5 associated questions. The SQL query will be: </span></p><p class="c14"><span class="c12">Select </span><span class="c178">* </span><span class="c12">From R r </span></p><p class="c11 c168"><span class="c12">Where r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;ClassBird2&rsquo;). getLabelValue(&lsquo;Question&rsquo;) &gt; 5; </span></p><p class="c21"><span class="c0">Baseline Indexing Scheme: A straightforward indexing strat- egy over the Classifier-type summary objects is to normalize their representation by replicating their components, i.e., the class labels and their counts, and storing them in a separate table (See Fig- ure 4(c)). And then, we can build a standard B-Tree index on each of the columns, i.e., the </span><span class="c12">ClassLabel </span><span class="c0">and </span><span class="c12">Cnt </span><span class="c0">columns. More- over, since most predicates over the Classifier-type objects will ref- erence both columns, we may create a third system-maintained (de- rived) column that concatenates these two columns, and then index its values using the B-Tree index as illustrated in Figure 4(c). </span></p><p class="c34"><span class="c0">The advantage of this scheme is that it uses the standard indexes without modifications. However, it has two major drawbacks. First, the storage overhead of the summary objects is doubled; one repli- cate is for efficient propagation, and another replica is for indexing. And second, starting from the index to reach the actual data tuples in relation R, we will need several join operations among multi- ple tables, which certainly degrades the query performance. The proposed Summary-BTree indexing scheme will overcome these limitations. </span></p><p class="c41"><span class="c132">4.1.1 Summary-BTree Index Structure </span></p><p class="c37"><span class="c0">The proposed Summary-BTree index is a variant of the standard B-Tree that can be directly built over the de-normalized represen- tation of the Classifier-type summary objects. The structure of the index is depicted in Figure 4(d). Assume the index is built on top of the summary instance ClassBird1 defined on Relation R. The creation of the index involves three steps: </span></p><p class="c190"><span class="c0">&#9702; Itemization: The Rep[] array within the object will be item- ized by converting the array elements (String classLabel, Inte- ger AnnotationCnt) to a sequence of text values in the form of </span><span class="c12">&quot;classLable:ExtendedAnnotationCnt&quot; </span><span class="c0">as illustrated in Figure 4(c) Step 1. The ExtendedAnnotationCnt will have an ini- </span></p><p class="c3 c43"><span class="c0">tial 3-character format to preserve the order among the integer val- ues even after converting them into strings</span><span class="c22">1</span><span class="c0">. In Figure 4(d) Step 1, we illustrate the itemization of the ClassBird1 summary object attached to tuple r1. </span></p><p class="c43 c193"><span class="c0">&#9702; Indexing: The text values generated from the Itemization step will be inserted into the Summary-BTree index. The index fol- lows the same structure and operations of the standard B-Tree. And hence, the B-Tree&rsquo;s maintenance algorithms, i.e., insertion and deletion, are all leveraged in the Summary-BTree index. The in- dexed values will appear in the leaf nodes of the index sorted alpha- betically as depicted in the figure. The only exception compared to the standard B-Tree will be in the heap pointers stored in the leaf nodes, which are called backward pointers and described next. </span></p><p class="c43 c199"><span class="c0">&#9702; Backward Referencing: We make use of the fact that the storage of the annotation summaries is entirely transparent from (and not directly query-able by) the end-users. Hence, we have the opportunity to optimize the internal structure of the proposed tables and indexes for efficient performance. A key trick in the Summary-BTree index is that the leaf nodes will point back to their annotated data tuples in Relation R instead of pointing back to the R_SummaryStorage table. For example, the index entries </span><span class="c12">&quot;Disease:002&quot; </span><span class="c0">and </span><span class="c12">&quot;Disease:008&quot; </span><span class="c0">will point back to tu- ple R.r2 and R.r1, respectively. These backward pointers will be created and maintained under the different operations as described in sequel </span><span class="c22">2</span><span class="c0">. </span></p><p class="c91 c43"><span class="c0">The advantages of the Summary-BTree index are two fold: (1) It builds on the existing storage scheme of InsightNotes without the need to replicate or normalize the summary objects, and hence the optimized propagation performance is not affected. And (2) As the experimental evaluation will confirm (Section 6), the backward- referencing mechanism achieves up to 11x speedup in query per- formance compared to the baseline indexing scheme. </span></p><p class="c200"><span class="c132">4.1.2 Summary-BTree Index Operations </span></p><p class="c43 c152"><span class="c0">To enable the backward-referencing mechanism, we developed an internal function, called diskTupleLoc(), within the database en- gine, which takes a tuple&rsquo;s identifier (OID) and returns its heap location. This function will be used inside the index&rsquo;s maintenance algorithms to create the correct backward pointers. Notice that this mechanism does not break the transparency concept in database systems since it is entirely encapsulated within the index struc- ture and not exposed to the outside world (neither end-users nor database developers). The index is maintained under the following operations: </span></p><p class="c43 c195"><span class="c0">&#9702; Adding Annotation&minus;Insertion: Adding a new annotation on an un-annotated tuple in R results in inserting a new tuple in R_SummaryStorage. The system will then retrieve the heap loca- tion of the data tuple, itemize the indexed classifier summary ob- ject, and insert them into the Summary-BTree index as illustrated in Figure 4(d). </span></p><p class="c43 c123"><span class="c0">&#9702; Adding Annotation&minus;Update: Adding a new annotation on an already-annotated tuple in R will result in updating the correspond- ing summary objects in R_SummaryStorage. For example, if a new annotation highlighting a disease is added to R.r1, then the Class- Bird1&rsquo;s summary object will be updated by incrementing the count </span></p><p class="c43 c141"><span class="c20">1</span><span class="c10">If the number of annotations assigned to a single classifier&rsquo;s label exceeds 999, then InsightNotes automatically increments the num- ber of allocated characters and re-builds the index. However, it is a very rare operation. </span><span class="c20">2</span><span class="c10">The SummaryStorage tables are still directly accessible using SQL queries, but for administrative tasks only. Such administra- tive queries use table-scan plans instead of index-scan plans. </span></p><p class="c85"><span class="c8">54 </span></p><p class="c11"><span class="c76">ClassBird2 </span><span class="c118">Snippet Summary Classifier Summary </span></p><p class="c11"><span class="c53">Classifier Summary </span><span class="c87">[(Provenance, 10), </span><span class="c1">(Question, 8), (Other, 5)] </span></p><p class="c11"><span class="c1">System&rsquo;s </span></p><p class="c11"><span class="c1">[(Provenance, 8), </span><span class="c76">TextSummary1 </span></p><p class="c11"><span class="c1">column </span></p><p class="c11"><span class="c1">(Question, 15), </span></p><p class="c11"><span class="c70">(b) </span><span class="c55">R_SummaryStorage </span><span class="c38">(optimized for summary propagation) </span></p><p class="c11"><span class="c1">[&ldquo;Experiment E ... &rdquo;, </span></p><p class="c11"><span class="c1">(Other, 42)] &ldquo;Wikipedia article ...&ldquo;] </span></p><p class="c11"><span class="c9">OID C</span><span class="c74">1 </span><span class="c9">C</span><span class="c74">n </span></p><p class="c11"><span class="c76">ClassBird1 </span><span class="c48">[(Behavior, 33), </span><span class="c2">(Disease, 8), (Anatomy, 25), (Other, 16)] </span></p><p class="c11"><span class="c76">ClassBird1 </span><span class="c48">[(Behavior, 6), </span><span class="c2">(Disease, 2), (Anatomy, 10), (Other, 5)] </span></p><p class="c26"><span class="c171">Referencing </span><span class="c162">Backward </span><span class="c35">Heap </span><span class="c103">backward </span><span class="c35">pointers to relation </span><span class="c196">R </span><span class="c35">instead of </span><span class="c196">R_SummaryStorage </span></p><p class="c11"><span class="c53">OID ClassBird1 ClassBird2 </span><span class="c107">TextSummary1 </span></p><p class="c11"><span class="c1">r1 r1 Swan </span></p><p class="c11"><span class="c1">Goose </span></p><p class="c11"><span class="c112">... ... ... ... </span></p><p class="c11"><span class="c1">r2 </span><span class="c112">... ... ... </span></p><p class="c11"><span class="c1">Behavior:033 Disease:008 Anatomy:025 </span></p><p class="c11"><span class="c81">Root </span></p><p class="c11"><span class="c1">Other:016 </span><span class="c17">Anatomy:010 Anatomy:025 Disease:002 Disease:008 </span><span class="c90">ClassBird1 </span></p><p class="c11"><span class="c84">ClassBird2 </span><span class="c120">TextSummary1 </span><span class="c111">[(Behavior, 33), (Disease, 8), (Anatomy, 25), </span></p><p class="c11"><span class="c98">[(Provenance, 10), (Question, 8), (Other, 5)] </span></p><p class="c11"><span class="c17">[&ldquo;Experiment E ... &rdquo;, </span><span class="c1">... ... </span></p><p class="c11"><span class="c17">&ldquo;Wikipedia article ...&ldquo;] </span><span class="c99">InsightNotes </span></p><p class="c11"><span class="c111">(Other, 16)] </span><span class="c53">Classifier Summary </span></p><p class="c11"><span class="c1">... ... </span></p><p class="c11"><span class="c99">Storage </span></p><p class="c11"><span class="c76">ClassBird2 </span></p><p class="c11"><span class="c1">... </span><span class="c87">r2 phoA ... ... </span></p><p class="c11"><span class="c70">(a) User&rsquo;s Relation </span><span class="c55">R </span></p><p class="c11"><span class="c94">3 </span></p><p class="c11"><span class="c94">2 </span><span class="c99">Indexing </span></p><p class="c11"><span class="c53">OID Label Count </span><span class="c107">Derived Col </span></p><p class="c11"><span class="c1">r1 Behavior 33 Behavior-033 </span></p><p class="c11"><span class="c1">r1 Disease 8 Disease-008 </span></p><p class="c11"><span class="c1">... ... ... ... </span></p><p class="c26"><span class="c53">Pointer to R.r1 </span></p><p class="c26"><span class="c92">(c) Baseline indexing scheme </span><span class="c9">(</span><span class="c38">on ClassBird1 column</span><span class="c9">) </span></p><p class="c11"><span class="c99">1- Create a normalized table for the classifier&rsquo;s primitives </span></p><p class="c26"><span class="c92">(d) Summary-BTree index </span><span class="c9">(</span><span class="c38">on ClassBird1 column</span><span class="c9">) </span></p><p class="c11"><span class="c99">2- Build a standard B-Tree </span><span class="c53">Pointer to </span></p><p class="c11"><span class="c53">Pointer to </span></p><p class="c11"><span class="c53">Pointer to </span></p><p class="c11"><span class="c99">index on the derived column </span><span class="c53">R.r2 </span></p><p class="c11"><span class="c53">R.r1 </span></p><p class="c11"><span class="c53">R.r2 </span></p><p class="c11"><span class="c0">Figure 4: Summary-Btree Index For Indexing The Classifier Type Summary Objects. </span></p><p class="c3"><span class="c0">of the Disease class label to be 9. To update the index, the system will trigger a deletion and then re-insertion only for the modified class label&mdash;The other class labels within the object will remain untouched. For example, a deletion of key </span><span class="c12">&quot;Disease:008&quot; </span><span class="c0">and insertion of key </span><span class="c12">&quot;Disease:009&quot; </span><span class="c0">will take place. </span></p><p class="c3"><span class="c0">&#9702; Deleting Annotation or Tuple: The deletion of an an- notation will result in updating the corresponding summary ob- jects in R_SummaryStorage. Therefore, the same procedure de- scribed above will be applied. Similarly, the deletion of a data tuple from R will result in deleting the corresponding tuple in R_SummaryStorage, and all its index entries will be deleted. </span></p><p class="c3"><span class="c0">&#9702; Summary-BTree Querying: To answer an equality query over the index, e.g., </span><span class="c12">&quot;classLabel = constant&quot; </span><span class="c0">, a probing key will be formed by concatenating the two operands, i.e., </span><span class="c12">&quot;classLabel:Extended_constant&quot;</span><span class="c0">, where </span><span class="c12">Extended_constant </span><span class="c0">is the 3-character for- mat of the constant value. In the case of a range query, e.g., </span><span class="c12">&quot;constant1 &gt; classLabel &gt; constant2&quot;</span><span class="c0">, two probing keys will be formed; a starting key as </span><span class="c12">&quot;classLabel:Extended_constant1&quot;</span><span class="c0">, and a stop- ping key as </span><span class="c12">&quot;classLabel:Extended_constant2&quot;</span><span class="c0">. All the keys in between will lead to the qualifying data tuples. If either of the starting or stopping keys is missing, then it will be replaced by </span><span class="c12">&quot;classLabel:000&quot;</span><span class="c0">, or </span><span class="c12">&quot;classLabel:999&quot;</span><span class="c0">, respectively. </span></p><p class="c11"><span class="c132">4.1.3 Summary-BTree Theoretical Bounds </span></p><p class="c3"><span class="c0">The Summary-BTree inherits the efficient logarithmic perfor- mance from the B-Tree index since they have similar structure. The following Theorem states the theoretical bounds of the index. </span></p><p class="c3"><span class="c0">Theorem: Assuming that the number of data tuples in the user&rsquo;s relation R is M, the number of Classifier-type summary objects is N, the number of class labels per summary object is k, and the disk page size in records is B, then the following theoretical bounds hold for a Summary-BTree index: </span></p><p class="c11"><span class="c0">&#9702; Adding Annotation&minus;Insertion is O(kLog</span><span class="c20">B</span><span class="c0">kN + Log</span><span class="c20">B</span><span class="c0">M) </span></p><p class="c11"><span class="c0">&#9702; Adding Annotation&minus;Update is O(2Log</span><span class="c15">B</span><span class="c10">kN + Log</span><span class="c15">B</span><span class="c10">M) </span></p><p class="c11"><span class="c0">&#9702; Deleting data tuple is O(kLog</span><span class="c15">B</span><span class="c10">kN + Log</span><span class="c15">B</span><span class="c10">M) </span></p><p class="c11"><span class="c0">&#9702; Equality search is O(Log</span><span class="c20">B</span><span class="c0">kN) 2 </span></p><p class="c3"><span class="c0">Proof: Assuming N summary objects and each object has k class labels, then the number of indexed keys is O(kN). There- fore, any single search, insertion or deletion will be bounded by O(Log</span><span class="c20">B</span><span class="c0">kN). When adding a new annotation that triggers a new insertion in the SummaryStorage table, the k class labels will be inserted into the index which will cost O(kLog</span><span class="c20">B</span><span class="c0">kN). In contrast, if the added annotation will trigger an update of an existing class label, then only that label is deleted and then re-inserted, which will cost O(2Log</span><span class="c15">B</span><span class="c10">kN). Finally, when inserting into or deleting from </span><span class="c0">the index tree, the system needs to retrieve the heap location of the data tuple. This operation uses a B-Tree index on the OID column in R with the cost of O(Log</span><span class="c15">B</span><span class="c10">M). </span></p><p class="c11"><span class="c27">5. SUMMARY-BASED QUERY OPTI- </span></p><p class="c11"><span class="c27">MIZATION </span><span class="c0">When a query involves both the summary-based and the standard SQL operators, then the traditional transformation and equivalence rules alone will be of a very limited use. This is because the seman- tics of the new operators are unknown to current optimizers. For example, the current optimizer may not be able to use the standard selection-pushdown rule to push a selection operator below a join operator because there is a summary-based operator in-between. Another example is illustrated in Figure 5(a), where the query plan involves a summary-based sort O and selection S operators on top of a traditional join operator &#8883;&#8882;. In this case the current optimizers cannot apply any of the known transformation rules to create equiv- alent query plans. In this section, we introduce several important equivalence rules involving the summary-based operators, and ex- tend the query optimizer to leverage them and create a larger pool of possible query plans. </span></p><p class="c11"><span class="c27">5.1 Extended Equivalence Rules </span></p><p class="c11"><span class="c8">55 </span></p><p class="c11"><span class="c0">&bull; Rules for Summary-Based Selection (S</span><span class="c20">p</span><span class="c0">(R)): Few important rules involving the S operator include: S</span><span class="c15">p</span><span class="c10">(&sigma;</span><span class="c15">c</span><span class="c10">(R)) = &sigma;</span><span class="c15">c</span><span class="c10">(S</span><span class="c15">p</span><span class="c10">(R)) (1) </span></p><p class="c11"><span class="c0">S</span><span class="c15">p</span><span class="c10">(R &#8883;&#8882;</span><span class="c15">c </span><span class="c10">S) = S</span><span class="c15">p</span><span class="c10">(R) &#8883;&#8882;</span><span class="c15">c </span><span class="c10">S, </span><span class="c4">iff p is on instances in R not in S. </span><span class="c10">(2) </span></p><p class="c3"><span class="c0">Proof: Rule 1 is correct since neither the &sigma; operator changes the summaries&rsquo; content nor the S operator changes the data&rsquo;s con- tent. And thus, the commutativity property between the two op- erators apply. This rule enables the system to switch the order of predicates and use the available indexes&mdash;either on the data or the summaries&mdash;as needed. Rule 2 enables pushing the summary- based selection operator before the join operator. Rule 2 is correct since predicates p are on instances linked only to one of the two relations, say R. Therefore, when the &#8883;&#8882; operator merges the sum- mary objects attached to the joined tuples, the summary objects related to p are guaranteed not to change since they have no coun- terparts on S. And hence, the rule applies. </span></p><p class="c11"><span class="c0">&bull; Rules for Summary-Based Sort (O</span><span class="c15">f[,direction]</span><span class="c0">(R)): We focus on an important case where an existing Summary-BTree index can provide R&rsquo;s tuples in an interesting order to the query, and hence the sort operator can be eliminated. The following rules state that the order of R&rsquo;s tuples is preserved under certain transformations. We use notation R</span><span class="c22">L </span><span class="c0">to indicate that R has an interesting order w.r.t a classifier instance </span><span class="c12">L</span><span class="c0">. &sigma;</span><span class="c20">c</span><span class="c0">(R</span><span class="c22">L</span><span class="c0">) = &sigma;</span><span class="c20">c</span><span class="c0">(R)</span><span class="c22">L </span><span class="c0">(3) </span></p><p class="c11"><span class="c0">S</span><span class="c15">p</span><span class="c10">(R</span><span class="c20">L</span><span class="c10">) = S</span><span class="c15">p</span><span class="c10">(R)</span><span class="c20">L </span><span class="c10">(4) </span></p><p class="c11"><span class="c0">R</span><span class="c22">L </span><span class="c0">&#8883;&#8882; S = R &#8883;&#8882; S</span><span class="c22">L</span><span class="c0">, </span><span class="c45">iff &#8883;&#8882; preserves R&rsquo;s order, and </span><span class="c82">L </span><span class="c45">is not on S</span><span class="c0">. (5) </span></p><p class="c11"><span class="c0">J (R</span><span class="c22">L</span><span class="c0">,S) = J (R, S)</span><span class="c22">L</span><span class="c0">, </span><span class="c45">iff J preserves R&rsquo;s order, and </span><span class="c82">L </span><span class="c45">is not </span></p><p class="c11"><span class="c45">defined on S</span><span class="c0">. (6) </span></p><p class="c3"><span class="c0">Proof: Rules 3 and 4 indicate that the selection operators (&sigma; and S) do not change the interesting order of R and preserve it in the output. This is guaranteed since these operators do not change the content of their summaries. For the join operators (Rules 5 and 6), the order w.r.t </span><span class="c12">L </span><span class="c0">is preserved only if two conditions are met: (1) The join algorithm preserves R&rsquo;s order, e.g., R is the outer relation of the join, and (2) Relation S does not have the summary instance </span><span class="c12">L </span><span class="c0">defined on it. If the 2</span><span class="c22">nd </span><span class="c0">condition is not met, then the join operators (&#8883;&#8882; or J ) would merge the summary objects of </span><span class="c12">L</span><span class="c0">, and thus the order may not be preserved. Otherwise, Rules 5 and 6 also applies. </span></p><p class="c11"><span class="c0">Example 4: Assume a query Q that joins Relation R depicted in Figure 4 with another relation S(c1,c2) based on data at- tributes R.c</span><span class="c20">1 </span><span class="c0">= S.c</span><span class="c20">1</span><span class="c0">. Then, Q selects only the tuples with more than five disease annotations, i.e., </span><span class="c12">ClassBird1.disease &gt; 5</span><span class="c0">, and produces the output sorted by the count of these disease annotations. An initial query plan based on the sequence presented above is illustrated in the following figure (Figure 5(a)). Then, con- sider the following two cases: Case I: Relation S has the ClassBird1 summary instance defined on it. In this case, the summary-based selection operator cannot be pushed below the join operator, and the system will use the initial plan in Figure 5(a). Case II: Relation S does not have the ClassBird1 summary in- stance defined on it. In this case, the system will use Rule 2 to push the summary-based selection operator before the join. And assum- ing that ClassBird1 summary instance on R is indexed, then the index can be used to retrieve the tuples with more than five disease annotations (in a sorted order). Then, based on Rule 5, the join operator preserves the order of the tuples, and hence the summary- </span></p><p class="c11"><span class="c149">Output&quot; </span><span class="c79">SummaryAbased&amp; sor,ng&amp; </span></p><p class="c11"><span class="c79">...disease </span></p><p class="c26"><span class="c79">DataAbased&amp; join&amp; </span></p><p class="c11"><span class="c93">(a)&amp;Ini,al&amp;plan&amp; </span></p><p class="c11"><span class="c46">Rules&quot;2&quot;&amp;&quot;5&quot; </span></p><p class="c11"><span class="c0">Figure 5: Rule-Based Equivalent Plans in InsightNotes. </span></p><p class="c11"><span class="c0">based sort operator can be removed as illustrated in Figure 5(b). </span></p><p class="c11"><span class="c0">&bull; Rules for Summary-Based Filter (F</span><span class="c15">p</span><span class="c10">(R)): Few important rules </span><span class="c0">involving the F operator include: </span></p><p class="c11"><span class="c0">F</span><span class="c20">p</span><span class="c0">(R &#8883;&#8882;</span><span class="c20">c </span><span class="c0">S) = F</span><span class="c20">p</span><span class="c0">(R) &#8883;&#8882;</span><span class="c20">c </span><span class="c0">S, </span><span class="c45">iff p is on instances in R not in S. </span><span class="c0">(7) </span></p><p class="c11"><span class="c0">F</span><span class="c20">p</span><span class="c0">(R &#8883;&#8882;</span><span class="c20">c </span><span class="c0">S) = F</span><span class="c20">p</span><span class="c0">(R) &#8883;&#8882;</span><span class="c20">c </span><span class="c0">F</span><span class="c20">p</span><span class="c0">(S), </span><span class="c45">iff p is structural predicate. </span><span class="c0">(8) </span></p><p class="c3"><span class="c0">Proof: Rules 7 and 8 address pushing the filter operator be- fore the join. Both rules aim for eliminating unnecessary summary objects&mdash;and hence their processing cost in the query pipeline&mdash; as early as possible. Rule 7 can be proved in similar way to Rule 2, i.e., the &#8883;&#8882; operator is guaranteed not to alter the summary ob- jects related to predicate p since they are attached to only relation R. Similarly, the F operator does not change the data&rsquo;s content, and hence the join predicates c are not affected. Therefore Rule 7 applies. </span></p><p class="c3"><span class="c0">Rule 8 indicates that if the predicate is structural&mdash;A structural predicate is defined as a predicate on the InstanceID or the Sum- maryType of the summary object&mdash;then p can be pushed to both sides before the join operation. For example, referring to Figure 4, if a query is interested only in the summary objects of instance ClassBird1, then all other summaries of instances ClassBird2 and TextSummary1 can be dropped as early as possible. Rule 8 can be proved in the same way as Rule 7. </span></p><p class="c11"><span class="c0">&bull; Rules for Summary-Based Join (J</span><span class="c20">p</span><span class="c0">(R, S)): Few important rules involving the J operator include: &sigma;</span><span class="c15">c</span><span class="c10">(J</span><span class="c15">p</span><span class="c10">(R, S)) = J</span><span class="c15">p</span><span class="c10">(&sigma;</span><span class="c15">c</span><span class="c10">(R),S), iff c is on R&rsquo;s attributes. (9) </span><span class="c0">S</span><span class="c15">p1</span><span class="c10">(J</span><span class="c15">p2</span><span class="c10">(R, S)) = J</span><span class="c15">p2</span><span class="c10">(S</span><span class="c15">p1</span><span class="c10">(R),S), </span><span class="c4">iff p</span><span class="c119">1 </span><span class="c4">is on instances in </span></p><p class="c11"><span class="c45">R not in S. </span><span class="c0">(10) </span></p><p class="c11"><span class="c0">T &#8883;&#8882;</span><span class="c15">c </span><span class="c10">J</span><span class="c15">p</span><span class="c10">(R, S) = J</span><span class="c15">p</span><span class="c10">((T &#8883;&#8882;</span><span class="c15">c </span><span class="c10">R),S), </span><span class="c4">iff p is on instances not in T </span></p><p class="c11"><span class="c45">and c does not involve S&rsquo;s attributes. </span><span class="c0">(11) </span></p><p class="c3"><span class="c0">Proof: Rules 9 and 10 address pushing the selection operators (&sigma; or S) before the summary-based join operator whenever possible. It is always a valid transformation in the case of the &sigma; operator as long as the predicates c are on one of the two relations (Rule 9). This is because the &sigma; and the J operate on disjoint pieces of the tuple, i.e., the data values, and the summaries, respectively. Rule 10 is correct since the summary objects related to p1 are only attached to relation R. And thus, the J is guaranteed not to alter these objects after the join. Rule 11 states the conditions for switching the order between summary- and data-based join operators. The order can be switched iff the summary-based join predicates p involve instances not defined on T. And thus, joining early with T (T &#8883;&#8882;</span><span class="c15">c </span><span class="c10">R) is </span><span class="c0">guaranteed not to affect the evaluation of p. </span></p><p class="c11"><span class="c8">56 </span></p><p class="c26"><span class="c79">SummaryAbased&amp; selec,on&amp; </span></p><p class="c11"><span class="c79">(disease &gt;5) </span></p><p class="c11"><span class="c79">R.c1 = S.c1 </span></p><p class="c11"><span class="c46">R </span></p><p class="c11"><span class="c46">S </span></p><p class="c11"><span class="c93">(b)&amp;Op,mized&amp;plan&amp;(if&amp;S&amp;does&amp; not&amp;have&amp;ClassBird1&amp; summary&amp;instance)&amp; </span></p><p class="c11"><span class="c149">Output&quot; </span></p><p class="c26"><span class="c79">DataAbased&amp; join&amp; </span></p><p class="c11"><span class="c57">R.c1 = S.c1 </span></p><p class="c26"><span class="c79">SummaryABTree&amp; Index&amp;lookup&amp; </span></p><p class="c11"><span class="c79">(disease &gt;5) </span><span class="c33">S </span></p><p class="c11"><span class="c46">R </span></p><p class="c11"><span class="c50">AvgObjectSize = 50 Behavior Label: </span></p><p class="c11"><span class="c0">. . . </span><span class="c50">{Min </span><span class="c0">. . . </span></p><p class="c11"><span class="c50">= 3, Max = 43, NumDistinct = 27, } </span></p><p class="c11"><span class="c68">OID ClassBird1 ClassBird2 </span><span class="c133">TextSummary1 </span></p><p class="c11"><span class="c50">r1 </span><span class="c90">ClassBird2 </span><span class="c172">TextSummary1 </span></p><p class="c11"><span class="c111">[&ldquo;Experiment E ... &rdquo;, &ldquo;Wikipedia article ...&ldquo;] </span></p><p class="c11"><span class="c175">... ... ... ... </span></p><p class="c11"><span class="c0">Figure 6: Example of Classifier-Type Maintained Statistics. </span></p><p class="c11"><span class="c27">5.2 Cost Model and Cardinality Estimation </span></p><p class="c3"><span class="c0">Statistics Collection: The equivalence rules presented in Sec- tion 5.1 enable the query optimizer to generate a larger pool of equivalent query plans. The next step is to estimate the cost of the new summary-based operators in order to select the cheapest plan. Towards this goal, InsightNotes maintains several statistics over the summary objects attached to a given relation R. These statistics are similar to those maintained by traditional DBMSs except that they capture the internal semantics of the summary objects. </span></p><p class="c3"><span class="c0">Demonstrating over an example, assume relation R has three summary instances linked to it as illustrated in Figure 6. Then, for each summary instance (one column in Figure 6), InsightNotes maintains the average object size (</span><span class="c12">AvgObjectSize</span><span class="c0">). In the case of Classifier-type objects, e.g., ClassBird1 and ClassBird2, the size is fixed for all objects within one instance. In contrast, for the Snippet-type and Cluster-type objects, the size may differ from one object to another. Moreover, the system maintains several statis- tics for each classifier label within the Classifier-type objects. For example, for ClassBird1, four data structures are maintained&minus;one for each class label. Each data structure holds some statistics on the count field associated with that label, which include </span><span class="c12">{Min, Max, NumDistinct, Equi-Width Histogram} </span><span class="c0">as de- picted in Figure 6. These statistics are maintained whenever a sum- mary object is updated. </span></p><p class="c3"><span class="c0">Cardinality and Cost Estimation: To avoid re-inventing the wheel, the new summary-based operators leverage the same heuristics that the standard SQL operators use to estimate their cardinalities and costs. For example, the filter operator F uses the same heuristics as the standard projection operator &pi;, e.g., based on the AvgObjectSize statistics, the F operator es- timates the size of the new tuples and the number of needed disk blocks. Similarly, the summary-based selection operator S uses the same heuristics as the standard selection operator &sigma;, e.g., referring to the S operator in Example 4, the system uses the maintained statistics (</span><span class="c12">{Min, Max, NumDistinct, Equi-Width Histogram}</span><span class="c0">) over the ClassBird1.Disease label to estimate the number of output tuples having more than 5 disease- related annotations. Moreover, if a Summary-BTree index is used to answer this predicate, then the number of performed I/Os can be estimated based on the index&rsquo;s theoretical bounds. </span></p><p class="c3"><span class="c0">The summary-based join operator J also follows the same heuristics as the standard join operator &#8883;&#8882;, e.g., the size of joining two relations R and S based on an equality join on </span><span class="c12">ClassBird2.Provenance </span><span class="c0">can be estimated by mul- tiplying the size of both relations, and then dividing by the largest value between the </span><span class="c12">NumDistinct </span><span class="c0">statistics on </span><span class="c12">ClassBird2.Provenance </span><span class="c0">from both sides. Currently, In- sightNotes supports only two implementation choices for the J operator, which are either a block nested-loop join, or an index- based join. </span></p><p class="c11"><span class="c192">ClassBird1 </span><span class="c111">[(Behavior, 33), (Disease, 8), (Anatomy, 25), (Other, 16)] </span></p><p class="c11"><span class="c98">[(Provenance, 10), (Question, 8), (Other, 5)] </span></p><p class="c11"><span class="c27">6. EXPERIMENTS </span></p><p class="c3"><span class="c0">The proposed extensions are implemented within the Insight- Notes prototype engine [22], which is based on the open-source PostgreSQL DBMS. The experiments are conducted using an AMD Opteron Quadputer compute server with two 16-core AMD CPUs, 128GB memory, and 2 TBs SATA hard drive. </span></p><p class="c3"><span class="c0">Application Datasets: We use annotated database that stores information related to 10s of thousands of birds worldwide. The largest annotated table in the database is the Birds table that stores the birds&rsquo; basic information. The table consists of 45,000 tuples, each consisting of 12 attributes, e.g., scientific name, Ids across dif- ferent systems, description, genus, family, and habit. The table size in the database is approximately 450MBs. The collected number of annotations is approximately 9x10</span><span class="c22">6 </span><span class="c0">annotations describing a wide range of bird related information, e.g., color, body shape or weight, certain behavior or sound, eating habits, geographic location, or observed diseases. The size of each annotation varies between 150 and 8,000 characters. The total size of the raw annotations table (the 9x10</span><span class="c22">6 </span><span class="c0">annotations) is around 5GBs. </span></p><p class="c3"><span class="c0">Summarization Techniques: InsightNotes has several inte- grated data mining techniques for annotation summarization, e.g., the Naive Bayes [10] technique for annotation classification, the CluStream technique [2] for incremental clustering of annotations, and the LSA (Latent Semantic Analysis) technique [18] for text summarization and snippet creation. For the purpose of our ex- periments, we link the Birds table with two summary instances: (1) A Classifier summary instance ClassBird1 that classifies each annotation to one of the labels: {&lsquo;Disease&rsquo;, &lsquo;Anatomy&rsquo;, &lsquo;Behav- ior&rsquo;, &lsquo;Other&rsquo;}, and (2) A Snippet summary instance TextSummary1 that summarizes each annotation larger than 1,000 characters and creates a snippet that has a maximum of 400 characters. We then create a Summary-BTree index over ClassBird1. </span></p><p class="c3"><span class="c0">Index Creation Overhead: The first set of experiments study the overheads associated with the creation of the summary-based index (Figures 7, 8, and 9). In the experiments, we vary the number of annotations (over the x-axis) between 450x10</span><span class="c22">3 </span><span class="c0">(corresponding to 10 annotations per tuple on average), to 9x10</span><span class="c22">6 </span><span class="c0">(corresponding to 200 annotations per tuple on average). Figure 7 illustrates the stor- age overhead of both the Baseline and Summary-BTree schemes discussed in Section 4.1. In the former scheme, the summary ob- jects are replicated and stored in a normalized form, and then a standard B-Tree index is created over them. In contrast, in the latter scheme, a Summary-BTree index is created over the de-normalized representation of the summary objects. As the results show, the in- dex size in both cases is almost the same. However, the proposed Summary-BTree scheme saves up to 65% of the storage overhead as it requires no replication of the data. The results also show that the storage overhead is almost fixed under the different sizes of the raw annotations. The reason is that once each data tuple has an attached classifier summary object, then the number and size of the summary objects becomes fixed and will not change. The in- crease in the number of annotations only changes the integer value assigned to the class labels, which does not affect the size. </span></p><p class="c3"><span class="c0">In Figures 8 and 9, we measure the time overhead of creating the indexes in bulk and incremental modes, respectively. In the bulk mode (Figure 8), the raw annotations and the summary ob- jects will be first created, and then the indexes will be built. This is the recommended mode for initial uploading of large datasets into the database. We measured, over the y-axis, the relative time of creating the index to the time of uploading the raw annotations and creating the summary objects. The indexing time under the Summary-BTree scheme involves the time for itemization, insertion </span></p><p class="c11"><span class="c8">57 </span></p><p class="c159"><span class="c63">Index Summary Objects Overhead (Baseline scheme) Overhead Summary Objects Overhead (Summary-BTree scheme) </span></p><p class="c11 c153"><span class="c20">No Indexes </span></p><p class="c110 c165"><span class="c63">1400&quot; </span></p><p class="c11 c47"><span class="c25">12&quot; </span></p><p class="c11 c47"><span class="c25">12&quot; </span></p><p class="c47 c52"><span class="c25">10&quot; </span></p><p class="c11 c47"><span class="c25">10&quot; </span></p><p class="c5"><span class="c28">Summary-BTree scheme </span></p><p class="c5"><span class="c28">Summary-BTree scheme </span></p><p class="c5"><span class="c28">Summary-BTree scheme </span></p><p class="c78 c156"><span class="c28">Baseline scheme </span></p><p class="c11 c40"><span class="c16">180&quot; </span></p><p class="c11 c40"><span class="c16">180&quot; </span></p><p class="c11 c40"><span class="c16">180&quot; </span></p><p class="c11 c40"><span class="c16">180&quot; </span></p><p class="c40 c110"><span class="c16">150&quot; </span></p><p class="c11 c40"><span class="c16">150&quot; </span></p><p class="c11 c40"><span class="c16">150&quot; </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c11 c72"><span class="c20">Baseline scheme Summary-BTree scheme </span></p><p class="c144"><span class="c116">Base&quot; Opt&quot; Base&quot; Opt&quot; Base&quot; Opt&quot; Base&quot; Opt&quot; Base&quot; Opt&quot; </span></p><p class="c11 c180"><span class="c63">800&quot; </span></p><p class="c32"><span class="c63">600&quot; </span></p><p class="c32"><span class="c63">400&quot; </span></p><p class="c32"><span class="c63">200&quot; </span></p><p class="c80"><span class="c63">0&quot; </span></p><p class="c124"><span class="c116">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c26 c51"><span class="c128">6&quot;4&quot;2&quot;</span><span class="c25">0&quot;450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; Number of Annotations </span></p><p class="c26 c51"><span class="c128">6&quot;4&quot;2&quot;</span><span class="c25">0&quot;450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; Number of Annotations </span></p><p class="c11 c117"><span class="c16">90&quot; </span></p><p class="c65"><span class="c16">60&quot; </span></p><p class="c65"><span class="c16">30&quot; </span></p><p class="c142"><span class="c16">0&quot; </span></p><p class="c11 c143"><span class="c16">0&quot; </span></p><p class="c146"><span class="c16">450K&quot; 2.25M&quot; 9M&quot; </span></p><p class="c23"><span class="c16">Number of Annotations </span></p><p class="c26 c115"><span class="c63">Number of Annotations </span><span class="c0">Figure 7: Storage Overhead. </span></p><p class="c11 c140"><span class="c0">Figure 9: Incremental Indexing. </span></p><p class="c26 c51"><span class="c128">6&quot;4&quot;2&quot;</span><span class="c25">0&quot;450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; Number of Annotations </span></p><p class="c170"><span class="c0">Figure 8: Bulk Index Creation. </span></p><p class="c11 c182"><span class="c0">Figure 8: Bulk Index Creation. </span></p><p class="c11 c117"><span class="c16">90&quot; </span></p><p class="c65"><span class="c16">60&quot; </span></p><p class="c65"><span class="c16">30&quot; </span></p><p class="c142"><span class="c16">0&quot; </span></p><p class="c146"><span class="c16">450K&quot; 2.25M&quot; 9M&quot; </span></p><p class="c23"><span class="c16">Number of Annotations </span></p><p class="c11 c44"><span class="c16">Number of Annotations </span></p><p class="c11 c66"><span class="c63">1200&quot; </span></p><p class="c6"><span class="c63">1000&quot; </span></p><p class="c11 c187"><span class="c128">8&quot; </span></p><p class="c11 c78"><span class="c28">Baseline scheme </span></p><p class="c11 c40"><span class="c16">150&quot; </span></p><p class="c110 c40"><span class="c16">120&quot; </span></p><p class="c11 c40"><span class="c16">120&quot; </span></p><p class="c129"><span class="c0">of indexed keys, and computing the backward references. For the Baseline scheme, the indexing time includes the de-normalization and storage in other tables, and the insertion of the indexed keys. The figure illustrates that the creation of the Summary-BTree index is more efficient than the baseline index by up to 35%. </span></p><p class="c34"><span class="c0">The performance of the incremental indexing is studied in Fig- ure 9. We considered the cases of inserting annotations with: (1) No indexes, (2) A Summary-BTree index, and (3) A Baseline B-Tree index. For each data point in the figure, we insert 100 an- notations, measure the insertion time of each annotation under the three cases, and then report the average over the 100 insertions. As the figure shows, the indexing overhead using the Summary-BTree index is approximately 10% to 15% of the insertion time, while the baseline indexing scheme has around 20% to 37% overhead due to the de-normalization step. </span></p><p class="c67"><span class="c0">Query Performance: The next set of experiments study the effect of utilizing the Summary-BTree index to speedup queries involving summary-based predicates (Figures 10, 11, 12, and 13). The results in Figure 10 illustrate the performance gain from the Summary-BTree index using a Select-Project (SP) query, where the selection predicate is in the form of: </span><span class="c12">&quot;r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;ClassBird1&rsquo;). getLabelValue(&lsquo;Disease&rsquo;) = constant&quot;</span><span class="c0">. The query&rsquo;s response time is presented in the y-axis (in Log scale) under three cases: (1) using no indexes, (2) using the Baseline standard B-Tree index, and (3) using the Summary-BTree index. We experimented with different query selectivities, i.e., 0.1%, 1%, and 5%, and the differences were minor in each case. Therefore, in Figure 10 we report the results of only the 1% selectivity (around 450 data tuples). The figure illustrates that the Summary-BTree index has approximately 3x speedup over the baseline index. This is because the latter index involves more levels of indirection, and hence requires more join operations to reach the desired data tuples. As expected both indexes achieve around two orders of magnitude speedup compared to the NoIndex case. </span></p><p class="c194"><span class="c0">The experiment in Figure 11 studies the performance of a Select-Project (SP) query involving two conjunctive pred- icates: (1) A range predicate selecting the tuples having a number of anatomy-related annotations within a given range, i.e., </span><span class="c12">&quot;r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;ClassBird1&rsquo;). getLabelValue(&lsquo;Anatomy&rsquo;) in [x,y]&quot;</span><span class="c0">, and (2) A keyword search predicate over the text summarization instance, i.e., </span><span class="c12">&quot;r.</span><span class="c0">$</span><span class="c12">.getSummaryObject(&lsquo;TextSummary1&rsquo;). containsUnion(kw1, ...)&quot;</span><span class="c0">. When the index scan over ClassBird1 is disabled (the NoIndex case), InsightNotes uses a table scan followed by a summary-based selection operator S to apply both predicates. In contrast, when the index scan is enabled, InsightNotes uses the index to evaluate the range predicate and on top of that a S operator to apply the keyword search predicate. The </span></p><p class="c11 c155"><span class="c0">results illustrate that the Summary-BTree index is around 2x faster than the baseline index. </span></p><p class="c91 c43"><span class="c0">It is worth noting that in the previous experiments, the Base- line indexing scheme is used only to evaluate the selection predi- cates involved in the query. Yet, the for the summary propagation purpose to end-users, InsightNotes still reads the summary objects from its de-normalized storage, i.e., R_SummaryStorage (Refer to Figure 4). And hence, both indexes do not pay the cost of building the summary objects from their primitive components. To confirm that depending only on the Baseline scheme (the normalized stor- age of summary objects) can significantly slowdown the summary propagation, we performed the experiment in Figure 12. In the ex- periment, we used the same query as in Figure 11 and compared between the two indexing schemes. The only difference is that the Baseline scheme in this experiment will not only evaluate the pred- icates, but also form the summary objects for propagation. In this case, the Baseline scheme showed around 7x slower performance compared to the Summary-BTree indexing scheme. </span></p><p class="c43 c91"><span class="c0">In Figure 13, we study the effectiveness of augmenting the Summary-BTree index with backward pointers that point directly to the annotated data tuples instead of the conventional pointers that point to the indexed objects. We use the same SP query used in Figures 10. In the experiments, we consider four cases. The first case is that the index uses the backward pointers, and the annotation summaries are propagated along with the query&rsquo;s re- sult (labeled </span><span class="c12">Backward-Propagation</span><span class="c0">). The second case is that the index uses the backward pointers, and the annotation sum- maries are not propagated along with the query&rsquo;s result (labeled </span><span class="c12">Backward-NoPropagation</span><span class="c0">). The other two cases are the same of the above except that the index uses the conventional point- ers instead of the backward pointers, i.e., the Summary-BTree in- dex pointers will point to the ClassBird1 summary objects. The re- sults in Figure 13 show that propagating the annotation summaries has almost the same cost under both the backward and conventional pointers. The reason is that the join operation between the data ta- ble and its SummaryStorage table has a 1-1 cardinality, and hence the performance is very similar regardless of which table is used as the outer table in the join. In contrast, if the summary propagation is not required, then the backward pointers will save unnecessary join with the SummaryStorage table, which achieves up to 4x speedup in query execution. </span></p><p class="c43 c126"><span class="c0">Effectiveness of Query Optimization and Transformation Rules: In Figures 14 and 15, we study the effect of some of the new transformation rules and query optimizations proposed in Sec- tion 5. The first experiment (Figure 14) measures the performance of the query demonstrated in Example 4 in Section 5. Relations R and S in the rules correspond to the Birds and Synonyms tables, re- spectively. The Synonyms table consists of approximately 225,000 tuples and linked to the Birds table in a many-to-one relationship. </span></p><p class="c71"><span class="c8">58 </span></p><p class="c11 c42"><span class="c36">(a)$Overhead$of$Bulk$Index$Crea1on$$ </span></p><p class="c11 c56"><span class="c29">(b)$Overhead$of$Incremental$Indexing$ </span></p><p class="c11"><span class="c186">0</span><span class="c179">d0 </span></p><p class="c11"><span class="c28">Op#miza#on*Disabled0 </span></p><p class="c11"><span class="c28">Op#miza#on*Enabled0 </span></p><p class="c26"><span class="c69">Number&quot;of&quot;Annota&lt;ons&quot; </span><span class="c0">Figure 15: Optimization Rule {11}. </span></p><p class="c3"><span class="c0">Only the TextSummary1 instance is linked to the Synonyms table, and hence Optimization Rules 2 and 5 can be applied. The exper- iment compares the response time of the default query plan (Fig- ure 5(a)) against that of the optimized query plan (Figure 5(b)). We set the dataset size to 9x10</span><span class="c22">6 </span><span class="c0">annotations, and we consider two cases for each of the join and sort operators as illustrated in the x-axis. The join operator either uses an index-based algorithm with an in- dex on the join column in S (labeled </span><span class="c12">Index</span><span class="c0">), or a block nested- loop join algorithm (labeled </span><span class="c12">NLoop</span><span class="c0">), and the sort operator either uses a memory-based (labeled </span><span class="c12">Mem</span><span class="c0">) or disk-based (labeled </span><span class="c12">Disk</span><span class="c0">) sort algorithms. The figure illustrates the effectiveness of the trans- formation and optimization rules in all of the four cases to speedup the query&rsquo;s response time by a factor of 15x. </span></p><p class="c3"><span class="c0">In Figure 15, we study the effectiveness of Optimization Rule 11, where the order between data- and summary-based join oper- ators can be switched. Relations R and S correspond to the same tables as in the previous experiment, and the summary-based join between them involves a summary-based keyword search on their combined TextSummary1 summary objects&mdash;No summary-based index can be used in this case. Relation T is a replica to rela- tion R, and hence they have a 1-1 relationship through an indexed column for the birds&rsquo; unique identifiers. With no optimizations, the default plan performs the J (R, S) operation first using a block nested-loop join, and then performs the data-based join (&#8883;&#8882;) with T. In contrast, the optimized plan switches the join order to make use of the available index on the birds&rsquo; identifiers in T. Thus, the join operation R &#8883;&#8882; T is performed first using an index-based join, and then the results is summary-based joined (J) with S. The performance results in Figure 15 indicate that the optimized plan achieves around 3.5x speedup compared to the default plan. </span></p><p class="c3"><span class="c0">Usability Case Study: Similar to the motivating example pre- sented in Section 1.1, we performed a usability case study to show direct impact of the newly added features on users&rsquo; experience. We formed a team of 20 students divided into two groups, where one group uses the basic InsightNotes engine while the other group uses the extended system (called InsightNotes+). Each student will an- </span></p><p class="c11"><span class="c30">Query Semantics # Qualifying data tuples </span></p><p class="c26"><span class="c30">InsightNotes Group </span></p><p class="c26"><span class="c30">InsightNotes+ Group </span></p><p class="c11"><span class="c30">Q1: </span><span class="c62">Report the data tuples sorted based on the number of attached disease-related annotations </span></p><p class="c11"><span class="c62">100 Time: 5.2 min </span></p><p class="c11"><span class="c62">Accuracy: 100% </span></p><p class="c11"><span class="c62">Time: 40 sec Accuracy: 100% </span></p><p class="c11"><span class="c30">Q2: </span><span class="c62">Join version 1 of the data (V1) with version (V2) and report the same objects, i.e., V1.ID = V2.ID, having different number of provenance-related annotations </span></p><p class="c11"><span class="c62">5 Time: 8.1 min </span></p><p class="c11"><span class="c62">Accuracy: 100% </span><span class="c145">(Reports 450 Tuples) </span></p><p class="c11"><span class="c62">Time: 54 sec Accuracy: 100% </span></p><p class="c11"><span class="c30">Q3: </span><span class="c62">Select the birds&rsquo; records having more than 3 question-related annotations </span></p><p class="c11"><span class="c62">10 --- </span></p><p class="c11"><span class="c145">(Reports 45K Tuples) </span></p><p class="c11"><span class="c62">Time: 52 sec Accuracy: 100% </span></p><p class="c11"><span class="c0">Figure 16: Usability Case Study. </span></p><p class="c3"><span class="c0">swer each of the three queries highlighted in Figure 16. In the figure, we report the average time taken by each group (including the time of writing the query), and the results&rsquo; accuracy. </span></p><p class="c3"><span class="c0">As the results show, both groups are able to answer Q1 and Q2 queries with 100% accuracy. However, the InsightNotes group took significantly longer time to produce the results&mdash;which may not be acceptable in many applications. The reason is that Insight- Notes cannot fully answer any of these queries, and thus a manual effort is needed to post-process the answer produced from Insight- Notes. For example, in Q1 the students need to manually sort the 100 data tuples based on the number of their disease-related annota- tions (summary-based sorting), while in Q2, they needed to go over the joined tuples (based on the ID data columns)&mdash;which are 450 tuples&mdash;and manually check the second join predicate (based on the number of provenance-related annotations) and report the 5 quali- fying tuples. For Q3, since InsightNotes cannot apply a summary- based selection operation, all the data tuples (45,000) will be re- ported, and it is impractical to manually select the desired tuples from them. On the other hand, the InsightNotes+ group is able to answer the three queries in few seconds. </span></p><p class="c11"><span class="c27">7. RELATED WORK </span></p><p class="c11"><span class="c0">Annotation management has been extensively studied in the con- text of relational DBMSs [4, 9, 14, 15, 21]. Several of these sys- </span></p><p class="c11"><span class="c8">59 </span></p><p class="c11"><span class="c20">100000&quot; </span></p><p class="c11"><span class="c20">10000&quot; </span></p><p class="c11"><span class="c20">1000&quot; </span></p><p class="c11"><span class="c20">100&quot; </span></p><p class="c11"><span class="c50">NoIndex&quot; </span><span class="c151">x&quot; </span></p><p class="c11"><span class="c50">Baseline&quot;Index&quot; </span></p><p class="c11"><span class="c50">Summary2BTree&quot; </span></p><p class="c11"><span class="c20">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c11"><span class="c0">Figure 10: Index vs. No Index (SP Query) </span></p><p class="c11"><span class="c121">250&quot; </span></p><p class="c11"><span class="c35">Backward-Propagation Backward-NoPropagation </span></p><p class="c11"><span class="c121">200&quot; </span></p><p class="c11"><span class="c35">Conventional-Propagation Conventional-NoPropagation </span></p><p class="c11"><span class="c121">150&quot; </span></p><p class="c11"><span class="c121">100&quot; </span></p><p class="c11"><span class="c121">50&quot; </span></p><p class="c11"><span class="c121">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c11"><span class="c0">Figure 13: Effectiveness of Backward Ptrs. </span></p><p class="c11"><span class="c20">10&quot; </span></p><p class="c11"><span class="c20">1&quot; </span></p><p class="c11"><span class="c121">0&quot; </span></p><p class="c11"><span class="c54">(a)$Summary*Based$Selec1on$(Classifier)$ </span></p><p class="c11"><span class="c20">Number&quot;of&quot;Annota&lt;ons&quot; </span></p><p class="c11"><span class="c121">Number&quot;of&quot;Annota&lt;ons&quot; </span></p><p class="c11"><span class="c20">100000&quot; </span></p><p class="c11"><span class="c20">10000&quot; </span></p><p class="c11"><span class="c20">1000&quot; </span></p><p class="c11"><span class="c20">100&quot; </span></p><p class="c11"><span class="c50">NoIndex&quot; </span><span class="c134">x&quot; </span></p><p class="c11"><span class="c50">Baseline&quot;Index&quot; </span></p><p class="c11"><span class="c50">Summary2BTree&quot; </span></p><p class="c11"><span class="c20">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c26"><span class="c20">Number&quot;of&quot;Annota&lt;ons&quot; </span><span class="c0">Figure 11: Two-Predicates SP Query </span></p><p class="c11"><span class="c20">10&quot; </span></p><p class="c11"><span class="c20">1&quot; </span></p><p class="c11"><span class="c16">180&quot; </span></p><p class="c11"><span class="c16">150&quot; </span></p><p class="c11"><span class="c16">120&quot; </span></p><p class="c26"><span class="c20">NLoop2&quot; Mem&quot; </span></p><p class="c11"><span class="c20">Op#miza#on*Disabled0 </span></p><p class="c11"><span class="c20">Op#miza#on*Enabled0 </span></p><p class="c26"><span class="c16">Join/Sort&quot;Opera&lt;on&quot;types&quot; </span><span class="c0">Figure 14: Optimization Rules {2, 5}. </span></p><p class="c11"><span class="c16">90&quot; </span></p><p class="c11"><span class="c16">60&quot; </span></p><p class="c11"><span class="c16">30&quot; </span></p><p class="c11"><span class="c16">0&quot; </span></p><p class="c26"><span class="c20">NLoop2&quot; Disk&quot; </span></p><p class="c26"><span class="c20">Index2&quot; Mem&quot; </span></p><p class="c26"><span class="c20">Index2&quot; Disk&quot; </span></p><p class="c11"><span class="c93">1050&quot; </span></p><p class="c11"><span class="c93">900&quot; </span></p><p class="c11"><span class="c93">750&quot; </span></p><p class="c11"><span class="c93">600&quot; </span></p><p class="c11"><span class="c18">x&quot; </span></p><p class="c11"><span class="c75">Baseline&quot;Normalized&quot;Propaga&lt;on&quot; </span></p><p class="c11"><span class="c93">450&quot; </span></p><p class="c11"><span class="c75">Summary2BTree&quot;De2Normalized&quot;Prop.&quot; </span></p><p class="c11"><span class="c93">300&quot; </span></p><p class="c11"><span class="c93">150&quot; </span></p><p class="c11"><span class="c93">0&quot; </span></p><p class="c11"><span class="c93">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c26"><span class="c93">Number&quot;of&quot;Annota&lt;ons&quot; </span><span class="c0">Figure 12: De-Normalized Propagation. </span></p><p class="c11"><span class="c69">250&quot; </span></p><p class="c11"><span class="c69">200&quot; </span></p><p class="c11"><span class="c69">150&quot; </span></p><p class="c11"><span class="c69">100&quot; </span></p><p class="c11"><span class="c69">50&quot; </span></p><p class="c11"><span class="c69">0&quot; </span></p><p class="c11"><span class="c69">450K&quot; 1.125M&quot; 2.25M&quot; 4.5M&quot; 9M&quot; </span></p><p class="c100"><span class="c0">tems focus on extending the relational algebra and query semantics for propagating the annotations along with the queries&rsquo; answers [4, 9, 14, 21]. The Mondrian system [14] has proposed extensions to treat the annotations as first-class citizens, where users can query and manipulate the annotations through newly defined operators. Other systems address the annotation propagation in the context of containment queries [21], logical views [7], or automated copying to newly inserted data [11, 17]. The systems proposed in [8, 13] support special types of annotations, e.g., treating annotations as data and annotating them [8], and capturing users&rsquo; beliefs as an- notations [13]. All of these systems share a common limitation, which is that they all manipulate the raw annotations. Therefore, they do not provide any support for summarizing, extracting use- ful knowledge, or applying analytics over the raw annotations. The InsightNotes system and its extensions proposed in this paper ad- dress such limitations, and enable end-users to query the annotation summaries in novel ways, which otherwise were not possible. </span></p><p class="c194"><span class="c0">In the domains of e-commerce, social networks, and entertain- ment systems, e.g., [12, 19], the annotations are usually referred to as tags. These systems deploy advanced mining and summa- rization techniques for extracting the best insight possible from the annotations to enhance users&rsquo; experience. They use such extracted knowledge to take actions, e.g., providing recommendations and targeted advertisements. However, unlike relational DBs, the re- trieval mechanisms in these systems are typically straightforward and do not involve complex processing or transformations, i.e., no advanced query processing is required over the annotations sum- maries once created. Therefore, these techniques do not address the complex query processing and optimization challenges preva- lent to scientific relational DBs that are addressed in this paper. </span></p><p class="c34"><span class="c0">Scientific systems and workflows have also leveraged the con- cept of semantic and ontology-based annotations, e.g., [3, 6]. These systems use semantic annotations to either summarize complex workflows [3], or help in building and verifying workflows [6]. These systems are based on process-centric annotations, e.g., an- notations capturing the semantics of each function in a workflow, the structure of their input and output arguments, etc. In contrast, InsightNotes manages data-centric annotations that are indepen- dent from how the data is processed. Nevertheless, the proposed summary-based query operators, access methods, and optimiza- tions are all new and have not beed addressed in current systems. </span></p><p class="c166"><span class="c27">8. CONCLUSION </span></p><p class="c163"><span class="c0">The large volume, increasing complexity, and hidden seman- tics of the emerging annotation repositories in modern applica- tions create unprecedented challenges to annotation management techniques. In this paper, we proposed extensions to the Insight- Notes system for elevating the annotation summaries from being &ldquo;propagate-only&rdquo; objects to be &ldquo;first-class&rdquo; citizens. Hence, it be- comes feasible for applications to express complex queries over both the data and their attached annotation summaries, which oth- erwise is not possible. The key contributions include: (1) Propos- ing manipulation functions and query operators to seamlessly op- erate on the summary objects at query time, (2) Developing spe- cialized summary-based indexing scheme and access methods for efficient predicate evaluation and retrieval of the summary ob- jects, and (3) Introducing an extended query optimizer that enables advanced optimizations for queries involving both the summary- based and the standard query operators. The extensions are imple- mented within the InsightNotes prototype engine, and the results have demonstrated the practicality and efficiency of the proposed extensions and techniques w.r.t both the system&rsquo;s performance, and users&rsquo; experience. </span></p><p class="c3 c43 c183"><span class="c0">As part of future work, we plan to enrich the system with more implementation choices for the summary-based operators, enable multi-level (hierarchical) summarization, and extend the querying mechanisms over the multi-level model. </span></p><p class="c161"><span class="c27">9. REFERENCES </span><span class="c4">[1] eBird Trail Tracker Puts Millions of Eyes on the Sky. </span></p><p class="c147"><span class="c82">https://www.fws.gov/refuges/RefugeUpdate/ MayJune_2011/ebirdtrailtracker.html</span><span class="c45">. [2] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A Framework for </span></p><p class="c24"><span class="c45">Clustering Evolving Data Streams. In VLDB, pages 81&ndash;92, 2003. [3] P. Alper, K. Belhajjame, C. Goble, and P. Karagoz. Small Is </span></p><p class="c137"><span class="c45">Beautiful: Summarizing Scientific Workflows Using Semantic Annotations. In IEEE BigData Congress, pages 318&ndash;325, 2013. [4] D. Bhagwat, L. Chiticariu, and W. Tan. An annotation management </span></p><p class="c138"><span class="c45">system for relational databases. In VLDB, pages 900&ndash;911, 2004. [5] C. Bogdanschi and S. Santini. An annotation database for </span></p><p class="c160"><span class="c45">multimodal scientific data. In Proc. SPIE 7255, Multimedia Content Access: Algorithms and Systems III, pages 307&ndash;314, 2009. [6] S. Bowers and B. Lud&#321;scher. A Calculus for Propagating Semantic Annotations through Scientific Workflow Queries. In In Query Languages and Query Processing (QLQP), 2006. [7] P. Buneman and et. al. On propagation of deletions and annotations </span></p><p class="c105"><span class="c45">through views. In PODS, pages 150&ndash;158, 2002. [8] P. Buneman, E. V. Kostylev, and S. Vansummeren. Annotations are </span></p><p class="c131"><span class="c45">relative. In Proceedings of the 16th International Conference on Database Theory, ICDT &rsquo;13, pages 177&ndash;188, 2013. [9] L. Chiticariu, W.-C. Tan, and G. Vijayvargiya. DBNotes: a post-it </span></p><p class="c89"><span class="c45">system for relational databases based on provenance. In SIGMOD, pages 942&ndash;944, 2005. [10] P. R. Christopher D. Manning and H. Schutze. Book Chapter: Text classification and Naive Bayes, in Introduction to Information Retrieval. In Cambridge University Press, pages 253&ndash;287, 2008. [11] M. Eltabakh, W. Aref, A. Elmagarmid, and M. Ouzzani. Supporting </span></p><p class="c176"><span class="c45">annotations on relations. In EDBT, pages 379&ndash;390, 2009. [12] A. Gattani and et. al. Entity extraction, linking, classification, and </span></p><p class="c49"><span class="c45">tagging for social media: a wikipedia-based approach. Proc. VLDB Endow., 6(11):1126&ndash;1137, 2013. [13] W. Gatterbauer, M. Balazinska, N. Khoussainova, and D. Suciu. </span></p><p class="c164"><span class="c45">Believe it or not: adding belief annotations to databases. Proc. VLDB Endow., 2(1):1&ndash;12, 2009. [14] F. Geerts and et. al. Mondrian: Annotating and querying databases </span></p><p class="c185"><span class="c45">through colors and blocks. In ICDE, pages 82&ndash;93, 2006. [15] F. Geerts and J. Van Den Bussche. Relational completeness of query languages for annotated databases. In Proceedings of the 11th international conference on Database Programming Languages (DBPL), pages 127&ndash;137, 2007. [16] K. Ibrahim, D. Xiao, and M. Eltabakh. InsightNotes+: Advanced </span></p><p class="c86"><span class="c45">Query Processing in Summary-Based Annotation Management. Technical Report WPI-TR-14-05: http://web.cs.wpi.edu/&sim;meltabakh/TR-14-05.pdf. [17] Q. Li, A. Labrinidis, and P. K. Chrysanthis. ViP: A User-Centric View-Based Annotation Framework for Scientific Data. In Proceedings of the 20th international conference on Scientific and Statistical Database Management (SSDBM), pages 295&ndash;312, 2008. [18] A. Nenkova and K. McKeown. A Survey of Text Summarization </span></p><p class="c191"><span class="c45">Techniques. In Book: Mining Text Data, pages 43&ndash;76, 2012. [19] A. Rae, B. Sigurbj&ouml;rnsson, and R. van Zwol. Improving tag recommendation using social networks. In Adaptivity, Personalization and Fusion of Heterogeneous Information, RIAO, pages 92&ndash;99, 2010. [20] M. Stonebraker and et. al. Data Curation at Scale: The Data Tamer </span></p><p class="c106"><span class="c45">System. In CIDR, 2013. [21] W.-C. Tan. Containment of relational queries with annotation </span></p><p class="c157"><span class="c45">propagation. In DBPL, 2003. [22] D. Xiao and M. Y. Eltabakh. InsightNotes: Summary-Based </span></p><p class="c189"><span class="c45">Annotation Management in Relational Databases. In SIGMOD Conference, pages 661&ndash;672, 2014. </span></p><p class="c95"><span class="c8">60 </span></p></body></html>