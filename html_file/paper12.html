<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c38{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c73{margin-left:-26.2pt;padding-top:13.2pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c14{margin-left:-17.1pt;padding-top:1.7pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c66{margin-left:-21.4pt;padding-top:1.7pt;text-indent:35.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:23.7pt}.c28{margin-left:-17.1pt;padding-top:8.6pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c122{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c76{margin-left:-26.2pt;padding-top:4.1pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-28.4pt}.c44{margin-left:-26.2pt;padding-top:3.8pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c30{margin-left:-17.1pt;padding-top:8.6pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c93{margin-left:-26.2pt;padding-top:1.4pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c92{margin-left:-21.4pt;padding-top:1.7pt;text-indent:35.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:21pt}.c57{margin-left:-21.4pt;padding-top:1.4pt;text-indent:35.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.6pt}.c75{margin-left:-26.2pt;padding-top:1.7pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c39{margin-left:-26.2pt;padding-top:11.3pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c68{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c70{margin-left:-26.2pt;padding-top:9.1pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Courier New";font-style:normal}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c72{margin-left:-26.2pt;padding-top:12.7pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c96{margin-left:-17.1pt;padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-26.4pt}.c54{margin-left:-26.2pt;padding-top:1.7pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Arial";font-style:normal}.c21{margin-left:-26.2pt;padding-top:20.9pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c3{margin-left:-26.2pt;padding-top:4.1pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c71{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c11{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11pt}.c22{margin-left:218.2pt;padding-top:78.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c107{margin-left:-12.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c112{margin-left:-26.2pt;padding-top:10.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c63{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.6pt}.c123{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-13.7pt}.c121{margin-left:218.2pt;padding-top:64.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c37{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.5pt}.c113{margin-left:-12.7pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c62{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c59{margin-left:-6.3pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c109{margin-left:-26.2pt;padding-top:20.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c86{margin-left:-15.4pt;padding-top:11.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c100{margin-left:-12.7pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c97{margin-left:54.2pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:55.7pt}.c32{margin-left:-26.2pt;padding-top:15.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:121.8pt}.c119{margin-left:-12.7pt;padding-top:12.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c45{margin-left:-17.1pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-25pt}.c53{margin-left:-3.7pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c79{margin-left:-6.3pt;padding-top:9.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c117{margin-left:-26.2pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c7{margin-left:-3.7pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c40{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.1pt}.c52{margin-left:-3.7pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-24.7pt}.c101{margin-left:-3.7pt;padding-top:10.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c104{margin-left:-26.2pt;padding-top:11.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.5pt}.c80{margin-left:-12.7pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c64{margin-left:-6.3pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-24.7pt}.c56{margin-left:-3.7pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c78{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c51{margin-left:-3.7pt;padding-top:12.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c60{margin-left:156.5pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-96.1pt}.c116{margin-left:-12.7pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.8pt}.c89{margin-left:-26.2pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c99{margin-left:-12.7pt;padding-top:20.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c24{margin-left:-26.2pt;padding-top:12.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.5pt}.c47{margin-left:-6.3pt;padding-top:11.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c88{margin-left:-26.2pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:133.4pt}.c58{margin-left:-3.6pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c35{margin-left:1.8pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.3pt}.c12{margin-left:-3.7pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c120{margin-left:218.2pt;padding-top:77.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c5{margin-left:-17.1pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-24.7pt}.c31{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-15.6pt}.c42{margin-left:-17.1pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:55.4pt}.c103{margin-left:-21.4pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13pt}.c16{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-12.2pt}.c33{margin-left:43.7pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:44.9pt}.c114{margin-left:-21.4pt;padding-top:7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.7pt}.c49{margin-left:-26.2pt;padding-top:20.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:128.3pt}.c105{margin-left:-12.7pt;padding-top:10.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:48.9pt}.c67{margin-left:-3.7pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c25{margin-left:37.7pt;padding-top:227pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:38.9pt}.c87{margin-left:-12.7pt;padding-top:13.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c118{margin-left:-3.7pt;padding-top:7.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.9pt}.c61{margin-left:-6.3pt;padding-top:8.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c102{margin-left:-12.7pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c48{margin-left:-8pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:58.6pt}.c8{margin-left:-12.7pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c34{margin-left:-15.4pt;padding-top:11.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c15{margin-left:105.8pt;padding-top:541pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:4.6pt}.c50{margin-left:-26.2pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-15.9pt}.c83{margin-left:-12.7pt;padding-top:10.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.9pt}.c84{margin-left:20.2pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:21.4pt}.c46{margin-left:218.2pt;padding-top:66.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c82{margin-left:37.7pt;padding-top:152.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:35pt}.c85{margin-left:-3.7pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c41{margin-left:31pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:32.2pt}.c81{padding-top:3.8pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c111{padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c95{padding-top:12pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c106{padding-top:4.1pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c69{padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c55{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c77{padding-top:185.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c108{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c110{margin-left:55pt;margin-right:56.4pt}.c65{margin-left:-17.1pt;margin-right:-25pt}.c94{margin-left:-17.1pt;margin-right:-24.7pt}.c90{margin-left:-3.7pt;margin-right:43.2pt}.c91{margin-left:5.4pt;margin-right:-25pt}.c19{margin-left:-65.1pt;margin-right:177.8pt}.c98{margin-left:-12.6pt;margin-right:15.8pt}.c74{margin-left:23pt;margin-right:102.2pt}.c23{margin-left:-64.2pt;margin-right:178.8pt}.c9{margin-left:31.7pt;margin-right:32.9pt}.c115{margin-left:43.6pt;margin-right:31.7pt}.c36{margin-left:105.8pt;margin-right:4.6pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c108"><p class="c4"><span class="c43">Industrial and Applications Paper </span></p><p class="c26"><span class="c122">DBaaS Cloud Capacity Planning - Accounting for Dynamic RDBMS Systems that Employ Clustering and Standby Architectures </span></p><p class="c4"><span class="c17">Antony S. Higginson </span><span class="c27">Oracle Advanced Customer Support Services </span><span class="c29">antony.higginson@oracle.com </span></p><p class="c4"><span class="c27">Didsbury, Manchester, UK </span><span class="c17">Norman W. Paton </span><span class="c27">School of Computer Science University Of Manchester </span><span class="c29">norman.paton@manchester.ac.uk </span><span class="c27">Manchester, M13 9PL, UK. </span><span class="c17">Suzanne M. Embury </span><span class="c27">School of Computer Science University Of Manchester </span><span class="c29">suzanne.m.embury@manchester.ac.uk </span></p><p class="c4"><span class="c27">Manchester, M13 9PL, UK. </span><span class="c17">Clive Bostock </span><span class="c27">Oracle Advanced Customer Support Services </span><span class="c29">clive.bostock@oracle.com </span><span class="c27">Didsbury, Manchester, UK </span><span class="c17">ABSTRACT </span><span class="c2">There are several major attractions that Cloud Computing promises when dealing with computing environments, such as the ease with which databases can be provisioned, main- tained and accounted for seamlessly. However, this efficiency panacea that company executives look for when managing their estates often brings further challenges. Databases are an integral part of any organisation and can be a source of bottlenecks when it comes to provisioning, managing and maintenance. Cloud computing certainly can address some of these concerns when Database-as-a-Service (DBaaS) is employed. However, one major aspect prior to adopting DBaaS is Capacity Planning, with the aim of avoiding under- estimation or over-estimation of the new resources required from the cloud architecture, with the aim of consolidating databases together or provisioning new databases into the new architecture that DBaaS clouds will provide. Capac- ity Planning has not evolved sufficiently to accommodate complex database systems that employ advanced features such as Clustered or Standby Databases that are required to satisfy enterprise SLAs. Being able to efficiently capacity plan an estate of databases accurately will allow executives to expedite cloud adoption quickly, allowing the enterprise to enjoy the benefits that cloud adoption brings. This pa- per investigates the extent to which the physical properties resulting from a workload, in terms of CPU, IO and mem- ory, are preserved when the workload is run on different platforms. Experiments are reported that represent OLTP, OLAP and Data Mart workloads running on a range of ar- chitectures, specifically single instance, single instance with a standby, and clustered databases. </span></p><p class="c6"><span class="c71">c 2017, Copyright is with the authors. Published in Proc. 20th Inter- national Conference on Extending Database Technology (EDBT), March 21-24, 2017 - Venice, Italy: ISBN 978-3-89318-073-8, on OpenProceed- ings.org. Distribution of this paper is permitted under the terms of the Cre- ative Commons license CC-by-nc-nd 4.0 </span></p><p class="c4"><span class="c2">This paper proposes and empirically evaluates an approach to capacity planing for complex database deployments. </span></p><p class="c4"><span class="c17">Keywords </span><span class="c2">Cloud, DBaaS, Capacity Planning, Database, Provisioning, Standby, Clustering </span></p><p class="c4"><span class="c17">1. INTRODUCTION </span></p><p class="c6"><span class="c2">Traditionally, companies accounted for the cost of assets associated with their I.T. using Capex (Capital Expendi- ture) type models, where assets such as hardware, licenses and support, etc, were accounted for yearly. For example, a software license usually is based on an on-premises model that would be user based, or by the CPU if the application served many thousands of users. The advent of Cloud com- puting, with the pay-as-you-go subscription based model, has changed the way company executives look at the cost- ing models of their I.T. </span></p><p class="c6"><span class="c2">A similar paradigm unfolds when I.T. departments such as Development, Delivery and Support teams need to pro- vision environments quickly to meet their business goals. Traditional project methodologies would request environ- ments aiding development and testing with the goal of going live. Procurement and provisioning took time that was often added to the project lifecycle. Cloud computing addresses such issues so that a user can, with ease, request the rapid provision of resources for a period of time. </span></p><p class="c6"><span class="c2">Once the system went live those Delivery and Support teams would then need to account for resources those partic- ular systems consumed, reconciling with the Line Of Busi- ness (LOB). The results of that analysis would then feed back into next year&rsquo;s Capex model. This ongoing capacity planning to assess if they have enough resources is needed to ensure is that, as systems grow, there are enough resources to ensure that the system is able to meet QoS (Quality of Service) expectations. Cloud Computing has also made some advances here by enabling a metering or charge-back facility that can accurately account for the resources used (CPU, Memory, Storage). Cloud Computing can dynami- cally modify the cloud to reduce or increase those resources </span></p><p class="c4"><span class="c20">Series ISSN: 2367-2005 687 </span><span class="c68">10.5441/002/edbt.2017.89 </span></p><p class="c25"><span class="c2">Figure 1: Example Architecture: Typical customer legacy database architecture. </span></p><p class="c49"><span class="c2">as needed by the client. </span></p><p class="c75"><span class="c2">However, companies with large estates have the additional challenge of having a plethora of database versions, for ex- ample, each database version offering a different feature that has a performance benefit over another database version. Similarly, the databases may be running on a eclectic set of operating systems and hardware, each affecting the work- load in a subtle or major way. For example, the latest run- ning version of a database may run on a highly configured SAN utilising the latest techniques in query optimization and storage. Comparing this footprint with an older version of software and infrastructure often leads to a Finger-in-the- air type approach. </span></p><p class="c75"><span class="c2">A key feature of DBaaS is the ability to multi-tenant those databases where different workloads and database con- figurations can coexist in the shared resources, adding to the challenge of making effective capacity planning deci- sions. Determining the allocation is further complicated if the database utilises advanced features such as Clustering or Failover Technology, as workloads shift from one instance to another or are shared across multiple instances based on their own resource allocation managers. Furthermore, if a database employs a standby, this further complicates capac- ity planning decisions. </span></p><p class="c93"><span class="c2">Cloud Computing is in its infancy, with incremental adop- tion within the industry as companies try and determine how to unpick their database estates and move them to cloud in- frastructure. Databases often grow organically over many years in terms of their data and complexity, which often leads to major projects being derived when a major upgrade or re-platform exercise is required. With the introduction of cloud these exercises are becoming more prudent. This often leads to a series of questions on Capacity Planning. </span></p><p class="c100"><span class="c1">&bull; </span><span class="c2">What is the current footprint of the database including any advanced features such as Standby or Clustering? </span></p><p class="c83"><span class="c1">&bull; </span><span class="c2">What is the current configuration of the database? </span></p><p class="c105"><span class="c1">&bull; </span><span class="c2">What type of DBaaS should I create? </span></p><p class="c4 c90"><span class="c1">&bull; </span><span class="c2">What size of DBaaS should I create? </span></p><p class="c67"><span class="c1">&bull; </span><span class="c2">Can I consolidate databases that have similar configu- ration and utilisation foot-prints? </span></p><p class="c118"><span class="c1">&bull; </span><span class="c2">Will my SLAs be compromised if I move to a cloud? </span></p><p class="c30"><span class="c2">Such questions become very important prior to any pro- visioning or migration exercise. </span></p><p class="c65 c111"><span class="c2">The time taken to perform this analysis on databases also has a major impact on a company&rsquo;s ability to adopt cloud technologies often squeezing the bandwidth of the delivery and support teams. The departments suffer paralysis-by- analysis, and the migration to the cloud becomes more pro- tracted to the frustration of all involved. If the analysis is not performed accurately then the risks of over-estimation and under-estimation increase. Being able to automate the gathering of data, analysing the data and then making a decision becomes ever more important in enterprises with large estates. </span></p><p class="c14"><span class="c2">In this paper we look at the challenges of Capacity Plan- ning for advanced database systems that employ cluster- ing and standby databases, with a view to migration to a cloud. Our hypothesis is: &ldquo;That a model based on physical measures can be used to provide dependable predictions of performance for diverse applications&rdquo;. We make two main contributions: </span></p><p class="c61"><span class="c2">1. We propose an approach to workload analysis based on physical metrics that are important to capacity plan- ning for database systems with advanced configura- tions. </span></p><p class="c59"><span class="c2">2. We report the results of an empirical analysis of the metrics for several representative workloads on diverse real-life configurations. </span></p><p class="c28"><span class="c2">The remainder of the paper is organised as follows. Sec- tion 2 introduces the Background and Related Work. In Section 3 we detail the environmental setup for conducting experiments outlining the database capacity planning prob- lem. In Section 4 we introduce our solution in detail and </span></p><p class="c46"><span class="c20">688 </span></p><p class="c89"><span class="c2">provide details on the experiments and analysis. Section 5 gives conclusions and future work. </span></p><p class="c104"><span class="c17">2. BACKGROUND AND RELATED WORK </span></p><p class="c88"><span class="c17">2.1 Background </span></p><p class="c44"><span class="c2">Fig 1 shows an example environment of a company that is running different versions and configurations of databases on VM hardware. Physical machines are dissected into 10 VM&rsquo;s giving a level of separation. On these 10 VM&rsquo;s a total of 12 databases are run, of which 6 are primary databases and 6 are standby databases. This MAA (Maximum Avail- ability Architecture) allows the company some comfort by running their primary (Platinum) SLA level applications on VM numbers 3, 4, 5 and 6, which host two clustered databases (offering a degree of resilience against node fail- ure). In addition, these clustered databases have a physi- cal standby database running on VM&rsquo;s 9 and 10 in case of database failure or corruption. Similarly, the 4 single in- stance stand alone databases that are running on VM&rsquo;s 1 and 2 also have a replicated standby database running on VM&rsquo;s 7 and 8, again offering the company some comfort that their secondary (Gold) level of applications will have a standby database for failover, should they need it. </span></p><p class="c54"><span class="c2">The company also wish to increase their ROI (Return on Investment) with this environment and thus often open up the standby databases in &ldquo;Read Only&rdquo; mode during special times for applications that need to run year-end or month- end type BI (Business Intelligent) reports. This particular type of architectural pattern is a typical configuration com- panies use today to manage their database environments and applications that have 24*7 type SLAs. The difficulty be- comes apparent when a new exercise is introduced that looks at consolidating, upgrading and migrating those environ- ments listed in Fig 1 to a new cloud architecture, where re- sources can be tightly accounted and dynamically assigned. We are then faced with a capacity planning exercise. </span><span class="c17">2.2 Related Work </span></p><p class="c3"><span class="c2">The objective of capacity planning is to provide an ac- curate estimate of the resources required to run a set of applications in a database cloud. Achieving this answer re- lies on the accurate capture of some base metrics, based on historical patterns, and applying some modelling techniques to form a prediction. There are two main viewpoints: the viewpoint of the CSP (Cloud Service Provider) in what they offer and their capabilities, i.e are there enough resources to provide services to consumers; and the viewpoint of the con- sumer, for example, can a customer capacity plan their sys- tems against the CSP&rsquo;s capability? Indeed if the customer wishes to become a CSP but in a private cloud configuration, then the first viewpoint also becomes important. </span></p><p class="c93"><span class="c2">A CSP offers resources, and existing models use various techniques to help customers assess the CSP capabilities. MCDM (Multi Criteria Decision Making) weighs the at- tributes of an individual database by their importance in helping to choose the right cloud (Mozafari et al 2013 [16] and Shari et al 2014 [19]. CSP&rsquo;s can also be assessed us- ing a pricing model to validate their capability based on a consumers single systems workload as suggested by (Shang et al [20]); using this financial approach contributes to the value-for-money question that many enterprises seek when deciding on the right cloud. </span></p><p class="c55 c65"><span class="c2">If a consumer has a cloud, knowing where to place the workload based on utilisation to achieve the best fit is criti- cal when beginning to answer the QoS (Quality of Service) question, and techniques such as bin-packing algorithms (Yu et al [21]) help achieve this answer. However systems may have dynamic workloads, which may evolve organically as datasets and/or numbers of users grow or shrink, as is espe- cially common in internet based systems. There is a need for constant assessment of said workloads. Hacigumns et al [10] and Kouki et al [11] both look at the workload of an applica- tion or the query being executed, and then decide what type of database in a cloud would satisfy QoS. Mozafari et al [15] suggests using techniques that capture log and performance data over a period of time, storing them in a central repos- itory, and modelling the workloads at a database instance level. With the advent of Virtualisation that enterprises utilise, including CSP&rsquo;s, when running their estates, several techniques such as coefficient of variation and distribution profiling are used to look at the utilisation of a Virtual Ma- chine to try and capacity plan. Mahambre and Chafle [13] look at the workload of a Virtual Machine to create relation- ship patterns of workloads to understand how resources are being utilised, analysing the actual query being executed to predict if and when it is likely to exhaust resources available. There seems to be a consensus among several academics (Shang et al [20], Loboz [12] and Guidolin et al 2008 [9]) on the need for long term capacity planning and the inadequacy of capacity planning in this new age of cloud computing us- ing current techniques. The techniques used today assume that the architecture is simple, in that the architecture does not utilise virtualisation or advanced database features such as standby&rsquo;s and clustering technology, but in the age of con- solidation and drive for standardisation, the architecture is not simple. Enterprises use combinations of technology in different configurations to achieve their goals of consolida- tion or standardisation. Most models use a form of linear regression to predict growth patterns. Guidolin et al 2008 [9] conducted a study of those linear regression models and came to the conclusion that as more parameters are added the models become less accurate, something also highlighted by Mozafari et al 2013 [15]. To mitigate against this inac- curacy more controls are added at the cost of performance of the model itself. For example, predicting the growth of several databases based on resource utilisation may become more inaccurate as the number of source systems being anal- ysed increases, therefore requiring more controls to keep the accuracy. This is certainly interesting when trying to ca- pacity plan several applications running on different config- urations prior to a migration to a cloud. In addition, trying to simulate cloud computing workloads to develop new tech- niques is also an issue; Moussa and Badir 2013 [14] explained that the TPC-H [4] and TPC-DS [3] benchmarks are not de- signed for Data Warehouses in the cloud, further adding to the problem of developing and evaluating models. </span></p><p class="c42"><span class="c17">3. EXPERIMENTAL SETUP </span></p><p class="c65 c106"><span class="c2">Given a description of an existing deployment, including the Operating System, Database and Applications running on that database (Activity), a collection of monitors on the existing deployment that report on CPU, Memory, IOPS&rsquo;s and Storage, the goal is to develop models of the existing configuration that contain enough information to allow reli- able estimates to be made of the performance of a deploy- </span></p><p class="c46"><span class="c20">689 </span></p><p class="c4"><span class="c0">Duration Workload </span></p><p class="c4"><span class="c0">Workload Profile DBNAME(S) Workload Description Number of Type </span></p><p class="c4"><span class="c0">Users </span></p><p class="c4"><span class="c0">(hh:mi) </span></p><p class="c55"><span class="c0">Avg Transac- tion per sec OLTP General usage RAPIDKIT </span></p><p class="c4"><span class="c0">RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">General Online Application with updates, inserts and deletes simulate working day </span></p><p class="c4"><span class="c0">100 2000 (DBM01) </span></p><p class="c4"><span class="c0">23:59 0.2 </span></p><p class="c4"><span class="c0">OLTP Morning Peak </span></p><p class="c4"><span class="c0">Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Morning Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 1000 (DBM01) </span></p><p class="c4"><span class="c0">2:00 0.2 </span></p><p class="c6"><span class="c0">OLTP Lunch Time Peak Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Lunch Time Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 1000 (DBM01) </span></p><p class="c4"><span class="c0">1:00 0.2 </span></p><p class="c6"><span class="c0">OLTP Evening Time Peak Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Evening Time Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 1000 (DBM01) </span></p><p class="c4"><span class="c0">5:00 0.2 </span></p><p class="c4"><span class="c0">Daily OLTP Hot Backup taken at 23:00 OLAP Data Warehouse </span></p><p class="c4"><span class="c0">General Usage </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c6"><span class="c0">General Data Warehousing Application with heavy Se- lects taking place out of hours building Business Intel- ligence data </span></p><p class="c4"><span class="c0">5</span><span class="c13">400 (DBM01) </span></p><p class="c4"><span class="c0">8:00 0.4 </span></p><p class="c55"><span class="c0">Daily OLAP Hot Backup taken at 06:00 Daily OLAP archivelog backups taken at 12:00,18:00,00:00 DM OLTP General </span></p><p class="c4"><span class="c0">Usage </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Combination of DML taking place during the business day and heavy DML taking out of ours </span></p><p class="c4"><span class="c0">200 1000 (DBM01) </span></p><p class="c4"><span class="c0">23:59 0.2 </span></p><p class="c6"><span class="c0">DM OLTP Morning Peak Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Morning Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 500 (DBM01) </span></p><p class="c4"><span class="c0">2:00 0.2 </span></p><p class="c6"><span class="c0">DM OLTP Lunch Time Peak Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Morning Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 500 (DBM01) </span></p><p class="c4"><span class="c0">2:00 0.3 </span></p><p class="c6"><span class="c0">DM OLTP Evening Time Peak Logon Surge </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Evening Time Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">100 500 (DBM01) </span></p><p class="c4"><span class="c0">5:00 0.3 </span></p><p class="c4"><span class="c0">DM OLAP Batch </span></p><p class="c4"><span class="c0">Loads Peak </span></p><p class="c4"><span class="c0">RAPIDKIT RAPIDKIT2 DBM01 </span></p><p class="c4"><span class="c0">Evening Time Surge to simulate users logging on to the Online Application with updates, inserts and deletes </span></p><p class="c4"><span class="c0">5</span><span class="c13">400 (DBM01) </span></p><p class="c4"><span class="c0">8:00 0.3 </span></p><p class="c26"><span class="c0">Daily DM Hot Backup taken at 06:00 Daily DM archivelog backups taken at 12:00,18:00,00:00 </span></p><p class="c4"><span class="c2">Table 1: Database Workloads </span></p><p class="c4"><span class="c2">ment when it is migrated to a cloud platform that may in- volve a Single Database, a Clustered Database or Standby Databases. To meet this objective, we must find out if a workload executed on one database is comparable to the same workload running on the same database on a different host.</span><span class="c18">Our approach to this question is by way of empirical eval- </span><span class="c2">uation. Using increasingly complex deployments, of the type illustrated in Fig 2, and representative workloads, we estab- lish the extent to which we can predict the load on a target deployment based on readings on a source deployment. This section describes the workloads and the platforms used in the experiments. </span><span class="c17">3.1 Workloads </span></p><p class="c6"><span class="c2">A Workload can be described as the activity being per- formed on the database at a point-in-time, and essentially is broken down into the following areas: </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">Database - An Oracle database is a set of physical files on disk(s) that store data. Data may be in the form of logical objects, such as tables, Views and indexes, which are attached to those tables to aid speed of ac- cess, reducing the resources consumed in accessing the data. </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">Instance - An Oracle instance is a set memory struc- tures and processes that manage the database files. The instance exists in memory and a database exists on disk, an instance can exist without a database and a database can exist without an instance. </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">Activity - The DML (Data Modification Language)/DDL (Data Definition Language) i.e. SQL that is being exe- cuted on the database by the application, creates load consisting of CPU, memory and IOPS/s. </span></p><p class="c4"><span class="c2">. </span></p><p class="c4"><span class="c2">The monitors used to capture the data report on IOPS&rsquo;s (Physical reads and Physical Writes), Memory (RAM as- signed to a database or host) and CPU (SPECINT&rsquo;s). SPECInt is a benchmark based on the CINT92, which measures the integer speed performance of the CPU, (Dixit) [6]. The ex- periments involve controlled execution of several types of workloads on several configurations of database. Moussa and Badir 2013 [14] describe how running of controlled work- loads using TPC has not evolved for clouds, therefore we will use a utility called swingbench (Giles)[8] to generate a con- trolled load based on TPC-C [5]. The workload is generated on several Gb&rsquo;s of sample data based on the Orders Entry (OE) schema that comes with Oracle 12C. The OE schema is useful for dealing with intermediate complexity and is based on a company that sells several products such as software, hardware, clothing and tools. Scripts are then executed to generate a load against the OE schema to simulate DML transactions performed on the database of a number of users over a period of Hour. </span><span class="c17">3.2 Outline of the Platforms </span></p><p class="c6"><span class="c2">Three different types of workload were created (OLTP, OLAP and Data Mart) as shown in Table 1. The Database is placed in archivelog mode during each execution of the workload further creating IO on the Host and allowing for a hot backup to be performed on the database. The backup acts as a &rsquo;houskeeping&rsquo; routine by clearing down the archivel- ogs to ensure the host does not run out of storage space. This type of backup routine is normal when dealing with databases and each backup routine is executed periodically depending upon the workload. </span></p><p class="c4"><span class="c17">4. EXPERIMENTS AND ANALYSIS </span></p><p class="c6"><span class="c2">A number of experiments were conducted to investigate if a workload executed on one machine consumes similar resources when the workload is executed on another envi- ronment. The aim was to investigate what could cause dif- </span></p><p class="c4"><span class="c20">690 </span></p><p class="c4"><span class="c2">(c) Two Node Clustered Database </span></p><p class="c4"><span class="c2">Figure 2: Experiment Architecture: different database combinations used for experiments. </span></p><p class="c6"><span class="c2">ferences in the consumption of resources between workloads. The experiment focused on three types of database configu- ration: </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">Experiment 1 - Running three workloads (OLTP,OLAP and DM) on a single instance database. </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">Experiment 2 - Running the workloads (OLTP,OLAP and DM) on a single instance database with a Physical Standby Database. </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">Experiment 3 - Running the three workloads (OLTP,OLAP and DM) on a two node clustered database. </span></p><p class="c6"><span class="c2">The database was always the same version between each host, the data set was always the same size to start, the workload was always repeatable in that the workload could be executed, stopped, the database reset and the same work- load replayed. </span></p><p class="c4"><span class="c17">4.1 Experimental Methodology </span></p><p class="c6"><span class="c2">The experiments involve an eclectic set of hardware con- figured to run several different types of database as shown in Table 2. An agent polls the database instance every few min- utes for specific metrics namely; Database Instance Memory, IOPS&rsquo;s (physical Reads/Writes) and CPU per sec. The met- ric results are stored in a central repository database, and are aggregated at hourly intervals. The configuration of the hardware, such as CPU Make model and SPECInt, and the database configuration are also stored in a central reposi- tory, which is then used as lookup data when performing comparisons between the performance of one workload on one database with the same workload on another database. </span></p><p class="c26"><span class="c17">4.2 Experiment One - Single Database Instance </span><span class="c2">The first experiment was to execute three workloads on one single instance database on a virtual host (VM1) and </span></p><p class="c4"><span class="c20">691 </span></p><p class="c4"><span class="c0">Memory VM Name OS Type CPU De- </span></p><p class="c4"><span class="c0">Storage Database Type Products and Versions tails </span></p><p class="c4"><span class="c0">Single Database Instance Configuration Virtual Machine 1 OEL Linux </span></p><p class="c4"><span class="c0">2.6.39 </span></p><p class="c6"><span class="c0">4 * 2.9 Ghz 32Gb 300Gb Oracle Single In- stance Database (RapidKit) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Data Guard (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4), </span></p><p class="c4"><span class="c0">Virtual Machine 2 OEL Linux </span></p><p class="c4"><span class="c0">2.6.39 </span></p><p class="c6"><span class="c0">4 * 2.9 Ghz 32Gb 300Gb Oracle Single In- stance Database (RapidKit2) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Data Guard (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4), </span></p><p class="c4"><span class="c0">Clustered Database Instance Configuration Clustered Com- pute Node 1 </span></p><p class="c4"><span class="c0">OEL Linux </span></p><p class="c26"><span class="c0">24 * 2.9 96Gb 2.6.39 </span></p><p class="c4"><span class="c0">Ghz </span></p><p class="c4"><span class="c0">14Tb Oracle Clustered </span></p><p class="c4"><span class="c0">Multi-tenant Database Instance (DBM011) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Data Guard (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4, </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Grid Infrastructure (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Oracle Automatic Storage Manager (12.1.0.2), </span></p><p class="c4"><span class="c0">Clustered Com- pute Node 2 </span></p><p class="c4"><span class="c0">OEL Linux </span></p><p class="c26"><span class="c0">24 * 2.9 96Gb 2.6.39 </span></p><p class="c4"><span class="c0">Ghz </span></p><p class="c4"><span class="c0">14Tb Oracle Clustered </span></p><p class="c4"><span class="c0">Multi-tenant Database Instance (DBM012) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Data Guard (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4, </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Grid Infrastructure (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Oracle Automatic Storage Manager (12.1.0.2), </span></p><p class="c4"><span class="c0">Standby Database Instance Configuration Virtual Machine 3 OEL Linux </span></p><p class="c4"><span class="c0">2.6.39 </span></p><p class="c4"><span class="c0">4 * 2.9 Ghz 32Gb 1Tb Oracle Sin- gle Instance Standby Database (STBYRapidKit, STBYRapidKit2) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Data Guard (12.1.0.2), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4), </span></p><p class="c4"><span class="c0">Central Repository Details Storage Repository OEL Linux </span></p><p class="c4"><span class="c0">2.6.39 </span></p><p class="c4"><span class="c0">24 * 2.4 </span></p><p class="c4"><span class="c0">32Gb 500Gb Oracle Single In- Ghz </span></p><p class="c4"><span class="c0">stance Database (EMREPCTA) </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Edition (11.2.0.3), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager R4 including Webserver and BIPublisher (12.1.0.4), </span></p><p class="c4"><span class="c10">&bull; </span><span class="c0">Enterprise Manager Agent (12.1.0.4), </span></p><p class="c4"><span class="c2">Table 2: Platform Outline </span></p><p class="c4"><span class="c2">(a) Single Instance </span></p><p class="c4"><span class="c2">(b) Single Instances with Standby Databases </span></p><p class="c117"><span class="c2">then execute the same three workloads on another single in- stance database on another virtual host (VM2) as shown in Fig 2a. The database configurations were the same in In- stance Parameters, Software Version and Patch Level. The Hardware configurations were the same in OS Level, Kernel Version, and memory configuration. Some differences exist in the underlying architecture such as the Physical hardware and the Storage as these where VM&rsquo;s created on different physical machines. We capture the metrics for each work- load and analyse the extent to which physical properties are consistent across platforms. This is shown graphically in Fig 3</span><span class="c29">4.3 Results and Analysis Experiment One - OLTP Workload </span></p><p class="c3"><span class="c2">The results for OLTP, covering Memory, CPU and IOPS/s are shown graphically in Fig 3. These are simple line graphs from the OLTP workload shown in Table 1. It was observed that the OLTP workload from a CPU perspective had sev- eral distinguishing features. It clearly shows that the work- load starts off low until the beginning of the experiment where a sudden jump takes place and the OLTP workload begins. Then there is a general plateau that relates to the 24 hour periods and at various times from there on in there are spikes. </span></p><p class="c113"><span class="c1">&bull; </span><span class="c2">CPU utilisation - CPU over a 72 hour period was not the same between the two databases but at it largest peak (evening surge) there was a difference of approxi- mately 300 SPECInts or +88% (day 24 hour 11) in its utilisation. The difference in utilization between the two workloads without the peaks was approximately +20%. </span></p><p class="c102"><span class="c1">&bull; </span><span class="c2">CPU Spikes (Backup) - There were several spikes in CPU at 00:00 - 02:00 and relate to the daily hot RMAN backup that is taken for the databases. </span></p><p class="c102"><span class="c1">&bull; </span><span class="c2">CPU Spikes (Morning Surge) - A large CPU spike was observed for several hundred users accessing the database at 08:00. </span></p><p class="c102"><span class="c1">&bull; </span><span class="c2">IOPS/s (general) - There is a large difference in IOPS (day 23 hour 9) where the difference at peak is +88%. The difference in general usage (i.e. without the peaks) was +7%. </span></p><p class="c70"><span class="c2">CPU, Memory and IOPS/s over a 72 hour period show similar traits in that the workload begins and there is a jump in the activity as the users logon. The first set of results show that even when executed on similar platforms, the metrics for the OLTP workloads can be substantially different, especially in the CPU and IOPS utilisation. </span><span class="c17">4.4 Results and Analysis Experiment One - </span><span class="c29">OLAP Workload </span></p><p class="c3"><span class="c2">The results for OLAP covering Memory, CPU and IOPS/s are shown graphically in Fig 4. The difference between the OLTP and OLAP workload is that the OLAP workload is high in Select statements and the result set is larger. The IO is representative of a Data Warehouse building cubes for interrogation by a Business Intelligence reporting tool. The execution times for the workload are also different; OLTP is fairly constant in its usage, whereas OLAP is more concen- trated out of normal working hours. It was observed that </span></p><p class="c5"><span class="c2">the OLAP workload runs out of hours for a period of around five hours and this matches the description shown in Table 1. </span></p><p class="c56"><span class="c1">&bull; </span><span class="c2">CPU Spikes (General Usage) - CPU over a 72 hour period was not the same for the two databases, but at it largest peak there was a difference of only +1% (day 17 hour 05) in utilisation. Two workloads outside the peaks were essentially the same. </span></p><p class="c52"><span class="c1">&bull; </span><span class="c2">IOPS/s utilisation - IOPS over a 72 hour period had a difference of approximately +50% in utilisation (Day 16 Hour 8); outside the peaks (Day 16 Hour 19) the utilisation is 0%. </span></p><p class="c101"><span class="c1">&bull; </span><span class="c2">IOPS/s Spikes (Backup) - There are four backups that run during the 24 hours. Three of those backups are used as housekeeping routines that backup and delete the archivelogs; these backups are executed at 12:00, 18:00 and 00:00. One backup backs up the database (level-0) and the associated archivelogs, and this is ex- ecuted at 06:00. There was no spike for 18:00 because the backup at 12:00 had removed the archivelogs and thus there was nothing to backup. </span></p><p class="c65 c95"><span class="c2">The OLAP Memory chart also showed the same charac- teristics as the IOPS/s and CPU charts in that there is a uniform pattern to there being a plateau and a spike over the 72 hours. Each of the databases had a memory con- figuration of 3.5Gb, given the OLAP workload would have had SQL requiring larger memory than 3.5Gb for sorting, thus sorts would have gone to disk rather than memory, ac- counting for the higher IOPS&rsquo;s readings in Fig 4 than in Fig 3.</span><span class="c29">4.5 Results and Analysis Experiment One - DataMart Workload </span></p><p class="c65 c81"><span class="c2">The results for the Data Mart covering Memory, CPU and IOPS/s are shown in Fig 5. It was observed that the Data Mart workload from a CPU perspective had several distinguishing features. It clearly shows that the workload starts off as the users connect and the workload is running, a sudden jump takes place at Day 10 Hour 3 as the Batch Loads are executed for approximately 6 hours, and this is repeated twice more throughout the 72 hours. There are also other peaks and troughs observed and these are consistent with the workload described in Table 1. </span></p><p class="c56"><span class="c1">&bull; </span><span class="c2">CPU utilisation - CPU over a 72 hour period between the two databases and had a difference of approxi- mately +64% during the normal day (Day 9 Hour 21). When the batch loads ran (Day 11 Hour 05) the dif- ference in utilisation was +1%. </span></p><p class="c52"><span class="c1">&bull; </span><span class="c2">CPU Spikes (General) - generally, the CPU utilisation between the two databases was the same, there is a difference of +1% at peak times. </span></p><p class="c7"><span class="c1">&bull; </span><span class="c2">IOPS/s Utilisation - IOPS at peak (Day 9 Hour 21) had a difference of approximately +24% </span></p><p class="c12"><span class="c1">&bull; </span><span class="c2">Memory utilisation - Memory was the same in general footprint however there were differences at peaks times of 300mb or +4% </span></p><p class="c46"><span class="c20">692 </span></p><p class="c15"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c4 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c4 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c84"><span class="c2">Figure 5: Results Single Instance Data Mart: workload patterns for the 72 hour period. </span></p><p class="c21"><span class="c2">In general there is a difference in the VM&rsquo;s at a CPU level. The VM named acs-163 has a configuration of 16 Threads(s) per core (based on the lscpu command) from the VM infra- 69 which only has 1 thread per core. We believe this ac- counts for the difference in CPU for small concurrent trans- actions in the OLTP workload. Each of the databases had a memory (SGA) configuration of 3.5Gb, if the SQL state- </span></p><p class="c6 c65"><span class="c2">ment executed in the workload requires a memory larger than 3.5Gb, which is more common in OLAP and Data Mart workloads then sorts will go to disk. Database memory con- figurations influence the database execution plans and opti- misers and this sensitivity is reflected in the IOPS&rsquo;s charts shown in Fig&rsquo;s 3b, 4b and 5b. </span></p><p class="c120"><span class="c20">693 </span></p><p class="c4 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c77 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c4 c36"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c36"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c4 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c77 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c4 c23"><span class="c2">(b) IOPS&rsquo;s 72 Hours </span></p><p class="c41"><span class="c2">Figure 4: Results Single Instance OLAP: workload patterns for the 72 hour period. </span></p><p class="c4 c9"><span class="c2">Figure 3: Results Single Instance OLTP: workload patterns for the 72 hour period. </span></p><p class="c4"><span class="c2">(a) (a) Host Total IO&rsquo;s Made 72 hours </span></p><p class="c4"><span class="c2">Host CPU Load Avg (15Mins) 72 hours </span></p><p class="c4"><span class="c2">(b) Host CPU Utilisation 72 Hours </span></p><p class="c4"><span class="c2">Figure 6: Results HOST Metrics OLTP: workload patterns for the 72 hour period. </span></p><p class="c4"><span class="c17">4.6 Experiment </span><span class="c29">Configurations </span></p><p class="c4"><span class="c17">Two - Single Instance Standby </span><span class="c2">The Second set of experiments was to introduce a more complicated environment executing one workload (OLTP) on a single instance primary database with a physical standby database kept in sync using the Data Guard technology (Or- acle Data Guard [18]) across the two sites, as shown in Fig 2b. A key factor in this experiment is that the physical standby database is always in a recovering state and there- fore is not opened to accept SQL connections in the same way as a normal (primary) database. Therefore the agent is unable to gather the instance based metrics, so we capture host based metrics to compare and contrast the workload: </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">CPU load over 15mins - This is the output from the &ldquo;Top&rdquo; command executed in linux, this measurement is a number using or waiting for CPU resources. For example if there is a 1, then on average 1 process over the 15 min time period is using or waiting for CPU. </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">CPU Utilisation Percentage - This is based on the &ldquo;MPSTAT -P ALL&rdquo; command and looks at the per- centage of all cpu&rsquo;s being used . </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">TotalIOSMade - This is the total physical reads and total physical writes per 15 minute interval on the host. </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">MaxIOSperSec - This is the Maximum physical reads and physical writes per sec. </span></p><p class="c4"><span class="c2">The two VM&rsquo;s are located within the same site but in different rooms, Data Guard is configured using Maximum Performance mode to allow for network drops in the con- nectivity between the two physical locations. The database configurations were the same in Instance Parameters, Soft- ware Version and Patch Level. The Hardware configurations were the same in OS Level, Kernel Version and memory con- figuration. We capture the metrics of each workload and analyse the consistency of the metrics, as shown graphically in Figure 6. </span><span class="c17">4.7 Results </span><span class="c29">OLTP Workload </span></p><p class="c4"><span class="c17">and Analysis Experiment Two - </span><span class="c2">The results for OLTP covering CPU and IOPS/s are shown graphically in Figure 6. Relying on host based metrics has </span></p><p class="c6"><span class="c2">a profound effect in the ability to compare and contrast different CPU models, as there is no common denomina- tor (SPECInt) calculated. It also becomes difficult if there are multiple standby databases existing in the same envi- ronment. When the workloads were compared between the hosts, due to the nature of the physical standby and the pri- mary behaving, as designed, in a completely different way, the graphs clearly show that the standby database has a con- siderably lower utilisation of CPU and IO resources. This is for several reasons: </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">A physical Standby Database is in recovery mode there- fore is not open for SQL DML or DDL in the same manner as a primary database is opened in normal mode. Therefore processes are not spawned at OS level/Database level, consuming resources such as Mem- ory, CPU. </span></p><p class="c6"><span class="c1">&bull; </span><span class="c2">A Physical standby applies&ldquo;Archivelogs&rdquo;and therefore is much more dependent on Physical Writes as these logs (changes) are applied on the standby from the primary database, therefore less IO load is generated. </span></p><p class="c4"><span class="c1">&bull; </span><span class="c2">The reduction in IOPS/s is also attributed to DML/DDL is not being executed on the standby database in the same manner as a primary database (e.g. rows are not being returned as part of a query result set). </span></p><p class="c4"><span class="c2">It was clear after the first experiment OLTP, that the workloads would be profoundly different in their footprint regardless of the workload being executed, so we have not included the results of the other workloads namely, OLAP and Data Mart. </span><span class="c17">4.8 Experiment </span><span class="c29">(Advanced Configuration) </span></p><p class="c6"><span class="c17">Three - Clustered Database </span><span class="c2">The final set of experiments was to execute three the work- loads on a more advanced configuration, a two-node clus- tered database running in an Engineered system (Exadata X5-2 platform) [1], illustrated in Fig 2. During the experi- ment, compute nodes are closed down to simulate a fail-over. The database configurations were the same in Instance Pa- rameters, Software Version and Patch Level. The hardware configurations were the same in OS Level, Kernel Version and memory configuration. A difference in this experiment </span></p><p class="c4"><span class="c20">694 </span></p><p class="c112"><span class="c2">from the previous two is that the physical hardware and database are clustered. In this experiment we leverage the Exadata Technology in the IO substructure. </span></p><p class="c50"><span class="c17">4.9 Results and Analysis Experiment Three - </span><span class="c29">OLTP Workload </span><span class="c2">The results for OLTP covering Memory, CPU and IOPS/s are shown graphically in Fig 7. The OLTP workload was amended to run from node 1 for the second 24 hours and this is reflected in all three of the graphs, when the instance DBM012 is very much busier than instance DBM011. The workloads are then spread evenly for the following 48 hours. </span></p><p class="c87"><span class="c1">&bull; </span><span class="c2">CPU utilisation - for the first 24 hours, the workloads were executed fairly evenly across the cluster with a workload of 2000 users connecting consistently with peaks of 1000 users at peak times, and the CPU showed similar patterns during the workload execution. </span></p><p class="c8"><span class="c1">&bull; </span><span class="c2">CPU utilisation - When the workload ran abnormally and all users (3000 users) ran from one node, in the second 24 hours, then the CPU utilisation did almost double in usage as expected. The increase was approx- imately +99% (Day 7 Hour 15) </span></p><p class="c8"><span class="c1">&bull; </span><span class="c2">IOPS/s - The IOPS&rsquo;s utilisation for the first 24 hours was similar, as expected, when the workloads were evenly spread. However when the workloads were run from node 2 in the second 24 hours the IOPS increase significantly, as expected. The IOPS during the failure period was as expected, an increase of +99% (Day 7 Hour 15). </span></p><p class="c116"><span class="c1">&bull; </span><span class="c2">IOPS/S Spike - there are two major spikes occurring at Day 7 Hour 2 and Day 8 Hour 2, these are Level 0 database backups than only run from node 1 (DBM011) </span></p><p class="c8"><span class="c1">&bull; </span><span class="c2">Memory Consumption - The maximum memory utili- sation across both instances was consistent during the first 24 hours when the workload was evenly spread. The memory configuration on DBM012 is sufficient to handle the 3000 users during the failover period, al- though the increase in memory used on DBM012 was only +45% </span></p><p class="c73"><span class="c2">In general, the conclusion from this experiment when ex- ecuting the OLTP workloads was, it cannot be assumed that when a workload fails over from one node (database instance) to another node (database instance) the footprint will be double in terms of Memory. The workload did double for CPU and IOPS/s. The results show there is an increase in IOPS/s, Memory and CPU. The difference during normal running conditions (i.e. when workloads are evenly spread) was the following: +31% (Day 7 Hour 3) CPU, +2% Mem- ory (Day 6 Hour 21) and +1% (Day 6 Hour 12) IOPS. When the workload failed over there was a difference of +97% (Day 7 Hour 9) CPU, +99% (Day 7 Hour 20) Memory and +99% (Day 08 Hour 10) IOPS. There are two large spikes at Day 7 Hour 2 and Day 8 Hour 2; these are Level 0 RMAN backups which account for the large IOPS readings. The database instance was sufficiently sized to handle both workloads oth- erwise we would of expected to see out of memory errors in the database instance alert file. </span></p><p class="c55 c94"><span class="c17">4.10 Results and Analysis Experiment Three </span><span class="c29">- OLAP Workload </span><span class="c2">The results OLAP covering Memory, CPU and IOPS/s are shown graphically in Fig 8. The OLAP workload was amended to run from node 1 for the first 24 hours and this is clearly reflected in all three of the graphs, as the instance DBM011 is very much busier than instance DBM012 during this period. The workloads are then spread evenly for the following 48 hours. </span></p><p class="c85"><span class="c1">&bull; </span><span class="c2">CPU utilisation - for the first 24 hours, node 1 ran the whole workload of 400 users and thus the DBM011 instance is busier compared with the workload across days two and three; as expected, utilization is effec- tively doubled, at +99%. </span></p><p class="c53"><span class="c1">&bull; </span><span class="c2">CPU utilisation - when the workload ran normally (400 users) across both nodes then the utilisation was sim- ilar in its SPECint count with a difference of approxi- mately +20%. </span></p><p class="c53"><span class="c1">&bull; </span><span class="c2">IOPS/s - The IOPS&rsquo;s utilisation for the first 24 hours was busier on node 1, as expected, than node 2 given that both workloads were executed from DBM011 in- stance. The IOPS utilisation was almost double +99% (Day 25 Hour 05) the amount from the second period of time (Day 26 Hour 05) when the workloads were spread evenly across both instances. </span></p><p class="c53"><span class="c1">&bull; </span><span class="c2">Memory Consumption - The maximum memory util- isation observed across both instances was consistent with the workload, the first 24 hours when the work- load ran from node 1 is as expected in that there was sufficient memory to serve both workloads. However there is a difference of +55% (Day 25 Hour 04) in mem- ory between nodes 1 and 2. For the second 24 hours, as the workloads reverted back to their normal hosts I.E. spread evenly across both nodes, their utilisation is similar with a difference of +1% (Day 26 Hour 04) between the nodes in memory utilisation. </span></p><p class="c45"><span class="c2">In general, the conclusion from this experiment when exe- cuting the OLAP workloads was that it cannot be assumed that when a workload fails over from one node (database instance) to another node the footprint will be double in terms of Memory. For the metrics IOPS and CPU the in- crease was almost double; CPU had a difference of +99% (Day 25 Hour 04) and IOPS +99% (Day 24 Hour 04). When the workload was spread evenly across both nodes the differ- ences between the nodes where CPU +20% (Day 26 Hour 3), Memory +2% (Day 26 Hour 3) and IOPS +1% (Day 26 Hour 4). The database instance was sufficiently sized to handle both workloads otherwise we would of expected to see out of memory errors in the database instance alert file. </span><span class="c17">4.11 Results and Analysis Experiment Three </span><span class="c29">- Data Mart Workload </span><span class="c2">The results are as follows for the Data Mart workloads covering Memory, CPU and IOPS/s, as shown graphically in Fig 9. The Data Mart workload was run normally for the first 24 hours, which is reflected in the workloads being sim- ilar for this period. A simulated failure of database instance DBM011 is then performed and all connections then fail- over to DBM012 on node 2 for the second 24 hours. This is </span></p><p class="c121"><span class="c20">695 </span></p><p class="c15"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c4 c19"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c4 c19"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c33"><span class="c2">Figure 9: Results RAC Data Mart: workload patterns for the 72 hour period. </span></p><p class="c109"><span class="c2">reflected in all three of the graphs as the instance DBM012 becomes much busier than instance DBM011. </span></p><p class="c119"><span class="c1">&bull; </span><span class="c2">CPU utilisation - For the first 24 hours, the workloads were executed fairly evenly across the cluster with a workload of 2700 users connecting at different times from the two nodes and the SPECInt count was similar </span></p><p class="c4 c91"><span class="c2">with a average CPU difference of +15% (Day 2 Hour 04). </span></p><p class="c51"><span class="c1">&bull; </span><span class="c2">CPU utilisation - When the workload ran abnormally and all users (2700 users) ran from one node, in the second 24 hours, then the CPU utilisation almost dou- bled in usage as expected +99% (Day 3 Hour 04). </span></p><p class="c46"><span class="c20">696 </span></p><p class="c4 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c77 c74"><span class="c2">(a) CPU 72 hours </span></p><p class="c4 c36"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c36"><span class="c2">(c) Memory 72 Hours </span></p><p class="c4 c19"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c4 c19"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c19 c77"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c4 c19"><span class="c2">(b) IOPS/s 72 Hours </span></p><p class="c97"><span class="c2">Figure 8: Results RAC OLAP: workload patterns for the 72 hour period. </span></p><p class="c4 c110"><span class="c2">Figure 7: Results RAC OLTP: workload patterns for the 72 hour period. </span></p><p class="c82"><span class="c2">(a) Volatility of workload Peak </span></p><p class="c4 c115"><span class="c2">(b) Volatility of workload Avg </span></p><p class="c60"><span class="c2">Figure 10: Workload Impacts </span></p><p class="c99"><span class="c1">&bull; </span><span class="c2">IOPS/s - The IOPS&rsquo;s utilisation for the first 24 hours was similar, as expected, when the workloads were evenly spread with a difference on average of +17% (Day 2 Hour 04). However, when the workloads were run from node 2 in the second 24 hours the IOPS in- creased significantly, rising to almost double at +99% (Day 3 Hour 04). </span></p><p class="c80"><span class="c1">&bull; </span><span class="c2">Memory Consumption - The maximum memory utili- sation across both instances was as expected during the first 24 hours, when the workloads were evenly spread, showing a difference of +9% (Day 2 Hour 04). This behaviour was not expected during the failover period when all users execute their workload on DBM012 as the utilisation difference is +60% (day 3 Hour 04). The memory configuration on DBM012 is sufficient to han- dle the 2700 users. </span></p><p class="c39"><span class="c2">In general, the conclusion from this experiment when exe- cuting the Data Mart workloads was, it cannot be assumed that when a workload fails over from one node (database in- stance) to another node the footprint will be double in terms of memory, as it only increased by approximately +60%. CPU and IOPS however, did double in its usage to approx- imately +99%. When the workload was spread evenly the average utilisation had a difference of CPU +15% (Day 2 Hour 04), Memory +9% (Day 2 Hour 04) and IOPS +17% (Day 2 Hour 04). </span></p><p class="c24"><span class="c17">5. CONCLUSIONS AND FUTURE WORK </span></p><p class="c76"><span class="c2">From the experiments conducted and the model we pro- posed, we conclude that capacity planning of databases that employ advanced configurations such as Clustering and Standby Databases is not a simple exercise. Taking the Average and Maximum readings for each metric (CPU, Memory Utilisa- tion and IOPS) over a period of 72 hours, the outputs are volatile. One should not assume that a workload running on one database instance configured in one type of system will consume the same amount of resource as an another database instance running on another system, regardless of similarity; this is clearly shown in Fig 10 (a) (OLTP, OLAP, Data Mart RAC Failovers). These charts show us that as workloads become assimilated they completely change as the difference grows, sometimes considerably. The differences </span></p><p class="c6 c65"><span class="c2">between the footprints based on configuration can vary be- tween +10% (CPU OLAP RAC) in normal circumstances shown in Fig 10 (b) to 99% (CPU OLAP RAC) as shown in Fig 10 (a). Fig 10(a &amp; b, OLTP Standby) also highlights that configuration has a big impact on capacity planning databases with advanced configurations, such as standby databases. </span></p><p class="c96"><span class="c2">In this paper we highlighted the problems that organisa- tions are faced with over-estimation and under-estimation when trying to budget on non-cloud compliant financial mod- els such as capex or cloud compliant models, which are sub- scription based. Accurate capacity planning can help in re- ducing wastage when metrics are captured and the assump- tion of workloads being the same is not employed. Capturing and storing the data in a central repository, like the approach we proposed, allowed us to mine the data successfully with- out the labour intensive analysis that often accompanies a capacity planning exercise. </span></p><p class="c48"><span class="c2">The main points from this work are. </span></p><p class="c47"><span class="c2">1. When capacity planning DBaaS, it should be done on a instance-by-instance basis and not at a database level - this is especially the case in clustered environments where workloads can move between one database and another or fail-over technology is employed. </span></p><p class="c64"><span class="c2">2. Metrics need to be captured at different layers of the infrastructure in advanced configurations, for example in the storage layer, caching can mask IOPS causing the workload to behave differently. </span></p><p class="c79"><span class="c2">3. Hypervisors and VMManagers can influence capacity planning as these tools allocate resource. For exam- ple, a CPU can be dissected and allocated as a vcpu (Oracle VM) [2]. How does one know that the CPU assigned is a full CPU? The Oracle Software and the database itself may assume that a full CPU was made available, when in fact it was assigned 0.9 of a CPU due to overheads. </span></p><p class="c79"><span class="c2">4. CPU configuration (Thread(s) per core) within a VM has a profound effect when capacity planning. We ob- served in experiment one (OLTP and Data Mart) that small concurrent transactions in the OLTP workload executed on VM acs-163 were a lot more efficient than </span></p><p class="c46"><span class="c20">697 </span></p><p class="c58"><span class="c2">the same workload executed on another VM with lower thread(s) per core, and this is reflected in Figures 3, 4 and 5. </span></p><p class="c86"><span class="c2">5. SPECInt benchmark is a valid benchmark when com- paring one varient of CPU with another, especially when trying to capacity plan databases with a view to a migration or upgrade of the infrastructure. </span></p><p class="c86"><span class="c2">6. Standby Databases presented a different footprint. A standby database is always in a mounted state and therefore is configured in a recovering mode by apply- ing logs or changes from the primary. It should not be assumed that the footprints are the same. </span></p><p class="c34"><span class="c2">7. In environments that employ standby database con- figurations, metrics that are available for collection on the primary database are not available on the standby, namely physical reads/writes, CPU and memory, thus gathering accurate metrics is impractical. Metrics can be gathered at a host level, however if multiple standby databases are running on the same host this makes reconciliation of which database is using what more challenging. </span></p><p class="c34"><span class="c2">8. In environments that employ clustered databases, if a workload running on one node fails-over from an- other node within the cluster, one should not assume that the properties of the composed workload will fol- low obviously from its constituents. Upon failover, the workload from the failing node is assimilated, with the result being the formation of a completely new foot- print. </span></p><p class="c72"><span class="c2">Future work is to conduct the same type of experiments between different database versions, for example a workload running on Oracle Database Version 10G/11G and Oracle Database Version 12C, analysing if the internal database al- gorithms have any influence and by how much. However techniques already exist that go some way to answering this question through the use of a product called Database replay [7]. Being able to gather metrics from a standby database in- stance for CPU, IOPS and Memory is critical for our model as this would allow us to accurately analyse the CPU such as SPECInt, Memory and IOPS&rsquo;s. We could configure a cus- tom metric to execute internal queries against the standby database, and this is now in the design phase, but until then capacity planning architectures with standby database will need to rely on host metrics. </span></p><p class="c32"><span class="c17">6. REFERENCES </span></p><p class="c114"><span class="c2">[1] U. Author. Oracle exadata database machine. Security </span></p><p class="c57"><span class="c2">Overview, 2011. [2] O. Corporation. Oracle vm concept guide for release </span></p><p class="c66"><span class="c2">3.3. [3] T. P. P. Council. Tpc-ds benchmark. [4] T. P. P. Council. Tpc benchmark h standard </span></p><p class="c92"><span class="c2">specification version 2.1. 0, 2003. [5] T. P. P. Council. Tpc benchmark c (standard </span></p><p class="c103"><span class="c2">specification, revision 5.11), 2010. URL: http://www. tpc. org/tpcc, 2010. [6] K. M. Dixit. Overview of the spec benchmarks., 1993. </span></p><p class="c4 c98"><span class="c2">[7] L. Galanis, S. Buranawatanachoke, R. Colle, </span></p><p class="c107"><span class="c2">B. Dageville, K. Dias, J. Klein, S. Papadomanolakis, L. L. Tan, V. Venkataramani, Y. Wang, and G. Wood. Oracle database replay. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD &rsquo;08, pages 1159&ndash;1170, New York, NY, USA, 2008. ACM. [8] D. Giles. Swingbench 2.2 reference and user guide. [9] M. Guidolin, S. Hyde, D. McMillan, and S. Ono. </span></p><p class="c123"><span class="c2">Non-linear predictability in stock and bond returns: When and where is it exploitable? International journal of forecasting, 25(2):373&ndash;399, 2009. [10] H. Hac&#305;g&uuml;m&uuml;s, J. Tatemura, Y. Chi, W. Hsiung, </span></p><p class="c65 c69"><span class="c2">H. Jafarpour, H. Moon, and O. Po. Clouddb: A data store for all sizes in the cloud. Internet: http://www. neclabs. com/dm/CloudDBweb. Pdf,[January 25, 2012], 2012. [11] Y. Kouki and T. Ledoux. Sla-driven capacity planning for cloud applications. In Cloud Computing Technology and Science (CloudCom), 2012 IEEE 4th International Conference on, pages 135&ndash;140. IEEE, 2012. [12] C. Loboz. Cloud resource usage</span><span class="c38">&nbsp;&#774;</span><span class="c2">A</span><span class="c38">&#711;</span><span class="c2">Ttailed distributions invalidating traditional capacity planning models. Journal of grid computing, 10(1):85&ndash;108, 2012. [13] S. Mahambre, P. Kulkarni, U. Bellur, G. Chafle, and </span></p><p class="c62"><span class="c2">D. Deshpande. Workload characterization for capacity planning and performance management in iaas cloud. In Cloud Computing in Emerging Markets (CCEM), 2012 IEEE International Conference on, pages 1&ndash;7. IEEE, 2012. [14] R. Moussa and H. Badir. Data warehouse systems in </span></p><p class="c63"><span class="c2">the cloud: Rise to the benchmarking challenge. IJ Comput. Appl., 20(4):245&ndash;254, 2013. [15] B. Mozafari, C. Curino, A. Jindal, and S. Madden. </span></p><p class="c11"><span class="c2">Performance and resource modeling in highly-concurrent oltp workloads. In Proceedings of the 2013 acm sigmod international conference on management of data, pages 301&ndash;312. ACM, 2013. [16] B. Mozafari, C. Curino, and S. Madden. Dbseer: </span></p><p class="c16"><span class="c2">Resource and performance prediction for building a next generation database cloud. In CIDR, 2013. [17] J. Murphy. Performance engineering for cloud </span></p><p class="c78"><span class="c2">computing. In European Performance Engineering Workshop, pages 1&ndash;9. Springer, 2011. [18] A. Ray. Oracle data guard: Ensuring disaster recovery </span></p><p class="c31"><span class="c2">for the enterprise. An Oracle white paper, 2002. [19] S. Sahri, R. Moussa, D. D. Long, and S. Benbernou. </span></p><p class="c40"><span class="c2">Dbaas-expert: A recommender for the selection of the right cloud database. In International Symposium on Methodologies for Intelligent Systems, pages 315&ndash;324. Springer, 2014. [20] S. Shang, Y. Wu, J. Jiang, and W. Zheng. An </span></p><p class="c37"><span class="c2">intelligent capacity planning model for cloud market. Journal of Internet Services and Information Security, 1(1):37&ndash;45, 2011. [21] T. Yu, J. Qiu, B. Reinwald, L. Zhi, Q. Wang, and </span></p><p class="c35"><span class="c2">N. Wang. Intelligent database placement in cloud environment. In Web Services (ICWS), 2012 IEEE 19th International Conference on, pages 544&ndash;551. IEEE, 2012. </span></p><p class="c22"><span class="c20">698 </span></p></body></html>