<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c50{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c75{margin-left:-15.4pt;padding-top:1pt;text-indent:27.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.4pt}.c85{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.8pt;font-family:"Arial";font-style:normal}.c69{margin-left:-16.9pt;padding-top:1pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.7pt}.c104{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.5pt;font-family:"Arial";font-style:normal}.c100{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.1pt;font-family:"Arial";font-style:normal}.c37{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c68{margin-left:-19pt;padding-top:6.2pt;text-indent:28.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.8pt}.c95{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:17.2pt;font-family:"Arial";font-style:normal}.c129{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Courier New";font-style:normal}.c44{color:#c00000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c77{color:#4f81bd;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c72{margin-left:-17.1pt;padding-top:1.9pt;text-indent:27.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-19.4pt}.c105{margin-left:-18.7pt;padding-top:14.4pt;text-indent:19pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.6pt}.c97{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.3pt;font-family:"Arial";font-style:normal}.c26{color:#e7e6e6;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.6pt;font-family:"Arial";font-style:normal}.c80{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:16.3pt;font-family:"Arial";font-style:normal}.c55{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13pt;font-family:"Arial";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.7pt;font-family:"Arial";font-style:normal}.c46{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.3pt;font-family:"Arial";font-style:normal}.c54{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.8pt;font-family:"Arial";font-style:normal}.c78{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.3pt;font-family:"Arial";font-style:normal}.c106{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Arial";font-style:normal}.c58{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Courier New";font-style:normal}.c123{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:normal}.c103{margin-left:-19pt;padding-top:10.3pt;text-indent:19.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.6pt}.c60{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.7pt;font-family:"Arial";font-style:normal}.c59{margin-left:-17.1pt;padding-top:2.2pt;text-indent:27.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-19.4pt}.c17{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c34{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c124{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c112{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.8pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c120{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.8pt;font-family:"Arial";font-style:normal}.c0{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Courier New";font-style:normal}.c96{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.8pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c117{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.2pt;font-family:"Arial";font-style:normal}.c71{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.7pt;font-family:"Arial";font-style:normal}.c111{margin-left:-18.5pt;padding-top:1.9pt;text-indent:28.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.6pt}.c121{color:#c00000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.6pt;font-family:"Arial";font-style:normal}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c128{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.1pt;font-family:"Arial";font-style:normal}.c40{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c98{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.8pt;font-family:"Arial";font-style:normal}.c87{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.6pt;font-family:"Arial";font-style:normal}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.6pt;font-family:"Arial";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.4pt;font-family:"Arial";font-style:normal}.c57{margin-left:-16.9pt;padding-top:1.2pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.2pt}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c108{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.8pt;font-family:"Arial";font-style:normal}.c83{margin-left:-16.9pt;padding-top:2.2pt;text-indent:27pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18pt}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c70{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Courier New";font-style:normal}.c38{margin-left:-16.9pt;padding-top:1pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18pt}.c109{margin-left:-16.9pt;padding-top:2.2pt;text-indent:27pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-19.4pt}.c28{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.1pt;font-family:"Arial";font-style:normal}.c24{margin-left:-16.9pt;padding-top:1pt;text-indent:32.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18pt}.c65{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Arial";font-style:normal}.c84{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.8pt;font-family:"Arial";font-style:normal}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.1pt;font-family:"Arial";font-style:normal}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.4pt;font-family:"Arial";font-style:normal}.c52{margin-left:-16.9pt;padding-top:1pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19pt}.c47{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.8pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c119{margin-left:-18.7pt;padding-top:10.1pt;text-indent:19pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.6pt}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.3pt;font-family:"Arial";font-style:normal}.c116{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.3pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c51{color:#9bbb59;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c56{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.1pt;font-family:"Arial";font-style:normal}.c101{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.6pt;font-family:"Arial";font-style:normal}.c67{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:normal}.c88{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:17.4pt;font-family:"Arial";font-style:normal}.c94{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c126{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c48{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c73{margin-left:-16.9pt;padding-top:1pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.2pt}.c90{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.6pt;font-family:"Arial";font-style:normal}.c86{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.8pt;font-family:"Arial";font-style:normal}.c64{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:17.3pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c91{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.4pt;font-family:"Arial";font-style:normal}.c32{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.9pt;font-family:"Arial";font-style:normal}.c53{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.7pt;font-family:"Arial";font-style:normal}.c93{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:16.9pt;font-family:"Arial";font-style:normal}.c10{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.1pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c114{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.1pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.8pt;font-family:"Arial";font-style:normal}.c74{margin-left:-18.5pt;padding-top:2.2pt;text-indent:28.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.8pt}.c125{color:#ffffff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c62{margin-left:-19pt;padding-top:2.2pt;text-indent:28.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.6pt}.c81{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.1pt;font-family:"Courier New";font-style:normal}.c49{margin-left:-19pt;padding-top:9.1pt;text-indent:19.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c76{color:#00ff00;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.5pt;font-family:"Arial";font-style:normal}.c33{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12.1pt;font-family:"Arial";font-style:normal}.c113{margin-left:-16.9pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.2pt}.c89{margin-left:55pt;padding-top:14.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:38.6pt}.c122{margin-left:-1.3pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:4.1pt}.c66{margin-left:218.6pt;padding-top:68.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-35.4pt}.c115{margin-left:58.3pt;padding-top:10.6pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:42.6pt}.c82{margin-left:-23.8pt;padding-top:737.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c36{margin-left:-15.4pt;padding-top:3.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.4pt}.c31{margin-left:-18.5pt;padding-top:10.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:146.3pt}.c25{margin-left:-15.4pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-16.9pt}.c63{margin-left:-16.9pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-17.8pt}.c118{margin-left:-18.5pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.9pt}.c102{padding-top:1.2pt;text-indent:32.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c107{padding-top:1.2pt;text-indent:32.2pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c20{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c92{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c110{margin-left:36.2pt;margin-right:36.5pt}.c99{margin-left:-16.9pt;margin-right:-18pt}.c61{margin-left:35.2pt;margin-right:52.1pt}.c79{margin-left:38.3pt;margin-right:54.2pt}.c127{margin-left:-13.5pt;margin-right:-18pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c92"><p class="c82"><span class="c9">Series ISSN: 2367-2005 325 </span><span class="c37">10.5441/002/edbt.2018.29 </span></p><p class="c5 c110"><span class="c95">QUASII: QUery-Aware Spatial Incremental Index </span></p><p class="c89"><span class="c34">Mirjana Pavlovic </span><span class="c33">EPFL mirjana.pavlovic@epfl.ch </span></p><p class="c20 c79"><span class="c34">Darius Sidlauskas </span><span class="c33">EPFL darius.sidlauskas@epfl.ch </span></p><p class="c115"><span class="c34">Thomas Heinis </span><span class="c33">Imperial College t.heinis@imperial.ac.uk </span></p><p class="c20 c61"><span class="c34">Anastasia Ailamaki </span><span class="c33">EPFL &amp; RAW Labs SA anastasia.ailamaki@epfl.ch </span></p><p class="c49"><span class="c30">ABSTRACT </span><span class="c1">With large-scale simulations of increasingly detailed models and improvement of data acquisition technologies, massive amounts of data are easily and quickly created and collected. Traditional systems require indexes to be built before analytic queries can be executed efficiently. Such an indexing step requires substantial computing resources and introduces a considerable and growing data-to-insight gap where scientists need to wait before they can perform any analysis. Moreover, scientists often only use a small fraction of the data &mdash; the parts containing interesting phenomena &mdash; and indexing it fully does not always pay off. </span></p><p class="c74"><span class="c1">In this paper we develop a novel incremental index for the exploration of spatial data. Our approach, QUASII, builds a data- oriented index as a side-effect of query execution. QUASII dis- tributes the cost of indexing across all queries, while building the index structure only for the subset of data queried. It reduces data-to-insight time and curbs the cost of incremental indexing by gradually and partially sorting the data, while producing a data-oriented hierarchical structure at the same time. As our experiments show, QUASII reduces the data-to-insight time by up to a factor of 11.4x, while its performance converges to that of the state-of-the-art static indexes. </span></p><p class="c105"><span class="c30">1 INTRODUCTION </span><span class="c1">The advances in data acquisition technologies and supercomput- ing for large-scale simulations rapidly increase the amounts of spatial data generated and collected. For instance, in the Human Brain Project (HBP) [27], neuroscientists build spatial models of the brain which will ultimately feature 10</span><span class="c21">11 </span><span class="c1">neurons [42], each reconstructed with thousands of 3d cylinders. NASA re- leased 500 TB of earth observation data generated through re- mote sensing [30], while the Dutch government released point cloud data with 640 billion points [31] acquired through airborne scanning. Similarly, volunteers generate large amounts of spa- tial data through services such as OpenStreetMap [33]. Given these massive and growing amounts of spatial data, algorithms to query them efficiently are crucial. </span></p><p class="c62"><span class="c1">Previous research has proposed many techniques [11, 26, 42] for the fast and scalable querying of spatial datasets. Existing ap- proaches, however, have two major drawbacks. First, they require a time-consuming step to build indexes before they can be used. This pre-processing step significantly delays the analyses: index- ing a model in the HBP, for example, can take several hours [42]. With increasing dataset size, the data-to-insight time grows as well. Second, scientists frequently only analyse a small fraction of the data [1, 8]. In the HBP, for example, a scientist builds a </span></p><p class="c118"><span class="c129">&copy; </span><span class="c14">2018 Copyright held by the owner/author(s). Published in Proceedings of the 21st International Conference on Extending Database Technology (EDBT), March 26-29, 2018, ISBN 978-3-89318-078-3 on OpenProceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0. </span></p><p class="c2 c99"><span class="c1">model of the brain but after a few queries may determine that it is not biorealistic (e.g., density in certain areas does not agree with measurements) and stops the analysis. Given the small number of queries executed, the overhead of indexing the entire model cannot be fully amortized. </span></p><p class="c72"><span class="c1">The problems of delayed analysis (due to prior indexing) and the impossibility to amortize indexing cost (due to too few queries) are not exclusive to spatial data management. Database research has proposed incremental indexes for relational data (e.g., crack- ing [18] and adaptive merging [14]) and for time-series [45]. The core idea is to incrementally index only the parts of the data queried, spreading the cost of indexing over the first few queries. The major data-to-insight bottleneck is thus eliminated, i.e., queries are answered as soon as data is available (albeit the first queries run slower, as no index is initially available). </span></p><p class="c59"><span class="c1">In this paper, we develop an incremental indexing approach for spatial data in main memory, with the aim of reducing data- to-insight time, as well as achieving performance comparable to traditional spatial indexes (after enough queries are executed). As no current incremental indexing approach for main memory exists, we demonstrate the limitations of applying current op- tions to incrementally index spatial data. As we show, using the concepts for incrementally indexing one-dimensional data [18] to index three-dimensional data does not significantly reduce data-to-insight time, as the major bulk of work still has to be done for the first query. Adapting Space Odyssey [35], an incremental index for exploratory analyses of multiple spatial datasets on disk, to main memory leads to excessive reorganization of the data. As a consequence, a static index (including pre-processing cost) quickly outperforms the proposed incremental solution, in terms of total execution time. </span></p><p class="c72"><span class="c1">We thus develop a QUery-Aware Spatial Incremental Index - QUASII: a novel data-oriented, query-driven incremental index- ing approach. QUASII substantially reduces data-to-insight time and keeps the cost of incremental strategy low, by gradually and partially sorting the spatial objects considering all dimensions. QUASII thus distributes the cost of indexing across all queries, while preserving spatial proximity and producing a data-oriented style partitioning &mdash; which typically entails an expensive pre- processing step in the static setting. Finally, being data-oriented, it executes queries efficiently, as it adjusts to the distribution of the data, while avoiding data replication. </span></p><p class="c109"><span class="c1">Our experiments show that QUASII substantially accelerates the exploratory analysis of spatial data in main memory by re- ducing the data-to-insight time by up 11.4&times;, while achieving the query performance of current algorithms for spatial indexing. Static algorithms are not able to amortize their building cost over QUASII even after 10000 queries. </span></p><p class="c83"><span class="c1">To our knowledge we are the first to develop and analyze incremental indexing for spatial data. Our contributions are: </span></p><p class="c2"><span class="c1">&bull; We demonstrate the challenges of adapting and using known incremental indexing [18, 35] to spatial data in main memory. We use the resulting approaches as moti- vation and baseline. </span></p><p class="c2"><span class="c1">&bull; We develop QUASII, an incremental approach that signifi- cantly reduces the data-to-insight time, while achieving the query performance of state-of-the-art spatial indexes. </span></p><p class="c5"><span class="c1">&bull; We experimentally analyse QUASII&rsquo;s performance and the number of queries it needs to reach the performance of its static counterparts. The remainder of the paper is structured as follows. We define the problem in Section 2 and motivate it in Section 3. We then describe QUASII in Sections 4 and 5 and experimentally evaluate it in Section 6. Section 7 gives an overview of related work before we conclude in Section 8. </span></p><p class="c5"><span class="c30">2 PROBLEM DEFINITION </span><span class="c1">Our work is driven by the need for the exploratory analysis of spatial datasets through querying. The queries executed are ad hoc, i.e., the next query is only known after the results of the first query are analyzed, and they thus cannot be batched and executed with only one sequential read of the dataset. </span></p><p class="c2"><span class="c1">Example Application. In the Human Brain Project, neuro- scientists build spatial models of the brain [27]. Already now the models are so detailed that to simulate a neocortical volume of only 0.29 mm</span><span class="c21">3 </span><span class="c1">supercomputers are needed [28]. </span></p><p class="c2"><span class="c1">Once the part of a model is built, neuroscientists need to val- idate it by choosing a subset of its regions at random and in- specting them. Each region is queried with several spatially close queries and the query results are used to verify the composition, density and other metrics agree with the real brain. The results of these analyses are crucial to determine whether or not the model can be simulated or should be abandoned (subsequently building a new one using a different configuration). Scientists currently only have two fundamentally different options: index all data a priori and execute queries with the index or scan all data each time to answer a query. Not knowing a priori how many queries will be executed (and if indexing can be amortized) makes it difficult to decide. </span></p><p class="c11"><span class="c1">Data. We consider spatially extended (volumetric) objects en- closed by a minimum bounding box (MBB). In a three-dimensional (3d) setting, each MBBb is defined by two 3d points lower</span><span class="c29">(</span><span class="c1">b</span><span class="c29">) </span><span class="c1">and upper</span><span class="c29">(</span><span class="c1">b</span><span class="c29">) </span><span class="c1">corresponding to lower and upper coordinate at each di- mension (lower</span><span class="c29">(</span><span class="c1">b</span><span class="c29">) </span><span class="c1">= </span><span class="c29">(</span><span class="c1">x</span><span class="c22">l</span><span class="c1">,y</span><span class="c22">l</span><span class="c1">,z</span><span class="c22">l </span><span class="c29">) </span><span class="c1">andupper</span><span class="c29">(</span><span class="c1">b</span><span class="c29">) </span><span class="c1">= </span><span class="c29">(</span><span class="c1">x</span><span class="c22">u</span><span class="c8">,y</span><span class="c22">u</span><span class="c8">,z</span><span class="c22">u</span><span class="c58">)</span><span class="c8">) [11]. </span><span class="c1">Queries. We focus on range (window) queries as they are broadly used in many applications and are also the building block for many other spatial queries (e.g., k-nearest neighbor queries [22]). Each query is a 3d box specified by two 3d points, e.g., (q</span><span class="c22">l</span><span class="c1">,q</span><span class="c4">u</span><span class="c1">). Given a query q, all objects with their bounding box b intersecting with q, i.e., where b &cap; q &empty;, are in the result. </span></p><p class="c2"><span class="c1">Setting. We assume that all data and necessary index struc- tures fit in main memory. We consider a static setting, i.e., all raw data is available before querying. </span></p><p class="c5"><span class="c30">3 MOTIVATION </span><span class="c1">No current incremental indexing approach can index spatial data in main memory. Research has developed incremental indexing for relational, one-dimensional data in main memory, i.e., crack- ing [18] and for spatial data on disk [35]. In the following we extend the former [18] to the spatial domain and adapt the lat- ter [35] to use in main memory &mdash; to demonstrate the limitations </span></p><p class="c5"><span class="c1">of these ideas in reducing the data-to-insight time and to motivate the need for a new approach. </span></p><p class="c5"><span class="c30">3.1 Cracking for Spatial Data </span><span class="c1">Relational Cracking. Database cracking [16, 18, 19] incremen- tally builds an index as a byproduct of query execution in the context of main memory column-stores. The proposed techniques partially sort elements based on the query execution, essentially performing an incremental quick sort. In its simplest form, crack- ing [18] rearranges elements in an array according to the end points of the query range </span><span class="c29">(</span><span class="c1">q</span><span class="c22">l</span><span class="c1">,q</span><span class="c4">u</span><span class="c29">)</span><span class="c1">: all values &lt; q</span><span class="c22">l </span><span class="c1">are moved to- wards the beginning of the array, while values &gt; q</span><span class="c22">u </span><span class="c8">are moved </span><span class="c1">towards the end. With each query, the index becomes more re- fined until it is fully sorted and indexed. </span></p><p class="c2"><span class="c1">SFCracker. Using this strategy to index spatial data is in- herently challenging: spatial data has multiple dimensions and, unlike 1d data, no total order can be directly imposed on it. There- fore, to be able to use the strategy of cracking we transform data from the multi- to the one-dimensional domain. We perform this transformation using a space-filling curve (SFC) &mdash; a common approach to impose a total, 1d order on spatial objects. </span></p><p class="c2"><span class="c1">A SFC maps data to 1d domain by visiting all the points in a d-dimensional grid exactly once; the order in which the objects are visited defines their order in 1d space. When mapping spatial data, it is crucial to consider SFCs that preserve proximity (such as Z-order [34] or the Hilbert curve [21]), so that data points close in multi-dimensional space remain close in 1d space [10, 29]. </span></p><p class="c2"><span class="c1">The resulting approach, SFCracker, incrementally sorts SFC codes based on the queried region. Both, data and queries are transformed to 1d space. The data transformation takes place in the first query, which makes it the most expensive one. Once the data is transformed, the queries perform cracking based on the 1d intervals obtained through the query transformation. </span></p><p class="c2"><span class="c1">A naive query transformation to 1d space results in a substantial num- ber of false positives (needed to be </span></p><p class="c5"><span class="c39">3 </span><span class="c1">tested for intersection) because the transformed 1d range can be signifi- cantly larger than the original multi- dimensional range if only the lower </span></p><p class="c5"><span class="c39">4</span><span class="c54">8 </span></p><p class="c5"><span class="c1">and upper coordinates of the range query are considered. An example is shown in Figure 1: the curve seg- ments in blue belong to the trans- formed range (SFCcode</span><span class="c22">l</span><span class="c1">, SFCcode</span><span class="c22">u</span><span class="c8">), </span><span class="c1">but they are outside of the original query range (in red). To re- duce the overhead of false positives, we use a technique that partitions the curve into multiple sub-intervals each of which is fully contained in the original range [43]. Consequently, a range query is transformed into a number of intervals and the data is thus cracked multiple times per query, once for every interval. </span></p><p class="c2"><span class="c1">Limitations. Cracking in the relational domain decreases data-to-insight time, distributing the cost of sorting over all queries with fairly low overhead and initialization cost. These benefits, however, decrease for datasets with a higher number of dimensions. First, the initial query is expensive as it maps all the objects from the multi- to the one-dimensional domain. Second, as opposed to relational data, a single query has to perform mul- tiple expensive cracks to avoid performance penalties introduced with the transformation to 1D space. Consequently, spatial crack- ing still has a considerable data-to-insight time, along with an </span></p><p class="c5"><span class="c9">326 </span></p><p class="c5"><span class="c71">ll </span></p><p class="c5"><span class="c71">ur </span></p><p class="c5"><span class="c1">Figure 1: 1d transfor- mation: overhead. </span></p><p class="c5"><span class="c1">expensive incremental strategy. We demonstrate these limitations experimentally in Section 6.3. </span></p><p class="c5"><span class="c30">3.2 Disk-based Incremental Indexing </span></p><p class="c5"><span class="c30">in Main Memory </span><span class="c1">Disk-based Incremental Indexing. Space Odyssey [35] is a recently proposed incremental index for the exploration of spatial data. However, it tackles a different problem: Space Odyssey is designed for exploratory analyses of multiple spatial datasets. Without prior information, it incrementally indexes the datasets and adapts the physical layout of the data on disk for datasets frequently queried together. Although Space Odyssey addresses a different problem, we use its ideas related to incremental indexing and adapt them for use in main memory in Mosaic. </span></p><p class="c2"><span class="c1">Mosaic. Mosaic incrementally builds an Octree [20] by dividing the space uniformly into eight parti- tions. Figure 2 depicts the indexing process (in 2d for clarity). For ev- ery query, Mosaic identifies the par- titions that overlap with the query, </span></p><p class="c5"><span class="c26">q1 </span></p><p class="c5"><span class="c1">splits them into eight partitions and reassigns their objects to the newly created partitions. Frequently queried areas in a dataset are in- dexed fully, whereas less frequently queried areas are coarser grained. The top-down strategy is thus beneficial for consecutive queries, as they can reuse the previous partitioning, independent of the workload pattern. However, data in frequently queried areas is re-partitioned multiple times. </span></p><p class="c2"><span class="c1">Limitations. Mosaic introduces significant overhead as the data in frequently queried areas is re-partitioned multiple times until it reaches its final configuration. Consequently, a static ap- proach based on space-oriented partitioning, such as the uniform grid, outperforms quickly Mosaic in terms of total execution time (we provide more details in Section 6.3). </span></p><p class="c2"><span class="c1">Mosaic additionally suffers from considering more objects than strictly necessary &mdash; a problem inherent in space-oriented partitioning and related to data assignment. For indexes based on space-oriented partitioning, objects can be assigned to cells with two strategies: replication and query extension. Replication assigns an object to all partitions that it overlaps with. As a con- sequence more objects need to be considered for intersection, the memory footprint increases and an expensive de-duplication step is needed. The alternative is to use query extension [40] which assigns an object to a cell based only on its center. This technique avoids object replication, however, it can considerably increase the number of objects necessary to be tested for intersection. More precisely, to ensure the correctness of the query result, it extends the query range by the maximum object extent. As a result, the area queried for is bigger than the initial query. Both strategies, replication and query extension, slow down query ex- ecution but, as we show in Section 6.2, replication is particularly expensive when working with volumetric spatial objects and we thus use query extension in Mosaic. </span></p><p class="c5"><span class="c30">4 QUASII OVERVIEW </span><span class="c1">As discussed, an approach to incrementally index spatial data is not as straightforward as adapting known approaches. Besides the challenges, we also identify important design goals: </span></p><p class="c5"><span class="c26">q3 </span></p><p class="c5"><span class="c26">q2 </span></p><p class="c5"><span class="c1">Figure 2: Mosaic: incremental strategy. </span></p><p class="c5"><span class="c1">(i) minimal data-to-insight time: the main requirement for incremental indexing is to enable instant access to the data, i.e., the first queries must not introduce undue overhead/processing; (ii) efficient query performance: the performance of fre- quently queried subsets of data should converge to that of the fully indexed approach (or better); (iii) low cost incremental indexing: indexing should intro- duce as little overhead as possible, i.e., its cumulative exe- cution time should only exceed the one of static indexes after as many queries as possible (or not at all). </span></p><p class="c2"><span class="c1">Given the design goals and our analyses, we develop QUery- Aware Spatial, Incremental Index, QUASII. QUASII is a data- oriented index, incrementally built as a side effect of query exe- cution. It reduces data-to-insight time and curbs the cost of incre- mental indexing by gradually and partially sorting the data, while simultaneously producing a data-oriented hierarchical structure. It is based on a nested reorganization strategy which incremen- tally slices the space in each dimension and a hierarchical, data- oriented structure designed to accommodate the incremental in- dexing process and provide efficient query execution. </span></p><p class="c2"><span class="c1">Overview. Figure 3a illustrates QUASII&rsquo;s incremental strategy on a high level. Given range queries of the form q = [q</span><span class="c22">l </span><span class="c1">= </span><span class="c29">(</span><span class="c1">x</span><span class="c22">l</span><span class="c1">, y</span><span class="c22">l</span><span class="c1">, z</span><span class="c22">l</span><span class="c29">)</span><span class="c1">, q</span><span class="c22">u </span><span class="c8">= </span><span class="c58">(</span><span class="c8">x</span><span class="c22">u</span><span class="c8">, y</span><span class="c22">u</span><span class="c8">, z</span><span class="c22">u</span><span class="c58">)</span><span class="c8">], QUASII reorganizes the objects based </span><span class="c1">on each query&rsquo;s lower </span><span class="c29">(</span><span class="c1">q</span><span class="c22">l</span><span class="c29">) </span><span class="c1">and upper </span><span class="c29">(</span><span class="c1">q</span><span class="c4">u</span><span class="c29">) </span><span class="c1">coordinate by slicing each dimension and performing a nested reorganization. It first reorganizes objects on the x dimension, producing three x slices where the middle one contains the objects in the range [x</span><span class="c22">l</span><span class="c1">, x</span><span class="c4">u</span><span class="c1">] given the query range in dimension x. Subsequently, it continues reorganizing the middle x slice on the y dimension, producing again three slices where the middle one contains objects in the range [y</span><span class="c22">l</span><span class="c1">, y</span><span class="c22">u</span><span class="c8">]. Finally, QUASII reorganizes the y slice on the z </span><span class="c1">dimension producing the z slice which contains the query result. QUASII never performs a complete sort but reorganizes data locally, given the query&rsquo;s boundaries. </span></p><p class="c11"><span class="c1">The slices produced are organized in a hierarchical structure that incrementally forms the index. Figure 3b illustrates the struc- ture of QUASII after the very first query (left) and after an ar- bitrary number of queries (right) are executed. QUASII forms a hierarchical structure with one level per dimension, i.e., the first (top), second, and third (bottom) levels correspond to slices at x, y, and z dimensions, respectively. The top level has the coarsest granularity as its objects are constrained with one di- mension, while the bottom level is the most fine-grained since it is constrained by all dimensions. When executing the queries, QUASII traverses the structure depth-first, performing additional refinements when necessary, as we discuss later in Algorithm 1. Nested Reorganization Strategy. The incremental strategy of QUASII is query-driven and data-oriented. Being query-driven, it reorganizes the minimal amount of data while executing queries. At the same time, being data-oriented, it achieves query efficiency as it adjusts to the data distribution, while avoiding replication. QUASII accomplishes both through its nested reorganization. </span></p><p class="c2"><span class="c1">Data-oriented partitioning typically entails an expensive pre- processing step in the static setting as it preserves spatial prox- imity based on a strategy for ordering multi-dimensional ob- jects. QUASII distributes the cost of this pre-processing across all queries by performing nested and partial reorganization. It reorganizes only a subset of data driven by queries, gradually curbing the amount of data partially sorted with every dimen- sion. This strategy is inspired by the Sort-Tile-Recursive (STR) </span></p><p class="c5"><span class="c9">327 </span></p><p class="c5"><span class="c100">Query </span></p><p class="c5"><span class="c100">Universe </span></p><p class="c5"><span class="c51">slice x </span></p><p class="c5"><span class="c51">X level </span></p><p class="c5"><span class="c100">Query </span><span class="c65">Query </span><span class="c100">Query </span></p><p class="c5"><span class="c41">(a) Incremental indexing strategy </span></p><p class="c5"><span class="c77">slice y </span></p><p class="c5"><span class="c77">Y level </span></p><p class="c5"><span class="c121">Z level </span></p><p class="c5"><span class="c51">1. reorganize x </span><span class="c77">2. reorganize y </span><span class="c121">3. reorganize z </span></p><p class="c5"><span class="c41">(b) Index structure after the first (left) and few more (right) queries </span></p><p class="c5"><span class="c1">Figure 3: QUASII incremental indexing strategy and data structure. </span></p><p class="c2"><span class="c1">R-tree bulkloading algorithm [26]. STR produces tiles that form leaf-level nodes for the R-Tree by recursively, fully sorting spatial objects in each dimension. More precisely, STR for 3d objects first sorts the spatial objects on the x-axis and partitions them in vertical tiles of equal size (i.e., the same number of objects). Then, within each x tile, it recursively applies the same strategy first considering y and then z dimension. This tiling strategy is particularly efficient as the resulting R-Tree has less overlap than other approaches [26]. By only performing partial reorganiza- tions for the parts of the data that is actually queried, QUASII outputs partitions targeting these characteristics at lower cost (as opposed to complete sorts in STR). </span></p><p class="c11"><span class="c1">Index Structure. QUASII&rsquo;s index structure is designed to sup- port an efficient incremental strategy with as little performance penalty as possible. Its hierarchical structure is designed to ac- commodate the reorganization strategy: each level corresponds to one (reorganization) dimension and each parent node is rep- resented by its children in a nested form along the dimensions QUASII reorganizes data. We discuss the data structure and how it accommodates incremental indexing in more detail in Section 5.1. Benefits. Ultimately, the design choices behind our approach enable us to achieve the goals we outlined. To reduce data-to- insight time (i), QUASII keeps data in the multi-dimensional, spatial domain. This avoids transforming all data at the very be- ginning which significantly hurts performance of the first query. Next, to achieve query efficiency (ii), QUASII uses data-oriented partitioning that preserves spatial proximity, adjusts to the distri- bution of data, and avoids object replication. Finally, to keep the cost of the incremental indexing low (iii), QUASII gradually and partially sorts the data using a nested reorganization strategy. </span></p><p class="c5"><span class="c30">5 DATA STRUCTURE &amp; QUERY </span></p><p class="c5"><span class="c30">PROCESSING </span><span class="c1">In the following, we explain the QUASII index structure and data organization before we proceed with discussing querying and incremental indexing algorithms. </span></p><p class="c2"><span class="c1">Throughout this section, we refer to a 2d example given in Figure 4. It depicts a dataset D = {o</span><span class="c22">0</span><span class="c8">,...,o</span><span class="c22">9</span><span class="c8">} of ten (gray) rect- </span><span class="c1">angular spatial objects. All subfigures have three main parts: the top part shows a 2d view of the dataset D and how the space is conceptually &ldquo;sliced&rdquo; by QUASII, the middle (&ldquo;Data array&rdquo;) depicts how (raw) data objects are re-organized in main memory, and the bottom shows QUASII&rsquo;s hierarchical data structure that is incrementally built. All x- and y-axis related slicing is marked in green and blue, respectively. Figure 4a) shows the initial state: the &ldquo;slice-less&rdquo; view of the data space with D objects and the very first query q</span><span class="c22">1</span><span class="c8">, the data array of spatial objects in an arbitrary </span><span class="c1">initial order, and the data structure containing the initial slice, s</span><span class="c4">0 </span><span class="c1">(capturing the entire dataset). </span></p><p class="c5"><span class="c30">5.1 Data Structure </span><span class="c1">QUASII forms a d-level hierarchical structure, organized accord- ing to the number d of dimensions. Each level l has a one-to-one mapping to the corresponding dimension. That is, the first level (l = 1) represents slicing of data at x, the second level (l = 2) slices aty, and the third level (l = 3) slices at the z dimension. The top level always slices data objects at the coarsest granularity, while the bottom level is the most fine-grained. Each slice is de- scribed with four attributes: (i) its level, (ii) a minimum bounding box capturing all its objects, (iii) indices to the data array corre- sponding to the first and last entry of the objects that belong to the slice, and (iv) pointers to sub-slices refining the slice further on the subsequent dimension. In Figure 4, this corresponds to the four fields present in each node of the data structure (next to slice label, e.g., s</span><span class="c22">0</span><span class="c8">): l, box, ids, and arrow pointers (when not </span><span class="c1">null). In our two-dimensional view of the dataset, we mark boxes with a solid line (in the corresponding color), while the slice cuts are marked as dashed lines. </span></p><p class="c11"><span class="c1">Data-oriented Slicing. One of the main advantages of data- oriented partitioning is that each spatial object is always assigned to just one partition (slice). However, QUASII determines the slices in each dimension based on query ranges. Given volu- metric spatial objects, objects can be sliced through and thus overlap with multiple slices. To overcome this problem, QUASII represents each object using only one of its coordinates and uses this coordinate to identify a slice where an object will be assigned to. In particular, during indexing, it uses each object&rsquo;s lower coordinate not require any additional </span><span class="c29">(</span><span class="c1">x</span><span class="c22">l</span><span class="c1">,y</span><span class="c22">l</span><span class="c1">,z</span><span class="c22">l</span><span class="c29">)</span><span class="c1">. computation Being part of or object&rsquo;s storageMBB, </span><span class="c21">1</span><span class="c1">. this does In Figure 4, this coordinate is marked as a black dot for all objects. Figure 4b illustrates slicing based on the very first query q</span><span class="c22">1 </span><span class="c8">and its range </span><span class="c1">[2, 4] on the x-axis. Slicing at x = 2 and x = 4 results in three x-slices (s</span><span class="c22">1</span><span class="c8">,s</span><span class="c22">2</span><span class="c8">, ands</span><span class="c22">3</span><span class="c8">). While objecto</span><span class="c22">6 </span><span class="c8">overlaps two slices (s</span><span class="c22">2 </span><span class="c8">and </span><span class="c1">s</span><span class="c22">3</span><span class="c8">), it is assigned to s</span><span class="c22">2 </span><span class="c8">based on its lower coordinate (x</span><span class="c22">l</span><span class="c1">). Note how the objects are re-organized in the data array and correspond to three partitions (slices) with coordinates x &lt; 2, 2 &le; x &le; 4, and 4 &lt; x. Accordingly, the data structure is updated with three new (more refined) slices replacing the initial (coarser) slice s</span><span class="c4">0 </span><span class="c1">(capturing the whole dataset). </span></p><p class="c2"><span class="c1">While QUASII assigns objects to slices based on their single (lower) coordinate, it records a minimum bounding box for each slice taking into account the actual spatial extent of the objects and thus ensures the correctness of the query result. This also results in slice representations (their MBBs) that are often much smaller but not necessarily within the originally sliced bounds. For example, s</span><span class="c22">1 </span><span class="c8">contains only one object and thus has a very </span><span class="c1">small MBB (i.e., its box = o</span><span class="c4">2</span><span class="c1">), while the MBB of s</span><span class="c4">2 </span><span class="c1">is b</span><span class="c4">2 </span><span class="c1">and exceeds the original cut at x = 4 (Figure 4b). As we show later, this enables QUASII to discard many unnecessary slices during </span></p><p class="c5"><span class="c12">1</span><span class="c101">The upper coordinate </span><span class="c81">(</span><span class="c22">x</span><span class="c3">u</span><span class="c22">, y</span><span class="c3">u</span><span class="c22">, z</span><span class="c3">u</span><span class="c81">) </span><span class="c101">or the object&rsquo;s center (requires to be computed, </span><span class="c14">though) can equally be used. </span></p><p class="c5"><span class="c9">328 </span></p><p class="c5"><span class="c50">b</span><span class="c6">y </span></p><p class="c5"><span class="c96">s</span><span class="c124">x 1 </span></p><p class="c5"><span class="c13">X</span><span class="c86">q</span><span class="c48">1 </span></p><p class="c5"><span class="c84">s</span><span class="c76">1 </span></p><p class="c5"><span class="c84">s</span><span class="c76">2 </span></p><p class="c5"><span class="c84">s</span><span class="c76">3 </span><span class="c13">X</span><span class="c84">s</span><span class="c76">3 </span></p><p class="c11"><span class="c114">&prime;</span><span class="c84">s</span><span class="c76">4 </span><span class="c13">XXX</span><span class="c10">4 </span><span class="c13">X</span><span class="c94">x = 2 </span><span class="c13">Data array: </span></p><p class="c5"><span class="c13">Data array: </span><span class="c6">o</span><span class="c3">1 </span><span class="c6">o</span><span class="c3">2 </span><span class="c6">o</span><span class="c3">3 </span><span class="c15">o</span><span class="c3">4 </span><span class="c6">o</span><span class="c3">5 </span><span class="c15">o</span><span class="c3">6 </span><span class="c15">o</span><span class="c3">7 </span><span class="c15">o</span><span class="c3">8 </span><span class="c15">o</span><span class="c3">9 </span><span class="c15">o</span><span class="c3">0 </span></p><p class="c5"><span class="c6">o</span><span class="c3">2 </span><span class="c6">o</span><span class="c3">7 </span><span class="c15">o</span><span class="c3">9 </span><span class="c15">o</span><span class="c3">4 </span><span class="c6">o</span><span class="c3">6 </span><span class="c15">o</span><span class="c3">5 </span><span class="c15">o</span><span class="c3">8 </span><span class="c15">o</span><span class="c3">0 </span><span class="c15">o</span><span class="c3">1 </span><span class="c6">o</span><span class="c3">3 </span></p><p class="c5"><span class="c13">Data structure: </span></p><p class="c5"><span class="c13">Data structure: </span></p><p class="c5"><span class="c13">Data structure: </span></p><p class="c5"><span class="c13">l=1 </span></p><p class="c5"><span class="c108">s</span><span class="c12">0 </span></p><p class="c5"><span class="c13">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">1 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">2 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">3 </span></p><p class="c5"><span class="c13">l=1 </span><span class="c6">s</span><span class="c3">1 </span><span class="c13">box=</span><span class="c6">inf </span><span class="c13">ids=</span><span class="c6">0</span><span class="c13">:</span><span class="c6">9</span><span class="c17">o</span><span class="c0">0 </span><span class="c6">y </span></p><p class="c5"><span class="c86">q</span><span class="c48">1 </span></p><p class="c5"><span class="c17">o</span><span class="c0">0 </span><span class="c6">y </span></p><p class="c5"><span class="c47">s</span><span class="c40">23 </span></p><p class="c5"><span class="c13">X </span><span class="c86">q</span><span class="c48">1 </span></p><p class="c5"><span class="c13">box=</span><span class="c6">o</span><span class="c23">ids=</span><span class="c15">0</span><span class="c23">:</span><span class="c15">0</span><span class="c3">2 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">4</span><span class="c3">2 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">5</span><span class="c23">:</span><span class="c15">9</span><span class="c3">3 </span><span class="c13">box=</span><span class="c6">o</span><span class="c23">ids=</span><span class="c15">0</span><span class="c23">:</span><span class="c15">0</span><span class="c3">2 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">2 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">4</span><span class="c3">2 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">5</span><span class="c23">:</span><span class="c15">6</span><span class="c6">s</span><span class="c12">3 </span><span class="c7">&prime;</span><span class="c12">3 </span><span class="c7">&prime;</span><span class="c126">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">4 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">7</span><span class="c23">:</span><span class="c15">9</span><span class="c3">4 </span><span class="c13">l=2 </span></p><p class="c5"><span class="c13">l=2 </span></p><p class="c5"><span class="c23">l=2 </span></p><p class="c5"><span class="c6">s</span><span class="c3">21 </span></p><p class="c5"><span class="c13">l=2 </span><span class="c6">s</span><span class="c3">22 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">3</span><span class="c23">:</span><span class="c15">4 </span></p><p class="c5"><span class="c3">22 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">3</span><span class="c23">:</span><span class="c15">4 </span><span class="c3">22 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">2</span><span class="c3">21 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">3</span><span class="c23">:</span><span class="c15">4</span><span class="c3">22 </span><span class="c41">(a) Spatial data and query q</span><span class="c78">1 </span></p><p class="c5"><span class="c41">(d) After processing q</span><span class="c78">2 </span></p><p class="c5"><span class="c1">Figure 4: An example of query processing and incremental indexing in QUASII (configured with &tau;</span><span class="c22">x </span><span class="c8">= 4 and &tau;</span><span class="c22">y </span><span class="c8">= 2), given </span><span class="c1">ten spatial objects (o</span><span class="c22">0</span><span class="c8">&ndash;o</span><span class="c22">9</span><span class="c8">) and two range queries (q</span><span class="c22">1 </span><span class="c8">and q</span><span class="c22">2</span><span class="c8">). </span></p><p class="c11"><span class="c1">query execution. To limit unnecessary computation (as a slice can be reorganized multiple times until it is fully refined), QUASII computes a full MBB only when a slice is completely refined. Otherwise, a slice is represented with an open-ended MBB, i.e., the MBB has bounds only on the dimension it has been sliced on. Configuration.QUASII has only one configuration parameter, a size threshold &tau;, that determines the maximum number of ob- jects in a slice at the finest level. That is, at the bottom level, when- ever a slice s contains less or &tau; number of objects (i.e, |s| &le; &tau;), it is considered to be fully refined. Intuitively, this is similar to setting a (leaf) node size in the R-Tree. </span></p><p class="c2"><span class="c1">The sizes of the remainingd &minus;1 levels are calculated as follows. Since QUASII performs data-oriented slicing, the total number of partitions required to satisfy threshold &tau; is &lceil;n/&tau;&rceil;, where n is the total number of objects (i.e., n = |D|). Consequently, the number of times QUASII has to slice the data space across each dimension to produce &lceil;n/&tau;&rceil; partitions r = is </span><span class="c70">&lceil; </span><span class="c1">equal </span><span class="c70">&radic;</span><span class="c12">d</span><span class="c1">n/&tau;to: </span></p><p class="c5"><span class="c70">&rceil; </span><span class="c1">(1) </span></p><p class="c2"><span class="c1">If we use &tau;</span><span class="c22">d </span><span class="c1">to denote the slice threshold at the bottom level l = d (i.e., &tau;</span><span class="c22">d </span><span class="c1">= &tau;), then the maximum number of objects per slice for the remaining levels (up to the top) can be expressed recursively as &tau;</span><span class="c22">d&minus;1 </span><span class="c1">= r &times; &tau;</span><span class="c22">d</span><span class="c1">. Note that r corresponds to the number of sub-slices (within a slice) at each index level. </span></p><p class="c11"><span class="c1">Turning to our 2d example</span><span class="c21">2</span><span class="c1">, after x-based slicing in Figure 4b, s</span><span class="c22">1 </span><span class="c8">contains one object and thus is considered fully refined (i.e., </span><span class="c1">|s</span><span class="c22">1</span><span class="c8">| = 1 &le; &tau;</span><span class="c22">x</span><span class="c8">), while s</span><span class="c22">3 </span><span class="c8">has five objects and may be refined in the </span><span class="c1">future. Also note that s</span><span class="c4">3 </span><span class="c1">stores an open-ended MBB (s</span><span class="c4">3</span><span class="c1">.box = b</span><span class="c4">3</span><span class="c1">). The number of levels in QUASII is fixed and always equals to the dimensionality of the queried dataset. That is, it does not depend on the size of the dataset. Therefore, to accommodate the index growth (the index grows in breadth) and enable efficient query execution, QUASII keeps the children (within a slice) or- ganized/sorted according to the level&rsquo;s dimension. QUASII uses this order and the minimum bounding boxes (box) of each node </span></p><p class="c5"><span class="c12">2</span><span class="c101">To minimize the required number of objects in Figure 4, we fix </span><span class="c22">&tau;</span><span class="c3">x </span><span class="c22">= 4 </span><span class="c101">and </span><span class="c22">&tau;</span><span class="c35">y </span><span class="c22">= 2</span><span class="c101">. </span></p><p class="c5"><span class="c17">o</span><span class="c0">0 </span><span class="c6">y </span></p><p class="c5"><span class="c17">o</span><span class="c0">0 </span></p><p class="c5"><span class="c17">o</span><span class="c0">4 </span></p><p class="c5"><span class="c17">o</span><span class="c0">3 </span></p><p class="c5"><span class="c17">o</span><span class="c0">4 </span></p><p class="c5"><span class="c17">o</span><span class="c0">3 </span></p><p class="c5"><span class="c47">s</span><span class="c40">22 </span></p><p class="c5"><span class="c13">X </span><span class="c17">o</span><span class="c0">4 </span></p><p class="c5"><span class="c17">o</span><span class="c0">3 </span></p><p class="c5"><span class="c17">o</span><span class="c0">4 </span></p><p class="c5"><span class="c17">o</span><span class="c0">3 </span></p><p class="c5"><span class="c17">o</span><span class="c0">6 </span><span class="c98">o</span><span class="c0">1 </span></p><p class="c5"><span class="c17">o</span><span class="c0">6 </span><span class="c98">o</span><span class="c0">1 </span></p><p class="c5"><span class="c32">b</span><span class="c28">22 </span></p><p class="c5"><span class="c17">o</span><span class="c0">6 </span><span class="c98">o</span><span class="c0">1 </span></p><p class="c5"><span class="c17">o</span><span class="c0">6 </span><span class="c98">o</span><span class="c0">1 </span></p><p class="c5"><span class="c17">o</span><span class="c0">7 </span></p><p class="c5"><span class="c17">o</span><span class="c0">7 </span></p><p class="c5"><span class="c32">b</span><span class="c28">21</span><span class="c17">o</span><span class="c0">7 </span></p><p class="c5"><span class="c17">o</span><span class="c0">7 </span></p><p class="c5"><span class="c17">o</span><span class="c0">9 </span></p><p class="c5"><span class="c17">o</span><span class="c0">5 </span><span class="c17">o</span><span class="c0">9 </span></p><p class="c5"><span class="c50">b</span><span class="c10">2 </span></p><p class="c5"><span class="c17">o</span><span class="c0">5 </span><span class="c47">s</span><span class="c40">21 </span></p><p class="c5"><span class="c13">X </span><span class="c17">o</span><span class="c0">9 </span></p><p class="c5"><span class="c17">o</span><span class="c0">5 </span><span class="c17">o</span><span class="c0">9 </span><span class="c17">o</span><span class="c0">5 </span><span class="c17">o</span><span class="c0">2 </span></p><p class="c5"><span class="c17">o</span><span class="c0">8 </span><span class="c17">o</span><span class="c0">2 </span></p><p class="c5"><span class="c17">o</span><span class="c0">8 </span><span class="c50">b</span><span class="c10">3 </span></p><p class="c5"><span class="c17">o</span><span class="c0">2 </span></p><p class="c5"><span class="c17">o</span><span class="c0">8 </span><span class="c50">b</span><span class="c10">3 </span></p><p class="c5"><span class="c17">o</span><span class="c0">2 </span><span class="c17">o</span><span class="c0">8 </span><span class="c50">x = 2 x = 4 </span></p><p class="c5"><span class="c50">x = 5.5 </span><span class="c13">Data array: </span></p><p class="c5"><span class="c13">Data array: </span><span class="c6">o</span><span class="c3">2 </span><span class="c6">o</span><span class="c3">4 </span><span class="c6">o</span><span class="c3">6 </span><span class="c15">o</span><span class="c3">7 </span><span class="c15">o</span><span class="c3">9 </span><span class="c15">o</span><span class="c3">0 </span><span class="c15">o</span><span class="c3">1 </span><span class="c6">o</span><span class="c3">3 </span><span class="c15">o</span><span class="c3">5 </span><span class="c15">o</span><span class="c3">8 </span></p><p class="c5"><span class="c6">o</span><span class="c3">2 </span><span class="c6">o</span><span class="c3">7 </span><span class="c15">o</span><span class="c3">9 </span><span class="c15">o</span><span class="c3">4 </span><span class="c6">o</span><span class="c3">6 </span><span class="c15">o</span><span class="c3">0 </span><span class="c15">o</span><span class="c3">1 </span><span class="c6">o</span><span class="c3">3 </span><span class="c15">o</span><span class="c3">5 </span><span class="c15">o</span><span class="c3">8 </span></p><p class="c5"><span class="c13">Data structure: </span></p><p class="c5"><span class="c13">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">1 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">2 </span><span class="c23">l=1 </span></p><p class="c5"><span class="c6">s</span><span class="c3">3 </span><span class="c13">box=</span><span class="c6">o</span><span class="c23">ids=</span><span class="c15">0</span><span class="c23">:</span><span class="c15">0</span><span class="c3">2 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">4</span><span class="c3">2 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">5</span><span class="c23">:</span><span class="c15">9</span><span class="c3">3 </span><span class="c23">l=2 </span></p><p class="c5"><span class="c6">s</span><span class="c3">21 </span></p><p class="c20"><span class="c13">l=2 </span><span class="c6">s</span><span class="c3">22 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">2</span><span class="c3">21 </span><span class="c13">box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">3</span><span class="c23">:</span><span class="c15">4</span><span class="c3">22 </span><span class="c41">(c) After slicing based on y of q</span><span class="c78">1 </span></p><p class="c5"><span class="c94">q</span><span class="c48">2 </span></p><p class="c5"><span class="c50">b</span><span class="c76">3 </span><span class="c114">&prime;</span><span class="c6">x </span></p><p class="c5"><span class="c6">x </span></p><p class="c5"><span class="c6">x </span></p><p class="c5"><span class="c6">x </span></p><p class="c11"><span class="c13">l=2 box=</span><span class="c6">b</span><span class="c23">ids=</span><span class="c15">1</span><span class="c23">:</span><span class="c15">2 </span><span class="c3">21 </span><span class="c41">(b) After slicing based on x of q</span><span class="c78">1 </span></p><p class="c5"><span class="c1">to prune the amount of objects necessary to be tested during the query execution. </span></p><p class="c11"><span class="c30">5.2 Query Processing and Index Refinement </span><span class="c1">Having defined QUASII&rsquo;s data structure, we discuss how it is incrementally built and maintained as a side effect of each query. Query Processing. Algorithm 1 shows the pseudo-code for query processing. Each query traverses the d-level structure depth-first, starting from the first level (having x-slices). Because the slices are sorted, QUASII performs a binary search (Line 3) to find the starting slice. It then scans all the slices S[i] within the query range on the current dimension (i.e., while the loop conditions in Line 4 hold). The loop conditions guarantee that each slice S[i] intersects q only in the current dimension. To discard potential false positive slices early, Line 5 checks if its actual boundaries (S[i].box) also intersect with the query range. Next, QUASII potentially refines S[i] (Line 6), which may be further sliced into multiple more fine-grained slices S</span><span class="c21">&prime;&prime; </span><span class="c1">if it is larger than the maximum size threshold &tau; (discussed in the next algorithm). In Lines 7&mdash;16, QUASII traverses (potentially refined) slicesS</span><span class="c21">&prime;&prime;</span><span class="c1">. For eachs &isin; S</span><span class="c21">&prime;&prime;</span><span class="c1">, it either checks alls objects for intersec- tion in case of the bottom level or recursively proceeds querying its children based on the next level/dimension (a default child is assigned to a not fully refined slice, Line 15). Finally, all the newly created slices are accumulated in S</span><span class="c21">&prime; </span><span class="c1">(Line 17), appended to S (Line 19), and re-sorted (Line 20). The slices are sorted based on their ids, i.e., the position (index) of the first slice&rsquo;s object in the data array. </span></p><p class="c11"><span class="c1">Index Refinement. With each query, QUASII attempts to refine all query intersecting slices (i.e., Line 6 in Algorithm 1). Algorithm 2 provides the simplified pseudo-code for this refine- ment process. Note that the processing within Algorithm 2 is always based only on the current dimension/level of slice s (s.l). The input slice s is considered for slicing only if it exceeds the threshold &tau;. Given s is coarse enough, QUASII proceeds with determining the type of slicing based on the intersection between </span></p><p class="c5"><span class="c9">329 </span></p><p class="c5"><span class="c1">Algorithm 1: query</span><span class="c29">(</span><span class="c1">query q,data D,slices S,result R</span><span class="c29">) </span></p><p class="c5"><span class="c14">1: </span><span class="c1">S</span><span class="c21">&prime; </span><span class="c1">&larr; &empty; // to store newly created (refined) slices </span><span class="c14">2: </span><span class="c1">dim &larr; S[0].l // current level/dimension of slices in S </span><span class="c14">3: </span><span class="c1">i &larr; binarySearch</span><span class="c29">( </span><span class="c1">S, lower</span><span class="c29">(</span><span class="c1">q[dim]</span><span class="c29">) ) </span><span class="c14">4: </span><span class="c1">while i &lt; |S| and lower</span><span class="c29">(</span><span class="c1">S[i].box[dim]</span><span class="c29">) </span><span class="c1">&le; upper</span><span class="c29">(</span><span class="c1">q[dim]</span><span class="c29">) </span></p><p class="c5"><span class="c1">do </span><span class="c14">5: </span><span class="c1">if q &cap; S[i].box = &empty; then continue </span><span class="c14">6: </span><span class="c1">S</span><span class="c21">&prime;&prime; </span><span class="c1">&larr; refine</span><span class="c29">( </span><span class="c1">S[i], D, q </span><span class="c29">) </span><span class="c1">// as per Algorithm 2 </span><span class="c14">7: </span><span class="c1">for each slice s &isin; S</span><span class="c21">&prime;&prime; </span><span class="c1">do </span><span class="c14">8: </span><span class="c1">if q &cap; s.box &empty; then </span><span class="c14">9: </span><span class="c1">if s.l is the bottom level then </span><span class="c14">10: </span><span class="c1">for each j &isin; {s.ids} do </span><span class="c14">11: </span><span class="c1">if D[j] &cap; q &empty; then </span><span class="c14">12: </span><span class="c1">R &larr; R &cup; D[j] </span><span class="c14">13: </span><span class="c1">else </span><span class="c14">14: </span><span class="c1">if |s.children| = 0 then </span><span class="c14">15: </span><span class="c1">createDefaultChild</span><span class="c29">(</span><span class="c1">s</span><span class="c29">) </span><span class="c14">16: </span><span class="c1">query</span><span class="c29">(</span><span class="c1">q, D, s.children, R</span><span class="c29">) </span><span class="c14">17: </span><span class="c1">S</span><span class="c21">&prime; </span><span class="c1">&larr; S</span><span class="c21">&prime; </span><span class="c1">&cup; S</span><span class="c21">&prime;&prime; </span><span class="c14">18: </span><span class="c1">i &larr; i + 1 </span><span class="c14">19: </span><span class="c1">S &larr; S &cup; S</span><span class="c21">&prime; </span><span class="c14">20: </span><span class="c1">sort</span><span class="c29">(</span><span class="c1">S</span><span class="c29">) </span></p><p class="c11"><span class="c1">query q and slice s. It considers three types of slicing. If both q&rsquo;s lower and upper coordinates are within s, a three-way slicing is performed splitting s into three sub-slices (Line 5). If only one of q&rsquo;s coordinates is within s, a two-way slicing is performed splitting s into two sub-slices (Line 6). Finally, if q contains s (i.e., both q&rsquo;s coordinates are outside of s&rsquo;s bounds), QUASII performs a two-way slicing based on an artificially introduced coordinate. QUASII iterates through the generated slices and for the ones that still exceed &tau; (and overlap with the query) it applies addi- tional refinement according to artificially introduced boundaries in Line 10 (it repeats the process recursively until a slice is fully refined in the corresponding dimension). The three- and two- way slicing algorithms (Line 5 and Line 6) reorganize the data (D) following the incremental quick sort strategy introduced in database cracking [18]. In the reorganization process, QUASII also records the information about the boundaries (box) of newly created or modified slices. </span></p><p class="c2"><span class="c1">Example. Continuing with our example in Figure 4, after refining s</span><span class="c22">0 </span><span class="c8">into three x sub-slices in Line 6 of Algorithm 1 (and </span><span class="c1">resulting in Figure 4b), QUASII recursively continues with the intersecting (and just refined) slice s</span><span class="c4">2 </span><span class="c1">based on the y dimension (Figure 4c). As such, s</span><span class="c22">2 </span><span class="c8">is further refined based on the queried y </span><span class="c1">range and results in three new slices (s</span><span class="c22">21</span><span class="c8">,s</span><span class="c22">22</span><span class="c8">, ands</span><span class="c22">23</span><span class="c8">). In this step, </span><span class="c1">only the objects within the s</span><span class="c4">2 </span><span class="c1">range (ids = [1..4]) are three-way sliced and re-organized in the data array. The two new slices (s</span><span class="c22">23 </span><span class="c1">is empty) are appended to the data structure as children of s</span><span class="c22">2</span><span class="c8">. </span><span class="c1">They are fully refined (as |s</span><span class="c4">21</span><span class="c1">| &le; 2 and |s</span><span class="c4">22</span><span class="c1">| &le; 2) and have much smaller MBBs (b</span><span class="c22">21 </span><span class="c8">andb</span><span class="c22">22</span><span class="c8">, respectively) than the initial slice cuts. </span><span class="c1">Finally, because it is the bottom level, the objects within s</span><span class="c22">22 </span><span class="c8">are </span><span class="c1">checked against the query range and the two qualifying objects {o</span><span class="c22">4</span><span class="c8">,o</span><span class="c22">6</span><span class="c8">} are added to the result set (R). </span></p><p class="c2"><span class="c1">The subsequent queryq</span><span class="c22">2 </span><span class="c8">benefits greatly from previous slicing, </span><span class="c1">as illustrated in Figure 4d. For example, x-slices s</span><span class="c4">1 </span><span class="c1">and s</span><span class="c4">2 </span><span class="c1">are skipped completely because query q</span><span class="c22">2 </span><span class="c8">does not intersect with </span><span class="c1">their MBBs (i.e, test on Line 5 in Algorithm 1). Therefore, QUASII proceeds with the only intersecting slice s</span><span class="c4">3</span><span class="c1">, which is not fully refined and requires further slicing. As per Algorithm 2, this time a two-way slicing is performed (at x = 5.5) resulting in two finer </span></p><p class="c5"><span class="c1">Algorithm 2: refine</span><span class="c29">(</span><span class="c1">slice s, data D,query q</span><span class="c29">) </span><span class="c1">&minus;&rarr; slices S </span></p><p class="c5"><span class="c14">1: </span><span class="c1">if |s| &le; &tau;[s.l] then </span></p><p class="c5"><span class="c1">return {s} </span><span class="c14">2: </span><span class="c1">S &larr; &empty; // to store refined slices </span><span class="c14">3: </span><span class="c1">t &larr; determineSliceType</span><span class="c29">(</span><span class="c1">s, q</span><span class="c29">) </span><span class="c14">4: </span><span class="c1">switch ( t ) </span><span class="c14">5: </span><span class="c1">case both: S</span><span class="c21">&prime; </span><span class="c1">&larr; sliceThreeWay</span><span class="c29">(</span><span class="c1">s, q, D</span><span class="c29">) </span><span class="c14">6: </span><span class="c1">case one: S</span><span class="c21">&prime; </span><span class="c1">&larr; sliceTwoWay</span><span class="c29">(</span><span class="c1">s, q, D</span><span class="c29">) </span><span class="c14">7: </span><span class="c1">default: S</span><span class="c21">&prime; </span><span class="c1">&larr; sliceArtificial</span><span class="c29">(</span><span class="c1">s, q, D</span><span class="c29">) </span><span class="c14">8: </span><span class="c1">for each slice s &isin; S</span><span class="c21">&prime; </span><span class="c1">do </span><span class="c14">9: </span><span class="c1">if |s| &gt; &tau;[s.l] and q[s.l] &cap; s.box[s.l] &empty; then </span><span class="c14">10: </span><span class="c1">S</span><span class="c21">&prime;&prime; </span><span class="c1">&larr; sliceArtificial</span><span class="c29">(</span><span class="c1">s, q, D</span><span class="c29">) </span><span class="c14">11: </span><span class="c1">S &larr; S &cup; S</span><span class="c21">&prime;&prime; </span><span class="c14">12: </span><span class="c1">else </span><span class="c14">13: </span><span class="c1">S &larr; S &cup; s </span><span class="c14">14: </span><span class="c1">return S </span></p><p class="c2"><span class="c1">slices continues Since Finally, are checked s(s</span><span class="c4">3 </span><span class="c21">&prime;</span><span class="c1">the </span><span class="c4">3 </span><span class="c21">&prime;</span><span class="c45">reaches and </span><span class="c1">with actual for </span><span class="c45">s</span><span class="c4">4</span><span class="c1">) y-based intersection </span><span class="c45">the </span><span class="c1">replacing data </span><span class="c45">size </span><span class="c1">array slicing </span><span class="c45">threshold </span><span class="c1">the objects with of previous the withinsq</span><span class="c45">&tau;</span><span class="c22">2 </span><span class="c4">y</span><span class="c1">, fully </span><span class="c8">and </span><span class="c1">it slice is q</span><span class="c4">3 </span><span class="c8">the </span><span class="c21">&prime;</span><span class="c22">2</span><span class="c8">-contained </span><span class="c1">not </span><span class="c45">range </span><span class="c1">s</span><span class="c22">3</span><span class="c8">. qualifying </span><span class="c1">refined </span><span class="c8">Next, </span><span class="c45">(ids </span><span class="c8">QUASII </span><span class="c1">further. </span><span class="c8">slice s</span><span class="c22">3</span><span class="c4">&prime;</span><span class="c1">. </span></p><p class="c11"><span class="c45">= [5..6]) </span><span class="c8">o</span><span class="c22">8 </span><span class="c8">is </span><span class="c1">added to the result set. </span></p><p class="c2"><span class="c1">Artificial Refinement. To produce a balanced hierarchical structure QUASII has to conform with the defined thresholds when forming the slices and using only query boundaries does not meet these requirements. One query is usually not suffi- cient and we cannot use the subsequent queries for this purpose, as they may interfere with the existing order of the slices. For instance, reorganizing a slice again (that has been organized ac- cording to all dimensions) based on the x dimension, may disrupt the previously established partitioning for y and z dimensions. </span></p><p class="c2"><span class="c1">To address this problem, QUASII reorganizes a slice s (Lines 7 and 10 in Algorithm 2) until it meets a size threshold &tau; in the corresponding dimension. It achieves this by forcing a two-way slicing based on artificially introduced coordinate and thus split- ting the slice into two sub-slices. Given the range </span><span class="c29">(</span><span class="c1">x</span><span class="c22">l</span><span class="c1">,x</span><span class="c22">u</span><span class="c58">)</span><span class="c8">, the </span><span class="c1">new coordinate is c = &lfloor;</span><span class="c29">(</span><span class="c1">x</span><span class="c22">l </span><span class="c1">+ x</span><span class="c22">u</span><span class="c58">)</span><span class="c8">/2&rfloor;. The two new slices are </span><span class="c1">recursively sliced further until the threshold &tau; is satisfied. </span></p><p class="c5"><span class="c1">While more advanced approaches, e.g., based on the concepts from R*-Tree node splitting algorithms [6], would minimize over- lap in data structure, they would also significantly increase the cost of incremental strategy. Therefore, QUASII employs the above uniform and low-cost artificial slicing strategy to meet &tau; thresholds at each of d levels. </span></p><p class="c2"><span class="c1">Query &amp; Refine. The outcome of QUASII&rsquo;s reorganization strat- egy are the slices that are within the query range and consequently </span></p><p class="c5"><span class="c125">o </span><span class="c44">q </span><span class="c1">only the objects in these slices are checked for intersection. However, </span></p><p class="c5"><span class="c44">q&rsquo; </span></p><p class="c5"><span class="c1">performing the reorganization fol- </span></p><p class="c5"><span class="c106">x </span><span class="c1">lowing strictly the query&rsquo;s bound- aries would produce an incomplete result, as illustrated in Figure 5. For instance, the object o overlaps with the query range q, however, its lower coordinate is outside the query&rsquo;s boundaries and conse- quently o would not be identified as a part of the result. </span></p><p class="c5"><span class="c1">To ensure correct query execution while preforming refine- ment, QUASII employs the query extension technique [40]. More </span></p><p class="c5"><span class="c9">330 </span></p><p class="c5"><span class="c106">y</span><span class="c8">Figure 5: Refinement </span><span class="c1">step: query extension. </span></p><p class="c2"><span class="c1">precisely, it extends the query for maximum object extent in each dimension, considering lower coordinate. This extension is done only when performing refinement and only within not fully refined slice. Consequently, the query that performs refinement potentially considers more objects for intersection as its range is enlarged. However, this introduces a minimal overhead as the only alternative is the expensive scan of the entire unrefined slice. We apply the same logic for the binary search where, to avoid missing any slices due to the overlap within them, we extend the query range (while performing binary search) for the maximum slice extent in the corresponding dimension. </span></p><p class="c5"><span class="c30">6 EXPERIMENTAL EVALUATION </span><span class="c1">In this section, we first describe the experimental setup &amp; method- ology and then present a thorough experimental analyses that illustrates the benefits of our incremental approach, both on a real-world neuroscience and synthetic datasets. We start the anal- yses by outlining the shortcomings of the approaches based on space-oriented partitioning in Section 6.2. We then study the incremental approaches by comparing them with their static counterparts in Section 6.3 and cross-evaluating their perfor- mance in Section 6.4. Finally, Section 6.5 describes the sensitivity analyses of QUASII. </span></p><p class="c5"><span class="c30">6.1 Experimental Setup &amp; Methodology </span><span class="c1">Hardware. We run our experiments on a Red Hat Enterprise Linux Server release 7.3 machine equipped with 2 Intel Xeon CPU E5-2650L processors at 1.80GHz and 768GB of RAM. Each processor has 12 cores (24 hardware threads) with private L1 (32KB) and L2 (256KB) caches and 30MB of shared L3 cache. Implementations. All indexing techniques are implemented in C++ and compiled with </span><span class="c29">g++ 4.9.3 </span><span class="c1">with the maximum optimiza- tion level. The list below summarizes the implementations that we study: Scan: performs a full data scan to answer each query. SFCracker: is our incremental variant of database cracking [18] for spatial data, described in Section 3.1. We use the Z-order as a SFC order. The average farthest distance of neighbours in the Z-order is (slightly) higher than in the Hilbert order [10] (i.e., it has better locality), however, we opt to use the Z-order due to its simplicity and the huge body of work on its efficient range query algorithms [5, 39, 43, 44]. We use 32-bit to represent zcodes (i.e., 10 bits per dimension) as a trade-off between memory resources and precision (the number of false positives to be filtered). SFC: is a static counterpart of SFCracker. In the pre-processing phase, SFC transforms data from multi- to one-dimensional do- main and sorts it according to the produced SFCcodes. During querying, a (3d) query range is also converted to a 1d range and a binary search is used to locate the objects in the 1d interval. We employ the same representation of zcodes and query optimization as in SFCracker (described in Section 3.1). QUASII: is our incremental approach discussed in Section 4. We use 60 objects as a node capacity &tau;</span><span class="c22">z</span><span class="c8">. </span><span class="c1">R-Tree: According to our setting, all data is available before query- ing. Therefore, we use a bulk-loading approach to build the R-Tree index as it reduces overlap and decreases pre-processing time compared to the R-Tree built by inserting one object at a time [26]. For this purpose, we use an efficient STR [26] bulk-loading strat- egy that balances well the overhead of partitioning the data and query performance. It outperforms Hilbert R-Tree [23] in terms of query performance [26], while its pre-processing cost is not </span></p><p class="c5"><span class="c18">0</span><span class="c19">51015202530 </span></p><p class="c11"><span class="c18">100 220 100 220 Uniform Neuro </span><span class="c112">Query execution time (s) </span><span class="c123">Datasets &amp; Configurations </span></p><p class="c5"><span class="c41">(b) Configuration </span></p><p class="c5"><span class="c1">Figure 6: The impact of space-oriented partitioning. </span></p><p class="c5"><span class="c1">significantly higher [42]. Similarly, TGS [12] and PR-Tree [4] can outperform STR on datasets with extreme skew and aspect ratio, however, they incur considerable overhead for data partition- ing. We use the same configuration for node capacity (60) as in QUASII. Mosaic: corresponds to the space-oriented incremental approach described in Section 3.2. Grid: is a uniform grid-based index used as a static counterpart of Mosaic. We use query extension [40] technique (as discussed in Section 3.2) to assign an object to a grid cell. We use two config- urations with 100 and 220 partitions per dimension for synthetic and neuroscience datasets, respectively. Both configurations are obtained through a parameter sweep. Dataset and Queries. We use real-world neuroscience and syn- thetic datasets. Neuroscience: we use a small part of the rat brain model repre- sented with 450 million cylinders as elements in a volume of 285 &mu;m</span><span class="c21">3</span><span class="c1">. We approximate the cylinders with MBBs, resulting in the total number of 450 million MBBs with a size of 21GB on disk. Based on the previously described use cases, we synthetically generate queries, each having a fixed volume qvol of 10</span><span class="c21">&minus;2</span><span class="c1">% of the queried brain volume and a clustered distribution. We gener- ate 5 query clusters each with 100 queries, where query centers are distributed around the cluster centers following a Gaussian distribution (&mu; = 0, &sigma; = qvol). Synthetic: we create synthetic datasets by distributing spatial boxes in a space of 10 000 units in each dimension of the 3d space. The length of each side of each box is determined uniform randomly between 1 and 10 for 99% of the objects, while 1% of the objects has a side ranging from 10 - 1000 units. The spatial elements are distributed according to a uniform distribution. The datasets have 500 million and 1 billion elements (size on disk 22.5GB and 45GB). For completeness and to test non-skewed cases, we generate uniform workload. The uniform workload contains up to 10 000 uniformly distributed queries. To have range queries of different selectivity, we vary qvol: 10</span><span class="c21">&minus;3</span><span class="c1">%, 10</span><span class="c21">&minus;1</span><span class="c1">%, 1%, and 10% of the universe. </span></p><p class="c5"><span class="c30">6.2 Space-oriented Partitioning Challenges </span><span class="c1">Both, Mosaic and SFCracker (introduced in Section 3), use space- oriented partitioning at their core &mdash; Mosaic partitions space, while SFCracker assigns the SFCcodes using a uniform grid. Be- fore we start the analysis of incremental approaches we experi- mentally demonstrate the shortcoming of space-oriented parti- tioning &mdash; the overhead introduced with data assignment strat- egy &mdash; since it also affects incremental solutions. Further on, we illustrate why a static approach based on space-oriented parti- tioning, such as a uniform grid, is not a suitable replacement for an incremental index despite having a comparatively cheap pre-processing step (once properly configured). </span></p><p class="c5"><span class="c9">331 </span></p><p class="c5"><span class="c18">0</span><span class="c19">51015202530354045 </span></p><p class="c5"><span class="c18">R-Tree GridQueryExt GridReplication </span></p><p class="c5"><span class="c41">(a) Query execution </span></p><p class="c5"><span class="c12">100 </span><span class="c21">) s(e mitn oitucexey reuQ</span><span class="c12">100 0 100 200 300 400 500 100 </span></p><p class="c5"><span class="c43">R-Tree QUASII Scan </span></p><p class="c5"><span class="c12">0 100 200 300 400 500 </span></p><p class="c5"><span class="c12">0 100 200 300 400 500 </span><span class="c4">a) Query sequence </span></p><p class="c5"><span class="c4">b) Query sequence </span></p><p class="c5"><span class="c4">c) Query sequence </span></p><p class="c5"><span class="c1">Figure 7: Convergence of a) one-dimensional, b) space-oriented c) data-oriented based approaches. </span></p><p class="c5"><span class="c7">10 </span><span class="c12">1</span><span class="c43">SFC SFCracker Scan </span><span class="c7">10 </span></p><p class="c5"><span class="c7">10 </span></p><p class="c5"><span class="c12">0.01 </span></p><p class="c5"><span class="c43">Grid Mosaic Scan </span></p><p class="c5"><span class="c7">10 </span></p><p class="c5"><span class="c7">111</span><span class="c12">0.10.10.10.01 </span></p><p class="c5"><span class="c12">0.01 </span></p><p class="c5"><span class="c12">0.001 </span></p><p class="c5"><span class="c21">) s(e mite vitalumu</span><span class="c4">C</span><span class="c12">10000 1000 </span></p><p class="c5"><span class="c12">10000 10000 </span></p><p class="c5"><span class="c56">SFC </span><span class="c43">SFCracker </span><span class="c7">10 </span><span class="c128">Scan </span></p><p class="c2"><span class="c43">R-Tree QUASII Scan </span></p><p class="c5"><span class="c12">0 100 200 300 400 0 100 200 300 400 </span><span class="c22">c) Query sequence</span><span class="c1">Figure 8: Cumulative time of a) one-dimensional, b) space-oriented c) data-oriented based approaches. </span></p><p class="c2"><span class="c1">Data Assignment. In the first experiment we illustrate the im- pact of data assignment strategies by comparing the performance of Grid and R-Tree. We use two variants of the Grid approach: GridQueryExt avoids the objects replication by using the query extension technique &mdash; it assigns an object to the grid partition based on its center, while GridReplication replicates the objects &mdash; it assigns an object to all the overlapping partitions. </span></p><p class="c2"><span class="c1">Figure 6a) shows the results of the experiments where we exe- cute 500 clustered queries of selectivity 0.01% on the neuroscience dataset. GridReplication is heavily affected by object replication which increases the number of objects necessary to be checked for intersection and introduces an expensive de-duplication step (needed due to objects replication). GridQueryExt achieves better performance, however, it still considers 3.1&times; more objects for intersection than the R-Tree as it extends the initial query for the maximum object extent. The R-Tree clearly outperforms both GridReplication and GridQueryExt with a speedup of 19.4&times; and 3.7&times; respectively. </span></p><p class="c2"><span class="c1">Configuration. In the second experiment we demonstrate the difficulty to configure the grid-based approaches. We use two datasets with identical extent and number of elements but different data distributions: Uniform (uniform distribution, syn- thetic dataset) and Neuro (skewed distribution, the neuroscience dataset). We use the same experimental setup as for the previous experiment. The best configuration (number of partitions per dimension) is 100 for Uniform and 220 for the Neuro dataset and is determined in a parameter sweep. We measure the execu- tion time when using both configurations for each dataset and illustrate the results in Figure 6b). </span></p><p class="c2"><span class="c1">Although both datasets have the same number of elements and extent, the best configuration significantly depends on the data distribution &mdash; the neuroscience dataset requires more partitions compared to the Uniform dataset since it has the very dense regions that require fine grained partitioning. Furthermore, the grid configuration significantly affects performance &mdash; the grid performance on the Uniform dataset deteriorates notably when using the Neuro dataset configuration and vice versa. </span></p><p class="c5"><span class="c56">Grid </span><span class="c43">Mosaic </span></p><p class="c5"><span class="c7">10 </span><span class="c43">Scan </span></p><p class="c11"><span class="c12">10 100 200 300 400 </span><span class="c4">b) Query sequence</span><span class="c12">1000 1</span><span class="c4">a) Query sequence</span><span class="c12">1000 100 </span></p><p class="c5"><span class="c12">100 </span></p><p class="c5"><span class="c12">100 </span></p><p class="c5"><span class="c1">Summary.Space-oriented partitioning introduces performance penalties. Depending of data assignment strategy, we either con- sider more elements or suffer from replication. Additionally, the grid configuration is non-trivial and using the wrong one has a detrimental impact on the execution time. In practice we have to use a parameter sweep to find the configuration for a given workload. Consequently, grid configuration turns into a time- consuming process, increasing data-to-insight time. </span></p><p class="c5"><span class="c30">6.3 Incremental versus Static </span><span class="c1">We first analyze the incremental approaches by comparing their performance with the performance of their static counterparts (introduced in Section 6.1). Each static approach has similar prop- erties as its incremental counterpart, however, it involves nec- essary pre-processing. We categorize the approaches according to these properties as a) one-dimensional, b) space-oriented and c) data-oriented approaches. For each category we present the performance of the incremental approach, its static counterpart and Scan. We first evaluate if and when the approaches converge to the performance of their static counterparts and then analyze the overhead of the incremental strategy. For this purpose we ex- ecute the clustered query workload with 500 queries of selectivity 0.01% on the neuroscience dataset. </span></p><p class="c2"><span class="c1">Convergence. In the first experiment we evaluate the conver- gence of the incremental approaches &mdash; how fast an approach con- verges to the execution time of a fully indexed dataset. Figure 7 measures the execution time of each query for all approaches. </span></p><p class="c2"><span class="c1">The results show five peaks in execution time, one for each query cluster. The execution of the first cluster of queries (and the associated processing of the data) takes the longest as no index structure exists at the beginning. The first queries therefore exceed the cost of Scan, because at this point, the entire dataset has to be scanned along with building partial index structures. Subsequent queries within a cluster use a partial index and thus execute in less time than a full scan, but take longer than queries on the static approach. This process continues as queries in the </span></p><p class="c5"><span class="c9">332 </span></p><p class="c5"><span class="c87">QUASII </span><span class="c64">) s(e mitn oitucexey reu</span><span class="c42">Q</span><span class="c85">100 </span></p><p class="c5"><span class="c104">Scan R-Tree QUASII Mosaic SFCracker </span></p><p class="c5"><span class="c85">400 </span></p><p class="c5"><span class="c97">Mosaic </span><span class="c55">10 </span></p><p class="c5"><span class="c87">SFCracker </span><span class="c97">Grid </span><span class="c55">1</span><span class="c85">0.10.01 </span></p><p class="c5"><span class="c85">0 100 </span><span class="c42">Query </span><span class="c85">200 </span><span class="c42">sequence </span></p><p class="c5"><span class="c85">300 400 500 </span></p><p class="c5"><span class="c85">0 100 200 300 400 </span></p><p class="c5"><span class="c41">(a) Convergence </span></p><p class="c5"><span class="c41">(b) Cumulative time </span></p><p class="c5"><span class="c1">Figure 9: Comparative analysis of incremental approaches. </span></p><p class="c2"><span class="c1">same cluster further refine the index. Queries in one cluster not only refine the index locally but also carry out limited, global refinement. The queries in a subsequent cluster thus benefit from previous clusters and execute faster. As the index converges to its full structure, the query execution time approaches that of the to static approach. </span></p><p class="c2"><span class="c1">Cumulative Response Time. While in the previous set of ex- periments we measure the individual query performance, in this analysis we measure the cumulative execution time (including index building step for the static approaches). Figure 8 illustrates the experimental results. </span></p><p class="c2"><span class="c1">Similar to the convergence experiment, the query clusters are visible: the cumulative response time jumps each time the experi- ment moves to a new cluster. The most expensive is the transition from the first to the second cluster while subsequent transitions become less evident as the index becomes more refined. </span></p><p class="c2"><span class="c1">The cumulative cost of SFCracker is comparatively high and, crucially, with a very expensive first query. One reason is that the first query takes 12.9% of the total pre-processing by assign- ing the objects to the grid cells and calculating the zcode values for the entire dataset. Adding to this the cost of cracking, the total execution time of the first query grows to 43% of the total pre-processing time. More precisely, in order to minimize the overhead introduced by the transformation to 1d space, we par- tition the 1d query range into sub-intervals that tightly cover its original 3d range. This optimization [43] results in a high number of small intervals per query &mdash; on average 197. As a consequence, the first queries crack the previously uncracked area into a number of small adjacent intervals and therefore reorganize significant amounts of data. </span></p><p class="c2"><span class="c1">The static (SFC) index, on the other hand, is not substantially slower for the first queries or, put differently, the building cost of SFC is not much higher than the first query of SFCracker. In fact, the cumulative execution time of SFCracker exceeds the one of SFC after 23 queries already. The incremental approach SFCracker thus does not offer a considerable benefit over SFC. </span></p><p class="c2"><span class="c1">The incremental strategy of Mosaic is less expensive compared to SFCracker &mdash; the objects within the partition queried are poten- tially reassigned to the eight newly created partitions based on their location. Therefore, it takes Mosaic longer, i.e., 100 queries, before it exceeds the cumulative time of the static Grid. However, its cumulative execution time is still considerable with the biggest overhead being its top-down incremental strategy. The top-down strategy ensures fast convergence but it also introduces overhead </span></p><p class="c5"><span class="c88">) s(e mite vitalumu</span><span class="c42">C</span><span class="c85">300 200 </span></p><p class="c5"><span class="c85">100 </span></p><p class="c5"><span class="c85">0.001 </span></p><p class="c5"><span class="c85">0 </span></p><p class="c5"><span class="c42">Query sequence </span></p><p class="c5"><span class="c1">as the data in frequently queried areas is re-partitioned multiple times until Mosaic reaches its final level of refinement. </span></p><p class="c2"><span class="c1">QUASII, at the same time, does not exceed the cumulative exe- cution of the R-Tree in our experiments. Even after 500 executed queries, the cumulative execution time for QUASII is 39.4% of that of the R-Tree. The main benefit comes from its partial reor- ganization strategy where the objects are gradually reorganized within the query boundaries, as opposed to the complete sort. </span></p><p class="c2"><span class="c1">Summary. While all the incremental approaches reach the performance of their static counterparts, the incremental strate- gies of SFCracker and Mosaic are comparatively expensive. As we show for SFCracker, the major bulk of work has to be done when executing the first query &mdash; as the data needs to be trans- formed to 1d space and a single query has to perform multiple cracking operations to avoid performance penalties due to the transformation to 1d space. Mosaic increases its cumulative time considerably due to its top-down partitioning strategy &mdash; it reor- ganizes data in frequently queried areas multiple times until it reaches its final level of refinement. Only the cumulative execu- tion time of QUASII does not exceed the one of its static counter part, the R-Tree, in our experiments. </span></p><p class="c5"><span class="c30">6.4 Comparative Analysis </span><span class="c1">We now compare the performance of incremental approaches. We use the same setup as previously and measure the convergence of execution time as well as the cumulative execution time. </span></p><p class="c2"><span class="c1">Convergence. Figure 9a) depicts the single query execution time for all the incremental approaches compared with the R-Tree and Scan. We use the R-Tree approach as a reference because it is the fastest approach among the static indexes for the workloads tested. We analyze the execution time of the first query and then focus on the performance of the converged data structure. </span></p><p class="c2"><span class="c1">The execution time of the first query determines data-to- insight time and thus has to be as small as possible. Among the incremental approaches, SFCracker has the most expensive first query due to the transformation of data to the 1d space. Mosaic&rsquo;s first query is faster, but still expensive as it has to reassign all the objects to new partitions, examining all three coordinates. Finally, QUASII has the least expensive first query due to the nested data reorganization &mdash; the number of objects necessary to be examined and reorganized becomes smaller as more dimensions are taken into account: all objects are scanned on the x-dimension, but on the y-dimension only the objects with a x-value satisfying the </span></p><p class="c5"><span class="c9">333 </span></p><p class="c5"><span class="c67">Q</span><span class="c46">) s(e mitn oitucexey reu</span><span class="c27">100 </span></p><p class="c5"><span class="c27">0 100 </span><span class="c67">a) Query </span><span class="c27">200 </span><span class="c67">sequence </span></p><p class="c5"><span class="c27">300 400 500 </span></p><p class="c20"><span class="c46">) s(e mitn oitucexey reuQ</span><span class="c53">10 </span><span class="c90">R-Tree QUASII Scan </span><span class="c53">10 11</span><span class="c27">0.10.1</span><span class="c90">R-Tree QUASII Scan </span></p><p class="c5"><span class="c27">10000 </span><span class="c46">) s(e mite vitalumu</span><span class="c67">C</span><span class="c27">1000 100 </span></p><p class="c5"><span class="c53">10 </span></p><p class="c5"><span class="c27">0 20 40 60 80 100 </span><span class="c27">0 100 200 300 400 </span></p><p class="c5"><span class="c67">b) Query sequence </span></p><p class="c5"><span class="c46">) s(e mite vitalumu</span><span class="c67">C</span><span class="c27">10000 1000 </span></p><p class="c11"><span class="c91">R-Tree </span><span class="c60">QUASII GRID Scan </span><span class="c27">0.01 </span></p><p class="c5"><span class="c27">10 20 40 60 80 </span></p><p class="c20"><span class="c67">c) Query sequence d) Query sequence</span><span class="c1">Figure 10: Convergence and cumulative time: the first 500 (a &amp; c) and last 100 (b &amp; d) queries. </span></p><p class="c11"><span class="c1">query will be scanned (accordingly for the z-dimension). Over- all, Scan is 13.7, 9.2 and 4.6 times faster compared to SFCracker, Mosaic and QUASII respectively, when executing the first query. Among the incremental approaches, only QUASII attains the query execution time of R-Tree on a fully converged index. Mo- saic and SFCracker have at their core space-oriented partitioning and therefore, their performance is affected by the data assign- ment strategy as well as the skew in distribution, as Section 6.2 shows. SFCracker additionally transforms data to 1d domain and thus cannot preserve spatial proximity to the same extent as the other approaches. Consequently, QUASII outperforms Mosaic and SFCracker with a speedup of 3.68x and 4.9x respectively for the average execution time of a query in a fully refined area. </span></p><p class="c2"><span class="c1">Cumulative Execution Time. We use the cumulative execu- tion time as metric to evaluate the decrease in the data-to-insight time as well as the &quot;break-even&quot; point &mdash; the point when the cu- mulative cost of incremental exceeds that of static indexing &mdash; to assess the quality of an incremental index. Figure 9b) shows the experimental results. We use Grid as a reference since it has the smallest cumulative execution time among the static approaches &mdash; its pre-processing step is comparatively cheap (once its optimal configuration is determined). </span></p><p class="c2"><span class="c1">As discussed in Section 6.3, SFCracker and Mosaic have com- paratively expensive strategies and thus reach the performance of Grid after13 and100 queries respectively. Grid, on the other hand, compared to QUASI, has not amortized its building cost after 500 queries. More precisely, QUASII reaches 84% of the Grid cumu- lative execution time and, more importantly, it achieves 3.66x faster query performance for completely refined areas. QUASII executes the first query the fastest and consequently achieves the highest decrease in data-to-insight time &mdash; 5.1x and 11.4x compared to Grid and R-Tree. </span></p><p class="c2"><span class="c1">For single query execution, the major benefit of QUASII comes from its data-oriented partitioning. Similar the to R-Tree, it ad- justs to the distribution of the data and, as opposed to Grid and SFC, it does not replicate the objects or extend the query. It ad- ditionally keeps the data in multidimensional space and does consequently not suffer from decrease in dimensionality. Its low cumulative cost is mostly attributed to its incremental strategy. QUASII does not sort all objects, but rather reorganizes them within the specific bounds, gradually curbing the amount of data necessary to be reorganized. </span></p><p class="c2"><span class="c1">Summary.QUASII outperforms other incremental approaches with respect to the convergence of execution time and cumula- tive time. It achieves performance comparable to the R-Tree (the fastest static approach) in the areas of the dataset where enough queries have been executed, while not exceeding the cumula- tive time of Grid (the static approach with the least expensive pre-processing) or the R-Tree. Its major benefits come from the data-oriented partitioning and the nested reorganization strategy which reorganizes precisely the data touched and used. </span></p><p class="c5"><span class="c60">R-Tree </span></p><p class="c5"><span class="c27">100 </span></p><p class="c5"><span class="c60">QUASII Grid </span></p><p class="c11"><span class="c53">10 </span><span class="c60">Scan </span><span class="c27">0.01 </span></p><p class="c5"><span class="c27">1</span><span class="c1">Building Querying </span></p><p class="c5"><span class="c1">Figure 11: Analysis of QUASII: scalability. </span></p><p class="c5"><span class="c30">6.5 Analysis of QUASII </span><span class="c1">In this section we focus on QUASII. We evaluate its performance on the workloads other than neuroscience, analyze its scalability and the impact of query selectivity. </span></p><p class="c5"><span class="c30">6.6 Uniform Workload </span><span class="c1">In the previous analyses we used workloads with query clus- ters that show the benefit of incremental approaches: the index quickly converges to the final performance as the queries are targeting the same areas. In this experiment we evaluate the per- formance of QUASII for a uniform workload. We execute 10000 uniformly distributed queries of selectivity 0.1% on the dataset with uniform distribution and 500M elements. We compare the performance of QUASII with Scan and R-Tree and additionally consider Grid for the cumulative execution time. Figure 10 illus- trates both convergence and cumulative time for the first 500 and last 100 queries of the workload. </span></p><p class="c2"><span class="c1">None of the first 500 queries is executed on a completely re- fined index. Starting with the 300th query, however, the single query execution is close to the final performance. Among the last 100 queries, 64 are executed on a completely refined index. The performance of queries on the refined structure is equal or very close to the performance of the R-Tree, i.e., on average 7.5% slower than the R-Tree. </span></p><p class="c2"><span class="c1">After 10000 executed queries QUASII reaches 75% and 63.8% of the cumulative time of the R-Tree and Grid approaches respec- tively (y axis is in log scale). Likewise, it decreases data-to-insight time by 10.3x and 5.6x compared to R-Tree and Grid. Although the pre-processing step of Grid is significantly cheaper compared to the R-Tree, its cumulative time deteriorates with more queries executed due to the expensive single query performance. </span></p><p class="c5"><span class="c30">6.7 Performance Trends </span><span class="c1">In the following experiment we evaluate the scalability of QUASII by executing 10000 queries of selectivity 0.1% on datasets with </span></p><p class="c5"><span class="c9">334 </span></p><p class="c5"><span class="c4">1200 </span><span class="c80">) s(e mite vitalumu</span><span class="c120">C</span><span class="c4">1000 800 </span></p><p class="c5"><span class="c4">600 </span></p><p class="c5"><span class="c4">400 </span></p><p class="c5"><span class="c4">200 </span></p><p class="c5"><span class="c4">0 </span></p><p class="c5"><span class="c4">R-Tree QUASII R-Tree QUASII </span></p><p class="c20"><span class="c4">500 1000 </span><span class="c120">Objects in datasets (millions) </span></p><p class="c5"><span class="c116">Building Querying </span></p><p class="c5"><span class="c1">Figure 12: Analysis of QUASII: impact of selectivity. </span></p><p class="c2"><span class="c1">500 million and 1 billion elements. In Figure 11 we compare the cumulative time of QUASII with R-Tree, where we additionally split the execution time of R-Tree into Building and Querying. </span></p><p class="c2"><span class="c1">After 10000 executed queries QUASII reaches 75% and 73.7% of the cumulative time of the R-Tree with datasets of 500M and 1B elements respectively. By the time the R-Tree finishes its building process QUASII has executed around 8000 queries in both cases. QUASII also decreases data-to-insight time by 10.3x (on the 500M dataset) and 10.6x (on the 1B dataset) compared to the R-Tree. As illustrated in this experiment, QUASII maintains the performance trends as the dataset size increases. </span></p><p class="c5"><span class="c30">6.8 Impact of Selectivity </span><span class="c1">In this set of experiments we evaluate the impact of query selec- tivity on the performance of QUASII. We measure the cumulative time for a uniform workload: 500M dataset and 5000 queries of 0.001%, 1%, and 10% selectivity. Figure 12 illustrates the results where we consider both the R-Tree and QUASII. </span></p><p class="c2"><span class="c1">Intuitively, a static index (R-Tree) takes more time to amortize its building cost when executing 0.001% selectivity queries. On the other hand, the lower selectivity queries (10%) touch and reorganize a significant amount of data and QUASII thus reaches the break-even point with the R-Tree faster. Overall, after 5000 executed queries, QUASII reaches 68.8%, 79.8% and 85.6% of the cumulative time of the R-Tree for queries with 0.001%, 1%, and 10% selectivity. </span></p><p class="c5"><span class="c30">7 RELATED WORK </span><span class="c1">To the best of our knowledge, no incremental strategy has been proposed to spatial indexing in main memory. While recently an incremental indexing technique has been proposed for ex- ploration of multiple spatial datasets [35], the addressed prob- lem is different (spatial search within multiple datasets) and the proposed solution focuses solely on disk-based efficiency, i.e., reducing the number of expensive disk I/O operations. Never- theless, there has been considerable interest in incremental data processing within relational databases. Therefore, before giving an overview of related (but not incremental) spatial indexing techniques, we briefly describe incremental approaches used by relational database systems. </span></p><p class="c5"><span class="c30">7.1 Relational Incremental Indexing </span><span class="c1">Incremental (one-dimensional) indexing techniques are exten- sively studied in database cracking [16, 18, 19] and adaptive merg- ing [13, 14]. The former partially sorts keys in an in-memory </span></p><p class="c5"><span class="c117">C</span><span class="c93">) s(e mite vitalumu</span><span class="c16">4000 3000 </span></p><p class="c5"><span class="c16">2000 </span></p><p class="c5"><span class="c16">1000 </span></p><p class="c5"><span class="c16">0 </span></p><p class="c5"><span class="c16">R-Tree QUASII R-Tree QUASII R-Tree QUASII </span></p><p class="c5"><span class="c16">0.001 1 10 </span></p><p class="c5"><span class="c117">Query selectivity (%) </span></p><p class="c2"><span class="c1">relation, essentially performing quicksort. The latter, adaptive merging, takes the idea further and devises an incremental, ex- ternal sort to make use of external memory as well. </span></p><p class="c2"><span class="c1">Driven by the same goal (minimize data-to-insight time), novel systems have been proposed that bypass data pre-processing step and execute queries on raw data files. Instead, auxiliary data structures are built incrementally so that the most popular data subsets are serviced at the speeds of fully loaded/indexed data. For example, NoDB [2], RAW [25], and ViDa [24] incrementally build positional maps to track the position of frequently accessed data fields. This enables the systems to &ldquo;jump&rdquo; to previously queried data regions and potentially reduce the costs of tokenizing and parsing raw data sources. </span></p><p class="c5"><span class="c30">7.2 Spatial Indexing </span><span class="c1">Research in indexing spatial data has produced numerous ap- proaches in past decades [11]. In the following we briefly review spatial indexing approaches that we group into three classes depending on how amenable they are to incremental indexing. </span></p><p class="c2"><span class="c1">One-dimensional Indexing. One way to address the curse of dimensionality in the context of spatial data is to transform it from multi- to one-dimensional domain. Typical methods to perform this transformation are space-filling curves like the Z- order [34], the Hilbert curve [21], and the Gray-code curve [9]. They impose a total order and preserve spatial proximity between objects - if the objects are close in higher-dimensional space, they are also close on the space-filling curve - reasonably well. Given such a mapping of spatial data, the existing 1d access methods, such as B-Tree [5], can be used for querying. </span></p><p class="c2"><span class="c1">Data-oriented Indexing. The data-oriented partitioning ap- proaches create an index structure taking into consideration the data distribution, where the prominent representatives are the KD-Tree [7], the R-Tree [15], and its variants. The R-Tree, arguably the most important data-oriented spatial index, is multi- dimensional generalization of the B-Tree which recursively en- closes objects in minimum bounding rectangles (MBRs). The basic R-Tree definition faces the problems of overlap and dead space, both detrimental to query execution performance [15, 42]. Multi- ple approaches have been devised to address the issue. The R*- Tree [6], for example, uses an improved version of the node split algorithm and reinsertion of objects while the R+-Tree [37] tries to avoid overlap through the duplication of MBRs (leading to a big- ger index). A priori knowledge of the entire dataset may help to re- duce the above problems of the R-Tree by packing spatially close objects on the same disk page. The Hilbert R-Tree [23] achieves this using the Hilbert curve, Sort-Tile-Recursive (STR) [26] recur- sively sorts objects in all dimensions to do so, while Top-down Greedy Split (TGS) [12] recursively splits the data set into parti- tions minimizing the area on each level. </span></p><p class="c2"><span class="c1">Adaptive index structures [41] rearrange the nodes of data- oriented hierarchical indexes (including the R-Tree index) in response to queries so that they can be accessed sequentially on disk. However, this reorganization is performed to improve query performance by optimizing disk-access without taking into consideration data-to-insight time. </span></p><p class="c2"><span class="c1">A recently proposed partitioning mechanism for large-scale spatial data also adapts to an incoming query workload [3]. In contrast to QUASII, however, its primary goal is not to minimize data-to-insight time (as all necessary data structures are still built during pr-eprocessing), but to efficiently accommodate changes in data and workload. Also, it considers a distributed setting. </span></p><p class="c5"><span class="c9">335 </span></p><p class="c68"><span class="c1">Space-oriented Indexing. The space-oriented partitioning approaches assign the data to the partitions based on space, re- gardless of data distribution. A typical representative is the uni- form grid that partitions the space uniformly into partitions of equal size [38]. Similarly, the Quadtree [36] and its variant for 3d space, the Octree [20], recursively divide space into four/eight partitions of equal size to build a hierarchy of partitions. Further approaches, for example the grid file [32], use a non-uniform grid to better accommodate skew in the data (and to also optimize for disk access). The downside, is a more complex query execution due to the cells of different size and location. The two level grid file [17] addresses the issue by introducing an additional level with a coarser grid. Still, the overhead of testing the query against multiple cells can be substantial. </span></p><p class="c119"><span class="c30">8 CONCLUSIONS </span><span class="c1">The advances in data acquisition technologies and supercomput- ing for large-scale simulations rapidly increase the amounts of spatial data generated and collected. This data helps the scientist tremendously to gain insights and understand natural phenom- ena, however, at the same time, it leaves them with the chal- lenge of analyzing it. Known approaches to spatial indexing have two major drawbacks with respect to exploratory analyses. First, they require a time-consuming pre-processing step that delays analyses. Second, given the massive amounts of data, a scientist frequently only analyzes a small fraction of it and consequently indexing the entirety of the data does not always pay off. </span></p><p class="c111"><span class="c1">In this paper we propose a novel incremental index for the exploration of spatial data, where the ultimate goal is to let the scientists perform exploratory analyses as soon as the data is available, while using their queries to incrementally index the data. Our approach, QUASII, reduces data-to-insight time and curbs the cost of incremental indexing, by gradually and partially sorting the data, while producing a data-oriented hierarchical structure. As our experiments show, QUASII reduces the data- to-insight time by up to a factor of 11.4x, while its performance converges to that of the fastest state-of-the-art static indexes. </span></p><p class="c103"><span class="c30">ACKNOWLEDGEMENTS </span><span class="c1">We would like to thank the reviewers, the DIAS laboratory mem- bers, and Georgios Chatzopoulos for their comments and sugges- tions on how to improve the paper. This work is partially funded by the EU FP7 programme (ERC-2013-CoG), Grant No 617508 (ViDa) and EU Horizon 2020, GA No 720270 (HBP SGA1). </span></p><p class="c31"><span class="c30">REFERENCES </span></p><p class="c36"><span class="c14">[1] C.L. Abad, N. Roberts, Yi Lu, and R.H. Campbell. 2012. A storage-centric anal- ysis of MapReduce workloads: File popularity, temporal locality and arrival patterns. In IISWC. 100&ndash;109. [2] Ioannis Alagiannis, Renata Borovica, Miguel Branco, Stratos Idreos, and Anas- tasia Ailamaki. 2012. NoDB: efficient query execution on raw data files. In SIGMOD. 241&ndash;252. [3] Ahmed M. Aly, Ahmed R. Mahmood, Mohamed S. Hassan, Walid G. Aref, Mourad Ouzzani, Hazem Elmeleegy, and Thamir Qadah. 2015. AQWA: Adap- tive Query-Workload-Aware Partitioning of Big Spatial Data. PVLDB 8, 13 (2015), 2062&ndash;2073. [4] Lars Arge, Mark de Berg, Herman J. Haverkort, and Ke Yi. The Priority R-tree: </span></p><p class="c25"><span class="c14">a practically efficient and worst-case optimal R-tree. In SIGMOD &rsquo;04. [5] Rudolf Bayer. 1997. The Universal B-Tree for Multidimensional Indexing: </span></p><p class="c75"><span class="c14">General Concepts. In WWCA. 198&ndash;209. [6] Norbert Beckmann, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. 1990. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. In SIGMOD. [7] Jon Louis Bentley. 1975. Multidimensional binary search trees used for asso- ciative searching. CACM 18, 9 (1975), 509&ndash;517. </span><span class="c101">[8] Yanpei Chen, Sara Alspaugh, and Randy Katz. 2012. Interactive analytical pro- </span><span class="c14">cessing in big data systems: A cross-industry study of MapReduce workloads. PVLDB 5, 12 (2012), 1802&ndash;1813. </span></p><p class="c5 c127"><span class="c14">[9] Christos Faloutsos. 1988. Gray codes for partial match and range queries. TSE </span></p><p class="c99 c107"><span class="c14">14, 10 (1988), 1381&ndash;1393. [10] Christos Faloutsos and Shari Roseman. 1989. Fractals for secondary key </span></p><p class="c52"><span class="c14">retrieval. In PODS. 247&ndash;252. [11] Volker Gaede and Oliver Guenther. 1998. Multidimensional Access Methods. </span></p><p class="c38"><span class="c14">CSUR 30, 2 (1998). [12] Yv&aacute;n J. Garc&iacute;a, Mario A. L&oacute;pez, and Scott T. Leutenegger. 1996. A Greedy </span></p><p class="c24"><span class="c14">Algorithm for Bulk Loading R-trees. In GIS. [13] G. Graefe and H. Kuno. 2010. Adaptive Indexing for Relational Keys. In </span></p><p class="c73"><span class="c14">ICDEW. [14] Goetz Graefe and Harumi Kuno. 2010. Self-selecting, Self-tuning, Incremen- </span></p><p class="c57"><span class="c14">tally Optimized Indexes. In EDBT. [15] Antonin Guttman. 1984. R-trees: a dynamic index structure for spatial search- </span></p><p class="c73"><span class="c14">ing. In SIGMOD. 47&ndash;57. [16] Felix Halim, Stratos Idreos, Panagiotis Karras, and Roland H. C. Yap. 2012. Stochastic database cracking: Towards robust adaptive indexing in main- memory column-stores.. In VLDB. [17] Klaus Hinrichs. 1985. Implementation of the Grid File: Design Concepts and </span></p><p class="c52"><span class="c14">Experience. BIT 25, 4 (1985). [18] Stratos Idreos, Martin L Kersten, and Stefan Manegold. Database Cracking.. </span></p><p class="c73"><span class="c14">In CIDR. [19] Stratos Idreos, Stefan Manegold, Harumi Kuno, and Graefe Goetz. 2011. Merg- ing what&rsquo;s cracked, cracking what&rsquo;s merged: adaptive indexing in main- memory column-stores.. In VLDB. [20] Chris L Jackins and Steven L Tanimoto. 1980. Oct-trees and their use in representing three-dimensional objects. Comp. Graphics and Image Proc. 14, 3 (1980), 249&ndash;270. [21] Hosagrahar V Jagadish. 1990. Linear clustering of objects with multiple </span></p><p class="c38"><span class="c14">attributes. SIGMOD Rec. 19, 2 (1990), 332&ndash;342. [22] Christian S Jensen, Dan Lin, and Beng Chin Ooi. 2004. Query and update efficient B</span><span class="c7">+</span><span class="c14">-tree based indexing of moving objects. In VLDB. 768&ndash;779. [23] Ibrahim Kamel and Christos Faloutsos. 1993. Hilbert R-tree: An improved </span></p><p class="c69"><span class="c14">R-tree using fractals. In VLDB. 500&ndash;509. [24] Manos Karpathiotakis, Ioannis Alagiannis, Thomas Heinis, Miguel Branco, and Anastasia Ailamaki. Just-in-time data virtualization: Lightweight data management with ViDa. In CIDR&rsquo;15. [25] Manos Karpathiotakis, Miguel Branco, Ioannis Alagiannis, and Anastasia Ailamaki. 2014. Adaptive query processing on RAW data. PVLDB 7, 12 (2014), 1119&ndash;1130. [26] Scott T Leutenegger, Mario Lopez, Jeffrey Edgington, et al. 1997. STR: A simple </span></p><p class="c63"><span class="c14">and efficient algorithm for R-tree packing. In ICDE. 497&ndash;506. [27] Henry Markram et al. 2011. Introducing the Human Brain Project. Procedia </span></p><p class="c99 c102"><span class="c14">Computer Science 7, 1. FET &rsquo;11. [28] Henry Markram et al. 2015. Reconstruction and simulation of neocortical </span></p><p class="c73"><span class="c14">microcircuitry. Cell 163, 2 (2015), 456&ndash;492. [29] Bongki Moon, Hosagrahar V Jagadish, Christos Faloutsos, and Joel H Saltz. 2001. Analysis of the clustering properties of the Hilbert space-filling curve. TKDE 13, 1 (2001), 124&ndash;141. [30] EarthData NASA. https://earthdata.nasa.gov/. [31] Actueel Hoogte Bestand Nederland. 2017. AHN datasets. http://www.ahn.nl. [32] J. Nievergelt, Hans Hinterberger, and Kenneth C. Sevcik. 1984. The Grid File: </span></p><p class="c24"><span class="c14">An Adaptable, Symmetric Multikey File Structure. TODS 9, 1 (1984). [33] OpenStreetMap. https://www.openstreetmap.org. [34] Jack A Orenstein and Tim H Merrett. 1984. A class of data structures for </span></p><p class="c73"><span class="c14">associative searching. In PODS. 181&ndash;190. [35] Mirjana Pavlovic, Eleni Tzirita Zacharatou, Darius Sidlauskas, Thomas Hei- </span></p><p class="c113"><span class="c14">nis, and Anastasia Ailamaki. 2016. Space Odyssey: Efficient Exploration of Scientific Data. In ExploreDB. 12&ndash;18. [36] Hanan Samet. 1984. The quadtree and related hierarchical data structures. </span></p><p class="c69"><span class="c14">CSUR 16, 2 (1984), 187&ndash;260. [37] Timos Sellis, Nick Roussopoulos, and Christos Faloutsos. 1987. The R+-tree: </span></p><p class="c107 c99"><span class="c14">A dynamic index for multi-dimensional objects. In VLDB. [38] Darius &Scaron;idlauskas, Simonas &Scaron;altenis, et al. 2009. Trees or grids? Indexing </span></p><p class="c73"><span class="c14">moving objects in main memory. In SIGSPATIAL. 236&ndash;245. [39] Tom&aacute;&scaron; Skopal, Michal Kr&aacute;tk`y, Jaroslav Pokorn`y, and V&aacute;clav Sn&aacute;&scaron;el. 2006. A new range query algorithm for Universal B-trees. Information Systems 31, 6 (2006), 489&ndash;511. [40] Emmanuel Stefanakis, Yannis Theodoridis, Timos Sellis, and Yuk-Cheung Lee. 1997. Point representation of spatial objects and query window extension: A new technique for spatial access methods. GIScience 11, 6 (1997), 529&ndash;554. [41] Yufei Tao and Dimitris Papadias. 2002. Adaptive Index Structures. In VLDB. [42] Farhan Tauheed, Laurynas Biveinis, Thomas Heinis, Felix Sch&uuml;rmann, Henry Markram, and Anastasia Ailamaki. 2012. Accelerating Range Queries For Brain Simulations. In ICDE. 941&ndash;952. [43] Hermann Tropf and H. Herzog. 1981. Multimensional Range Search in Dy- </span></p><p class="c57"><span class="c14">namically Balanced Trees. Angewandte Informatik 23, 2 (1981), 71&ndash;77. [44] Peter van Oosterom, Oscar Martinez-Rubi, Milena Ivanova, Mike H&ouml;rham- mer, Daniel Geringer, Siva Ravada, Theo Tijssen, Martin Kodde, and Romulo Goncalves. 2015. Massive point cloud data management: Design, implemen- tation and execution of a point cloud benchmark. Computers &amp; Graphics 49 (2015), 92&ndash;125. [45] Kostas Zoumpatianos, Stratos Idreos, and Themis Palpanas. 2014. Indexing </span></p><p class="c122"><span class="c14">for interactive exploration of big data series. In SIGMOD. 1555&ndash;1566. </span></p><p class="c66"><span class="c9">336 </span></p></body></html>