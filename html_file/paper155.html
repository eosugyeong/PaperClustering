<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c54{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.7pt;font-family:"Courier New";font-style:normal}.c5{color:#231f20;font-weight:400;text-decoration:none;vertical-align:super;font-size:6.3pt;font-family:"Arial";font-style:normal}.c56{color:#231f20;font-weight:400;text-decoration:none;vertical-align:super;font-size:6.8pt;font-family:"Arial";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7pt;font-family:"Arial";font-style:normal}.c60{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.2pt;font-family:"Arial";font-style:normal}.c25{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.6pt;font-family:"Arial";font-style:normal}.c26{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.9pt;font-family:"Arial";font-style:normal}.c23{margin-left:-26.2pt;padding-top:6.7pt;text-indent:32.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c49{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c2{margin-left:-26.2pt;padding-top:1.4pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c76{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.1pt;font-family:"Arial";font-style:normal}.c50{margin-left:-26.2pt;padding-top:1.9pt;text-indent:38.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c74{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.5pt;font-family:"Arial";font-style:normal}.c91{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c51{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:normal}.c62{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c59{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c36{color:#ed1d24;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.9pt;font-family:"Arial";font-style:normal}.c106{margin-left:-26.2pt;padding-top:1.2pt;text-indent:45.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.2pt}.c108{color:#ed1d24;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c63{margin-left:-26.2pt;padding-top:1.7pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.7pt}.c97{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.3pt;font-family:"Arial";font-style:normal}.c111{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.7pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c67{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.2pt;font-family:"Arial";font-style:normal}.c7{margin-left:-17.1pt;padding-top:1.7pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c95{color:#110f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.9pt;font-family:"Arial";font-style:normal}.c112{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.8pt;font-family:"Courier New";font-style:normal}.c117{margin-left:-17.1pt;padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-26.6pt}.c96{color:#231f20;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.9pt;font-family:"Arial";font-style:normal}.c100{margin-left:-26.2pt;padding-top:4.1pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c65{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.8pt;font-family:"Arial";font-style:normal}.c81{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.8pt;font-family:"Arial";font-style:normal}.c19{margin-left:-17.1pt;padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c133{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:super;font-size:16.5pt;font-family:"Courier New";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Arial";font-style:normal}.c78{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c139{color:#100f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.9pt;font-family:"Courier New";font-style:normal}.c52{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.2pt;font-family:"Arial";font-style:normal}.c29{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c44{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Courier New";font-style:normal}.c102{color:#2e3192;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.2pt;font-family:"Arial";font-style:normal}.c45{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.2pt;font-family:"Arial";font-style:normal}.c57{color:#110f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c58{color:#110f0d;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.1pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c130{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c94{margin-left:-26.2pt;padding-top:4.1pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.9pt}.c61{color:#231f20;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.4pt;font-family:"Arial";font-style:normal}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.8pt;font-family:"Arial";font-style:normal}.c85{margin-left:-17.1pt;padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-24.7pt}.c104{color:#cd1e25;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.2pt;font-family:"Arial";font-style:normal}.c73{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c22{color:#00adef;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c66{margin-left:-26.2pt;padding-top:5.5pt;text-indent:74.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c4{margin-left:-26.2pt;padding-top:3.8pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c14{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c127{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.3pt;font-family:"Arial";font-style:normal}.c47{color:#110f0d;font-weight:400;text-decoration:none;vertical-align:sub;font-size:6.6pt;font-family:"Arial";font-style:normal}.c110{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c123{margin-left:-17.1pt;padding-top:1.7pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-24.7pt}.c64{color:#231f20;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.9pt;font-family:"Arial";font-style:normal}.c15{margin-left:-17.1pt;padding-top:1.7pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.7pt}.c125{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c86{color:#231f20;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.1pt;font-family:"Arial";font-style:normal}.c70{margin-left:-17.1pt;padding-top:3.8pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.7pt}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:7pt;font-family:"Arial";font-style:normal}.c30{margin-left:-26.2pt;padding-top:1.4pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c87{margin-left:389.5pt;padding-top:81.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.5pt}.c105{margin-left:-12.7pt;padding-top:9.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c84{margin-left:-26.2pt;padding-top:21.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c113{margin-left:-21.4pt;padding-top:16.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3pt}.c103{margin-left:218.2pt;padding-top:169.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c69{margin-left:-26.2pt;padding-top:15.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:70.7pt}.c140{margin-left:1.8pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.4pt}.c35{margin-left:66.4pt;padding-top:7.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:59pt}.c118{margin-left:218.2pt;padding-top:33.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c75{margin-left:-26.2pt;padding-top:20.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:12.6pt}.c114{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-22.1pt}.c43{margin-left:53pt;padding-top:14.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:45.8pt}.c37{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.6pt}.c27{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.7pt}.c46{margin-left:-21.4pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.7pt}.c129{margin-left:-26.2pt;padding-top:16.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c98{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-23.5pt}.c115{margin-left:-21.4pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c53{margin-left:-17.1pt;padding-top:57.1pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c141{margin-left:-26.2pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.8pt}.c120{margin-left:-11.6pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1.2pt}.c11{margin-left:-26.2pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.2pt}.c143{margin-left:-17.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.8pt}.c131{margin-left:-26.2pt;padding-top:14.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:19.8pt}.c109{margin-left:-26.2pt;padding-top:21.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c137{margin-left:218.2pt;padding-top:37.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c41{margin-left:-17.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.3pt}.c124{margin-left:-26.2pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-1.8pt}.c121{margin-left:-12.7pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c34{margin-left:-26.2pt;padding-top:15.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:121.8pt}.c93{margin-left:-26.2pt;padding-top:139.7pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25pt}.c90{margin-left:-26.2pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-11.6pt}.c71{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c68{margin-left:71.8pt;padding-top:37.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:248.6pt}.c142{margin-left:-26.2pt;padding-top:283.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25pt}.c32{margin-left:-6.6pt;padding-top:107pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:13pt}.c92{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.6pt}.c16{margin-left:-21.4pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-5.4pt}.c126{margin-left:-26.2pt;padding-top:9.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c77{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c82{margin-left:-12.7pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c48{margin-left:-17.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.5pt}.c33{margin-left:218.2pt;padding-top:31.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c80{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c18{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c38{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c72{padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c40{padding-top:3.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c122{padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c138{padding-top:27.6pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c128{padding-top:4.1pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c135{padding-top:15.8pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c21{margin-left:-17.1pt;text-indent:26.2pt;margin-right:-25pt}.c101{margin-left:-26.2pt;text-indent:35.3pt;margin-right:-15.9pt}.c107{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c99{margin-left:-26.2pt;text-indent:45.1pt;margin-right:-2.7pt}.c116{margin-left:-21.4pt;margin-right:-15pt}.c89{margin-left:-17.1pt;margin-right:-21.4pt}.c134{margin-left:-6.6pt;margin-right:13pt}.c136{margin-left:-26.2pt;margin-right:-15.9pt}.c88{margin-left:-7.2pt;margin-right:22.5pt}.c79{margin-left:-26.2pt;margin-right:-3.7pt}.c20{margin-left:-17.1pt;margin-right:7.4pt}.c132{margin-left:-21.4pt;margin-right:-11.4pt}.c55{margin-left:-17.1pt;margin-right:-25pt}.c119{margin-left:-26.2pt;margin-right:-1pt}.c83{margin-left:-26.2pt;margin-right:11.7pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c107"><p class="c80"><span class="c130">Time series anomaly discovery with grammar-based compression </span></p><p class="c1"><span class="c8">Pavel Senin </span><span class="c59">University of Hawai&lsquo;i at M &#772;anoa Collaborative Software Development Laboratory </span><span class="c13">senin@hawaii.edu </span></p><p class="c1"><span class="c8">Jessica Lin, Xing Wang </span><span class="c59">George Mason University Dept. </span><span class="c13">jessica@gmu.edu, </span><span class="c59">of Computer Science </span><span class="c13">xwang24@gmu.edu </span></p><p class="c1"><span class="c8">Tim Oates, Sunil Gandhi </span><span class="c59">University of Maryland, Baltimore County Dept. of Computer Science </span><span class="c13">oates@cs.umbc.edu, sunilga1@umbc.edu </span><span class="c8">Arnold P. Boedihardjo Crystal Chen Susan Frankenstein </span></p><p class="c1"><span class="c91">U.S. Army Corps of Engineers, Engineer Research and Development Center </span><span class="c13">{arnold.p.boedihardjo, crystal.chen, susan.frankenstein}@usace.army.mil </span></p><p class="c1"><span class="c8">ABSTRACT </span><span class="c3">The problem of anomaly detection in time series has recently received much attention. However, many existing techniques require the user to provide the length of a potential ano- maly, which is often unreasonable for real-world problems. In addition, they are also often built upon computing costly distance functions &ndash; a procedure that may account for up to 99% of an algorithm&rsquo;s computation time. </span></p><p class="c18"><span class="c3">Addressing these limitations, we propose two algorithms that use grammar induction to aid anomaly detection with- out any prior knowledge. Our algorithm discretizes contin- uous time series values into symbolic form, infers a context- free grammar, and exploits its hierarchical structure to effec- tively and efficiently discover algorithmic irregularities that we relate to anomalies. The approach taken is based on the general principle of Kolmogorov complexity where the randomness in a sequence is a function of its algorithmic incompressibility. Since a grammar induction process natu- rally compresses the input sequence by learning regularities and encoding them compactly with grammar rules, the al- gorithm&rsquo;s inability to compress a subsequence indicates its Kolmogorov (algorithmic) randomness and correspondence to an anomaly. </span></p><p class="c18"><span class="c3">We show that our approaches not only allow discovery of multiple variable-length anomalous subsequences at once, but also significantly outperform the current state-of-the-art exact algorithms for time series anomaly detection. </span></p><p class="c1"><span class="c8">1. INTRODUCTION </span></p><p class="c18"><span class="c3">The ability to detect anomalies in time series efficiently is important in a variety of application domains where ano- malies convey critical and actionable information, such as in health care, equipment safety, security surveillance, and </span></p><p class="c1"><span class="c3">c </span><span class="c31">2015, </span><span class="c42">&nbsp;&#775;</span><span class="c31">Copyright is with the authors. Published in Proc. 18th Inter- national Conference on Extending Database Technology (EDBT), March 23-27, 2015, Brussels, Belgium: ISBN 978-3-89318-067-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 . </span></p><p class="c18"><span class="c3">fraud detection. Consequently, the anomaly detection prob- lem has been studied in diverse research areas [10]. Despite the problem&rsquo;s simplicity at the abstract level, where an ano- maly is defined as a pattern that does not conform to the underlying generative processes, the problem is difficult to solve in its most general form [3]. </span></p><p class="c18"><span class="c3">Anomalies in time series can be divided into two broad categories: point anomalies and structural anomalies. Point anomalies are statistical outliers, i.e., points which are sig- nificantly different from others [11], and have been studied the most [3]. In contrast, structural anomalies, whose disco- very is our present focus, are defined as subsequences whose shape do not conform to the rest of the observed, or expected patterns [10, 3, 13]. </span></p><p class="c18"><span class="c3">Previously in [13], the notion of time series discord was in- troduced. Discords are shown to capture in a sense the most unusual subsequences within a time series that are likely to correspond to many possible anomalies within the genera- tive processes &ndash; a property which was confirmed in a recent extensive empirical study by Chandola et al., where they concluded &rdquo;..on 19 different publicly available data sets, com- paring 9 different techniques time series discord is the best overall technique among all techniques&rdquo;[3]. However, to dis- cover a discord, the user must specify its length. There are two limitations with this requirement in real world problems. First, the user may not know the exact discord length, or even the best range of lengths in advance. Second, restrict- ing the discovery to only fixed length discords limits the algorithm&rsquo;s exploratory capacity since multiple discords of different lengths may co-exist in a time series. As a result, determining all possible lengths to discover the best discords would be extremely cost prohibitive. </span></p><p class="c18"><span class="c3">In this work, we focus on the discovery of structural ano- malies that can also be described as the most unusual sub- sequences within a given time series, and we introduce a framework that addresses the above limitation by enabling efficient detection of variable-length anomalies. The pro- posed algorithms relies on the grammar induction proce- dure, which once applied to a string obtained by symbolic time series discretization, learns algorithmically exploitable symbol correlations and builds a hierarchical structure of context-free grammar rules, each of which maps to variable- length subsequences of the input time series. Through the </span></p><p class="c1"><span class="c6">481 10.5441/002/edbt.2015.42 </span></p><p class="c43"><span class="c76">Excerpt from the Video dataset </span></p><p class="c32"><span class="c54">0 1000 2000 3000 </span></p><p class="c18 c136"><span class="c3">analysis of the grammar&rsquo;s hierarchical structure, the algo- rithms efficiently identify substrings that are rarely used in the grammar rules and whose corresponding subsequences can be considered as candidate anomalies. </span></p><p class="c63"><span class="c3">Our approach builds upon the general notion of Kolmogorov complexity [15], which defines a string&rsquo;s complexity as a size of the smallest program that generates the string. While the Kolmogorov complexity is an uncomputable function due to the undecidability of the Turing machine halting problem, its value is typically approximated by the size of the input string in its algorithmically compressed form, and the tight- ness of the approximation bound is related to the overall ef- ficiency of the compressor [27, 17]. This practical notion of algorithmic compressibility allows for the estimation, study, and application of Kolmogorov complexity in a number of generic solutions to common data mining tasks. For exam- ple it underlies the Minimum Description Length (MDL) [9] and Normalized Compression Distance (NCD) [5] principles, and has been used for time series anomaly discovery [14]. </span></p><p class="c2"><span class="c3">Within the algorithmic compressibility framework, the al- gorithmic (Kolmogorov) randomness of a string has been defined through its incompressibility, i.e., the lack of algo- rithmically exploitable redundancy [17, 9, 6, 20]. Since a grammar induction algorithm can be used to provide ef- fective and efficient compression [21], naturally, it can be used for both the estimation of Kolmogorov complexity and algorithmic randomness discovery. Hence our present goal is to explore this property and to show that the algorith- mic randomness discovered with the application of grammar induction-based compression to discretized time series can be correlated to the anomalousness within the time series. </span></p><p class="c30"><span class="c3">In summary, our work has the following significant contri- butions: </span></p><p class="c105"><span class="c3">&bull; To the best of our knowledge, we are the first to explore the application of grammar-based compression to the problem of time series anomaly discovery. </span></p><p class="c82"><span class="c3">&bull; We propose two novel techniques for time series ano- maly discovery based on grammatical compression, in which we define an anomaly as an incompressible, al- gorithmically random subsequence. </span></p><p class="c121"><span class="c3">&bull; Our approaches offer the unique ability to discover multiple variable-length anomalies at once (Figure 1). </span></p><p class="c126"><span class="c3">The remainder of the paper is organized as follows. In Sec- tion 2, we provide notation and define our research prob- lem. In Section 3, we give a motivational example and de- scribe algorithms used. We discuss our approach in detail in Section 4, showing two algorithms enabling grammatical compression-driven anomaly detection in time series. In Sec- tion 5, we empirically evaluate our algorithms on datasets as diverse as spatial trajectories, space shuttle telemetry, medicine, surveillance, and industry. We also show the util- ities of incorporating the algorithms into our visualization tool, GrammarViz 2. Finally, we review related work and conclude. </span></p><p class="c131"><span class="c8">2. NOTATION AND THE PROBLEM </span></p><p class="c50"><span class="c8">DEFINITION </span><span class="c3">To precisely state the problem at hand, and to relate our work to previous research, we will define the key terms used </span></p><p class="c1 c134"><span class="c54">0 1000 2000 3000 </span></p><p class="c35"><span class="c76">Grammar rules density </span></p><p class="c53"><span class="c31">Figure 1: An example of multiple anomalous events found in a recorded video time series [14] shown at the top panel. The rule density curve, which we propose in this paper, and which is built in linear time and space, is shown in the bottom panel. Reflect- ing the hierarchical grammar structure, the rule density curve reaches its minima where no algorithmic redundancy is observed, pinpointing anomalous locations precisely. </span></p><p class="c55 c138"><span class="c3">throughout this paper. We begin by defining our data type, time series: </span></p><p class="c15"><span class="c3">Time series T = t</span><span class="c28">1</span><span class="c3">,...,t</span><span class="c28">m </span><span class="c3">is a set of scalar observations ordered by time. </span></p><p class="c7"><span class="c3">Since we focus on the detection of anomalous patterns, which are likely to be local features, we consider short sub- sections of time series called subsequences: </span></p><p class="c123"><span class="c3">Subsequence C of time series T is a contiguous sampling t</span><span class="c0">p</span><span class="c12">,...,t</span><span class="c0">p+n</span><span class="c44">&minus;</span><span class="c0">1 </span><span class="c12">of points of length n &lt;&lt; m where p is an </span><span class="c3">arbitrary position, such that 1 &le; p &le; m &minus; n + 1. </span></p><p class="c15"><span class="c3">Typically subsequences are extracted from a time series with the use of a sliding window: </span></p><p class="c7"><span class="c3">Sliding window subsequence extraction: for a time se- ries T of length m, and a user-defined subsequence length n, all possible subsequences of T can be found by sliding a window of size n across T. </span></p><p class="c7"><span class="c3">As it is well acknowledged in the literature, and as we have shown before in [25], it is often meaningless to compare time series unless they are z-normalized: </span></p><p class="c15"><span class="c3">Z-normalization is a process that brings the mean of a subsequence C to zero and its standard deviation to one. </span></p><p class="c7"><span class="c3">Given two time series subsequences C and M, both of length n, the distance between them is a real number that accounts for how much these subsequences are different, and the function which outputs this number when given C and M is called the distance function and denoted Dist(C, M). One of the most commonly used distance func- tions is the Euclidean distance, which is the square root of the sum of the squared differences between each pair of the corresponding data points in C and M. </span></p><p class="c85"><span class="c3">One of our proposed techniques is built upon determining if a given subsequence C is similar to other subsequences M under distance measure Dist. This notion is formalized in the definition of a match: </span></p><p class="c7"><span class="c3">Match: Given a positive real number t (i.e., threshold) and subsequences C and M, if Dist(C, M) &le; t then sub- sequence M is a match to C. </span></p><p class="c19"><span class="c3">When searching for potential anomalies using a distance function, it is important to exclude self matches, which are subsequences that overlap the subsequence currently being considered. Such self-matches can yield degenerate and un- intuitive solutions as discussed in [13]. For two subsequences C and M we define a non-self match: </span></p><p class="c33"><span class="c6">482 </span></p><p class="c1"><span class="c3">A Non-self match: Given a subsequence C of length n </span></p><p class="c1"><span class="c3">careful look at the string shows that there are repeated starting at position p of time series T, the subsequence M be- </span></p><p class="c1"><span class="c3">patterns abc abc cba separated by xxx. Ideally, we expect ginning at q is a non-self match to C at distance Dist(C, M) </span></p><p class="c1"><span class="c3">the grammar induction or compression algorithm to reflect if |p &minus; q| &ge; n. </span></p><p class="c1"><span class="c3">this, as shown in the possible grammar for input S: As mentioned, one of the most effective methods for time series anomaly detection is via discord discovery. Formally, </span></p><p class="c1"><span class="c3">Grammar Rule Expanded Grammar Rule it is defined as: </span></p><p class="c1"><span class="c3">R0 &rarr; R1 xxx R1 </span><span class="c29">abc abc </span><span class="c22">cba </span><span class="c73">xxx </span><span class="c29">abc abc </span><span class="c22">cba </span><span class="c3">Time Series Discord: Given a time series T, the time </span></p><p class="c1"><span class="c3">R1 &rarr; R2 </span><span class="c22">cba </span><span class="c29">abc abc </span><span class="c22">cba </span><span class="c3">series subsequence C &isin; T is called the discord if it has the </span></p><p class="c1"><span class="c3">R2 &rarr; </span><span class="c29">abc abc abc abc </span><span class="c3">largest Euclidean distance to its nearest non-self match [13]. Thus, time series discord is a subsequence within a time se- ries that is maximally different to all the rest of subsequences in the time series, and therefore naturaly captures the most unusual subsequence within the time series [13]. </span></p><p class="c38"><span class="c3">As shown, the grammar induction algorithm has reduced the length of the input string (i.e., compressed it) by creating a grammar whose rules are encoded by non-terminals R1 and R2, which reveal repeated patterns in the input. </span><span class="c8">2.1 Problem definition </span></p><p class="c1"><span class="c3">The task of finding a structural time series anomaly is defined as </span></p><p class="c18"><span class="c3">Given a time series T, find a subsequence C that is the most (structurally) different from the rest of the observed subsequences. </span></p><p class="c18"><span class="c3">This task, however, is very difficult to solve in its gen- eral form without a notion of the context [3]. The context is information that can be induced from the structure of the dataset or specified as a part of the problem. It places constraints on both the search space and the results, mak- ing it possible to find a meaningful solution. Based on this rationale, we re-define the anomaly discovery problem as: </span></p><p class="c1"><span class="c3">Given a time series T and some context, find a subsequence C that is the most structurally different from others and </span></p><p class="c18"><span class="c3">In previous work, we have shown that by the analysis of a grammar built upon time series discretization it is possible to identify recurrent patterns, i.e. time series motifs [16]. Since anomaly detection can be viewed as the inverse prob- lem to motif discovery, in this work, we argue that symbols that are rarely used in grammar rules (i.e. </span><span class="c73">xxx</span><span class="c3">) may aid in anomaly detection as well. The intuition is that subsequen- ces of any length that never or rarely occur in grammar rules are non-repetitive and are thus most likely to be unusual or anomalous. </span></p><p class="c18"><span class="c3">To illustrate this, suppose we annotate each word of the input string S with the number of rules that the word ap- pears in excluding the top-level rule R0. The input string S becomes the following: </span></p><p class="c1"><span class="c3">S = abc</span><span class="c0">2 </span><span class="c12">abc</span><span class="c0">2 </span><span class="c12">cba</span><span class="c0">1 </span><span class="c12">xxx</span><span class="c0">0 </span><span class="c12">abc</span><span class="c0">2 </span><span class="c12">abc</span><span class="c0">2 </span><span class="c12">cba</span><span class="c0">1 </span><span class="c3">which can be related to the context. </span></p><p class="c18"><span class="c3">In discords&mdash;the current state of the art in structural ano- maly detection [3]&mdash;the context is provided by the user- defined anomaly length, and the notion of the &ldquo;most struc- turally different&rdquo; is defined as the largest Euclidean distance to the nearest non-self match. Both constraints, while defin- ing the problem and the solution exactly, place severe restric- tions on the result by assuming unrealistic a priori knowl- edge about the exact anomaly length. </span></p><p class="c1"><span class="c3">In this work we address this issue by allowing the discord length to vary in boundaries that are consistent with the time series context. Toward this end, we represent the con- text as a hierarchical grammar structure obtained through the processes of time series symbolic discretization and context- free grammar induction. In turn, by exploiting the use fre- quencies of the induced grammar rules, our technique finds the most unusual rules which we consider as discord candi- dates to be evaluated and which, naturally, vary in length. </span></p><p class="c18"><span class="c3">All occurrences of the word abc have a count of 2 be- cause they appear in both R1 and R2; the word cba has count of 1 since it appears only in R1; whereas the word xxx has a count 0, because it is not a part of any rule. Since the counts naturally reflect the algorithmic compressibility of the sequence of terminal and non-terminal symbols, the triplet xxx</span><span class="c0">0 </span><span class="c12">is algorithmically incompressible by the gram- </span><span class="c3">mar induction algorithm and thus algorithmically random. In turn, if the input string S is derived by discretizing a time series into a sequence of words, where each word corresponds to a time series subsequence, then based on our hypothesis, the subsequence in the time series that xxx represents is a potential anomaly. </span></p><p class="c38"><span class="c3">Note that when identifying a potential anomaly we have not used any explicit distance computation between termi- nal or non-terminal symbols, grammar rules, or their cor- responding (i.e., raw) subsequences. Moreover, note that the time series discretization technique SAX [25] and the </span><span class="c8">3. GRAMMAR-BASED TIME SERIES DE- </span></p><p class="c1"><span class="c3">grammatical inference algorithm Sequitur [22] that we rely upon, also do not compute any distance (i.e., they do not </span><span class="c8">COMPOSITION </span><span class="c3">Before describing our approach in detail, consider the fol- lowing example showing the context-free grammar proper- ties used in our approach. Let </span></p><p class="c1"><span class="c3">S = abc abc cba xxx abc abc cba </span></p><p class="c18"><span class="c3">explicitly measure how far apart objects are). Hence, unlike most anomaly discovery algorithms, our approach does not require any distance computation to discover and to rank multiple potential anomalies. </span></p><p class="c38"><span class="c3">Discovered in the above example potential anomaly is the most unusual substring of a larger input string in terms of be the input string under analysis (e.g. derived from a time </span></p><p class="c1"><span class="c3">the grammatical inference algorithm of choice. Specifically, series and reflecting its structure). For reason that will be- </span></p><p class="c1"><span class="c3">in contrast to other terminal symbols, the word xxx is not come clearer later, the input string consists of a sequence </span></p><p class="c1"><span class="c3">included in any of grammatical rules &ndash; the property that of words (in this example, 3-letter words or triplets). Each </span></p><p class="c1"><span class="c3">is discovered and accounted for by the grammatical infer- triplet is considered an atomic unit, or a terminal in the </span></p><p class="c1"><span class="c3">ence algorithm. Thus, the discovered anomalous substring sequence. The task is to compress this input sequence by </span></p><p class="c1"><span class="c3">is analogous in meaning to a time series discord. However, grammar induction. </span></p><p class="c1"><span class="c3">our approach determines the anomalous subsequence length </span></p><p class="c1"><span class="c6">483 </span></p><p class="c129"><span class="c3">automatically in the course of grammar induction process, whereas the discord discovery algorithm requires the length of a potential anomaly to be known in advance. </span></p><p class="c72 c101"><span class="c3">Based on the intuition shown above, we shall present two algorithms that enable the discovery of variable-length ano- malies. Before that, we discuss time series discretization and grammatical inference &ndash; the procedures upon which our techniques are built. </span><span class="c8">3.1 Discretization </span></p><p class="c101 c128"><span class="c3">Since grammar induction algorithms are designed for dis- crete data, we begin by discretizing a continuous time se- ries with SAX (Symbolic Aggregate approXimation) [25]. In addition, since an anomaly is a local phenomenon, we apply SAX to subsequences extracted via a sliding window. SAX performs discretization by dividing z-normalized sub- sequence into w equal-sized segments. For each segment, it computes a mean value and maps it to symbols according to a pre-defined set of breakpoints dividing the distribution space into &alpha; equiprobable regions, where &alpha; is the alphabet size specified by the user. This subsequence discretization process [19] outputs an ordered set of SAX words, where each word corresponds to the leftmost point of the sliding window, and which we process with numerosity reduction at the next step. </span></p><p class="c2"><span class="c3">As an example, consider the sequence S1 where each word (e.g. aac) represents a subsequence extracted from the orig- inal time series via a sliding window and discretized with SAX (the subscript following each word denotes the start- ing position of the corresponding subsequence in the time series): </span></p><p class="c23"><span class="c3">S1 = aac</span><span class="c0">1 </span><span class="c12">aac</span><span class="c0">2 </span><span class="c12">abc</span><span class="c0">3 </span><span class="c12">abb</span><span class="c0">4 </span><span class="c12">acd</span><span class="c0">5 </span><span class="c12">aac</span><span class="c0">6 </span><span class="c12">aac</span><span class="c0">7 </span><span class="c12">aac</span><span class="c0">8 </span><span class="c12">abc</span><span class="c0">9 </span><span class="c12">... </span><span class="c3">In contrast to many SAX-based anomaly discovery tech- niques that store SAX words in a trie or a hash table for optimizing the search, and essentially throw away the or- dering information, we argue that the sequential ordering of SAX words provides valuable contextual information, and is the key for allowing variable-length pattern discovery. </span><span class="c8">3.2 Numerosity reduction </span></p><p class="c4"><span class="c3">As we have shown in [19], neighboring subsequences ex- tracted via sliding window are often similar to each other. When combined with the smoothing properties of SAX, this phenomenon persists through the discretization, resulting in a large number of consecutive SAX words that are identi- cal. Later, these yield a large number of trivial matches significantly affecting performance. To address this issue, we employ a numerosity reduction strategy: if in the course of discretization, the same SAX word occurs more than once consecutively, instead of placing every instance into the re- sulting string, we record only its first occurrence. Applied to S1, this process yields: </span></p><p class="c66"><span class="c3">S1 = aac</span><span class="c0">1 </span><span class="c12">abc</span><span class="c0">3 </span><span class="c12">abb</span><span class="c0">4 </span><span class="c12">acd</span><span class="c0">5 </span><span class="c12">aac</span><span class="c0">6 </span><span class="c12">abc</span><span class="c0">9 </span><span class="c3">In addition to speeding up the algorithm and reducing its space requirements, the numerosity reduction procedure pro- vides an important feature in this work &ndash; it naturally enables the discovery of variable-length anomalies as we show next. </span><span class="c8">3.3 Grammar induction on SAX words </span></p><p class="c4"><span class="c3">Next, the reduced (from repetitions) sequence of SAX words is inputted into Sequitur [22], our grammar induction algorithm of choice, to build a context-free grammar. </span></p><p class="c18 c21"><span class="c3">Sequitur is a linear time and space algorithm that derives the context-free grammar from a string incrementally. Pro- cessing the input string from left to right, Sequitur builds the hierarchical structure of a context-free grammar by iden- tifying and exploiting symbol correlations while maintaining the two constraints of uniqueness and utility at all times. Al- though simple in design, Sequitur has been shown to be com- petitive with state of the art compression algorithms &ndash; the property which allows us to use the notion of Kolmogorov complexity. In addition, Sequitur performance tends to im- prove with the growth of the input string size [21]. </span></p><p class="c7"><span class="c3">When applied to a sequence of SAX words, Sequitur treats each word as an input string token and builds the context- free grammar&rsquo;s hierarchical structure. This structure re- cursively reduces all digrams that are consecutive pairs of tokens (terminal or non-terminal) occurring more than once in the input string to a single new non-terminal symbol. </span></p><p class="c19"><span class="c3">To reiterate the benefit of the numerosity reduction strat- egy and how it lends itself to variable-length pattern dis- covery with Sequitur, consider the single grammar rule R1 generated by Sequitur from the string S1 as shown here: </span></p><p class="c120"><span class="c3">Grammar Rule Expanded Grammar Rule R0 &rarr; R1 abb acd R1 </span><span class="c29">aac</span><span class="c28">1 </span><span class="c29">abc</span><span class="c28">3 </span><span class="c3">abb</span><span class="c28">4 </span><span class="c3">acd</span><span class="c28">5 </span><span class="c29">aac</span><span class="c28">6 </span><span class="c29">abc</span><span class="c28">9 </span><span class="c3">R1 &rarr; aac abc </span><span class="c29">aac abc </span></p><p class="c21 c135"><span class="c3">In this grammar, R1 concurrently maps to substrings of different lengths: S1</span><span class="c0">[1:3] </span><span class="c12">of length 3 (i.e., aac</span><span class="c0">1 </span><span class="c12">aac</span><span class="c0">2 </span><span class="c12">abc</span><span class="c0">3</span><span class="c12">) and </span><span class="c3">S1</span><span class="c0">[6:9] </span><span class="c3">of length 4 (i.e., aac</span><span class="c0">6 </span><span class="c12">aac</span><span class="c0">7 </span><span class="c12">aac</span><span class="c0">8 </span><span class="c12">abc</span><span class="c0">9</span><span class="c12">), respectively. </span><span class="c3">The potential anomalous substring &ldquo;abb</span><span class="c28">4 </span><span class="c3">acd</span><span class="c28">5</span><span class="c3">&rdquo; has length 2. Since each SAX word corresponds to a single point of the input time series (a subsequence starting point), R1 maps to its subsequences of variable lengths. </span><span class="c8">3.4 Mapping rules to subsequences </span></p><p class="c70"><span class="c3">As shown in the above example, by keeping SAX words&rsquo; offsets throughout the procedures of discretization and gram- mar induction, our algorithm is able to map rules and SAX words back to their original time series subsequences. </span><span class="c8">3.5 Pattern mining with Sequitur </span></p><p class="c21 c40"><span class="c3">Previously in [16], we proposed GrammarViz, an algo- rithm for variable-length time series motif discovery that makes full use of the hierarchy in Sequitur&rsquo;s grammar. We showed the ability of the proposed algorithm to discover re- current patterns of variable lengths. This is due to several properties of the algorithm, including: the data smoothing capability of SAX, numerosity reduction which enables the patterns&rsquo; variable length, and Sequitur&rsquo;s utility constraint which ensures that all of the grammar&rsquo;s non-terminals cor- respond to recurrent patterns. We later implemented visual- ization software based on this concept [26] that also provides a pilot module demonstrating the potential for a grammar- based approach to identify anomalies. </span></p><p class="c7"><span class="c3">In this work, we formally introduce the notion of the rule density curve which is the key to our grammar-driven ano- maly detection algorithm. Simply put, the rule density curve reflects the number of Sequitur grammar rules that span a time series point. We also provide theoretical background for our empirical observations. For this, we emphasize the role of the second Sequitur constraint, digram uniqueness, which ensures that none of the digrams processed by the algorithm (i.e., compressed into non-terminals) repeats it- </span></p><p class="c33"><span class="c6">484 </span></p><p class="c18"><span class="c3">self. This property guarantees the exhaustiveness of the search for algorithmically exploitable redundancies in the input string, and consequently asymptotically maximal com- pression of the output string [21]. Both properties allow us to put our approach within the Kolmogorov complex- ity framework based on the algorithmic compressibility and relate algorithmically incompressible subsequences to ano- malies as we discuss in the next section. </span></p><p class="c1"><span class="c8">4. GRAMMAR-DRIVEN ANOMALY </span></p><p class="c1"><span class="c8">DISCOVERY </span><span class="c3">Within Kolmogorov complexity research, it has been pro- ven that algorithmic incompressibility is a necessary and sufficient condition for randomness [6, 17], thanks to the elegant statistically-sound theory developed by Martin-L&ouml;f [20]. This theoretically grounds our intuition and effectively supports the claim that if a grammar induction algorithm is incapable of encoding a subsequence by finding exploitable correlations within the input string, such a subsequence is random within the context of the input string and applied al- gorithm. We call such subsequences algorithmically anoma- lous and equate them to time series anomalies. </span></p><p class="c1"><span class="c3">Let us explain the utility of &ldquo;algorithmic anomalousness&rdquo;. When searching for an anomaly in a time series, we expect that while the true generative process is unknown, it is likely to be regular and that the time series reflects these regular- ities. At the same time, we also assume that the time series may contain some abnormal segments, whose identification is our goal. Further, assuming that the discretization pro- cess preserves these regularities and irregularities, the Se- quitur algorithm should be able to learn the regularities and effectively compress the input string. However, due to its in- variants of utility and uniqueness, Sequitur will not be able to form rules that contain symbolic subsequences occurring just once in the input string, because it will not be able to find any short- or long-term correlations between them and the rest of the string &ndash; the property that reflects irregularity and defines a variable-length anomaly in the most natural way.</span><span class="c12">Based on the intuition behind algorithmic anomalousness </span><span class="c3">we propose two algorithms for grammatical compression- driven variable-length anomaly discovery from time series. Configured only by the discretization parameters, both algo- rithms are capable of efficient discovery of putative anoma- lous subsequences without any prior knowledge of their length, shape, or minimal occurrence frequency. While the result produced by the first algorithm is an approximate solution, our second algorithm is based on explicit distance computa- tions and outputs time series discords of variable length. </span></p><p class="c1"><span class="c8">4.1 Efficient, </span><span class="c13">discovery </span></p><p class="c18"><span class="c8">rule density-based anomaly </span><span class="c3">To efficiently discover approximate anomalies, we propose to compute the rule density curve for the input time series. Toward that end, an empty array of length m (the length of the time series), is first created. Each element in this ar- ray corresponds to a time series point and is used to keep count of the grammar rules that span (or &ldquo;cover&rdquo;) the point. Second, since the locations of corresponding subsequences for all grammar rules are known, by iterating over all gram- mar rules the algorithm increments a counter for each of the time series points that the rule spans. After this process </span></p><p class="c1"><span class="c52">Dataset ECG qtdb 0606, excerpt [701-3000] </span></p><p class="c1"><span class="c14">Sequitur grammar rules density (discretization parameters W=100,P=9,A=5) </span></p><p class="c1"><span class="c28">Non-self distance to the nearest neighbor among rule-corresponding subsequences </span></p><p class="c1"><span class="c14">The true anomaly location at ST wave </span></p><p class="c18"><span class="c31">Figure 2: Anomaly discovery in ECG dataset. Top panel shows the anomalous heartbeat location. Middle panel shows that the rule density curve clearly identifies the true anomaly by its global minimum. Bottom panel confirms that the RRA-reported discord has indeed the largest distance to its nearest non-self match. </span></p><p class="c18"><span class="c3">each element of the array contains a value indicating the to- tal number of grammar rules that covers the corresponding time series point. The curve that corresponds to the array&rsquo;s values is the rule density curve. As an example, consider the rule density curves shown in the middle panels of Figures 2 and 3. </span></p><p class="c18"><span class="c3">Since each SAX string corresponds to a subsequence start- ing at some position of the time series, the points whose rule density counters are global minima correspond to the gram- mar symbols (terminals or non-terminals) whose inclusion in the grammar rules are minimal. These subsequences are algorithmically anomalous by our definition and we argue that the rule density curve intervals that contain minimal values correspond to time series anomalies, and our algo- rithm simply outputs these intervals. </span></p><p class="c18"><span class="c3">Consider the example shown in Figure 2. The top panel shows an excerpt of an ECG time series with a highlighted instance of an anomalous heartbeat featuring a very subtle premature ventricular contraction. The middle panel shows a significant drop in the grammar rule density over the inter- val 462-484, which is in perfect alignment with the ground truth &ndash; an expert&rsquo;s annotation of an anomaly occuring in the ST interval of the ECG curve (as discussed in [13]). Similar to that, the global minima of the rule density curve shown in the middle panel of Figure 3 pinpoints the weekly interval that has the most unusual power consumption pattern (the dataset in the top panel of Figure 3 shows the power con- sumption history of a Dutch research facility for the entire year of 1997 [28]). </span></p><p class="c18"><span class="c3">The rule density-based approach is capable of discovering multiple anomalies of variable length. When given a fixed threshold, it simply reports contiguous points of the input time series whose density is less than the threshold value. If needed, an additional ranking criterion can be defined, such as a minimal anomaly length or a statistically sound criterion based on probabilities. </span></p><p class="c18"><span class="c3">Note that even though we need to specify the sliding win- dow length, it is only the initial &ldquo;seed&rdquo; value. Unlike most existing algorithms in which this subsequence length is the exact length of the anomaly, anomalies reported by our tech- nique are not bounded by the seed length and may range from very short to very long time spans. </span></p><p class="c1"><span class="c6">485 </span></p><p class="c1"><span class="c24">0 500 1000 1500 2000 </span></p><p class="c1"><span class="c24">0 500 1000 1500 2000 </span></p><p class="c1"><span class="c24">0 500 1000 1500 2000 </span></p><p class="c1"><span class="c74">Dataset Dutch Power Demand and 3 anomalies discovered by SAXSequitur </span></p><p class="c1"><span class="c51">Non-self distance to the nearest neighbor among rule-corresponding subsequences </span></p><p class="c1"><span class="c3">Algorithm 1 RRA algorithm </span></p><p class="c1"><span class="c3">1: </span><span class="c31">function Find discord(T,Intervals,Outer,Inner) </span><span class="c60">0 5000 10000 15000 20000 25000 30000 35000 </span><span class="c12">2: </span><span class="c17">best so far dist = 0 </span><span class="c51">Sequitur grammar rules density (discretization parameters W=750,P=10,A=4) </span><span class="c36">Second discord </span><span class="c108">Best discord </span><span class="c36">Third discord </span><span class="c12">3: </span><span class="c17">best so far loc = NaN </span><span class="c12">4: </span><span class="c17">for each p in Intervals ordered by Outer do </span><span class="c12">5: </span><span class="c17">nearest neighbor dist = Infinity </span><span class="c12">6: </span><span class="c17">for each q in Intervals ordered by Inner do </span><span class="c60">0 5000 10000 15000 20000 25000 30000 35000 </span><span class="c12">7: 8: </span><span class="c17">if |p</span><span class="c0">0 </span><span class="c17">&minus; q</span><span class="c0">0</span><span class="c17">| &ge; Length(p) </span><span class="c28">1 </span><span class="c17">then current dist = Dist(p, q) </span><span class="c12">9: </span><span class="c17">if current dist &lt; best so far dist then </span><span class="c12">10: </span><span class="c17">break </span><span class="c12">11: </span><span class="c17">if current dist &lt; nearest neighbor dist then </span><span class="c60">0 5000 10000 15000 20000 25000 30000 35000 </span></p><p class="c1"><span class="c12">12: </span><span class="c17">nearest neighbor dist = current dist </span></p><p class="c18"><span class="c31">Figure 3: Multiple discord discovery in Dutch power demand data [28]. Top panel shows 52 weeks of power demand by a re- search facility. Middle panel shows that while the rule density- based technique was able to discover the best discord, others are </span></p><p class="c1"><span class="c3">13: </span><span class="c31">if nearest neighbor dist &gt; best so far dist then </span><span class="c12">14: </span><span class="c17">best so far dist = nearest neighbor dist </span><span class="c12">15: </span><span class="c17">best so far loc = p </span><span class="c3">16: </span><span class="c31">return (best so far dist, best so far loc) </span></p><p class="c18"><span class="c31">difficult to discriminate. The bottom panel shows distances to the nearest non-self match computed for each rule-corresponding subsequence, which allows for the ranking of discords discovered with RRA. </span></p><p class="c18"><span class="c28">1</span><span class="c12">p</span><span class="c0">0 </span><span class="c12">and q</span><span class="c0">0 </span><span class="c12">are the global indexes (in T) of the first points </span><span class="c3">of subsequences p and q respectively. In this line we check that currently analyzed subsequences do not overlap (i.e., q is non-self match of p). </span></p><p class="c1"><span class="c26">Typical week</span><span class="c78">, Dutch Power Demand dataset </span><span class="c26">Best discord </span></p><p class="c1"><span class="c81">M</span><span class="c5">onday </span></p><p class="c1"><span class="c81">T</span><span class="c5">uesday </span></p><p class="c1"><span class="c81">W</span><span class="c5">ednesday </span></p><p class="c1"><span class="c81">T</span><span class="c5">hursday </span></p><p class="c1"><span class="c81">F</span><span class="c5">riday </span></p><p class="c1"><span class="c81">S</span><span class="c5">aturday </span></p><p class="c1"><span class="c81">S</span><span class="c5">unday </span><span class="c96">Queen&rsquo;s Birthday </span></p><p class="c1"><span class="c111">Liberation Day Wednesday, April, 30 </span></p><p class="c1"><span class="c111">Monday, May, 5 </span></p><p class="c18"><span class="c3">The RRA algorithm is based on the HOTSAX framework initially proposed in [13] for the discord discovery. The al- gorithm&rsquo;s input includes the original time series T, a list </span></p><p class="c1"><span class="c26">Second </span><span class="c25">0 </span><span class="c26">to </span><span class="c25">200 </span><span class="c26">best discord </span><span class="c25">400 600 </span><span class="c64">750 </span><span class="c26">Third </span><span class="c25">0 </span><span class="c26">discord </span></p><p class="c1"><span class="c25">200 400 600 </span><span class="c64">754 </span></p><p class="c1"><span class="c86">S</span><span class="c56">aturday </span></p><p class="c1"><span class="c86">S</span><span class="c56">unday </span><span class="c61">Annunciation</span><span class="c78">Good Friday </span></p><p class="c1"><span class="c111">Ascension Day Thursday, May, 8 </span></p><p class="c18"><span class="c3">of variable length subsequences corresponding to grammar rules which we call Intervals, and two heuristics: Inner and Outer, which can be applied to list of subsequences. </span></p><p class="c1"><span class="c3">Similar to HOTSAX, our algorithm iterates over all can- </span></p><p class="c1"><span class="c25">0 200 400 600 </span><span class="c64">757 </span><span class="c25">0 200 400 600 </span><span class="c64">756 </span></p><p class="c1"><span class="c3">didate subsequences in the outer loop (line 4 of Algorithm 1) while computing distances to all other non-self matches in </span><span class="c31">Figure 4: A detailed view of RRA-ranked variable length dis- cords discovered in the Dutch power demand dataset. All of them highlight time intervals where typical weekly patterns are inter- rupted by state holidays. </span></p><p class="c38"><span class="c3">the inner loop (lines 6&ndash;8; p</span><span class="c28">0 </span><span class="c3">and q</span><span class="c28">0 </span><span class="c3">in line 7 are the indexes) and selecting the closest non-self match (lines 9&ndash;15). The candidate subsequence from the outer loop which yields the largest distance to a non-self match is output as the result. In HOTSAX, the candidates in the outer (Outer) and inner (Inner) loops are ordered based on the SAX representations of the candidate subsequences such that the order of consid- Another distinguishable and desirable characteristic of this </span></p><p class="c1"><span class="c3">eration is as close to the optimal ordering (i.e., the ordering approach is its efficiency. It has linear time and space com- </span></p><p class="c1"><span class="c3">that would result in the most elimination of computations) plexity since the sequential processing of SAX, Sequitur, and </span></p><p class="c1"><span class="c3">as possible. However, as mentioned earlier, HOTSAX can- the global minima search take linear time and space. This </span></p><p class="c1"><span class="c3">didates are restricted by their subsequence length. Our pro- efficiency, when combined with effective rule density curve- </span></p><p class="c1"><span class="c3">posed technique differs from HOTSAX in that subsequences based visualization, enables the user to interactively explore </span></p><p class="c1"><span class="c3">(i.e., Intervals in Algorithm 1) and their ordering for the the dataset and to refine discretization parameters and the </span></p><p class="c1"><span class="c3">inner (Inner) and outer (Outer) loops are provided as the anomaly selection threshold. </span></p><p class="c1"><span class="c3">input based on the information derived from grammar. </span></p><p class="c38"><span class="c3">Specifically, Intervals subsequences are those that corre- spond to the grammar rules plus all continuous subsequences </span><span class="c8">4.2 Exact, distance-based anomaly discovery </span></p><p class="c1"><span class="c3">If the time series under analysis has low regularity (an is- sue that impacts the grammar&rsquo;s hierarchy) or the discretiza- tion parameters are far from optimal and regularities are not conveyed into the discretized space, the rule density- based anomaly discovery technique may fail to output true anomalies. In addition, some applications may require addi- tional anomaly evidence or ranking. To address this, we pro- pose a second variant of a grammar-driven variable-length anomaly discovery algorithm based on an explicit distance computation which outputs discords &ndash; the subsequences whose distance to their nearest non-self match is the largest. Since anomalous subsequences correspond to rare grammar rules, we call the algorithm RRA (Rare Rule Anomaly). </span></p><p class="c18"><span class="c3">of the discretized time series that do not form any rule. The Outer subsequence ordering utilizes the information derived from a hierarchical grammar structure &ndash; we order subsequen- ces in ascending order of their corresponding rule usage fre- quency (note that continuous subsequences of the discretized time series that do not form any rule have frequency 0 and are thus considered first). The intuition behind this order- ing is simple and is a reflection of the previously discussed properties of algorithmically anomalous subsequences. That is, the sooner we encounter the true anomaly, the larger the best so far dist is, and the more computations we can po- tentially eliminate later on (line 9). </span></p><p class="c1"><span class="c3">The Inner candidate match ordering is also based on grammar information. First, having a candidate subsequence </span></p><p class="c1"><span class="c6">486 </span></p><p class="c1"><span class="c31">Table 1: Performance comparison for brute-force, state-of-the-art, and the proposed exact discord discovery algorithms. </span></p><p class="c1"><span class="c31">Dataset name and discretization Length Number of calls to the distance function Reduction in HOTSAX &amp; RRA dis- param. (window, PAA, alphabet) Brute-force HOTSAX RRA distance calls cords length and overlap </span></p><p class="c18"><span class="c31">Daily commute (350,15,4) 17&rsquo;175 271&rsquo;442&rsquo;101 879&rsquo;067 112&rsquo;405 87.2% 350 / 366 100.0% Dutch power demand (750,6,3) 35&rsquo;040 1.13 &times; 10</span><span class="c62">9 </span><span class="c31">6&rsquo;196&rsquo;356 327&rsquo;950 95.7% 750 / 773 96.3% ECG 0606 (120,4,4) 2&rsquo;300 4&rsquo;241&rsquo;541 72&rsquo;390 16&rsquo;717 76.9% 120 / 127 79.2% ECG 308 (300,4,4) 5&rsquo;400 23&rsquo;044&rsquo;801 327&rsquo;454 14&rsquo;655 95.5% 300 / 317 97.7% ECG 15 (300,4,4) 15&rsquo;000 207&rsquo;374&rsquo;401 1&rsquo;434&rsquo;665 111&rsquo;348 92.2% 300 / 306 65.0 % ECG 108 (300,4,4) 21&rsquo;600 441&rsquo;021&rsquo;001 6&rsquo;041&rsquo;145 150&rsquo;184 97.5% 300 / 324 89.7% ECG 300 (300,4,4)</span><span class="c62">i </span><span class="c31">536&rsquo;976 288 &times; 10</span><span class="c62">9 </span><span class="c31">101&rsquo;427&rsquo;254 17&rsquo;712&rsquo;845 82.6% 300 / 312 83.0% ECG 318 (300,4,4) 586&rsquo;086 343 &times; 10</span><span class="c62">9 </span><span class="c31">45&rsquo;513&rsquo;790 10&rsquo;000&rsquo;632 78.0% 300 / 312 80.7% Respiration, NPRS 43 (128,5,4) 4&rsquo;000 14&rsquo;021&rsquo;281 89&rsquo;570 45&rsquo;352 49.3% 128 / 135 96.0% Respiration, NPRS 44 (128,5,4) 24&rsquo;125 569&rsquo;753&rsquo;031 1&rsquo;146&rsquo;145 257&rsquo;529 77.5% 128 / 141 61.7% Video dataset (gun) (150,5,3) 11&rsquo;251 119&rsquo;935&rsquo;353 758&rsquo;456 69&rsquo;910 90.8% 150 / 163 89.3% Shuttle telemetry, TEK14 (128,4,4) 5&rsquo;000 22&rsquo;510&rsquo;281 691&rsquo;194 48&rsquo;226 93.0% 128 / 161 72.7% Shuttle telemetry, TEK16 (128,4,4) 5&rsquo;000 22&rsquo;491&rsquo;306 61&rsquo;682 15&rsquo;573 74.8% 128 / 138 65.6% Shuttle telemetry, TEK17 (128,4,4) 5&rsquo;000 22&rsquo;491&rsquo;306 164&rsquo;225 78&rsquo;211 52.4% 128 / 148 100.0% </span></p><p class="c1"><span class="c28">i </span><span class="c17">RRA reported the best discord discovered with HOTSAX as the second discord (Figure 5). </span></p><p class="c18"><span class="c3">from a grammar rule selected in the Outer loop, we consider all other subsequences from the same rule as possible near- est non-self matches. After this step, the rest of the subse- quences are visited in random order. The intuition behind this ordering is also simple &ndash; the subsequences correspond- ing to the same Sequitur rule are very likely to be highly similar. Thus, considering those in the beginning of Inner loop allows us to potentially encounter a distance that is smaller than best so far dist sooner and to benefit from early abandoning (lines 9&ndash;10 of the Algorithm 1) while con- sidering all other candidates in the Outer loop. Since RRA operates with rule-corresponding subsequences of variable lengths, when searching for nearest non-self match we em- ploy the Euclidean distance normalized by the subsequence length, which favors shorter subsequences for the same dis- tance value: </span></p><p class="c1"><span class="c3">Dist(p, q) = </span></p><p class="c1"><span class="c14">Best HOTSAX discord </span></p><p class="c1"><span class="c14">Best RRA discord </span></p><p class="c1"><span class="c45">54000 54500 55000 55500 56000 </span></p><p class="c1"><span class="c45">236000 236500 237000 237500 238000 </span></p><p class="c1"><span class="c14">Second HOTSAX discord </span></p><p class="c1"><span class="c14">Second RRA discord </span></p><p class="c1"><span class="c45">441000 441500 442000 442500 443000 </span></p><p class="c1"><span class="c45">54000 54500 55000 55500 56000 </span></p><p class="c1"><span class="c14">Third HOTSAX discord </span></p><p class="c1"><span class="c14">Third RRA discord </span></p><p class="c1"><span class="c45">236000 236500 237000 237500 238000 </span></p><p class="c1"><span class="c45">441000 441500 442000 442500 443000 </span></p><p class="c1"><span class="c3">&radic;&sum;</span><span class="c0">ni=1</span><span class="c3">(p</span><span class="c28">i </span><span class="c3">&minus; q</span><span class="c28">i</span><span class="c3">)</span><span class="c62">2 </span></p><p class="c1"><span class="c3">Length(p) </span><span class="c31">Figure 5: The comparison of discords ranking by HOTSAX </span></p><p class="c1"><span class="c125">(1) </span></p><p class="c1"><span class="c31">and RRA algorithms from ECG300 dataset of length 536&rsquo;976. RRA ranked the shorter discord first due to the larger value of normalized by the subsequence length Euclidean distance (Eq.(1)) </span><span class="c3">When run iteratively, excluding the current best discord from Intervals list, RRA outputs a ranked list of multi- ple co-existing discords of variable length, as shown in Fig- </span></p><p class="c18"><span class="c31">to its nearest non-self match: the best discord has length 302, whereas the second and third discords have a length of 312 and 317 respectively. </span></p><p class="c18"><span class="c3">ures 3 and 4. The bottom panels of Figures 2 and 3 in- dicate locations and true distances from each time series subsequence corresponding to a grammar rule to its nearest non-self match by a vertical line placed at the rule beginning and whose height equals the distance. </span></p><p class="c38"><span class="c3">We compared the algorithms performance in terms of calls to the distance computation routine, which, as pointed out in [13], typically accounts for up to 99% of these algorithms&rsquo; computation time. Table 1 compares the number of distance </span><span class="c8">5. EXPERIMENTAL EVALUATION </span></p><p class="c38"><span class="c3">function calls made by the competing techniques. Note that in the ECG300 dataset (which is record 300 of the MIT-BIH We evaluated both proposed techniques on a number of </span></p><p class="c1"><span class="c3">ST change database [8]), RRA failed to rank discords in the datasets previously studied in [13] that include Space Shuttle </span></p><p class="c1"><span class="c3">same order as the HOTSAX algorithm. Marotta Valve telemetry (TEK), surveillance (Video data- </span></p><p class="c1"><span class="c3">Our rule density-based algorithm was also able to discover set), health care (electrocardiogram and respiration change), </span></p><p class="c1"><span class="c3">anomalies in all data sets, though more careful parameter and industry (Dutch Power Demand). We also evaluated on </span></p><p class="c1"><span class="c3">selection was needed at times; nevertheless, we found that a new dataset of spatial trajectories. We compared the per- </span></p><p class="c1"><span class="c3">this technique allows the discovery of very short anomalies formance of the proposed algorithms against brute force and </span></p><p class="c1"><span class="c3">which other evaluated techniques missed. For example, in HOTSAX [13] discord discovery algorithms. Since RRA re- </span></p><p class="c1"><span class="c3">the spatial trajectory dataset, the rule density-based tech- turns discords of variable length that may differ significantly </span></p><p class="c1"><span class="c3">nique was the only method capable of discovering a short, from the specified sliding window length, we show the RRA </span></p><p class="c1"><span class="c3">true anomaly that was intentionally planted by taking a de- discord recall rate as the overlap between discords discov- tour.ered by HOTSAX and RRA algorithms in the last column </span></p><p class="c1"><span class="c12">To summarize, the rule density-based approach, when used </span><span class="c3">of Table 1. </span></p><p class="c1"><span class="c3">alone, is extremely fast, but it has difficulty discriminating </span></p><p class="c1"><span class="c6">487 </span></p><p class="c1"><span class="c49">5 </span><span class="c133">1 2 </span></p><p class="c1"><span class="c49">6 9 10 </span></p><p class="c1"><span class="c49">4 </span><span class="c112">7 </span></p><p class="c1"><span class="c49">8 </span></p><p class="c1"><span class="c49">11 </span></p><p class="c1"><span class="c139">03 </span></p><p class="c1"><span class="c49">3 2 </span></p><p class="c38"><span class="c49">12 13 0 </span></p><p class="c1"><span class="c49">1 </span></p><p class="c1"><span class="c49">14 </span></p><p class="c1"><span class="c49">15 </span></p><p class="c18"><span class="c31">Figure 6: Approximations of the Hilbert space filling curve (first order at the left, second order at the right panel) and a trajec- tory conversion example. The trajectory shown at the right panel is converted into the sequence {0,3,2,2,2,7,7,8,11,13,13,2,1,1} by converting each recorded spatial position into the enclosing Hilbert cell id. </span></p><p class="c18"><span class="c3">and ranking subtle discords. Incorporating the grammatical context into the distance-based RRA algorithm, however, enables the efficient discovery of discords in all data sets. RRA is much faster than HOTSAX and brute force, and it allows for the discovery of variable-length discords. </span></p><p class="c1"><span class="c8">5.1 Spatial trajectory case study </span></p><p class="c18"><span class="c3">To demonstrate the utility of our technique for discover- ing anomalies of an unknown nature, we performed a case study on spatial trajectory data. The trajectory data is in- trinsically complex to explore for regularity since patterns of movement are often driven by unperceived goals and con- strained by unknown environmental settings. </span></p><p class="c18"><span class="c3">The data used in this study was gathered from a GPS device which recorded location coordinates and times while commuting during a typical week by car and bicycle. </span></p><p class="c18"><span class="c3">To apply RRA to the trajectory, the multi-dimensional trajectory data (time, latitude, longitude) was transformed into a sequence of scalars. To achieve this, the trajectory points were mapped to the visit order of a Hilbert space filling curve (SFC) [12] embedded in the trajectory mani- fold space and indexed by the recorded times in the visit order (Figure 6, right panel). The Hilbert SFC was chosen to reduce the distortion on the data&rsquo;s spatial locality. The Hilbert SFC-transformed trajectory produces a time series, which is then passed to the RRA algorithm for anomaly discovery. </span></p><p class="c18"><span class="c3">To visualize this data transformation approach, consider Figure 6 showing a Hilbert SFC of first order in the left panel and one of second order in the right panel. Note, that the left panel is divided into 4 quadrants and the first-order curve is drawn through their center points. The quadrants are ordered such that any two which are adjacent in the or- dering share a common edge. In the next step, shown in the right panel, each of the quadrants of the left panel are divided into 4 more quadrants and, in all, 4 &ldquo;scaled-down&rdquo; first order curves are drawn and connected together. Note that the adjacency property of consecutive squares is main- tained. As shown, maintaining adjacency helps to preserve spatial locality &ndash; points close in space are generally close in their Hilbert values. For our trajectory experimentation, we have used a Hilbert SFC of order eight. </span></p><p class="c18"><span class="c3">In general, a trajectory anomaly is defined as a sub-trajec- tory path that is atypical in the set of paths taken by an individual. Specifically, an anomaly can either be a sub- </span></p><p class="c1"><span class="c104">The global minimum of the rule coverage curve corresponds to the path travelled only once </span></p><p class="c1"><span class="c102">The best discord corresponds to the path with a partial GPS fix loss </span></p><p class="c1"><span class="c58">The sequence of Hilbert space filling curve visit order for GPS trail and best discords </span></p><p class="c1"><span class="c95">0 </span><span class="c47">5000 10000 15000 </span><span class="c58">Sequitur rules density for transformed trail (discretization param W=350,P=15,A=4) </span></p><p class="c1"><span class="c95">0 </span><span class="c47">5000 10000 15000 </span></p><p class="c1"><span class="c57">Non-self distance to the nearest neighbor among subsequences corresponding to Sequitur rules </span></p><p class="c1"><span class="c95">0 </span><span class="c47">5000 10000 15000 </span></p><p class="c18"><span class="c31">Figure 7: An example of anomaly discovery in the Hilbert SFC transformed GPS track. The true anomaly, corresponding to the unique detour, was discovered by the rule density curve global minima, which reaches 0 at the interval of length 9, the best RRA discord of length 366 corresponds to the path traveled with a par- tial GPS fix (abnormal path running across properties). Note that RRA approach was not able to capture the anomalous detour. </span></p><p class="c18"><span class="c3">trajectory that occurs in rarely visited spatial regions such as a detour, or a novel path taken within a frequently visited spatial region. The second type of trajectory anomaly is important because it considers the order in which the various locations are visited. For instance, if multiple points in a space are visited frequently, the occurrence of a visit to these points is not an anomaly by itself; however, the occurrence of visiting these points in an unseen order is an anomaly. To evaluate the proposed algorithm&rsquo;s efficiency in these specific settings, we also intentionally planted an anomaly by taking an atypical route. </span></p><p class="c18"><span class="c3">Figure 7 shows the results of the discovered anomalies in the GPS track by both proposed algorithms. As shown, the rule density curve pinpoints an unusual detour devi- ating from a normal route significantly (red colored seg- ment), the RRA algorithm highlighted a trajectory segment which was travelled with a partial GPS signal fix, but close to previously traveled routes (blue segment). This results highlight the difference in the algorithms&rsquo; sensitivity due to </span></p><p class="c1"><span class="c6">488 </span></p><p class="c1"><span class="c31">Figure 8: The second discord discovered by the RRA algorithm highlights a uniquely traveled segment. </span></p><p class="c18"><span class="c31">Figure 9: The third discord discovered by the RRA algorithm highlights an abnormal behavior that does not conform to the usual pattern of exiting and entering the block&rsquo;s parking lot. </span></p><p class="c18"><span class="c3">their nature: the rule density curve-based approach finds al- gorithmically anomalous, short subsequences (shorter than the specified sliding window length) in the symbolic space of discretized values, whereas RRA is capable to rank algorith- mically similar symbolic subsequences by discordance using their real representation. </span></p><p class="c18"><span class="c3">While the second RRA-discovered discord shown in Fig- ure 8 highlights a unique path, the third discord shown in Figure 9 spotlights the algorithm&rsquo;s sensitivity and ability to </span></p><p class="c1"><span class="c97">Area with successful rule density-based </span><span class="c65">discovery of the true anomaly </span></p><p class="c1"><span class="c9">0 </span></p><p class="c1"><span class="c97">Area with successful RRA-based </span><span class="c65">discovery of the true anomaly </span></p><p class="c18"><span class="c31">Figure 10: An illustration from our exploratory study concerned with optimal parameters selection based on the constructed gram- mar properties. Both plots show boundaries of optimal parame- ter choices: left panel for the rule density curve-based algorithm, right panel for RRA. Note that RRA algorithm-corresponding area is much larger indicating its robustness. </span></p><p class="c18"><span class="c3">capture subtle anomalies. The shown discord corresponds to an abnormal behavior within frequently traveled spatial regions &ndash; not visiting the block&rsquo;s parking lot when traveling through the area. </span></p><p class="c1"><span class="c8">5.2 Discretization parameters selection </span></p><p class="c18"><span class="c3">Similar to other discretization-based learning techniques, it is difficult to pinpoint a solution that offers the best trade- off between gain in tractability and loss in accuracy. Never- theless, we found that within the grammar-based paradigm, the sliding window length parameter is not as critical as it is for most of the existing anomaly and motif detection algo- rithms, since it is just the &rdquo;seed&rdquo; size. Specifically, we found that the rule density curve facilitates the discovery of pat- terns that are much shorter than the window size, whereas the RRA algorithm naturally enables the discovery of longer patterns. Second, we observed that when the selection of dis- cretization parameters is driven by the context, such as using the length of a heartbeat in ECG data, a weekly duration in power consumption data, or an observed phenomenon cycle length in telemetry, sensible results are usually produced. </span></p><p class="c18"><span class="c3">In addition, we found that the rule density approach alone is more sensitive to parameter choices than it is when incor- porated into the RRA distance-based algorithm. Consider an example shown in Figure 10 where we used the ECG0606 dataset featuring a single true anomaly (the dataset overview is shown in Figure 2). Since the discretization parameters affect both the precision of raw signal approximation and the size of the resulting grammar, by sampling this space and recording both algorithms&rsquo; results we found that the area where the RRA algorithm discovered the true anomaly is twice as large as the same area for the rule density curve- based algorithm. In particular, when we varied the window size in the range [10,500], PAA size in [3,20], and the al- phabet size in [3,12]; the rule density curve-based algorithm successfully discovered the anomaly for 1460 parameter com- binations whereas RRA for 7100. </span></p><p class="c1"><span class="c8">5.3 Visualization </span></p><p class="c18"><span class="c3">As we pointed out before, to explore the properties of algo- rithmically anomalous subsequences, we have incorporated both algorithms proposed in this paper into our visualiza- </span></p><p class="c1"><span class="c6">489 </span></p><p class="c1"><span class="c9">2000 </span></p><p class="c1"><span class="c9">0 50 </span><span class="c39">Approximation </span><span class="c9">100 </span><span class="c39">distance </span></p><p class="c1"><span class="c9">150 200 2000 1500 </span></p><p class="c1"><span class="c9">1500 </span></p><p class="c1"><span class="c10">r ammar</span><span class="c67">G</span><span class="c9">1000 </span></p><p class="c1"><span class="c10">r ammar</span><span class="c67">G</span><span class="c9">1000 </span></p><p class="c1"><span class="c9">500 </span></p><p class="c1"><span class="c9">500 </span></p><p class="c1"><span class="c9">0 </span></p><p class="c1"><span class="c9">0 50 </span><span class="c39">Approximation </span><span class="c9">100 </span><span class="c39">distance </span></p><p class="c1"><span class="c9">150 200 </span></p><p class="c87"><span class="c127">Third discord of length 189 </span></p><p class="c68"><span class="c127">The best discord of length 11 </span></p><p class="c93"><span class="c31">Figure 11: Incorporating the RRA algorithm in GrammarViz 2.0 [26]. The screenshot shows its application to the recorded video data set [14]. As shown, when configured with a window length of 150, RRA was able to detect multiple discords whose lengths vary from 11 to 189. </span></p><p class="c109"><span class="c3">tion tool called GrammarViz2.0 [26]. Figure 11 shows the screenshot of GrammarViz2.0 using the RRA algorithm to find anomalies in a recorded video dataset. The discovered candidate anomalies are ranked by the distances to their nearest non-self matches. As shown in the &ldquo;Length&rdquo; col- umn, all candidate anomalies have different lengths. The highlighted subsequences in the upper panel correspond to the anomalies selected in the bottom panel. </span></p><p class="c2"><span class="c3">Figure 12 shows the anomalies discovered in the same dataset using the rule density curve-based approach. As shown, we use the blue color intensity to express the gram- mar rules density: the darker is the shade, the higher is the corresponding value in rule density curve (i.e., the higher is rule count). Thus, the white-shaded regions denote the best potential anomalies since they correspond to global minima intervals in the rule density curve. </span></p><p class="c2"><span class="c3">Incorporating the proposed algorithms in our visualization tool allows interactive and efficient user-driven parameter tuning, as well as navigation and visualization of the results. </span></p><p class="c75"><span class="c8">6. PREVIOUS WORK ON ANOMALY </span></p><p class="c50"><span class="c8">DETECTION </span><span class="c3">The brute force solution for the problem of time series anomaly detection or, more specifically, the discovery of a discord of a given length n in time series T of length m, needs to consider all possible distances between each subsequence C of length n and all of its non-self matches M (C, M &isin; T). This method has O(m</span><span class="c62">2</span><span class="c3">) complexity and is simply untenable for large data sets. </span></p><p class="c72 c101"><span class="c3">To mitigate this heavy computational requirement, previ- ous work suggests that the subsequence comparisons should </span></p><p class="c18 c55"><span class="c3">be reordered for efficient pruning. For example HOTSAX [13], which is the pioneering work on discord discovery, sug- gests a fast heuristic technique that is capable of true discord discovery by reordering subsequences by their potential de- gree of discordance. Similarly in [29], the authors use local- ity sensitive hashing to estimate similarity between shapes with which they can efficiently reorder the search to dis- cover unusual shapes. The authors of [7] and [2] use Haar wavelets and augmented tries to achieve effective pruning of the search space. While these approaches achieve a speed- up of several orders of magnitude over the brute-force al- gorithm, their common drawback is that they all need the length of a potential anomaly to be specified as the input, and they output discords of a fixed length. In addition, even with pruning, they rely on the distance computation which, as suggested by Keogh et al. [13], accounts for more than 99% of these algorithms run-time. </span></p><p class="c7"><span class="c3">An interesting approach to find anomalies in a very large database (terabyte-sized data set) was shown by Yankov et al. [31]. The authors proposed an algorithm that requires only two scans through the database. However, this method needs an anomaly defining range r as the input. In addition, when used to detect an unusual subsequence within a time series, it also requires the length of the potential discord. </span></p><p class="c7"><span class="c3">Some techniques introduced approximate solutions that do not require distance computation on the raw time series. VizTree [18] is a time series visualization tool that allows for the discovery of both frequent and rare (anomalous) pat- terns simultaneously. VizTree utilizes a trie (a tree-like data structure that allows for a constant time look-up) to decode the frequency of occurrences for all patterns in their dis- cretized form. Similar to that defined in VizTree, Chen et </span></p><p class="c137"><span class="c6">490 </span></p><p class="c142"><span class="c31">Figure 12: Incorporating the rule-density-curve approach in GrammarViz2.0 [26]. The varying degrees of shades in the background correspond to rule density curve values; the non-shaded (white) intervals pinpoint true anomalies. </span></p><p class="c84"><span class="c3">al.[4] also consider anomalies to be the most infrequent time series patterns. The authors use support count to compute the anomaly score of each pattern. Although the definition of anomalies by Chen et al. is similar to discords, their tech- nique requires more input parameters such as the precision of the slope e, the number of anomalous patterns k, or the minimum threshold. In addition, the anomalies discussed in their paper contain only two points. Wei et al. [30] suggest another method that uses time series bitmaps to measure similarity. </span></p><p class="c2"><span class="c3">Finally, some previous work has examined the use of algo- rithmic randomness for time series anomaly discovery. Arn- ing et al. [1] proposed a linear time complexity algorithm for the sequential data anomaly detection problem from data- bases. Simulating a natural mechanism of memorizing pre- viously seen data entities with regular-expression based ab- stractions capturing observed redundancy, their technique has been shown capable of detecting deviations in linear time. The proposed method relies on the user-defined en- tity size (the database record size). Alternatively, Keogh et al. [14] have shown an algorithmic randomness-based para- meter-free approach to approximate anomaly detection (the WCAD algorithm). However, built upon use of an off-shelf compressor, their technique requires its numerous execu- tions, which renders it computationally expensive; in ad- dition, it requires the sliding window (i.e., anomaly) size to be specified. </span></p><p class="c124"><span class="c8">7. CONCLUSION AND FUTURE WORK </span></p><p class="c94"><span class="c3">In this work we hypothesized, that time series anomaly maps to algorithmically anomalous (i.e., incompressible with a grammatical inference algorithm) symbolic subsequence within the string obtained via time series symbolic discretiza- </span></p><p class="c18 c55"><span class="c3">tion. The rationale behind this hypothesis is that if true, it allows for an efficient variable-length time series anomaly discovery approach. </span></p><p class="c117"><span class="c3">Building upon subsequence discretization with SAX, which preserves the data structural context, and grammar induc- tion with Sequitur, which guarantees discovery of all existing algorithmically-effective correlations by maintaining its in- variants of uniqueness and utility at all times, we designed a generic framework for learning algorithmic regularities and detecting irregularities in time series in order to test our hypothesis. </span></p><p class="c7"><span class="c3">Using the framework, we constructed two time series ano- maly discovery algorithms to empirically evaluate the hy- pothesis. One of these algorithms operates in the space of discretized data, whose dimensionality is typically much smaller than the original time series, and therefore is highly efficient. The output of this algorithm, namely the rule den- sity curve, was found to behave according to our hypothe- sis and provides an intuitive and efficient way for putative anomaly detection. Our second algorithm is based on the explicit distance computation and is capable to detect even subtle variable-length discords. </span></p><p class="c19"><span class="c3">Through an experimental evaluation, we have validated our hypothesis and have shown, that the proposed tech- niques are orders of magnitude more efficient than current state of the art without a loss in accuracy (Table 1). </span></p><p class="c7"><span class="c3">Since the grammar-based time series decomposition allows us to quantitatively assess the time series context through analysis of the grammar&rsquo;s hierarchical structure, the pri- mary direction of our future effort is to analyze the effect of the discretization parameters on the algorithm&rsquo;s ability to discover contextually meaningful patterns. Since both tech- niques underlying our approach, namely, SAX discretization and grammatical inference with Sequitur, process the input </span></p><p class="c118"><span class="c6">491 </span></p><p class="c129"><span class="c3">time series from left to right, yet another research direction that suggests itself is the possibility of early anomaly detec- tion in real-time data streams. </span></p><p class="c69"><span class="c8">8. ACKNOWLEDGMENTS </span></p><p class="c100"><span class="c3">This research is partially supported by the National Sci- ence Foundation under Grant No. 1218325 and 1218318. </span></p><p class="c34"><span class="c8">9. REFERENCES </span></p><p class="c113"><span class="c3">[1] Arning, A., Agrawal, R., &amp; Raghavan, P., A Linear </span></p><p class="c46"><span class="c3">Method for Deviation Detection in Large Databases, In KDD (pp. 164-169) (1996) [2] Bu, Y., Leung, O., Fu, A., Keogh, E., Pei, J., </span></p><p class="c72 c116"><span class="c3">Meshkin, S., WAT: Finding Top-K Discords in Time Series Database, In Proc. of SIAM Intl. Conf. on Data Mining (2007) [3] Chandola, V., Cheboli, D., and Kumar, V., Detecting Anomalies in a Time Series Database, CS TR 09&ndash;004 (2009) [4] Chen, X., Zhan, Y., Multi-scale Anomaly Detection </span></p><p class="c116 c122"><span class="c3">Algorithm based on Infrequent Pattern of Time Series, J. of Computational and Applied Mathematics (2008) [5] Cilibrasi, R., Vit&aacute;nyi, P.M.B., Clustering by </span></p><p class="c16"><span class="c3">compression, IEEE Trans. Inform. Theory (2005) [6] Ferbus-Zanda, M., Grigorieff, S., Is Randomness &ldquo;Native&rdquo; to Computer Science?, arXiv (2008) [7] Fu, A., Leung, O., Keogh, E., Lin, J., Finding Time </span></p><p class="c72 c132"><span class="c3">Series Discords based on Haar Transform, In Proc. of Intl. Conf. on Adv. Data Mining and Applications (2006) [8] Goldberger, A.L. et al., PhysioBank, PhysioToolkit, </span></p><p class="c115"><span class="c3">and PhysioNet: components of a new research resource for complex physiologic signals, Circulation, 101(23) (2000) [9] Gr&uuml;nwald, P. D., The Minimum Description Length </span></p><p class="c106"><span class="c3">Principle, MIT Press (2007) [10] Gupta, M., Gao, J., Aggarwal, C.C., Han, J., Outlier </span></p><p class="c90"><span class="c3">Detection for Temporal Data: A Survey, IEEE Trans. on Knowledge and Data Engineering, 25, 1 (2013) [11] Hawkins, D. M., Identification of Outliers, Chapman </span></p><p class="c72 c99"><span class="c3">and Hall (1980) [12] Hilbert, D., </span><span class="c125">&nbsp;&#776;</span><span class="c3">Ueber stetige Abbildung einer Linie auf </span></p><p class="c11"><span class="c3">ein Fl&auml;chenst&uuml;ck, Mathematische Annalen, 38:459&ndash;460 (1891) [13] Keogh, E., Lin, J., Fu, A., HOT SAX: Efficiently </span></p><p class="c141"><span class="c3">Finding the Most Unusual Time Series Subsequence, In Proc. ICDM&rsquo;05 (2005) [14] Keogh, E., Lonardi, S., Ratanamahatana, C.A., </span></p><p class="c72 c79"><span class="c3">Towards parameter-free data mining, In Proc. KDD (2004) [15] Kolmogorov, A.N., Three approaches to the </span></p><p class="c72 c83"><span class="c3">quantitative definition of information, Problems Inform. Transms. (1965) [16] Li, Y., Lin, J., and Oates, T., Visualizing </span></p><p class="c72 c119"><span class="c3">variable-length time series motifs, In Proc. of SDM (2012) [17] Li, M. and Vit&aacute;nyi, P.M.B., An Introduction to </span></p><p class="c72 c88"><span class="c3">Kolmogorov Complexity and Its Applications, Springer-Verlag (1993) </span></p><p class="c1 c20"><span class="c3">[18] Lin, J., Keogh, E., Lonardi, S., Lankford, J.P., </span></p><p class="c72 c89"><span class="c3">Nystrom, D. M., Visually mining and monitoring massive time series, In Proc. ACM SIGKDD Intn&lsquo;l Conf. on KDD (2004) [19] Lin, J., Keogh, E., Patel, P., and Lonardi, S., Finding </span></p><p class="c71"><span class="c3">Motifs in Time Series, The 2nd Workshop on Temporal Data Mining, the 8th ACM Int&rsquo;l Conference on KDD (2002) [20] Martin-L&ouml;f, Per, On the definition of random </span></p><p class="c143"><span class="c3">sequences, Information and Control, MIT, 9:602-61 (1966) [21] Nevill-Manning, C. and Witten, I., Linear-Time, </span></p><p class="c41"><span class="c3">Incremental Hierarchy Inference for Compression, In Proc. of IEEE Conference on Data Compression (1997) [22] Nevill-Manning, C. and Witten, I., Identifying </span></p><p class="c48"><span class="c3">Hierarchical Structure in Sequences: A linear-time algorithm, Journal of Artificial Intelligence Research, 7, 67-84 (1997) [23] Oates, T., Boedihardjo, A., Lin, J., Chen, C., </span></p><p class="c55 c72"><span class="c3">Frankenstein, S., Gandhi, S., Motif discovery in spatial trajectories using grammar inference, In Proc. of ACM CIKM (2013) [24] Paper authors. Supporting webpage: </span><span class="c110">http://github.com/GrammarViz2 </span><span class="c3">(2015) [25] Patel, P., Keogh, E., Lin, J., Lonardi, S., Mining </span></p><p class="c37"><span class="c3">Motifs in Massive Time Series Databases, In Proc. ICDM (2002) [26] Senin, P., Lin, J., Wang, X., Oates, T., Gandhi, S., </span></p><p class="c77"><span class="c3">Boedihardjo, A.P., Chen, C., Frankenstein, S., Lerner, M., GrammarViz 2.0: a tool for grammar-based pattern discovery in time series, In Proc. ECML/PKDD (2014) [27] Solomonoff, R.J., A formal theory of inductive </span></p><p class="c92"><span class="c3">inference. Part I, Rockford Research Institute, Inc. (1962) [28] Van Wijk, J.J. and Van Selow, E.R., Cluster and </span></p><p class="c27"><span class="c3">calendar based visualization of time series data, In Proc. IEEE Symposium on Information Visualization (1999) [29] Wei, L., Keogh, E., Xi, X., SAXually explicit images: </span></p><p class="c114"><span class="c3">Finding unusual shapes, In Proc. ICDM (2006) [30] Wei, L., Kumar, N., Lolla, V., Keogh, E., Lonardi, S., </span></p><p class="c98"><span class="c3">Ratanamahatana, C., Assumption-free Anomaly Detection in Time Series, In Proc. SSDBM (2005) [31] Yankov, D., Keogh, E., Rebbapragada, U., Disk aware </span></p><p class="c140"><span class="c3">discord discovery: finding unusual time series in terabyte sized data sets, Knowledge and Information Systems, 241-262 (2008) </span></p><p class="c103"><span class="c6">492 </span></p></body></html>