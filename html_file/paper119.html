<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c42{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c82{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.1pt}.c81{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:3.9pt;font-family:"Arial";font-style:normal}.c4{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.3pt;font-family:"Times New Roman";font-style:normal}.c80{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.5pt;font-family:"Arial";font-style:normal}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c26{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.2pt;font-family:"Times New Roman";font-style:italic}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c59{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9.4pt;font-family:"Arial";font-style:normal}.c7{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:2.9pt;font-family:"Times New Roman";font-style:normal}.c47{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:4.4pt;font-family:"Times New Roman";font-style:normal}.c33{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:5.5pt;font-family:"Times New Roman";font-style:normal}.c123{margin-left:-16.6pt;padding-top:1.4pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-34.6pt}.c44{margin-left:-25.7pt;padding-top:4.1pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c89{margin-left:-16.6pt;padding-top:1.7pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c66{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:7.1pt;font-family:"Times New Roman";font-style:normal}.c17{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:3.8pt;font-family:"Times New Roman";font-style:normal}.c32{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:2.3pt;font-family:"Times New Roman";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.3pt;font-family:"Arial";font-style:normal}.c64{margin-left:-25.7pt;padding-top:3.8pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c16{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.3pt;font-family:"Arial";font-style:normal}.c52{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:5.5pt;font-family:"Times New Roman";font-style:normal}.c101{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:5.9pt;font-family:"Times New Roman";font-style:normal}.c83{margin-left:-26.6pt;padding-top:1.7pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.9pt}.c110{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:15.6pt;font-family:"Arial";font-style:normal}.c69{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.6pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c60{margin-left:-25.7pt;padding-top:1.7pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c85{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:18.3pt;font-family:"Arial";font-style:normal}.c56{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:3.8pt;font-family:"Times New Roman";font-style:normal}.c61{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.2pt;font-family:"Times New Roman";font-style:italic}.c58{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:4.8pt;font-family:"Times New Roman";font-style:normal}.c86{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c96{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c5{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:2.7pt;font-family:"Times New Roman";font-style:normal}.c117{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-17.4pt}.c40{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.6pt;font-family:"Times New Roman";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:2.8pt;font-family:"Arial";font-style:normal}.c92{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c38{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.8pt;font-family:"Arial";font-style:normal}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c55{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.6pt;font-family:"Arial";font-style:normal}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:4.7pt;font-family:"Times New Roman";font-style:normal}.c102{margin-left:-25.7pt;padding-top:3.8pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c53{margin-left:-25.7pt;padding-top:19.2pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.8pt}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.6pt;font-family:"Arial";font-style:normal}.c37{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:4.8pt;font-family:"Times New Roman";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c73{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:2.8pt;font-family:"Times New Roman";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c49{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.5pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c23{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c118{margin-left:-25.7pt;padding-top:0.5pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c50{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c70{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.7pt;font-family:"Times New Roman";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c51{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:5.6pt;font-family:"Arial";font-style:normal}.c93{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.1pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.3pt;font-family:"Arial";font-style:normal}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:4.6pt;font-family:"Arial";font-style:normal}.c20{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:4.4pt;font-family:"Times New Roman";font-style:normal}.c48{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.4pt;font-family:"Arial";font-style:normal}.c62{margin-left:-25.7pt;padding-top:7.4pt;text-indent:34.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c78{margin-left:-26.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-5.1pt}.c104{margin-left:-26.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.4pt}.c126{margin-left:-25.7pt;padding-top:12.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:3.5pt}.c121{margin-left:-25.7pt;padding-top:5.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.7pt}.c77{margin-left:-17.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c97{margin-left:218.2pt;padding-top:54.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c79{margin-left:-17.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c10{margin-left:-17.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.9pt}.c94{margin-left:-17.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:7.9pt}.c84{margin-left:-16.6pt;padding-top:11.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:15.6pt}.c1{margin-left:-17.6pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.4pt}.c120{margin-left:-26.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:2.1pt}.c67{margin-left:-25.7pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:127.1pt}.c103{margin-left:-26.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.1pt}.c116{margin-left:-22.1pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11.8pt}.c105{margin-left:-17.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11pt}.c74{margin-left:-7.5pt;padding-top:15.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.4pt}.c54{margin-left:218.2pt;padding-top:56.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c88{margin-left:-16.6pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:90pt}.c34{margin-left:-17.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-20.9pt}.c100{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-25.4pt}.c122{margin-left:-26.6pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-10.2pt}.c99{margin-left:-16.6pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-25.4pt}.c72{margin-left:-25.7pt;padding-top:5.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:77.4pt}.c109{margin-left:-22.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:8.6pt}.c87{margin-left:-25.7pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c46{margin-left:-17.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-24.5pt}.c91{margin-left:-26.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8pt}.c28{margin-left:1.4pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.5pt}.c68{margin-left:-22.8pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:86.8pt}.c71{margin-left:-25.7pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-0.1pt}.c112{margin-left:-22.1pt;padding-top:19pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:11pt}.c114{margin-left:-17.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.5pt}.c57{margin-left:-26.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.2pt}.c119{margin-left:-25.7pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-16.4pt}.c95{margin-left:-26.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-12.6pt}.c76{margin-left:-22.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c98{margin-left:-26.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.2pt}.c75{margin-left:-17.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.4pt}.c124{padding-top:4.1pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c111{padding-top:1.4pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c125{padding-top:3.8pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c35{margin-left:-11.1pt;padding-top:12pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c29{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c19{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c115{padding-top:18.5pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c108{padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c90{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c106{margin-left:-16.6pt;margin-right:-25.4pt}.c107{margin-left:-16.6pt;margin-right:-25.9pt}.c65{margin-left:-16.6pt;margin-right:-32.2pt}.c113{margin-left:-16.6pt;margin-right:-26.4pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c90"><p class="c19"><span class="c50">RPM: Representative Pattern Mining for Efficient Time Series Classification </span></p><p class="c3"><span class="c0">Xing Wang, Jessica Lin </span><span class="c13">George Mason University Dept. </span><span class="c11">xwang24@gmu.edu, </span><span class="c13">of Computer Science </span><span class="c11">jessica@gmu.edu </span></p><p class="c3"><span class="c0">Pavel Senin </span><span class="c13">Bioscience Division, Los Alamos National Laboratory, Los </span><span class="c11">psenin@lanl.gov </span></p><p class="c3"><span class="c13">Alamos, NM, 87544 </span><span class="c0">Tim Oates, Sunil Gandhi </span><span class="c13">University of Maryland, Baltimore County Dept. </span><span class="c11">oates@cs.umbc.edu, sunilga1@umbc.edu </span><span class="c13">of Computer Science </span><span class="c0">Arnold P. Boedihardjo Crystal Chen Susan Frankenstein </span><span class="c11">{arnold.p.boedihardjo, </span><span class="c86">U.S. Army Corps of Engineers, </span><span class="c11">crystal.chen, </span><span class="c86">Engineer </span><span class="c11">susan.frankenstein}@usace.army.mil </span><span class="c86">Research and Development Center </span><span class="c0">ABSTRACT </span><span class="c2">Time series classification is an important problem that has received a great amount of attention by researchers and prac- titioners in the past two decades. In this work, we propose a novel algorithm for time series classification based on the discovery of class-specific representative patterns. We define representative patterns of a class as a set of subsequences that has the greatest discriminative power to distinguish one class of time series from another. Our approach rests upon two techniques with linear complexity: symbolic dis- cretization of time series, which generalizes the structural patterns, and grammatical inference, which automatically finds recurrent correlated patterns of variable length, pro- ducing an initial pool of common patterns shared by many instances in a class. From this pool of candidate patterns, our algorithm selects the most representative patterns that capture the class specificities, and that can be used to effec- tively discriminate between time series classes. Through an exhaustive experimental evaluation we show that our algo- rithm is competitive in accuracy and speed with the state- of-the-art classification techniques on the UCR time series repository, robust on shifted data, and demonstrates excel- lent performance on real-world noisy medical time series. </span></p><p class="c3"><span class="c0">1. INTRODUCTION </span></p><p class="c29"><span class="c2">Massive amount of time series data are generated daily in areas as diverse as medicine, astronomy, industry, sciences, and finance, to name just a few. Even with the explosion of interest in time series data mining during the past two decades, and increasing popularity of new emerging topics such as motif discovery, classification of time series still re- mains one of the most important problems with many real- world applications in diverse disciplines. </span></p><p class="c29"><span class="c2">c </span><span class="c39">2016, Copyright is with the authors. Published in Proc. 19th Inter- national Conference on Extending Database Technology (EDBT), March 15-18, 2016 - Bordeaux, France: ISBN 978-3-89318-070-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c29"><span class="c2">While many classification algorithms have been proposed for time series, it has been shown that the nearest neigh- bor classifier, albeit simple in design, is competitive with the more sophisticated algorithms like SVM [32]. As a re- sult, many existing techniques on time series classification focus on improving the similarity measure, an essential part of the nearest neighbor classifier [4]. Recently, the notion of time series shapelets&mdash;time series subsequences that are &ldquo;maximally representative&rdquo; of a class&mdash;has been proposed. Shapelets generalize the lazy nearest neighbor classifier to an eager, decision-tree-like classifier [36][10], which typically improves the classification speed and interpretability of the results. </span></p><p class="c29"><span class="c2">In this work, we focus on a similar problem of finding the most representative patterns for the classification task. We call our algorithm RPM (Representative Pattern Mining). The key motivation is that the identification of a small set of distinctive and interpretable patterns of each class allows us to exploit their key characteristics for discriminating against other classes. In addition, we hypothesize that the classifi- cation procedure based on a set of highly class-characteristic short patterns will provide high generalization performance under noise and/or translation/rotation, i.e. it shall be ro- bust and shift/rotation invariant. </span></p><p class="c3"><span class="c18">Series ISSN: 2367-2005 185 </span><span class="c92">10.5441/002/edbt.2016.19 </span></p><p class="c3"><span class="c2">Figure 1: An illustration of the best patterns discovered </span><span class="c9">by rival subsequence-based techniques on Cricket data [20]. </span></p><p class="c3"><span class="c2">Our work is significantly different from existing subse- quence-based techniques such as K-shapelet discovery and </span></p><p class="c29"><span class="c2">classification algorithms. Specifically, one major difference lies in our definition of representative patterns. We define representative patterns to be class-specific prototypes, i.e. each class has its own set of representative patterns, whereas in shapelets some classes may share a shapelet. Figure 1 shows the patterns/shapelets identified by different algo- rithms on the Cricket dataset [20]. Note that SAX-VSM [31] captures visually similar short patterns of the same length in both classes. Fast Shapelets [27] selects a single subsequence to build a classifier. Our algorithm, RPM, selects different patterns that capture the data specificity (characteristic left and right hand movements) for each class. </span></p><p class="c29"><span class="c2">The methodology employed by our approach is also very different from existing shapelet-based techniques. Contrast- ing with a decision-tree-based shapelet classification which finds the best splitting shapelet(s) via the exhaustive candi- date elimination and explicit distance computation, we rely on the grammar induction (GI) procedure that automatically (i.e. by the algorithm&rsquo;s design) and without computing any distance explicitly [17][30] discovers frequent subsequences (motifs) of variable length, which we consider as represen- tative pattern candidates. The number of candidates for the exhaustive shapelet search approach is O(nm</span><span class="c15">2</span><span class="c2">) (n is the number of time series, m is their length) [27], since the algo- rithm examines all possible subsequences. For our method, the number of candidates considered is much smaller: O(K), where K is the number of motifs since only patterns that frequently occur in a class can be representative. </span></p><p class="c29"><span class="c2">In addition to speeding up the algorithm, grammar in- duction, by design, grows the lengths of the initial patterns when constructing grammar rules, thus eliminating the need for searching an optimal pattern length exhaustively &ndash; a procedure that is common to most of sliding window-based shapelet techniques [36][10][27]. </span></p><p class="c29"><span class="c2">Since GI requires discrete input, our algorithm transforms real-valued time series into discrete values using Symbolic Aggregate approXimation (SAX) [18]. The algorithm op- erates in the approximate symbolic space inferring a gram- mar and generating a set of candidate patterns through the analysis of the grammar hierarchy in linear time. Next, the algorithm maps the discovered patterns back into real val- ues and continues with pattern refinement using clustering. The cluster centroids (or medoids) are then reported as the best class-specific motifs, among which we select the most representative ones by verifying their classification power at the final step. </span></p><p class="c29"><span class="c2">Figures 2 and 3 show examples of representative patterns discovered by our technique in two datasets: CBF, a syn- thetic dataset [22], and Coffee, a real dataset [2]. Represen- tative patterns discovered in CBF highlight the most distinc- tive features in each of the three classes: a plateau followed by the sudden rise then followed by a plateau in Cylinder, the increasing ramp followed by a sudden drop in Bell, and a sudden rise by a decreasing ramp in Funnel. Representative patterns discovered in the Coffee dataset also correspond to the most distinctive natural features which not only include the discriminative caffeine and chlorogenic acid bands, but the spectra corresponding to other constituents such as car- bohydrates, lipids, etc. [2]. </span></p><p class="c29"><span class="c2">Since we use a different selection criterion, the representa- tive patterns discovered by our technique are different from the shapelets or patterns found by other subsequence-based techniques, thus providing a complementary functionality </span></p><p class="c29"><span class="c2">that can be used for exploratory studies. For example, the representative patterns discovered in CBF and Coffee datasets by our approach are different from the shapelets discovered by Fast Shapelets [27], a well-known shapelet dis- covery algorithm which we use for experimental comparison. For the CBF dataset, Fast Shapelets reports two branching shapelets that correspond to sudden rises in Cylinder and Funnel classes. For the Coffee dataset, Fast Shapelets re- ports a single branching shapelet corresponding to the caf- feine spectra band (Arabica). </span></p><p class="c29"><span class="c2">Note that the discovery of class-specific motifs, which is an integral part of our algorithm, also offers a unique advantage that extends beyond the classification task. Differing from the traditional notion of time series motifs [17][3], which can either be repeated subsequences of a fixed length within a long time series, or repeated time series instances within a group of data (e.g. shape motifs [16]), our class-specific mo- tifs are variable-length sub-patterns that occur frequently in many time series of a data group. They are, in a sense, related to time series subspace clusters [15]. Therefore, our approach provides an efficient mechanism to discover these subspace patterns without exhaustively searching through all subsequences. Throughout the paper, we will use the terms &rdquo;class-specific subspace motifs&rdquo; and &rdquo;class-specific mo- tifs&rdquo; interchangeably. </span></p><p class="c3"><span class="c43">2 </span></p><p class="c3"><span class="c55">Cylinder </span></p><p class="c3"><span class="c43">2 </span></p><p class="c3"><span class="c55">Bell </span></p><p class="c3"><span class="c43">3 </span></p><p class="c3"><span class="c55">Funnel </span></p><p class="c3"><span class="c43">1120010</span><span class="c6">-1</span><span class="c43">-1-1</span><span class="c6">-2-20 50 100 </span></p><p class="c3"><span class="c6">0 50 100 </span></p><p class="c3"><span class="c6">0 50 100 </span></p><p class="c3"><span class="c49">Class Cylinder and best rep. patterns </span></p><p class="c3"><span class="c49">Class Bell and best rep. pattern </span></p><p class="c3"><span class="c49">Class Funnel and best rep. pattern </span><span class="c43">2 </span></p><p class="c3"><span class="c43">3 </span></p><p class="c3"><span class="c43">12 20-1100-1</span><span class="c6">-2-2-20 50 100 </span></p><p class="c3"><span class="c6">0 50 100 </span></p><p class="c3"><span class="c6">0 50 100 </span></p><p class="c3"><span class="c2">Figure 2: The Cylinder-Bell-Funnel (CBF) dataset and the </span><span class="c9">best representative patterns for its classes discovered with the proposed technique. </span></p><p class="c3"><span class="c43">40 </span></p><p class="c3"><span class="c49">Class Robusta and the best representative patterns </span></p><p class="c3"><span class="c43">40 </span></p><p class="c3"><span class="c49">Class Arabica and the best representative patterns </span></p><p class="c3"><span class="c43">303020201010</span><span class="c6">000 100 200 300 </span></p><p class="c3"><span class="c6">0 100 200 300 </span></p><p class="c3"><span class="c2">Figure 3: Two classes from the Coffee dataset and the best </span><span class="c9">representative patterns. </span></p><p class="c3"><span class="c2">As we shall demonstrate, in addition to the excellent ex- ploratory characteristics, our approach achieves competi- tive classification accuracy compared to the state-of-the- art techniques: nearest neighbor classifiers, characteristic subsequence-based classifier (SAX-VSM), and shapelet-based classifiers, while maintaining great efficiency. </span></p><p class="c29"><span class="c2">The rest of the paper is organized as follows: Section 2 dis- cusses related work and background materials. We describe our approach for finding representative patterns in Section 3, and discuss parameter optimization in Section 4. Section 5 presents experimental results. We demonstrate the utili- ties of our approach with two case studies in Section 6, and conclude in Section 7. </span></p><p class="c3"><span class="c0">2. RELATED WORK AND BACKGROUND </span></p><p class="c3"><span class="c18">186 </span></p><p class="c72"><span class="c0">2.1 Notation and definition </span></p><p class="c44"><span class="c2">To precisely state the problem at hand, and to relate our work to previous research, we will define the key terms used throughout this paper. We begin by defining our data type, time series: </span></p><p class="c38"><span class="c2">Time series T = t</span><span class="c22">1</span><span class="c9">,...,t</span><span class="c22">m </span><span class="c9">is a set of scalar observations </span><span class="c2">ordered by time. </span></p><p class="c38"><span class="c2">Since we focus on finding local patterns that are represen- tative of a class, we consider time series subsequences: </span></p><p class="c60"><span class="c2">Subsequence S of time series T is a contiguous sampling t</span><span class="c22">p</span><span class="c9">,...,t</span><span class="c22">p+n&minus;1 </span><span class="c9">of points of length n &lt;&lt; m where p is an </span><span class="c2">arbitrary position, such that 1 &le; p &le; m &minus; n + 1. </span></p><p class="c38"><span class="c2">Typically subsequences are extracted from a time series with the use of a sliding window: </span></p><p class="c16"><span class="c2">Sliding window subsequence extraction: for a time se- ries T of length m, and a user-defined subsequence length n, all possible subsequences of T can be found by sliding a window of size n across T. </span></p><p class="c60"><span class="c2">Given two time series subsequences S</span><span class="c24">1 </span><span class="c2">and S</span><span class="c24">2</span><span class="c2">, both of length n, the distance between them is a real number that accounts for how much these subsequences are different, and the function which outputs this number when given S</span><span class="c22">1 </span><span class="c9">and S</span><span class="c22">2 </span><span class="c9">is called the distance function and denoted </span><span class="c2">Dist(S</span><span class="c24">1</span><span class="c2">,S</span><span class="c24">2</span><span class="c2">). One of the most commonly used distance func- tions is the Euclidean distance, which is the square root of the sum of the squared differences between each pair of the corresponding data points in S</span><span class="c24">1 </span><span class="c2">and S</span><span class="c24">2</span><span class="c2">. </span></p><p class="c118"><span class="c2">Closest (i.e. best) match: Given a subsequence S and a time series T, the time series subsequence T</span><span class="c24">p </span><span class="c2">of length |S| starting at position p : 0 &lt;p&lt; |T|&minus;|S| is the closest match of S if Dist(S, T</span><span class="c24">p</span><span class="c2">) &le; Dist(S, T</span><span class="c22">k</span><span class="c9">), where T</span><span class="c22">k </span><span class="c9">is a subsequence </span><span class="c2">of T starting at any position k : 0 &le; k &lt; |T|&minus;|S|, and k = p. The Dist(S, T</span><span class="c22">p</span><span class="c9">) is the closest match distance. </span></p><p class="c118"><span class="c2">Time series pattern is a subsequence that possesses certain interesting characteristics. For example it can be a subsequence that occurs frequently, i.e. whose observance frequency is above some arbitrary threshold t. A frequently occurring subsequence is also called time series motif. </span></p><p class="c83"><span class="c2">Class-specific motif: Given a class C and a set of train- ing instances X</span><span class="c22">C</span><span class="c9">, a class-specific motif M for C is a subse- </span><span class="c2">quence pattern S in C consisting of a set of similar subse- quences from different training instances such that count(S) &ge; (&gamma; &middot; |X</span><span class="c24">C</span><span class="c2">|), where 0 &lt; &gamma; &le; 1. This states that a pattern is considered frequent if it appears in at least &gamma; of the training instances in the class. We will describe what we mean by &ldquo;similar&rdquo; in a later section. </span></p><p class="c82"><span class="c2">Representative patterns: The most discriminative sub- sequences among the class motifs for class C are selected as the representative patterns for the class. The number of the representative patterns for each class is dynamically deter- mined by the algorithm. </span></p><p class="c117"><span class="c2">We will describe how to measure the &ldquo;representativeness&rdquo; and discriminative power of the candidate patterns in a later section. </span></p><p class="c60"><span class="c2">Time Series Transformation: The set of the closest match distances between a time series T and the (candidate) representative patterns can be viewed as a transformation of T &isin; </span><span class="c63">R</span><span class="c15">n&middot;m </span><span class="c2">into T &isin; </span><span class="c63">R</span><span class="c15">n&middot;K</span><span class="c2">, where K is the total number of the representative patterns from all classes. </span></p><p class="c67"><span class="c0">2.2 Related work </span></p><p class="c102"><span class="c2">Classification of time series has attracted much interest from the data mining community in the past two decades </span></p><p class="c29 c107"><span class="c2">[4][36][5][13][21][28][25][33][20][35][34]. Nevertheless, to date, the simple nearest neighbor classification is the most popu- lar choice due to its simplicity and effectiveness [32]. There- fore, a large body of work on time series classification has focused on the nearest neighbor classification improvement by developing new data representations or distance measures [32]. To date, a nearest neighbor classification with an effec- tive distance measure like Dynamic Time Warping (DTW) outperforms many existing techniques [32]. </span></p><p class="c111 c113"><span class="c2">Among the proposed alternatives, many methods focus on finding local patterns in time series as predictive features of the class [5]. Recently, Ye and Keogh introduced a novel concept called time series &ldquo;shapelet&rdquo;. A shapelet is an exact time series subsequence that is &ldquo;maximally representative&rdquo; of a class [36]. Once found, a shapelet-based technique clas- sifies an unlabeled time series by computing its similarity to the shapelet. The original shapelet technique proposed by the authors constructs a decision tree-based classifier which uses the shapelet similarity as the splitting criterion. While effective and interpretable, the original shapelet discovery technique is computationally intensive. </span></p><p class="c123"><span class="c2">Numerous improvements were proposed. The Logical Shape- lets [20] extends the original work by improving the efficiency and introducing an augmented, more expressive shapelet representation based on conjunctions or disjunctions of shape- lets. Fast Shapelets [27] improves the efficiency of the origi- nal shapelets algorithm by exploiting the projections into a symbolic representation. Learning Shapelets [7] proposes a new mathematical formalization that iteratively reduces the shapelet search space by computing a classification precision- based objective function. </span></p><p class="c89"><span class="c2">The &ldquo;Shapelet Transform&rdquo; [10] technique finds the best K-shapelets and transforms the original time series into a vector of K features, each of which represents the distance between a time series and a shapelet. This technique can thus be used with virtually any classification algorithm. </span></p><p class="c89"><span class="c2">SAX-VSM [31] is another approximate algorithm that en- ables the discovery of local class-characteristic (representa- tive) patterns based on the similar pattern-discrimination principle via tf&lowast;idf -based patterns ranking [29]. While sim- ilar to our notion of representative patterns, the length of SAX-VSM-generated patterns equals to the sliding window length. In addition, the algorithm makes no additional ef- fort to prune the discovered patterns, yielding a large sparse matrix of pattern weights. </span></p><p class="c106 c111"><span class="c2">Our algorithm can be related to the concept of mining in- teresting frequent patterns reviewed in [9], as it is essentially the selection of &ldquo;interesting&rdquo; pattern subset from a frequent pattern set. In our case, we regard the representative power of a pattern as its interestingness measure. </span></p><p class="c106 c115"><span class="c0">3. RPM: REPRESENTATIVE PATTERN MINING FOR CLASSIFICATION </span><span class="c2">The classification algorithm we propose consists of two stages: (a) Learning the representative patterns. (b) Clas- sification using the representative patterns. </span></p><p class="c106 c108"><span class="c2">In the training stage, the algorithm identifies the most representative patterns for each class from the training data by 3 steps: (i) pre-processing training data; (ii) generating representative pattern candidates from processed data; (iii) selecting the most representative patterns from candidates. Once the representative patterns are learned, we trans- </span></p><p class="c97"><span class="c18">187 </span></p><p class="c87"><span class="c2">form the training data into a new feature space, where each representative pattern is a feature and each training time se- ries is represented as a vector of distances to these patterns. We can then build a classifier from the transformed training data.</span><span class="c9">We will describe the algorithm in detail below, starting </span><span class="c2">with the classification stage. </span></p><p class="c119"><span class="c0">3.1 Time series classification using represen- </span><span class="c11">tative patterns </span><span class="c2">To classify a time series using the representative patterns learned from the training stage, the first step is to transform the test data T &isin; </span><span class="c63">R</span><span class="c15">n&middot;m </span><span class="c2">into a feature space representation T &isin; </span><span class="c63">R</span><span class="c15">n&middot;K </span><span class="c2">by computing distances from T to each of the K representative patterns from all classes. The transformed time series is thus represented as a fixed-length vector &ndash; a universal data type which can be used with many of the traditional classification techniques. In this paper, we use SVM [24] for its popularity, but note that our algorithm can work with any classifier. </span></p><p class="c71"><span class="c0">3.2 Training stage: Finding representative </span><span class="c11">patterns </span></p><p class="c44"><span class="c2">As mentioned previously, our goal is to find the most rep- resentative and distinctive patterns for each of the time se- ries classes. These class-specific patterns should satisfy two requirements: (i) they should be class-specific motifs, i.e. shared by at least &gamma; (a fraction) of the time series in the class; and (ii) they should enable the discrimination between the current and other classes &ndash; the capacity measured with a scoring function discussed below. </span></p><p class="c60"><span class="c2">At the high level, the algorithm can be viewed as a suc- cession of three steps. First, the algorithm performs data pre-processing for each class in the training data, by con- catenating all instances from the same class into a long time series, and discretizing the concatenated time series. Sec- ond, the algorithm finds frequent patterns via grammar in- ference and forms the candidate pool for each class. Third, it refines the candidates pool by eliminating redundant and non-discriminating patterns, and outputs patterns that rep- resent the class the best, i.e., the representative patterns. </span></p><p class="c16"><span class="c2">In our previous work, we proposed GrammarViz (v2.0), which uses time series discretization and grammar inference for time series motif discovery and exploration [17][30]. We observe that the same approach can be leveraged to find class-specific subspace motifs, thus enabling the classifica- tion as well. </span></p><p class="c68"><span class="c27">3.2.1 Step 1: Pre-processing </span></p><p class="c64"><span class="c2">We prepare the training data for subspace pattern discov- ery by concatenating all training time series from the same class into a single long time series. We note that the con- catenation step is not required for our learning algorithm and can in fact be skipped. The reason for concatenating the training instances is for visualization purpose only, as will be shown in Figure 4. </span></p><p class="c16"><span class="c2">Next, we discretize the concatenated time series into a sequence of tokens for grammar induction using Symbolic Aggregate approXimation (SAX) [18]. More specifically, we apply SAX to subsequences extracted from the concatenated time series of a training class via a sliding window. SAX performs subsequence discretization by first reducing the di- mensionality of the subsequence with Piecewise Aggregate </span></p><p class="c29 c106"><span class="c2">Approximation (PAA) [12]. Towards that end, it divides z-normalized subsequence into w equal-sized segments and computes a mean value for each segment. It then maps these values to symbols according to a pre-defined set of break- points dividing the distribution space into &alpha; equiprobable regions, where &alpha; is the alphabet size specified by the user. This subsequence discretization process outputs an ordered list of SAX words, where each word corresponds to the left- most point of the sliding window. Two parameters affect the SAX transform granularity &ndash; the number of PAA segments (PAA size) and the SAX alphabet size. </span></p><p class="c111 c106"><span class="c2">Since neighboring subsequences extracted via a sliding window share all points except one, they are similar to each other and often have identical SAX representations. To pre- vent over-counting a pattern, we apply numerosity reduction [17]: if in the course of discretization, the same SAX word occurs more than once consecutively, instead of placing ev- ery instance into the resulting string, we record only its first occurrence. </span></p><p class="c89"><span class="c2">As an example, consider the sequence S0 where each word (e.g. aba) represents a subsequence extracted from the con- catenated time series via a sliding window and then dis- cretized with SAX. The subscript following each word de- notes the starting position of the corresponding subsequence in the time series. </span></p><p class="c100"><span class="c2">S0 = aba</span><span class="c24">1 </span><span class="c2">bac</span><span class="c24">2 </span><span class="c2">bac</span><span class="c24">3 </span><span class="c2">bac</span><span class="c24">4 </span><span class="c2">cab</span><span class="c24">5 </span><span class="c2">acc</span><span class="c24">6 </span><span class="c2">bac</span><span class="c24">7 </span><span class="c2">bac</span><span class="c24">8 </span><span class="c2">cab</span><span class="c24">9 </span><span class="c2">... With numerosity reduction, S0 becomes: S1 = aba</span><span class="c24">1 </span><span class="c2">bac</span><span class="c24">2 </span><span class="c2">cab</span><span class="c24">5 </span><span class="c2">acc</span><span class="c24">6 </span><span class="c2">bac</span><span class="c24">7 </span><span class="c2">cab</span><span class="c24">9 </span><span class="c2">... Numerosity reduction not only reduces the length of the input for the next step of the algorithm (hence making it more efficient and reducing its space requirements) and sim- plifies the identification of non-overlapping time series motifs by removing &ldquo;noise&rdquo; from overlapping subsequences. Most importantly, numerosity reduction enables the discovery of representative patterns of varying lengths as we show next. </span></p><p class="c99"><span class="c27">3.2.2 Step 2: Generating representative pattern can- </span><span class="c85">didates </span><span class="c2">In this step, we use grammar induction to identify re- peated patterns in the concatenated time series, and gen- erate a representative pattern candidates pool from these patterns. The algorithm is outlined in Algorithm 1. The sequence of SAX words obtained from the pre-processing step is fed into a context-free grammar induction algorithm (Algorithm 1, Line 7). We use Sequitur, a string compres- sion algorithm that infers a context-free grammar in linear time and space [23]. We choose Sequitur due to its efficiency and reasonably good compression capability, but note that our technique also works with other (context-free) GI algo- rithms. When applied to a sequence of SAX words, Sequitur treats each word as a token and recursively reduces all di- grams, i.e. consecutive pairs of tokens (terminals or non- terminals), occurring more than once in the input string to a single new non-terminal symbol representing a grammar rule.</span><span class="c9">Consider the grammar induced by Sequitur from the input </span><span class="c2">string S1: </span></p><p class="c35"><span class="c2">Grammar Rule Expanded Grammar Rule R0 &rarr; aba R1 acc R1 aba</span><span class="c22">1 </span><span class="c23">bac</span><span class="c42">2 </span><span class="c23">cab</span><span class="c42">5 </span><span class="c9">acc</span><span class="c22">6 </span><span class="c23">bac</span><span class="c42">7 </span><span class="c23">cab</span><span class="c42">9 </span><span class="c2">R1 &rarr; bac cab </span><span class="c96">bac cab </span></p><p class="c74"><span class="c2">In this grammar, R1 describes a simplified version of the </span></p><p class="c97"><span class="c18">188 </span></p><p class="c3"><span class="c2">Figure 4: RPM pre-processing visualization with GrammarViz 2.0 [30]. The time series from Class 4 of SwedishLeaf dataset </span><span class="c9">were concatenated, discretized, Sequitur grammar was inferred, and one of the frequent motifs selected. Note that the grammar rule-corresponding subsequences vary in length from 72 to 80. The length of the original time series before concatenation is 128 as indicated by dotted lines. Note that one of time series does not contain the pattern and another contains it twice. </span></p><p class="c21"><span class="c2">repeated pattern [bac cab], which concurrently maps to two substrings of different lengths from S0: [bac</span><span class="c24">2 </span><span class="c2">bac</span><span class="c24">3 </span><span class="c2">bac</span><span class="c24">4 </span><span class="c2">cab</span><span class="c24">5</span><span class="c2">] (length of 4) and [bac</span><span class="c22">7 </span><span class="c9">bac</span><span class="c22">8 </span><span class="c9">cab</span><span class="c22">9</span><span class="c9">] (length of 3), respectively. </span><span class="c2">By keeping SAX words&rsquo; offsets throughout the procedures of discretization and grammar induction, we are able to map rules and SAX words back to their original time series subse- quences. Since each SAX word corresponds to a single point of the input time series (a subsequence starting point), R1 maps to subsequences of variable lengths ([2-5] and [7-9]). Figure 4 shows an example of the recurrent subsequences found in the concatenated time series from Class 4 of the Swedish Leaf dataset. Note, that when processing a con- catenated time series, the algorithm does not consider the subsequences that span time series junction points in order to avoid concatenation process artifacts. </span></p><p class="c3"><span class="c2">Algorithm 1 Finding repeated patterns 1: </span><span class="c39">function FindCandidates(T rain, SAXP arams, &gamma;) </span><span class="c9">2: </span><span class="c14">candidates &larr; &empty; </span><span class="c9">3: </span><span class="c14">allCandidates &larr; &empty; </span><span class="c9">4: </span><span class="c14">for each TrainClassI in T rain do </span><span class="c9">5: </span><span class="c14">cT S &larr; ConcatenateTS(TrainClassI) </span><span class="c9">6: </span><span class="c14">// {build grammar avoiding junctions (see Fig. 4)} </span><span class="c9">7: </span><span class="c14">allRepeats &larr; modifiedGI(cT S, SAXP arams) </span><span class="c9">8: </span><span class="c14">refinedRepeats &larr; &empty; </span><span class="c9">9: </span><span class="c14">// {r is repeated subsequences from a row in Fig. 4} </span><span class="c9">10: </span><span class="c14">for each r in allRepeats do </span><span class="c9">11: </span><span class="c14">clusters &larr; Clustering(r) </span><span class="c9">12: </span><span class="c14">refinedRepeats.addAll(clusters) </span><span class="c2">13: </span><span class="c39">for each cluster in refinedRepeats do </span><span class="c9">14: </span><span class="c14">if cluster.size &gt; &gamma; &middot; |I| then </span><span class="c9">15: </span><span class="c14">centroid &larr; GetCentroid(cluster) </span><span class="c9">16: </span><span class="c14">// {candidates for class I} </span><span class="c9">17: </span><span class="c14">candidates.add(centroid) </span><span class="c2">18: </span><span class="c39">// {candidates for all classes} </span><span class="c9">19: </span><span class="c14">allCandidates.add(candidates) </span><span class="c2">20: </span><span class="c39">return (allCandidates) </span></p><p class="c29"><span class="c2">Refining repeated subsequences: Every grammar rule induced from Sequitur describes an approximate repeated pattern (our candidate motif) observed in time series; how- ever, corresponding exact subsequences may differ signifi- cantly depending on the SAX granularity. To select the most representative of the frequent symbolic patterns (and essen- </span></p><p class="c29"><span class="c2">tially of the training class), we use hierarchical clustering al- gorithm (complete-linkage) to cluster all rule-corresponding subsequences based on their similarity (Algorithm 1, Line 11). Note that the purpose of applying clustering here is to handle the situation where a candidate motif found by gram- mar induction algorithm may contain more than one group of similar subsequences. In this case, we should partition the subsequences into sets of clusters, each of which corresponds to one motif. To determine the appropriate number of clus- ters, we first set the number of clusters as two. If the cluster sizes are drastically different, e.g. one of the clusters con- tains less than 30% of subsequences from the original group, we do not split the original group. If both clusters contain sufficient numbers of subsequences, we will continue to split them into smaller groups. The partitioning stops when no group can be further split (Algorithm 1, Line 12). </span></p><p class="c29"><span class="c2">Consistent with Section 3.2 requirement (i), if the size of a cluster is smaller than the specified threshold &gamma;, the cluster is discarded. If a cluster satisfies the minimum size require- ment, its centroid is added to the representative patterns candidates pool for a class (Algorithm 1, Line 14-15). Note an alternative is to use the medoid instead of centroid. As outlined in Algorithm 1, this refinement procedure outputs a list of representative pattern candidates for all classes. </span></p><p class="c3"><span class="c27">3.2.3 Step </span><span class="c85">terns </span></p><p class="c29"><span class="c27">3: Selecting the most representative pat- </span><span class="c2">The candidate patterns obtained so far are the frequent patterns that occur in a class. However, some of them may not be class-discriminative if they also occur in other classes. Addressing this issue, we prune the candidate patterns pool with Algorithm 2 whose input is the pool of candidate pat- terns identified from the previous step, and the entire train- ing dataset. The algorithm outputs the set of class-specific patterns. </span></p><p class="c29"><span class="c2">Remove Similar Patterns: The representative pattern candidates are repeated patterns found by the grammar in- duction algorithm applied to the discretized time series. Due to the aggregation, some structurally similar subsequences may be mapped to slightly different SAX strings, e.g. differ by one letter. Feeding such patterns to the subsequent step (selecting representative patterns) will slow down the search </span></p><p class="c3"><span class="c18">189 </span></p><p class="c3"><span class="c2">Algorithm 2 Find distinctive patterns 1: </span><span class="c39">function FindDistinct(T rain, allCandidates) </span><span class="c9">2: </span><span class="c14">candidates &larr; &empty; </span><span class="c9">3: </span><span class="c14">&tau; &larr; ComputeThreshold </span><span class="c9">4: </span><span class="c14">// {Remove similarities in allCandidates} </span><span class="c9">5: </span><span class="c14">for each c in allCandidates do </span><span class="c9">6: </span><span class="c14">isNonSimilar &larr; true </span><span class="c9">7: </span><span class="c14">for each c</span><span class="c22">ns </span><span class="c14">in candidates do </span><span class="c9">8: </span><span class="c14">// {c and c</span><span class="c22">ns </span><span class="c14">may have different length} </span><span class="c9">9: </span><span class="c14">dist &larr; ComputeClosestMatchDist(c, c</span><span class="c22">ns</span><span class="c14">) </span><span class="c9">10: </span><span class="c14">if dist &lt; &tau; then </span><span class="c9">11: </span><span class="c14">if c</span><span class="c22">ns</span><span class="c14">.frequent &lt; c.frequent then </span><span class="c9">12: </span><span class="c14">// {The frequency in concatenated TS} </span><span class="c9">13: </span><span class="c14">candidates.remove(c</span><span class="c22">ns</span><span class="c14">) </span><span class="c9">14: </span><span class="c14">candidates.add(c) </span><span class="c9">15: </span><span class="c14">isNonSimilar &larr; false </span><span class="c9">16: </span><span class="c14">break(); </span><span class="c2">17: </span><span class="c39">if isNonSimilar then </span><span class="c9">18: </span><span class="c14">candidates.add(c) </span><span class="c2">19: </span><span class="c39">// {Transform TS into new feature space where each fea- ture is the distance between time series and a candidate} </span><span class="c9">20: </span><span class="c14">TransformedTrain &larr; Transform(T rain, candidates) </span><span class="c9">21: </span><span class="c14">// {Perform feature selection algorithm on new data} </span><span class="c9">22: </span><span class="c14">selectedIndices &larr; FSalg(TransformedTrain) </span><span class="c9">23: </span><span class="c14">// {Select patterns according to indices } </span><span class="c9">24: </span><span class="c14">patterns &larr; Select(candidates,selectedIndices) </span><span class="c9">25: </span><span class="c14">return (patterns) </span></p><p class="c21"><span class="c2">when removing correlated patterns in feature selection step. In order to resolve this issue, our algorithm removes simi- lar candidates from the candidate set, as shown in Algorithm 2, Lines 5 &ndash; 18. Before the removal, it computes a threshold used to determine if two patterns are similar. The threshold (Alg. 2, Line 3) is determined as follows: (i) Compute pair- wise distances of subsequences within each refined grammar rule (i.e. the final clusters from Algorithm 1). (ii) Sort the distances in ascending order. (iii) Take the distance at the 30-th percentile as the threshold &tau; for similarity. We will show the effect on accuracy and running time with different values of &tau; in the experimental section. </span></p><p class="c29"><span class="c2">Select Representative Patterns: After refining the representative pattern candidates pool from the previous steps, we transform the original time series into a distance feature vector by computing the closest match distance be- tween each time series and all the candidate patterns. As an example, two patterns in dataset ECGFiveDays are shown in Figure 5, and the transformed training data is shown in Figure 6. The original time series from the two classes look visually similar. However, once we transform the raw time series into the two-dimensional feature vector (one feature from each class in this case), it is easy to separate the two classes. As can be seen in Figure 6, the transformed data is linearly separable. </span></p><p class="c29"><span class="c2">Since the transformation uses all the candidates as new features, a feature selection step is needed to select the most distinctive features. Each feature represents the distance from the original time series to one of the candidate pat- terns. Thus, the features selected represent the most rep- resentative patterns. Any feature selection algorithms can be applied here. In this work, we use the correlation-based feature selection from [8], since it is capable of identifying features that are highly correlated with the class. After fea- ture selection, the selected patterns will be used to classify future time series. Note that the number of selected patterns for each class is dynamically determined by the feature se- </span></p><p class="c3"><span class="c31">ECGFiveDays class #1 </span><span class="c8">best representative pattern </span></p><p class="c3"><span class="c41">-5.0 </span></p><p class="c3"><span class="c31">ECGFiveDays class #2 </span><span class="c8">best representative pattern </span></p><p class="c3"><span class="c51">3 </span></p><p class="c3"><span class="c41">2.5 </span></p><p class="c3"><span class="c41">0.0 </span><span class="c51">0-3</span><span class="c41">-60 50 100 </span></p><p class="c3"><span class="c41">0 50 100 </span></p><p class="c3"><span class="c2">Figure 5: Two classes from the ECGFiveDays dataset and </span><span class="c9">the best representative patterns. </span></p><p class="c3"><span class="c36">0.00 </span></p><p class="c3"><span class="c41">-2.5 </span></p><p class="c3"><span class="c59">Train instances of ECGFiveDays dataset in the </span><span class="c110">representative patterns feature space </span></p><p class="c3"><span class="c2">Figure 6: Transformed data of train data from ECGFive- </span><span class="c9">Days </span></p><p class="c3"><span class="c2">lection algorithm. </span></p><p class="c3"><span class="c0">4. PARAMETER SELECTION AND CLAS- </span></p><p class="c3"><span class="c0">SIFICATION WITH DIFFERENT SAX PA- RAMETERS </span><span class="c2">As shown in Algorithm 1, there is a parameter vector SAXParams in the input. The vector consists of three SAX discretization parameters, namely the sliding window size, PAA size, and the SAX alphabet size. In this section, we shall describe our algorithm for the optimal SAX parame- ters selection. Since time series data in different classes may have varying characteristics, a parameter set that is optimal for one class may not be optimal for another. Therefore, the parameter optimization is performed for each class. </span><span class="c0">4.1 Search </span><span class="c11">haustively </span></p><p class="c29"><span class="c0">for the best SAX parameters ex- </span><span class="c2">One way to find the optimal parameter set is by brute force grid search &ndash; as shown in Algorithm 3. The algo- rithm tests all parameter combinations within a specified range and selects the optimal set (the one that results in the best F1 measure score from five-fold cross validation on the validation data set). For each parameter combination candidate, the grid search algorithm first divides the origi- nal training data into training and validation data 5 times for 5 different splits. For each split, the algorithm invokes Algorithms 1 and 2 to obtain the representative patterns </span></p><p class="c3"><span class="c18">190 </span></p><p class="c3"><span class="c36">0.11 </span></p><p class="c3"><span class="c36">0.09 </span></p><p class="c3"><span class="c36">0.06 </span></p><p class="c3"><span class="c36">0.03 </span></p><p class="c3"><span class="c36">0.00 </span><span class="c101">Distance </span><span class="c36">0.03 </span><span class="c101">to the first representative </span><span class="c36">0.06 </span><span class="c101">pattern </span></p><p class="c3"><span class="c36">0.09 0.11 </span><span class="c80">Classes: </span><span class="c69">Class #1 Class #2 </span></p><p class="c87"><span class="c2">(Lines 8-9). The validation is performed on the validation data set (Line 12) with a five-fold cross validation. The F1 measure is computed using the classification result for each class. The parameter combination with the best F1 measure for each class is selected as the optimal parameters for the class. </span></p><p class="c126"><span class="c2">Algorithm 3 SAX Parameter selection (Brute-Force) </span></p><p class="c121"><span class="c2">1: </span><span class="c39">function ParamsSelect(P aramsRange, OriginalT rain) </span><span class="c9">2: </span><span class="c14">for each Class I do </span><span class="c9">3: </span><span class="c14">bestSoF arF orI &larr; 0 </span><span class="c9">4: </span><span class="c14">for each SAXPs in P aramsRange do </span><span class="c9">5: </span><span class="c14">// {Repeat 5 times for different splits} </span><span class="c9">6: </span><span class="c14">while iteration &lt; 5 do </span><span class="c9">7: </span><span class="c14">{train, validate} &larr; Split(OriginalTrain) </span><span class="c9">8: </span><span class="c14">candidates &larr; FindCandidates(train, SAXP s, &gamma;) </span><span class="c9">9: </span><span class="c14">patterns &larr; FindDistinct(train, candidates) </span><span class="c9">10: </span><span class="c14">validate</span><span class="c22">t </span><span class="c14">&larr; Transform(validate, patterns) </span><span class="c9">11: </span><span class="c14">// {fMeasure is the f1 measure of each class} </span><span class="c9">12: </span><span class="c14">fMeasure &larr; 5foldsCV(validate</span><span class="c22">t</span><span class="c14">) </span><span class="c9">13: </span><span class="c14">for each Class I do </span><span class="c9">14: </span><span class="c14">if f M easure.i &gt; bestSoF arF orI then </span><span class="c9">15: </span><span class="c14">bestParamForClassI &larr; SAXPs </span><span class="c9">16: </span><span class="c14">bestSoF arF orI &larr; fMeasure.i </span><span class="c2">17: </span><span class="c39">iteration + + </span><span class="c2">18: </span><span class="c39">for each Class I do </span><span class="c9">19: </span><span class="c14">bestP arams.add(bestParamForClassI) </span><span class="c2">20: </span><span class="c39">return (bestP arams) </span></p><p class="c53"><span class="c2">Instead of running Algorithm 3 completely to find the best parameter set, pruning can be performed by the observed number of repeated patterns. In Line 8 of Algorithm 3, if no candidate for a class is returned because all repeated patterns for that class have frequency below the specified threshold (&gamma;), the algorithm abandons the current iteration and proceeds with the next parameter combination. The intuition rests upon the fact that given the number of time series in the training data, we can estimate the required minimal frequency for the repeated patterns. </span><span class="c0">4.2 Searching for the best SAX parameters us- </span><span class="c11">ing DIRECT </span><span class="c2">We optimize the search for the best discretization param- eters set by using the DIviding RECTangles (DIRECT) al- gorithm [11] which is a derivative-free optimization scheme that possesses local and global optimization properties, con- verges quickly, and yields a deterministic optimal solution. DIRECT is designed to deal with optimization problems of the form: </span></p><p class="c62"><span class="c2">min</span><span class="c22">x </span><span class="c2">f(x), f &isin; R, x,X</span><span class="c22">L</span><span class="c9">,X</span><span class="c22">U </span><span class="c9">&isin; R, where X</span><span class="c22">L </span><span class="c9">&le; x &le; X</span><span class="c22">U </span><span class="c2">where f(x) is the objective (error) function, and x is a pa- rameters vector. The algorithm begins by scaling the search domain to a unit hypercube. Next, it iteratively performs a sampling procedure consisting of two steps: (i) partitioning the hypercube into smaller hyper-rectangles and (ii) identi- fying a set of potentially-optimal hyper-rectangles by sam- pling their centers. Iterations continue until the error func- tion converges. DIRECT is guaranteed to converge to the global optimal function value as the number of iterations approaches infinity and the function is continuous in the neighborhood of a global optimum [11]. If interrupted at any iteration, for example after exhausting a time limit, the algorithm reports the best-so-far parameters set. </span></p><p class="c21 c65"><span class="c2">Since SAX parameters are integer values, we round the values reported by DIRECT to the closest integers when op- timizing their selection for our cross validation-based error function (one minus fMeasure, as described in Section 4.1). While rounding affects the DIRECT convergence speed, this approach is not only much more efficient than the exhaus- tive search, but is also able to perform a time-constrained parameter optimization by limiting the number of iterations. </span><span class="c0">4.3 Classification with class-specific trained pa- </span><span class="c11">rameters </span><span class="c2">With the best SAX parameters learned from Section 4.2, the representative patterns can be obtained by calling Algo- rithms 1 and 2. To classify future instances, we follow the classification procedure described in Section 3.1. However, with the class-specific parameter optimization, we need to add more steps to the classification procedure to account for the adaptive parameter sets for different classes. Different classes may have different best SAX parameter combinations (SPCs). We learn the best SPCs for each class respectively as described previously. Then we apply Algorithms 1 and 2 to obtain the representative patterns for each SPC. We combine all these representative patterns together and re- move the correlated patterns by applying feature selection again. We then obtain the final set of representative pat- terns, which will be used as the input for the algorithm described in Section 3.1 to classify test data. </span></p><p class="c84"><span class="c0">5. EXPERIMENTAL EVALUATION </span></p><p class="c88"><span class="c0">5.1 Setup and Baseline </span></p><p class="c106 c125"><span class="c2">We evaluate the classification performance of our tech- nique on the standard time series archive from the UCR repository [14]. Information on the datasets is shown in Table 1. The code and datasets used for the case study (discussed next section) are available on [1]. We compare our method Representative Pattern Mining (RPM) with five other classification techniques, among which are two nearest- neighbor classifiers based on the global distance measures: Euclidean distance (1NN-ED) and DTW with the best warp- ing window (1NN-DTWB), and three classifiers based on the use of class-characteristic local patterns: Fast Shapelets (FS) [27], SAX-VSM [31] and Learning Shapelets (LS) [7]. These three subsequence-based techniques rely on different numbers of patterns for classification &ndash; while Fast Shapelets uses a minimal number of patterns to build a classification tree, SAX-VSM accounts for all patterns extracted via slid- ing window in each of the class-representing weight vectors. Learning Shapelets has the best accuracy so far. </span><span class="c0">5.2 Classification Accuracy </span></p><p class="c106 c124"><span class="c2">Table 1 shows the classification error rates for all six meth- ods on the UCR datasets. The best error rate for each dataset is denoted with boldface. In addition, Figure 7 shows the summary comparison of our proposed technique with other methods. The results shown are with parame- ter optimization, and the &gamma; (minimum cluster size) is set to be 20% of the training size for the class. From the re- sults, our method is the second best on classification ac- curacy among these six methods. We slightly lose to the Learning Shapelets method, which has the most &ldquo;wins&rdquo; in classification. However, the p-value of wilcoxon test is 0.834 &gt; 0.05, so the difference is not significant with a confidence </span></p><p class="c97"><span class="c18">191 </span></p><p class="c3"><span class="c2">Table 1: Datasets description and the classification error rates. </span></p><p class="c3"><span class="c25">Dataset Classes Train Test Length 1NN- ED </span></p><p class="c3"><span class="c25">FS LS RPM </span></p><p class="c29"><span class="c25">50words 50 450 455 270 0.369 0.242 0.374 0.483 0.232 0.242 Adiac 37 390 391 176 0.389 0.391 0.417 0.425 0.437 0.355 Beef 5 30 30 470 0.333 0.333 0.233 0.467 0.240 0.233 CBF 3 30 900 128 0.148 0.004 0.010 0.092 0.006 0.001 ChlorineConcentration 3 467 3840 166 0.352 0.350 0.341 0.667 0.349 0.355 CinC ECG torso 4 40 1380 1639 0.103 0.070 0.344 0.225 0.167 0.125 Coffee 2 28 28 286 0.000 0.000 0.000 0.071 0.000 0.000 Cricket X 12 390 390 300 0.423 0.252 0.308 0.549 0.209 0.236 Cricket Y 12 390 390 300 0.433 0.228 0.318 0.495 0.249 0.379 Cricket Z 12 390 390 300 0.413 0.238 0.297 0.533 0.201 0.190 DiatomSizeReduction 4 16 306 345 0.065 0.065 0.121 0.078 0.033 0.069 ECG200 2 100 100 96 0.120 0.120 0.140 0.250 0.126 0.170 ECGFiveDays 2 23 861 136 0.203 0.203 0.001 0.000 0.000 0.000 FaceAll 14 560 1690 131 0.286 0.192 0.245 0.408 0.218 0.231 FaceFour 4 24 88 350 0.216 0.114 0.114 0.091 0.048 0.045 FacesUCR 14 200 2050 131 0.231 0.088 0.109 0.296 0.059 0.034 Fish 7 175 175 463 0.217 0.154 0.017 0.189 0.066 0.065 Gun Point 2 50 150 150 0.087 0.087 0.013 0.040 0.000 0.027 Haptics 5 155 308 1092 0.630 0.588 0.584 0.610 0.532 0.562 InlineSkate 7 100 550 1882 0.658 0.613 0.593 0.733 0.573 0.535 ItalyPowerDemand 2 67 1029 24 0.045 0.045 0.089 0.063 0.031 0.044 Lightning2 2 60 61 637 0.246 0.131 0.213 0.361 0.177 0.262 Lightning7 7 70 73 319 0.425 0.288 0.397 0.397 0.197 0.219 MALLAT 8 55 2345 1024 0.086 0.086 0.199 0.054 0.046 0.020 MedicalImages 10 381 760 99 0.316 0.253 0.516 0.443 0.271 0.262 MoteStrain 2 20 1252 84 0.121 0.134 0.125 0.202 0.087 0.113 OliveOil 4 30 30 570 0.133 0.133 0.133 0.300 0.560 0.100 OSULeaf 6 200 242 427 0.479 0.388 0.165 0.421 0.182 0.211 SonyAIBORobotSurface 2 20 601 70 0.304 0.305 0.306 0.315 0.103 0.058 SonyAIBORobotSurfaceII 2 27 953 65 0.141 0.141 0.126 0.211 0.082 0.114 SwedishLeaf 15 500 625 129 0.211 0.157 0.278 0.229 0.087 0.070 Symbols 6 25 995 398 0.101 0.062 0.109 0.091 0.036 0.042 synthetic control 6 300 300 60 0.120 0.017 0.017 0.107 0.007 0.007 Trace 4 100 100 275 0.240 0.010 0.000 0.000 0.000 0.000 Two Patterns 4 1000 4000 128 0.093 0.002 0.004 0.741 0.003 0.005 TwoLeadECG 2 23 1139 82 0.253 0.132 0.014 0.075 0.003 0.048 uWaveGestureLibrary X 8 896 3582 315 0.261 0.227 0.323 0.316 0.200 0.226 uWaveGestureLibrary Y 8 896 3582 315 0.338 0.301 0.364 0.412 0.287 0.303 uWaveGestureLibrary Z 8 896 3582 315 0.350 0.322 0.356 0.353 0.269 0.279 Wafer 2 300 3000 426 0.005 0.005 0.001 0.003 0.004 0.013 WordsSynonyms 25 267 638 270 0.382 0.252 0.440 0.542 0.340 0.353 Yoga 2 300 3000 426 0.170 0.155 0.151 0.335 0.150 0.165 </span></p><p class="c3"><span class="c25"># of best (including ties) 2 9 7 2 19 15 </span></p><p class="c3"><span class="c25">Wilcoxon Test p-values (RPM vs Other) </span></p><p class="c3"><span class="c25">1NN- DTWB </span></p><p class="c3"><span class="c25">SAX- VSM </span></p><p class="c3"><span class="c25">0.006 0.287 0.217 0.002 0.834 - </span></p><p class="c3"><span class="c66">1NN DTWB vs RPM </span></p><p class="c3"><span class="c66">SAX&minus;VSM vs RPM </span></p><p class="c3"><span class="c66">FS vs RPM </span></p><p class="c3"><span class="c66">LS vs RPM </span></p><p class="c19"><span class="c30">8 8 ..008 8 ..008 8 ..008 8 ..00</span><span class="c26">1NN DTWB wins </span></p><p class="c3"><span class="c26">SAX&minus;VSM wins </span></p><p class="c3"><span class="c26">FS wins </span></p><p class="c3"><span class="c26">LS wins </span></p><p class="c3"><span class="c30">66..00</span><span class="c4">q</span><span class="c7">q </span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c30">66..00</span><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c2">Figure 7: Our technique and current state of the art classifiers performance comparison. </span></p><p class="c3"><span class="c18">192 </span></p><p class="c3"><span class="c30">66..00</span><span class="c4">q </span><span class="c7">q </span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c30">66..00</span><span class="c4">q </span><span class="c7">q </span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c30">44..00</span><span class="c52">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span><span class="c30">44..00</span><span class="c52">q</span><span class="c58">q</span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c30">44..00</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c40">0</span><span class="c30">44..00</span><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c30">22..002.00.</span><span class="c40">0</span><span class="c4">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c19"><span class="c52">q </span><span class="c58">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c29"><span class="c4">q </span><span class="c37">q </span><span class="c4">q </span></p><p class="c29"><span class="c4">qq </span><span class="c7">q q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span><span class="c37">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c21"><span class="c30">22..00</span><span class="c4">q </span><span class="c7">q </span><span class="c52">q </span><span class="c58">q </span></p><p class="c3"><span class="c4">qq </span></p><p class="c3"><span class="c30">22..00</span><span class="c4">q </span></p><p class="c3"><span class="c30">2.0</span><span class="c4">q </span></p><p class="c3"><span class="c30">00..</span><span class="c40">00</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c26">RPM wins </span></p><p class="c3"><span class="c30">00..</span><span class="c40">00</span><span class="c4">q </span></p><p class="c3"><span class="c30">0.</span><span class="c40">00</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c26">RPM wins </span><span class="c30">0.</span><span class="c33">q </span><span class="c37">q </span><span class="c4">q</span><span class="c7">qq</span><span class="c4">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span><span class="c4">q </span><span class="c7">q </span><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c29"><span class="c33">q </span><span class="c37">q </span><span class="c4">q </span><span class="c7">q q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c4">q q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span></p><p class="c3"><span class="c26">RPM wins </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c30">0.</span><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c4">q </span></p><p class="c3"><span class="c26">RPM wins </span></p><p class="c3"><span class="c4">q </span></p><p class="c21"><span class="c4">q q </span><span class="c7">q q </span><span class="c4">q q </span></p><p class="c21"><span class="c33">q </span><span class="c37">q </span><span class="c4">q </span><span class="c7">q </span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q q </span><span class="c4">q </span><span class="c7">q q </span><span class="c33">q</span><span class="c37">q</span><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c29"><span class="c4">q q </span><span class="c33">q </span><span class="c37">q </span><span class="c7">q q </span></p><p class="c3"><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span><span class="c4">q </span><span class="c7">q </span><span class="c4">q</span><span class="c7">q</span><span class="c37">q </span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span><span class="c33">q </span><span class="c37">q </span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c29"><span class="c4">q </span><span class="c33">q</span><span class="c7">q </span><span class="c37">q</span><span class="c7">q </span><span class="c4">q</span><span class="c7">qq </span></p><p class="c19"><span class="c52">q </span><span class="c33">q </span><span class="c58">q </span><span class="c37">q </span><span class="c4">qq</span><span class="c7">qq</span><span class="c4">qq </span><span class="c7">qq </span></p><p class="c19"><span class="c33">q </span><span class="c37">q </span></p><p class="c19"><span class="c33">q q </span><span class="c37">q q </span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c37">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c29"><span class="c4">q </span><span class="c33">q </span><span class="c7">q </span><span class="c37">q </span><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c7">q </span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c33">q</span><span class="c7">q </span><span class="c37">q</span><span class="c7">q </span><span class="c33">q </span><span class="c37">q </span><span class="c4">q </span><span class="c7">q </span><span class="c4">q</span><span class="c7">q</span><span class="c4">q </span></p><p class="c3"><span class="c7">q </span></p><p class="c3"><span class="c33">q </span><span class="c37">q </span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c52">q</span><span class="c58">q</span><span class="c4">q </span><span class="c7">q q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span><span class="c33">q</span><span class="c4">q </span><span class="c7">q </span><span class="c37">q</span><span class="c7">q </span><span class="c52">q </span><span class="c4">q</span><span class="c58">q </span><span class="c4">q </span><span class="c7">q q</span><span class="c4">q</span><span class="c7">q q</span><span class="c33">q </span><span class="c37">q </span></p><p class="c19"><span class="c4">q </span><span class="c7">q </span><span class="c4">q</span><span class="c7">q</span><span class="c33">q</span><span class="c37">q</span><span class="c4">q </span><span class="c7">q </span></p><p class="c3"><span class="c4">q </span><span class="c7">q </span><span class="c4">q</span><span class="c7">q</span><span class="c33">q </span><span class="c37">q </span></p><p class="c3"><span class="c40">0.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 </span></p><p class="c3"><span class="c40">0.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 </span></p><p class="c3"><span class="c40">0.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 </span></p><p class="c3"><span class="c40">0.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 </span></p><p class="c3"><span class="c2">the of 95%. Moreover, as we can visually inspect from Figure </span></p><p class="c3"><span class="c2">results using the 10</span><span class="c15">th</span><span class="c2">, 50</span><span class="c15">th</span><span class="c2">, 70</span><span class="c15">th</span><span class="c2">, and 90</span><span class="c15">th </span><span class="c2">percentiles. 7, the error rate difference between Learning Shapelets and </span></p><p class="c3"><span class="c2">The running time and classification error changes are shown RPM is very small &mdash; most of the points are located around </span></p><p class="c3"><span class="c2">in Figure 9. The average running time and classification er- the diagonal. In the next section, we will show that our </span></p><p class="c3"><span class="c2">ror changes on the 42 UCR data set are shown in Table 3. method is much faster than the Learning Shapelets method. </span></p><p class="c21"><span class="c2">The average standard deviation for running time is 268.71 seconds, and 0.014 for classification error . </span><span class="c0">5.3 Efficiency </span></p><p class="c3"><span class="c2">The pre-processing, discretization and Sequitur grammar Table 2: Running time and classification accuracy compar- </span><span class="c9">ison between Fast Shapelets, Learning Shapelets and Rep- </span><span class="c2">induction all have linear time complexity in the size of train- </span></p><p class="c3"><span class="c9">resentative Pattern Mining </span><span class="c2">ing data and, in practice, can be done simultaneously, since they process data sequentially. To select the best repre- </span></p><p class="c3"><span class="c25">Running Time (Seconds) </span><span class="c2">sentative patterns for each class, we need to first cluster </span></p><p class="c3"><span class="c25">Dataset LS FS RPM </span><span class="c2">the candidate motifs identified by the grammar rules. The </span></p><p class="c3"><span class="c25">50words 3396298 1666 4221 </span><span class="c2">time required for clustering depends on the number of mo- tif instances identified. Suppose there are (on average) u motif instances in each grammar rule, then the complex- ity is O(u</span><span class="c15">3 </span><span class="c2">&middot; |rules|) for hierarchical clustering. The cen- </span></p><p class="c21"><span class="c25">Adiac Beef CBF ChlorineConcentration CinC ECG torso 1551130 290 977 5971 175 202 275 7 32 7668 572 347 46979 3521 1636 </span><span class="c2">troids of the qualifying clusters are the pattern candidates. For each pattern candidate, we perform subsequence match- ing to identify the best matches (O(|Candidates|&middot;|Train|)). </span></p><p class="c21"><span class="c25">Coffee Cricket X Cricket Y Cricket Z 293 15 98 252834 2286 438 249889 2378 1208 260107 2611 594 </span><span class="c2">Even though the number of pattern candidates for each class is relatively small compared to the training size, this step seems to be the bottleneck of the training stage due to the re- </span></p><p class="c21"><span class="c25">DiatomSizeReduction ECG200 ECGFiveDays FaceAll 1013 17 69 224 12 55 41 3 20 93442 538 2139 </span><span class="c2">peated distance call. We use early abandoning strategy [32] to speed up the subsequence matching, but other options are possible such as approximate matching. The training needs </span></p><p class="c21"><span class="c25">FaceFour FacesUCR Fish Gun Point 1853 69 43 30516 195 2141 42766 802 755 209 6 34 </span><span class="c2">to be repeated for each class. Thus, the training complexity is O(|Train|+c&middot;(u</span><span class="c15">3</span><span class="c2">&middot;|rules|+|Candidates|&middot;|Train|)), where c is the number of classes, and u is the average number of </span></p><p class="c21"><span class="c25">Haptics InlineSkate ItalyPowerDemand Lightning2 81751 8100 1575 314244 43930 4970 14 1 9 1657 1212 373 </span><span class="c2">motif instances in each grammar rule. </span></p><p class="c3"><span class="c2">If the best SAX parameters are known, our algorithm is fast &mdash; in this case, simply using the classification method </span></p><p class="c21"><span class="c25">Lightning7 MALLAT MedicalImages MoteStrain 7923 219 93 65920 1645 267 19864 136 555 22 1 13 </span><span class="c2">described in Section 3.1 completes the classification task. To </span></p><p class="c3"><span class="c25">OliveOil 2499 123 287 </span><span class="c2">get the best SAX parameters, we evaluated cross-validation based parameter selection techniques, exhaustive search and DIRECT described in section 4.1 and 4.2. Exhaustive search </span></p><p class="c21"><span class="c25">OSULeaf SonyAIBORobotSurface SonyAIBORobotSurfaceII SwedishLeaf 31181 2337 154 34 1 6 44 1 10 83656 317 3312 </span><span class="c2">was found time-consuming even with early abandoning, there- fore we use DIRECT. The overall running time using DI- RECT in the worst case is O((|Train| + c &middot; (u</span><span class="c15">3 </span><span class="c2">&middot; |rules| + </span></p><p class="c21"><span class="c25">Symbols synthetic control Trace Two Patterns 3043 69 328 2616 37 18 6104 115 185 11219 601 1241 </span><span class="c2">|Candidates|&middot;|Train|))&middot;R), where R is the number of SAX parameters combinations tested by DIRECT algorithm. From the experiments on 42 UCR time series datasets, the average </span></p><p class="c21"><span class="c25">TwoLeadECG uWaveGestureLibrary X uWaveGestureLibrary Y uWaveGestureLibrary Z 24 267727 373482 409494 1 5060 4429 4230 19 274 567 619 </span><span class="c2">value for R is less than 200, which is smaller than the aver- age time series length 363. In most of the R evaluations, the program terminated search early because of the minimum motif frequency requirement (Sec. 3.2). The classification </span></p><p class="c21"><span class="c25">Wafer WordsSynonyms Yoga # best (including ties) 2746 217 1585 852394 877 2271 4414 2388 642 </span></p><p class="c3"><span class="c25">0 24 18 </span></p><p class="c3"><span class="c2">time, compared to training, is negligible. </span></p><p class="c3"><span class="c2">We compare the total running time of our algorithm us- </span></p><p class="c3"><span class="c70">Running Time (LOG) LS VS RPM </span></p><p class="c29"><span class="c2">ing DIRECT with that of Fast Shapelets (FS) and Learn- ing Shapelets (LS), and the results are shown in Table 2. Even when accounting for parameter selection, our algo- rithm is comparable to Fast Shapelets in running time, and </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c2">as shown in Table 1, our method is significantly more accu- </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c2">rate than Fast Shapelets (p-value equals 0.002). Compared </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c32">q </span></p><p class="c29"><span class="c2">to Learning Shapelets, our method is a lot faster. The great- est speedup we achieve through these 42 datasets is 1587X on dataset Adiac, and the average speedup is 178X. The experiment results show that our method is comparable to the fastest algorithm in speed and to the most accurate al- gorithm in accuracy. </span></p><p class="c29"><span class="c2">In Section 3.2.3, we use &tau; as the threshold to remove sim- ilar patterns. We choose the value at the 30</span><span class="c15">th </span><span class="c2">percentile of the pair-wise distances as the threshold. We also compare </span></p><p class="c3"><span class="c70">Running Time (LOG) FS VS RPM </span></p><p class="c3"><span class="c2">Figure 8: Runtime comparison between Representative </span><span class="c9">Patterns, Fast Shapelets, and Learning Shapelets classifiers. </span></p><p class="c29"><span class="c2">The average classification accuracy change with different &tau; values is below 1%. That means this parameter does not affect the classification result too much. The user can set a </span></p><p class="c3"><span class="c18">193 </span></p><p class="c3"><span class="c45">5 5 </span></p><p class="c3"><span class="c45">5 5 </span></p><p class="c3"><span class="c45">4444</span><span class="c5">q </span></p><p class="c3"><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c45">33</span><span class="c61">LS wins </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c21"><span class="c5">q </span><span class="c32">q </span><span class="c20">q</span><span class="c56">q</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c20">q </span></p><p class="c3"><span class="c45">33222211</span><span class="c5">q </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c61">RPM wins </span></p><p class="c3"><span class="c45">11</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c61">RPM wins </span><span class="c73">0000</span><span class="c61">FS wins </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c21"><span class="c20">q </span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c20">q</span><span class="c56">q</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c21"><span class="c5">q</span><span class="c32">q</span><span class="c5">q </span><span class="c32">q </span><span class="c5">q </span></p><p class="c19"><span class="c5">q</span><span class="c32">q</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q</span><span class="c32">q</span><span class="c20">q </span><span class="c56">q </span></p><p class="c3"><span class="c5">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span></p><p class="c3"><span class="c5">q </span><span class="c47">q </span><span class="c17">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c19"><span class="c5">q</span><span class="c32">q</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c21"><span class="c20">q </span><span class="c56">q </span><span class="c20">q</span><span class="c56">q</span><span class="c5">q</span><span class="c32">q</span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span><span class="c47">q </span><span class="c17">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c47">q </span><span class="c17">q </span></p><p class="c21"><span class="c5">q </span><span class="c32">q </span><span class="c5">q</span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c5">q </span><span class="c32">q </span></p><p class="c21"><span class="c5">q </span><span class="c32">q </span><span class="c5">q </span><span class="c32">q </span></p><p class="c3"><span class="c20">q </span><span class="c56">q </span></p><p class="c21"><span class="c5">q </span><span class="c20">q </span><span class="c32">q </span><span class="c56">q </span><span class="c5">q</span><span class="c32">q</span><span class="c5">q</span><span class="c32">q</span><span class="c73">0 0 1 1 2 2 3 3 4 4 5 </span></p><p class="c3"><span class="c73">5 </span></p><p class="c3"><span class="c73">0 0 1 1 2 2 3 3 4 4 5 5 </span></p><p class="c3"><span class="c2">Table Table 3: The average running time and classification error 4: Classification error rate on shifted time series </span><span class="c9">changes for different similar threshold on 42 UCR data. Pos- itive value means increase, negative value means decrease. </span></p><p class="c3"><span class="c25">Dataset 1NN- </span></p><p class="c3"><span class="c25">1NN- </span></p><p class="c3"><span class="c25">SAX- </span></p><p class="c3"><span class="c25">LS RPM ED </span></p><p class="c3"><span class="c25">DTWB </span></p><p class="c3"><span class="c25">VSM 10% - </span></p><p class="c3"><span class="c25">30% - </span></p><p class="c3"><span class="c25">50% - </span></p><p class="c3"><span class="c25">70% - 30% </span></p><p class="c3"><span class="c25">50% </span></p><p class="c3"><span class="c25">70% </span></p><p class="c3"><span class="c25">90% </span></p><p class="c21"><span class="c25">Coffee Face Four 0.536 0.460 0.000 0.036 0.000 0.682 0.625 0.125 0.080 0.045 Running Time Change (%) -4.66 -12.38 -15.09 -1.17 Error Change (%) -0.14 0.74 0.72 0.28 </span></p><p class="c29"><span class="c25">Gun point Swedish Leaf OSU Leaf 0.460 0.493 0.047 0.200 0.047 0.872 0.821 0.430 0.371 0.246 0.595 0.479 0.107 0.186 0.157 </span></p><p class="c3"><span class="c12">6000 </span></p><p class="c3"><span class="c31">Running time with different &tau; </span></p><p class="c3"><span class="c12">0.7 </span></p><p class="c3"><span class="c31">Classification error with different &tau; </span></p><p class="c3"><span class="c25"># best (including ties) 0 0 3 0 4 </span></p><p class="c3"><span class="c12">5000 </span></p><p class="c3"><span class="c12">0.6 </span></p><p class="c3"><span class="c43">2 </span></p><p class="c3"><span class="c49">Two classes from GunPoint dataset </span></p><p class="c3"><span class="c49">Two classes from the shifted Gun Point dataset </span></p><p class="c3"><span class="c12">0.5 4000 </span></p><p class="c3"><span class="c43">1 </span></p><p class="c3"><span class="c43">10</span><span class="c12">0.4 </span><span class="c43">0</span><span class="c12">3000 </span></p><p class="c3"><span class="c43">-1</span><span class="c12">0.3 </span><span class="c6">-1-2</span><span class="c12">2000 </span></p><p class="c3"><span class="c12">0.2 </span></p><p class="c3"><span class="c6">0 50 100 150 </span></p><p class="c3"><span class="c6">0 50 100 150 </span></p><p class="c3"><span class="c12">1000 </span></p><p class="c3"><span class="c12">0.1 </span></p><p class="c3"><span class="c81">Classes: </span><span class="c48">Class 1 Class 2 </span></p><p class="c3"><span class="c81">Classes: </span><span class="c48">Class 1 Class 2 </span></p><p class="c3"><span class="c12">0 </span></p><p class="c3"><span class="c12">0.0 </span></p><p class="c3"><span class="c49">Shifted Class 1 and the best representative patterns </span><span class="c93">10 30 50 70 90 </span></p><p class="c3"><span class="c93">10 30 50 70 90 </span></p><p class="c3"><span class="c43">2 </span></p><p class="c29"><span class="c43">2 </span><span class="c2">Figure 9: The running time and accuracy with different </span><span class="c43">11</span><span class="c9">similarity threshold &tau;. </span><span class="c43">00-1</span><span class="c6">-1-2</span><span class="c2">higher value for this parameter to achieve a fast speed and </span></p><p class="c3"><span class="c6">0 50 100 150 </span></p><p class="c3"><span class="c6">0 50 100 150 </span></p><p class="c3"><span class="c2">still could maintain a high accuracy. </span></p><p class="c29"><span class="c2">The &tau; value used for the experiment results (classification error and running time) shown in Tables 1 and 2 is set as 30% because it gives the best accuracy and still has a fast running speed. </span></p><p class="c3"><span class="c0">6. CASE STUDY </span></p><p class="c3"><span class="c2">In this section we demonstrate the application of our method to classification of rotated time series data and Medical Alarm data. We compare results with 1NN Euclidean dis- tance, 1NN DTW with the best warping window, SAX- VSM, Fast Shapelets, and Learning Shapelets classifiers. </span><span class="c0">6.1 Rotation invariance </span></p><p class="c29"><span class="c2">Many global-distance-based techniques do not work well if the time series data are shifted or out of phase. One type of time series data that is particularly susceptible to this kind of distortion is shape-converted time series [19], e.g. by ra- dial scanning of the shape profile to convert the image into a &ldquo;time series.&rdquo; Several datasets in the UCR repository are shape-converted time series, e.g. OSU Leaf, Swedish Leaf, Shields, etc. In this section we demonstrate the rotation- or shift-invariance of our technique on a number of shifted datasets. To shift or &ldquo;rotate&rdquo; a time series, we randomly choose a cut point in the time series, and swap the sec- tions before and after the cut point. This transformation is equivalent to starting the radial scanning of the shape at a different position on the shape profile. The out-of-phase phenomenon is also common in many other real-world time series data such as video. Figure 10 illustrates the original GunPoint dataset time series and their rotation. </span></p><p class="c29"><span class="c2">In our experiments, we leave the training set unmodified, and shift only the test data. The rationale is that while it is not uncommon for one to pre-process and create a &ldquo;cleaned&rdquo; version of training data to build a good model, it is less reasonable to expect that the test data will be in the same cleaned format. In other words, we learn the patterns on existing training data, but modify the test data to create rotation distortion, in order to evaluate the robustness of our technique. </span></p><p class="c3"><span class="c2">It is possible that the rotation cuts the best matching sub- sequence of the test time series. To handle this, we introduce </span></p><p class="c3"><span class="c49">Shifted Class 2 and the best representative patterns </span></p><p class="c3"><span class="c2">Figure 10: Shifted GunPoint dataset and the best repre- </span><span class="c9">sentative patterns. </span></p><p class="c29"><span class="c2">a new strategy to the test time series transformation step to make our algorithm rotation invariant. When transforming a raw time series into the new feature space of the closest match distances, our algorithm needs to calculate the dis- tance between the time series to each representative pattern. In order to solve the aforementioned problem, our algorithm will build another time series. For example, when transform- ing a rotated time series A, we generate another new time series B by cutting A from its midpoint and swapping the first and the second halves. By doing so, B will contain the concatenation of A&rsquo;s tail and head. If the best-matching subsequence happens to be broken up due to the rotation (A), then by rotating it again at the midpoint, one of A or B will contain the entirety of the best-matching subse- quence. When computing the distance of A to a pattern p, besides calculating a distance d</span><span class="c22">a </span><span class="c9">between A and p, the algo- </span><span class="c2">rithm will also calculating another best match distance d</span><span class="c22">b </span><span class="c9">between B and p. The minimal distance of these two will be </span><span class="c2">used as the distance from A to p. This solution overcomes the potential problem that arises when the best matching pattern is cut into different parts due to the rotation. </span></p><p class="c3"><span class="c2">The classification error rates of the rotated data are shown in Table 4. The accuracy of our method or SAX-VSM does not change very much from the unrotated version (though our technique seems to be more robust, with 4 wins), while the error rates of 1NN Euclidean distance and 1NN DTWB increase drastically. </span><span class="c0">6.2 Medical Alarm </span></p><p class="c29"><span class="c2">In this case study, we use the medical alarm data from Intensive Care Unit (ICU) database (MIMIC II database from PhysioNet) [6]. We used arterial blood pressure (ABP) waveforms to create the dataset used in this work. </span></p><p class="c3"><span class="c27">6.2.1 Normal or Alarm </span></p><p class="c29"><span class="c2">We selected two types of ABP series segments: those that triggered an alarm and those that did not. The data used are all from the same patient. The selected dataset contains 52 time series of length of 2126. Each of the time series repre- sents a segment of arterial blood pressure (ABP) waveform </span></p><p class="c3"><span class="c18">194 </span></p><p class="c29"><span class="c2">in a 17 second time range. The Normal class consists of segments without any alarms, whereas the Alarm class con- sists of segments that triggered the bedside patient monitors and were verified by the domain expert as true alarms. The dataset contains 26 time series in class Normal and 26 in class Alarm. Training and test data are split into sets of 16 and 36 time series respectively. Examples of medical alarm data from each class are shown in Figure 11. </span></p><p class="c29"><span class="c2">The first row of Table 5 shows the accuracy of competing classification techniques. Figure 11 shows the representa- tive patterns from medical alarm time series and their best matches on test data. Our method (RPM) achieves the best accuracy on this dataset. </span></p><p class="c3"><span class="c2">Table 5: Classification error rate on Medical Alarm data </span></p><p class="c3"><span class="c25">Dataset 1NN- ED </span></p><p class="c3"><span class="c25">1NN- DTWB </span></p><p class="c3"><span class="c25">SAX- VSM </span></p><p class="c3"><span class="c25">FS LS RPM </span></p><p class="c3"><span class="c25">NormalOrAlarm 0.333 0.333 0.167 0.306 0.111 0.056 FiveAlarmTypes 0.760 0.360 0.350 0.485 0.260 0.300 </span></p><p class="c3"><span class="c6">1000 </span></p><p class="c3"><span class="c55">Normal signal </span></p><p class="c3"><span class="c55">Signal with alarm </span></p><p class="c3"><span class="c6">400 </span></p><p class="c3"><span class="c6">400 0 500 1000 1500 2000 </span></p><p class="c3"><span class="c6">400 </span></p><p class="c3"><span class="c6">1200 800 </span></p><p class="c3"><span class="c6">1000 </span></p><p class="c3"><span class="c6">600 </span></p><p class="c3"><span class="c6">800 </span></p><p class="c3"><span class="c6">600 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span></p><p class="c3"><span class="c6">1400 </span></p><p class="c3"><span class="c49">Class Normal and the best representative patterns </span></p><p class="c3"><span class="c49">Class Anomalous and the best representative patterns </span></p><p class="c3"><span class="c6">1200 </span></p><p class="c3"><span class="c6">1000 </span></p><p class="c3"><span class="c6">1000 </span></p><p class="c3"><span class="c6">800 </span></p><p class="c3"><span class="c6">600 </span></p><p class="c3"><span class="c6">500 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span><span class="c2">Figure 11: Normal or Alarm data and the best represen- </span><span class="c9">tative patterns. </span></p><p class="c3"><span class="c27">6.2.2 Five types of alarm </span></p><p class="c29"><span class="c2">In PhysioNet&rsquo;s MIMIC II database, there are five cate- gories of critical arrhythmia alarms produced by a commer- cial ICU monitoring system: Asystole, Extreme Bradycardia, Extreme Tachycardia, Ventricular Tachycardia, and Ventric- ular Fibrillation/Tachycardia. We collected a dataset by taking the segments of an arterial blood pressure waveform. Each segment contains a verified alarm. The objective is to classify the alarm time series into one of the five types of alarms. </span></p><p class="c29"><span class="c2">The training set has 50 examples, 10 for each class. The test set has 100 examples, 20 for each class. All time series have the same length of 2126 (17 seconds). The time se- ries example of each class, the representative patterns, and the best matches are shown in Figure 12. Table 5 shows the accuracy of competing classification techniques for this dataset. </span></p><p class="c29"><span class="c2">Our method (RPM) has the second best accuracy on this dataset. We lose slightly to Learning Shapelets since we have 30 incorrectly classified instances compare to 26 with LS. However, our method finished in 1373 seconds compare to 86195 seconds of LS. The speedup of our algorithm over LS is 63X on this dataset. </span></p><p class="c3"><span class="c0">7. CONCLUSIONS </span></p><p class="c29"><span class="c2">In this work, we propose a novel method to discover rep- resentative patterns of time series, specifically for the prob- lem of classification. We demonstrate through extensive </span></p><p class="c3"><span class="c55">Asystole </span></p><p class="c3"><span class="c55">Extreme bradycardia </span><span class="c43">4 </span></p><p class="c3"><span class="c43">4 </span></p><p class="c3"><span class="c43">2200</span><span class="c6">-2-20 500 1000 1500 2000 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span></p><p class="c3"><span class="c55">Extreme tachycardia </span></p><p class="c3"><span class="c43">2 </span></p><p class="c3"><span class="c43">0</span><span class="c6">-2-2.5 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span></p><p class="c3"><span class="c55">VTach </span></p><p class="c3"><span class="c6">2.5 </span></p><p class="c3"><span class="c6">0.0 </span></p><p class="c3"><span class="c6">0 500 1000 1500 2000 </span></p><p class="c3"><span class="c55">VTach/VFib </span><span class="c43">4 </span></p><p class="c3"><span class="c43">20-2</span><span class="c6">-40 500 1000 1500 2000 </span></p><p class="c3"><span class="c2">Figure 12: Five type of Medical Alarm and the best rep- </span><span class="c9">resentative patterns. </span></p><p class="c29"><span class="c2">experimental evaluation that our technique achieves com- petitive classification accuracy on the standard UCR time series repository, and is able to discover meaningful sub- space patterns. The accuracy of our technique remains sta- ble even when the data are shifted, while NN classifiers with global distance measures suffer from shift distortion. We also demonstrate that our technique outperforms existing techniques on a real-world medical alarm data that is ex- tremely noisy. </span></p><p class="c29"><span class="c2">In terms of efficiency, while our approach is competitive or better than other techniques, there are other optimization strategies that we can consider to speed up the algorithm even further. From profiling, we identified the bottleneck of the algorithm, which can be improved by adapting the state-of-the-art subsequence matching strategies [26]. Also, we used Euclidean distance as the base distance function for pattern matching. We will consider a more robust distance measure such as DTW in future work. </span></p><p class="c3"><span class="c0">8. ACKNOWLEDGMENTS </span></p><p class="c3"><span class="c2">This research is partially supported by the National Sci- ence Foundation under Grant No. 1218325 and 1218318. </span></p><p class="c3"><span class="c0">9. REFERENCES </span></p><p class="c3"><span class="c2">[1] Webpage to download the code and dataset. </span></p><p class="c3"><span class="c25">http:// mason.gmu.edu/ &nbsp;&#771;xwang24/ Projects/ RPM.html</span><span class="c2">. [2] R. Briandet, E. K. Kemsley, and R. H. Wilson. </span></p><p class="c3"><span class="c2">Discrimination of arabica and robusta in instant coffee by fourier transform infrared spectroscopy and chemometrics. Journal of agricultural and food chemistry, 44(1):170&ndash;174, 1996. [3] B. Chiu, E. Keogh, and S. Lonardi. Probabilistic </span></p><p class="c3"><span class="c2">discovery of time series motifs. In Proc. of 9th ACM SIGKDD Intl. Conf., 2003. [4] H. Ding, G. Trajcevski, P. Scheuermann, X. Wang, </span></p><p class="c3"><span class="c2">and E. Keogh. Querying and mining of time series data: experimental comparison of representations and distance measures. Proceedings of the VLDB Endowment, 1(2):1542&ndash;1552, 2008. [5] P. Geurts. Pattern extraction for time series </span></p><p class="c3"><span class="c2">classification. In Principles of Data Mining and Knowledge Discovery, pages 115&ndash;127. Springer, 2001. </span></p><p class="c3"><span class="c18">195 </span></p><p class="c112"><span class="c2">[6] A. L. Goldberger, L. A. Amaral, L. Glass, J. M. </span></p><p class="c116"><span class="c2">Hausdorff, P. C. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. Physiobank, physiotoolkit, and physionet components of a new research resource for complex physiologic signals. Circulation, 101(23):e215&ndash;e220, 2000. [7] J. Grabocka, N. Schilling, M. Wistuba, and </span></p><p class="c76"><span class="c2">L. Schmidt-Thieme. Learning time-series shapelets. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 392&ndash;401. ACM, 2014. [8] M. A. Hall. Correlation-based Feature Subset Selection </span></p><p class="c109"><span class="c2">for Machine Learning. PhD thesis, University of Waikato, Hamilton, New Zealand, 1998. [9] J. Han, H. Cheng, D. Xin, and X. Yan. Frequent </span></p><p class="c91"><span class="c2">pattern mining: current status and future directions. Data Mining and Knowledge Discovery, 15(1):55&ndash;86, 2007. [10] J. Hills, J. Lines, E. Baranauskas, J. Mapp, and </span></p><p class="c98"><span class="c2">A. Bagnall. Classification of time series by shapelet transformation. Data Mining and Knowledge Discovery, 28(4):851&ndash;881, 2014. [11] D. R. Jones, C. D. Perttunen, and B. E. Stuckman. Lipschitzian optimization without the lipschitz constant. Journal of Optimization Theory and Applications, 79(1):157&ndash;181, 1993. [12] E. Keogh, K. Chakrabarti, M. Pazzani, and </span></p><p class="c95"><span class="c2">S. Mehrotra. Dimensionality reduction for fast similarity search in large time series databases. Knowledge and information Systems, 3(3):263&ndash;286, 2001. [13] E. Keogh and S. Kasetty. On the need for time series data mining benchmarks: a survey and empirical demonstration. DMKD, 7(4):349&ndash;371, 2003. [14] E. Keogh, X. Xi, L. Wei, and C. A. Ratanamahatana. </span></p><p class="c120"><span class="c2">The UCR time series classification/clustering homepage. </span><span class="c25">http://www.cs.ucr.edu/ &#771;eamonn/time series data</span><span class="c2">. [15] H. Kremer, S. G&uuml;nnemann, A. Held, and T. Seidl. </span></p><p class="c122"><span class="c2">Effective and robust mining of temporal subspace clusters. In ICDM, pages 369&ndash;378, 2012. [16] X. Li, E. Keogh, L. Wei, and A. Mafra-Neto. Finding </span></p><p class="c57"><span class="c2">motifs in a database of shapes. In SDM, pages 249&ndash;260, 2007. [17] Y. Li, J. Lin, and T. Oates. Visualizing variable-length time series motifs. In SDM, pages 895&ndash;906, 2012. [18] J. Lin, E. Keogh, L. Wei, and S. Lonardi. Experiencing </span></p><p class="c78"><span class="c2">SAX: a novel symbolic representation of time series. Data Mining and knowledge discovery, 2007. [19] J. Lin, R. Khade, and Y. Li. Rotation-invariant </span></p><p class="c104"><span class="c2">similarity in time series using Bag-of-Patterns representation. Journal of Intelligent Inform. Systems, 39, 2012. [20] A. Mueen, E. Keogh, and N. Young. Logical-shapelets: an expressive primitive for time series classification. In Proc. of 17th ACM SIGKDD Intl. Conf., 2011. [21] A. Nanopoulos, R. Alcock, and Y. Manolopoulos. </span></p><p class="c103"><span class="c2">Feature-based classification of time-series data. International Journal of Computer Research, 10(3), 2001. [22] S. Naoki. Local feature extraction and its application </span></p><p class="c1"><span class="c2">using a library of bases. Ph.D. thesis, Yale University, 1994. [23] C. G. Nevill-Manning and I. H. Witten. Identifying </span></p><p class="c34"><span class="c2">hierarchical structure in sequences: A linear-time algorithm. J. Artif. Intell. Res.(JAIR), 7:67&ndash;82, 1997. [24] J. Platt. Fast training of support vector machines </span></p><p class="c77"><span class="c2">using sequential minimal optimization. In Advances in Kernel Methods - Support Vector Learning. MIT Press, 1998. [25] M. Radovanovic, A. Nanopoulos, and M. Ivanovic. </span></p><p class="c114"><span class="c2">Time-series classification in many intrinsic dimensions. In SDM, pages 677&ndash;688, 2010. [26] T. Rakthanmanon, B. Campana, A. Mueen, </span></p><p class="c46"><span class="c2">G. Batista, B. Westover, Q. Zhu, J. Zakaria, and E. Keogh. Searching and mining trillions of time series subsequences under dynamic time warping. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &rsquo;12, pages 262&ndash;270, New York, NY, USA, 2012. [27] T. Rakthanmanon and E. Keogh. Fast shapelets: A </span></p><p class="c94"><span class="c2">scalable algorithm for discovering time series shapelets. In Proc. of SDM, 2013. [28] C. A. Ratanamahatana and E. Keogh. Making </span></p><p class="c114"><span class="c2">time-series classification more accurate using learned constraints. SIAM, 2004. [29] G. Salton. The SMART Retrieval System; Experiments in Automatic Document Processing. Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1971. [30] P. Senin, J. Lin, X. Wang, T. Oates, S. Gandhi, A. P. </span></p><p class="c46"><span class="c2">Boedihardjo, C. Chen, S. Frankenstein, and M. Lerner. Grammarviz 2.0: a tool for grammar-based pattern discovery in time series. In Proc. ECML/PKDD. 2014. [31] P. Senin and S. Malinchik. SAX-VSM: Interpretable </span></p><p class="c10"><span class="c2">time series classification using sax and vector space model. In Data Mining (ICDM), 2013 IEEE 13th International Conference on, pages 1175&ndash;1180. IEEE, 2013. [32] X. Wang, A. Mueen, H. Ding, G. Trajcevski, </span></p><p class="c105"><span class="c2">P. Scheuermann, and E. Keogh. Experimental comparison of representation methods and distance measures for time series data. Data Mining and Knowledge Discovery, 26(2):275&ndash;309, 2013. [33] L. Wei and E. Keogh. Semi-supervised time series classification. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 748&ndash;753. ACM, 2006. [34] X. Xi, E. Keogh, C. Shelton, L. Wei, and C. A. </span></p><p class="c79"><span class="c2">Ratanamahatana. Fast time series classification using numerosity reduction. In Proceedings of the 23rd international conference on Machine learning, pages 1033&ndash;1040. ACM, 2006. [35] Z. Xing, J. Pei, S. Y. Philip, and K. Wang. Extracting </span></p><p class="c75"><span class="c2">interpretable features for early classification on time series. In SDM, volume 11, pages 247&ndash;258. SIAM, 2011. [36] L. Ye and E. Keogh. Time series shapelets: a new </span></p><p class="c28"><span class="c2">primitive for data mining. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 947&ndash;956. ACM, 2009. </span></p><p class="c54"><span class="c18">196 </span></p></body></html>