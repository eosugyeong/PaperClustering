<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c126{margin-left:-19.7pt;padding-top:15.1pt;text-indent:97.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:63.6pt}.c113{margin-left:-19pt;padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23.5pt}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Courier New";font-style:normal}.c127{margin-left:-19pt;padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-28.6pt}.c65{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:italic}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Times New Roman";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Times New Roman";font-style:italic}.c56{margin-left:-19.2pt;padding-top:0.5pt;text-indent:31.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c76{margin-left:-19pt;padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c90{margin-left:-19pt;padding-top:4.1pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Courier New";font-style:normal}.c23{margin-left:-19pt;padding-top:4.1pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.8pt}.c101{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c50{margin-left:-19pt;padding-top:8.4pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c43{margin-left:-19pt;padding-top:1.4pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-27.1pt}.c79{margin-left:-19pt;padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.8pt}.c61{margin-left:-19pt;padding-top:1.4pt;text-indent:37.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c131{margin-left:-28.1pt;padding-top:1.4pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.8pt}.c78{margin-left:-28.1pt;padding-top:3.8pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c28{margin-left:-17pt;padding-top:0.5pt;text-indent:29.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Times New Roman";font-style:italic}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Times New Roman";font-style:normal}.c32{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c112{margin-left:-19pt;padding-top:1.4pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Times New Roman";font-style:italic}.c40{margin-left:-19pt;padding-top:0.5pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.4pt;font-family:"Arial";font-style:normal}.c107{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13.9pt;font-family:"Times New Roman";font-style:normal}.c89{margin-left:-19pt;padding-top:3.8pt;text-indent:28.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c123{margin-left:-19pt;padding-top:9.6pt;text-indent:28.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c51{margin-left:-19pt;padding-top:1.7pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c42{margin-left:-28.1pt;padding-top:1.7pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c106{margin-left:-19pt;padding-top:3.8pt;text-indent:27.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-23pt}.c64{margin-left:-14.5pt;padding-top:1.4pt;text-indent:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:4.3pt}.c52{margin-left:-28.1pt;padding-top:3.8pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.8pt}.c68{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Courier New";font-style:italic}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Times New Roman";font-style:normal}.c34{margin-left:-28.1pt;padding-top:1.4pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.6pt}.c119{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Courier New";font-style:italic}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Times New Roman";font-style:normal}.c55{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Times New Roman";font-style:normal}.c15{margin-left:-28.1pt;padding-top:4.1pt;text-indent:37pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Times New Roman";font-style:normal}.c10{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Times New Roman";font-style:italic}.c98{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Courier New";font-style:normal}.c94{margin-left:-19pt;padding-top:1.7pt;text-indent:33.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.2pt}.c70{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Times New Roman";font-style:normal}.c99{margin-left:-19pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-22.8pt}.c72{margin-left:218.2pt;padding-top:54.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c77{margin-left:-25.2pt;padding-top:7.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:54.2pt}.c117{margin-left:-23.5pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:2.6pt}.c38{margin-left:-19pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.1pt}.c49{margin-left:-21.4pt;padding-top:21.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c6{margin-left:-19pt;padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-22.8pt}.c62{margin-left:-0.3pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.1pt}.c41{margin-left:21.8pt;padding-top:15.8pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:65.4pt}.c108{margin-left:-10.2pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.8pt}.c37{margin-left:119.5pt;padding-top:13.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11.8pt}.c122{margin-left:-23.8pt;padding-top:60.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c130{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.1pt}.c83{margin-left:-22.6pt;padding-top:6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-12.1pt}.c109{margin-left:-25.2pt;padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:89.2pt}.c18{margin-left:174.2pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:179.5pt}.c100{margin-left:97.9pt;padding-top:32.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:40pt}.c104{margin-left:105.4pt;padding-top:33.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:47.2pt}.c74{margin-left:-25.2pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.2pt}.c71{margin-left:-28.1pt;padding-top:13.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c125{margin-left:-23.5pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.6pt}.c92{margin-left:-19pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c115{margin-left:-28.1pt;padding-top:3.6pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-14pt}.c22{margin-left:-8.2pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-23pt}.c58{margin-left:-10.2pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.4pt}.c85{margin-left:20.6pt;padding-top:23pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:162.2pt}.c31{margin-left:97.7pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:39.8pt}.c3{margin-left:-28.1pt;padding-top:20.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c121{margin-left:-14.6pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:7.1pt}.c66{margin-left:-28.1pt;padding-top:14.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c59{margin-left:-28.1pt;padding-top:19.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c67{margin-left:-23.5pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:21.3pt}.c118{margin-left:-19pt;padding-top:14.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:83.3pt}.c48{margin-left:-9.6pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:301pt}.c105{margin-left:112.6pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:54.6pt}.c54{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-23pt}.c95{margin-left:-28.1pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c111{margin-left:-14.6pt;padding-top:3.6pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-13.8pt}.c75{margin-left:-28.1pt;padding-top:13.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:109.1pt}.c82{margin-left:218.2pt;padding-top:64.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c16{margin-left:50.4pt;padding-top:13.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:55.4pt}.c47{margin-left:-16.4pt;padding-top:9.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:111.6pt}.c45{margin-left:-28.1pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-6.6pt}.c86{margin-left:-23.5pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.9pt}.c87{margin-left:-28.1pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:124pt}.c114{margin-left:23.4pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c102{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-19.4pt}.c19{margin-left:-5.8pt;padding-top:0.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:67.6pt}.c103{margin-left:-12.3pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c21{margin-left:-19pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-8.6pt}.c120{margin-left:-28.1pt;padding-top:7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c46{margin-left:-19pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c91{margin-left:-16.4pt;padding-top:7.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:119.5pt}.c80{margin-left:-21.8pt;padding-top:13.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:59.9pt}.c116{margin-left:-17pt;padding-top:5.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c69{margin-left:-19.7pt;padding-top:6.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.4pt}.c93{margin-left:-19pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-18.7pt}.c53{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-4.3pt}.c73{margin-left:-9.1pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-0.3pt}.c96{margin-left:-19pt;padding-top:9.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23pt}.c88{margin-left:-23.5pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-7.3pt}.c97{margin-left:-28.1pt;padding-top:59.5pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-14pt}.c110{margin-left:-9.9pt;padding-top:5.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.8pt}.c26{margin-left:-28.1pt;padding-top:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c124{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.2pt}.c84{margin-left:-19pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-2.6pt}.c44{margin-left:-23.5pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3pt}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c30{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c33{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c63{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c81{margin-left:-94.9pt;margin-right:164.2pt}.c57{margin-left:-19pt;margin-right:-19.9pt}.c129{margin-left:-14.5pt;margin-right:-22.8pt}.c128{margin-left:-23.8pt;margin-right:339.1pt}.c25{margin-left:-19pt;margin-right:-21.4pt}.c60{margin-left:54.9pt;margin-right:21.4pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c63"><p class="c13 c128"><span class="c1">Industrial and Applications Paper </span></p><p class="c16"><span class="c70">DECT: Distributed Evolving Context Tree for Mining Web Behavior Evolution </span></p><p class="c18"><span class="c107">Industrial Paper </span></p><p class="c41"><span class="c32">Xiaokui Shu</span><span class="c4">&lowast; </span><span class="c68">Department of Computer </span><span class="c36">Science, Virginia Tech Blacksburg, VA USA </span><span class="c29">subx@cs.vt.edu </span></p><p class="c13 c81"><span class="c32">Nikolay Laptev </span><span class="c36">Yahoo! Labs 701 First Avenue Sunnyvale, CA USA </span><span class="c29">nlaptev@yahoo-inc.com </span></p><p class="c13 c60"><span class="c32">Danfeng (Daphne) Yao </span><span class="c36">Department of Computer Science, Virginia Tech Blacksburg, VA USA </span><span class="c29">danfeng@cs.vt.edu </span></p><p class="c13 c60"><span class="c32">Danfeng (Daphne) Yao </span><span class="c36">Department of Computer Science, Virginia Tech Blacksburg, VA USA </span><span class="c29">danfeng@cs.vt.edu </span></p><p class="c66"><span class="c32">ABSTRACT </span><span class="c0">Internet user behavior models characterize user browsing dynamics or the transitions among web pages. The mod- els help Internet companies improve their services by accu- rately targeting customers and providing them the informa- tion they want. For instance, specific web pages can be cus- tomized and prefetched for individuals based on sequences of web pages they have visited. Existing user behavior mod- els abstracted as time-homogeneous Markov models do not provide efficient support for modeling user behavior varia- tion through time. This paper presents DECT, a scalable time-variant variable-order Markov model. DECT digests terabytes of user session data and yields user behavior pat- terns through time. We realize DECT using Apache Spark. Our implementation is being open-sourced and we deploy DECT on top of Yahoo! infrastructure. We demonstrate the benefits of DECT with anomaly detection and ad click rate prediction applications. DECT enables the detection of higher-order path anomalies that are masked out by exist- ing models. DECT also provides insights into ad click rates with respect to user visiting paths. </span></p><p class="c71"><span class="c32">Keywords </span><span class="c0">Markov Model; Context Tree; Distributed Computing; Time Series; Anomaly Detection; Link Prediction </span></p><p class="c75"><span class="c32">1. INTRODUCTION </span></p><p class="c15"><span class="c0">Understanding Internet user behavior is a key to the op- timization of Internet services and software. A web browser or server can prefetch or prepare webpages for a user, if the system knows the user will visit the page in the short fu- ture [23]. A service provider can customize clickable ads for </span></p><p class="c120"><span class="c1">&lowast;</span><span class="c7">The work was mostly done while the first author was an intern at Yahoo! Labs. </span></p><p class="c97"><span class="c119">&copy; </span><span class="c55">2016, Copyright is with the authors. Published in Proc. 19th Inter- national Conference on Extending Database Technology (EDBT), March 15-18, 2016 - Bordeaux, France: ISBN 978-3-89318-070-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c6"><span class="c0">a user, if the provider knows which ads the user is likely to click [17]. Service providers can also design search engines to fit human browsing dynamics [13]. </span></p><p class="c127"><span class="c1">Markov model </span><span class="c0">(first-order, time-homogeneous) is commonly adopted for Internet user behavior modeling [5]. It is, how- ever, amnesiac; the probability of the next user visit is purely based on the current status of the user. Higher-order Markov models cure the amnesia issue by digesting historical visiting sites of users [15]. Variable-order Markov models improve higher-order Markov models by pruning away unnecessarily higher-order paths for space saving purposes [3]. </span></p><p class="c112"><span class="c0">While the community has developed a string of advanced Markov models to describe Internet user behavior patterns, one strong assumption is constantly kept in all existing mod- els: user behavior patterns do not change over time. </span></p><p class="c76"><span class="c0">The above assumption, however, does not hold in the real world. New products are releasing; UI of existing websites are changing; cyber attacks occur; breaking news happen. </span><span class="c1">The Internet is evolving, and the observed Internet user be- havior patterns should reflect the changes. </span></p><p class="c76"><span class="c0">This paper presents DECT (distributed evolving context tree), a time-variant model for efficiently describing Inter- net user behavior patterns and their changes through time. DECT is a time-variant variable-order Markov model. It improves the state of the art variable-order Markov models by releasing its assumption of static time-invariant user be- havior patterns. DECT is designed to handle large volumes of user session data and can be efficiently constructed via distributed computing. </span></p><p class="c79"><span class="c0">Time-variant variable analysis, e.g., visit counts of ser- vices, has been widely used in industry to detect anomalies like attacks, failures, and bugs. However, these commonly used variables are stateless or only first-order with respect to Markov models. </span></p><p class="c76"><span class="c0">In contrast, DECT enables higher-order time-variant vis- iting path analysis. DECT yields both regular time series of individual path visiting probabilities and high-dimensional time series for a set of related paths, e.g., paths that share the same prefix. We demonstrate in Section 4.1 that DECT can produce deep signals for anomaly detection. It helps re- veal stealthy attacks, e.g., application layer DDoS attack [21] and browsing mimicry attack [22]. First-order Markov mod- els, in contrast, could mix these signals into noises. We demonstrate in Section 4.2 that DECT distinguishes ad click probability variations based on historical web pages a user visits, while existing first-order prediction is blind to differ- </span></p><p class="c122"><span class="c68">Series ISSN: 2367-2005 573 </span><span class="c101">10.5441/002/edbt.2016.54 </span></p><p class="c13"><span class="c10">Table 1: Symbols, Terms and Definitions Term Definition </span></p><p class="c13"><span class="c1">s </span><span class="c0">site the primitive unit to record user behavior </span></p><p class="c13"><span class="c0">(e.g., a URL, a web service, a website) </span><span class="c1">E </span><span class="c0">session a sequence of sites that a user visits </span></p><p class="c13"><span class="c0">(every session has a beginning and an end) &nbsp;&#772;</span><span class="c1">p </span><span class="c0">path a substring of a session </span><span class="c1">&tau; </span><span class="c0">target the next site a user is going to transit to &nbsp;&#772;</span><span class="c1">c </span><span class="c0">context a sequence of visited sites prior to </span><span class="c1">&tau; </span></p><p class="c13"><span class="c0">ent types of users who come from diverse paths. </span></p><p class="c13"><span class="c0">The contributions of our work are summarized as follows. </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">We design DECT to digest large volumes of user ses- sion data and construct time-variant user behavior mod- els in a distributed manner. </span></p><p class="c9"><span class="c1">&bull; </span><span class="c0">We explain the benefits of a time-variant user behavior model and showcase application examples of DECT in anomaly detection and ad click prediction. </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">We realize DECT using Apache Spark and demon- strate its performance processing terabytes of real-world user session datasets. </span></p><p class="c13"><span class="c32">2. DECT </span></p><p class="c13"><span class="c0">We discuss two major features of DECT in this section: </span><span class="c1">variable-order </span><span class="c0">and </span><span class="c1">time-variant</span><span class="c0">. These features are realized through a </span><span class="c1">flattened context tree</span><span class="c0">, which embeds time series information in its leaf nodes. </span><span class="c32">2.1 Definitions and Overview </span></p><p class="c9"><span class="c0">We study user behavior in terms of their visiting paths on the Internet. A (desktop or mobile) user session is recorded as a sequence of visits to a set of Internet </span><span class="c1">sites </span><span class="c0">&ndash; resources that users are visiting. Sites vary from specific URLs to do- mains</span><span class="c20">1</span><span class="c0">. We define related variables that are used to express user visiting paths in Table 1. </span></p><p class="c9"><span class="c0">Higher-order Markov models have been proved effective in modeling static user behavior [5]. Given a path &nbsp;&#772;</span><span class="c1">p</span><span class="c0">, a higher-order Markov model can be trained to predict the last transition of &nbsp;&#772;</span><span class="c1">p </span><span class="c0">based on previously visited sites in &nbsp;&#772;</span><span class="c1">p</span><span class="c0">. In this setup, we refer to the last transition in &nbsp;&#772;</span><span class="c1">p </span><span class="c0">as the target </span><span class="c1">&tau;</span><span class="c0">, and the sites prior to </span><span class="c1">&tau; </span><span class="c0">as the context &nbsp;&#772;</span><span class="c1">c</span><span class="c0">. </span></p><p class="c9"><span class="c0">The key question we aim to answer is how target transi- tion probabilities change over time. When considering the higher-order Markov model as a weighted directed graph </span><span class="c1">G</span><span class="c2">M </span><span class="c7">= (</span><span class="c8">V</span><span class="c2">M</span><span class="c8">,E</span><span class="c2">M</span><span class="c7">), we construct our model to keep track of: </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">change of </span><span class="c1">V</span><span class="c2">M</span><span class="c7">: new and obsoleted nodes </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">change of </span><span class="c1">E</span><span class="c2">M</span><span class="c7">: transition matrix variation </span><span class="c0">DECT enables the tracking of both changes, and it pro- vides two features to handle large amounts of data and mit- igate exponential space explosion caused by regular higher- order Markov model: </span></p><p class="c13"><span class="c0">i) variable-order context-target probability ii) fine-grained parallel path computing and pruning We realize the two features through </span><span class="c1">flattened context tree </span><span class="c0">&ndash; a new parallel and concise data structure for building dis- tributed time-variant variable-order Markov model. </span></p><p class="c13"><span class="c24">1</span><span class="c7">The granularity of sites is a data collection parameter. </span></p><p class="c13"><span class="c11">root -&gt; A 0.25 </span></p><p class="c30"><span class="c11">-&gt; B 0.5 </span></p><p class="c30"><span class="c11">-&gt; C 0.25 </span></p><p class="c13"><span class="c11">context A -&gt; A </span><span class="c11">0.8 </span></p><p class="c13"><span class="c11">context B </span></p><p class="c13"><span class="c11">-&gt; B </span></p><p class="c13"><span class="c11">-&gt; C </span><span class="c11">0.1 </span></p><p class="c13"><span class="c11">0.1 </span></p><p class="c30"><span class="c11">-&gt; A </span><span class="c11">0.15 </span></p><p class="c13"><span class="c11">-&gt; context </span><span class="c11">-&gt; A </span><span class="c11">-&gt; B </span></p><p class="c13"><span class="c11">C </span><span class="c11">0.7 </span></p><p class="c13"><span class="c11">0.15 </span></p><p class="c33"><span class="c11">C </span><span class="c11">-&gt; B 0.25 </span></p><p class="c13"><span class="c11">0.4 </span></p><p class="c30"><span class="c11">-&gt; C 0.35 </span></p><p class="c13"><span class="c11">context A -&gt; B </span><span class="c11">-&gt; A </span><span class="c11">0.7 </span></p><p class="c13"><span class="c11">context C -&gt; B </span></p><p class="c30"><span class="c11">-&gt; B </span><span class="c11">0.2 </span></p><p class="c30"><span class="c11">-&gt; C </span><span class="c11">0.1 </span></p><p class="c30"><span class="c11">-&gt; A </span><span class="c11">0.25 </span></p><p class="c30"><span class="c11">-&gt; B </span><span class="c11">0.7 </span></p><p class="c30"><span class="c11">-&gt; C </span><span class="c11">0.05 </span></p><p class="c13"><span class="c11">context C -&gt; C -&gt; B </span></p><p class="c30"><span class="c11">-&gt; A </span><span class="c11">0.2 </span></p><p class="c30"><span class="c11">-&gt; B </span><span class="c11">0.7 </span></p><p class="c30"><span class="c11">-&gt; C </span><span class="c11">0.1 </span></p><p class="c13"><span class="c10">Figure 1: Example of regular context tree (pruned to represent a variable-order Markov model). </span></p><p class="c13"><span class="c32">2.2 A New Context Tree Structure </span></p><p class="c9"><span class="c0">Context tree is a common data structure for constructing variable-order Markov model [2,5,6]. We first give a brief de- scription of regular context tree and its operations. Then we present our flattened context tree structure for distributed tree construction and fine-grained parallel pruning. </span></p><p class="c13"><span class="c65">2.2.1 Regular Context Tree </span></p><p class="c9"><span class="c0">A regular context tree </span><span class="c1">T</span><span class="c2">C </span><span class="c7">is a </span><span class="c8">k</span><span class="c7">-ary tree where </span><span class="c8">k </span><span class="c7">is the </span><span class="c0">number of all possible sites. </span><span class="c1">T</span><span class="c14">C </span><span class="c0">records static transition probabilities of any target given a limited length context. The limited context length is the depth of the tree. </span></p><p class="c33"><span class="c0">We give an example of a regular context tree in Figure 1. A site </span><span class="c1">s &isin; {A,B,C}</span><span class="c0">. Each node maps to one context that is recorded. A node </span><span class="c1">n</span><span class="c17">&nbsp;&#772;</span><span class="c14">c</span><span class="c0">, which corresponds to context &nbsp;&#772;</span><span class="c1">c </span><span class="c0">= parent (</span><span class="c1">s</span><span class="c2">&minus;y</span><span class="c8">,...,s</span><span class="c0">is the node </span><span class="c2">&minus;</span><span class="c12">2</span><span class="c8">,s</span><span class="c0">with </span><span class="c2">&minus;</span><span class="c12">1</span><span class="c8">,s</span><span class="c12">0</span><span class="c7">), </span><span class="c0">context </span><span class="c7">positions </span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c27">&prime; </span><span class="c7">at depth </span><span class="c8">y </span><span class="c7">in </span><span class="c8">T</span><span class="c2">C</span><span class="c7">. Its </span><span class="c0">= (</span><span class="c1">s</span><span class="c2">&minus;</span><span class="c12">(</span><span class="c2">y&minus;</span><span class="c12">1)</span><span class="c8">,...,s</span><span class="c2">&minus;</span><span class="c12">2</span><span class="c8">,s</span><span class="c2">&minus;</span><span class="c12">1</span><span class="c8">, </span><span class="c1">s</span><span class="c12">0</span><span class="c7">) at depth </span><span class="c8">y &minus; </span><span class="c7">1. Its children are nodes with context </span><span class="c0">&nbsp;&#772;</span><span class="c1">ci </span><span class="c2">c</span><span class="c1">&le; </span><span class="c35">i </span><span class="c0">= (</span><span class="c1">s</span><span class="c2">&minus;</span><span class="c12">(</span><span class="c2">y</span><span class="c12">+1)</span><span class="c1">&xi;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c </span><span class="c1">&le; k</span><span class="c0">. </span><span class="c1">&xi;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c </span><span class="c35">i</span><span class="c0">is </span><span class="c1">,...,s</span><span class="c0">the </span><span class="c2">&minus;</span><span class="c12">2</span><span class="c8">,s</span><span class="c2">&minus;</span><span class="c12">1</span><span class="c8">,s</span><span class="c12">0</span><span class="c7">) at depth </span><span class="c8">y </span><span class="c7">+ 1 where </span><span class="c0">total number of children of &nbsp;&#772;</span><span class="c1">c</span><span class="c0">. </span></p><p class="c13"><span class="c7">0 </span><span class="c8">&le; </span></p><p class="c9"><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">stores the target probability distribution with respect </span><span class="c0">to the context &nbsp;&#772;</span><span class="c1">c </span><span class="c0">= (</span><span class="c1">s</span><span class="c14">&minus;y</span><span class="c1">,...,s</span><span class="c14">&minus;</span><span class="c17">2</span><span class="c1">,s</span><span class="c14">&minus;</span><span class="c17">1</span><span class="c1">,s</span><span class="c17">0</span><span class="c0">), i.e., </span><span class="c1">P</span><span class="c0">(</span><span class="c1">&tau;</span><span class="c14">j</span><span class="c1">|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) where 0 </span><span class="c1">&le; j &le; &kappa;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c8">&le; k</span><span class="c7">. </span><span class="c8">&kappa;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">is the total number of reachable targets </span><span class="c0">given the context &nbsp;&#772;</span><span class="c1">c</span><span class="c0">. </span></p><p class="c9"><span class="c10">Pruning </span><span class="c0">Pruning a regular context tree of a higher-order Markov model results in a variable-order Markov model. The standard </span><span class="c1">T</span><span class="c14">C </span><span class="c0">pruning strategy is a bottom-up process: pruning away </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">if both criteria are satisfied: </span></p><p class="c13"><span class="c0">1. </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">is a leaf node. </span><span class="c0">2. The distance, e.g., KL divergence, between the target probability distribution of </span><span class="c1">n</span><span class="c17">&nbsp;&#772;</span><span class="c14">c </span><span class="c0">and that of its parent node </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">c</span><span class="c5">&prime; </span><span class="c0">is less than a predefined threshold </span><span class="c1">T</span><span class="c2">pv</span><span class="c7">. </span><span class="c10">Time-variant capability </span><span class="c0">Unfortunately, regular context tree is designed to accommodate static transition probabil- ities. The transition matrix of the corresponding Markov model is fixed when the model is built. Updating the tree to reflect a time-variant model is expensive. It requires to </span></p><p class="c13"><span class="c68">574 </span></p><p class="c105"><span class="c11">&Psi; (A | B) </span></p><p class="c104"><span class="c11">&Psi; (A | C -&gt; B) </span></p><p class="c85"><span class="c11">root </span></p><p class="c31"><span class="c11">&Psi; (A | C -&gt; C -&gt; B) </span></p><p class="c100"><span class="c11">&Psi; (B | C -&gt; C -&gt; B) </span></p><p class="c26"><span class="c10">Figure 2: Example of flattened context tree with change of transition probabilities in time series. </span></p><p class="c59"><span class="c10">Table 2: Flattened Context Tree vs. Regular Con- text Tree </span></p><p class="c37"><span class="c10">FCT</span><span class="c0">* </span><span class="c10">RCT</span><span class="c0">* </span></p><p class="c83"><span class="c0">Node semantics (context, target) context Tree depth 1 highest order Probability time series embedded none </span></p><p class="c80"><span class="c55">*FCT/RCT: flattened/regular context tree </span></p><p class="c3"><span class="c0">recalculate node probabilities and reevaluate previous prun- ing procedures for pruned nodes. </span></p><p class="c109"><span class="c65">2.2.2 Flattened Context Tree </span></p><p class="c52"><span class="c0">We present a </span><span class="c1">flattened context tree</span><span class="c0">. We define the pruning strategy to facilitate distributed tree operations for our time- variant Markov model. We prove that our parallel pruning strategy preserves the tree structure: one branch can be pruned only if all its children are pruned. </span></p><p class="c131"><span class="c0">A flattened context tree </span><span class="c1">T</span><span class="c2">F </span><span class="c7">only has a depth of two: depth </span><span class="c0">0: root, and depth 1: all data nodes. Each depth-1 node </span><span class="c1">n</span><span class="c17">&nbsp;&#772;</span><span class="c14">p </span><span class="c0">corresponds to a path &nbsp;&#772;</span><span class="c1">p </span><span class="c0">= ( &#772;</span><span class="c1">c, t</span><span class="c0">)=(</span><span class="c1">s</span><span class="c2">&minus;y</span><span class="c8">,...,s</span><span class="c2">&minus;</span><span class="c12">2</span><span class="c8">,s</span><span class="c2">&minus;</span><span class="c12">1</span><span class="c8">,s</span><span class="c12">0</span><span class="c8">,t</span><span class="c7">) </span><span class="c0">and it records a time series of transition probability &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) = </span><span class="c1">{P</span><span class="c2">t</span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">) : </span><span class="c8">t &isin; T}</span><span class="c7">. In comparison, a node </span><span class="c8">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">in </span><span class="c8">T</span><span class="c2">C </span><span class="c7">stores the </span><span class="c0">distribution of transition probabilities according to context &nbsp;&#772;</span><span class="c1">c</span><span class="c0">. Table 2 shows the most significant differences between our flattened context tree and regular context tree. We illustrate the structure of flattened context tree in Figure 2. </span></p><p class="c34"><span class="c0">The advantage of the flattened tree structure is that each node can be processed independently of other nodes, which enables fine-grained parallel probability computing and prun- ing for each ( &#772;</span><span class="c1">c, &tau;</span><span class="c0">) pair. Furthermore, different nodes in </span><span class="c1">T</span><span class="c2">F </span><span class="c0">can be processed on a different processing unit in a dis- tributed manner to scale out the process. </span></p><p class="c42"><span class="c10">Pruning </span><span class="c0">The purpose of pruning is to transform a higher- order Markov model to a variable-order one. Pruning of </span><span class="c1">T</span><span class="c14">F </span><span class="c0">is performed for individual nodes in parallel. A node </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">p </span><span class="c7">is </span><span class="c0">pruned away if &nbsp;&#772;</span><span class="c1">p </span><span class="c0">is rarely visited through a large segment of the monitored time period. The criteria can be measured as the total number of </span><span class="c1">path visits </span><span class="c0">or the total number of </span><span class="c1">path appearances </span><span class="c0">during the overall monitored time period. The latter yields </span><span class="c1">True </span><span class="c0">or </span><span class="c1">False </span><span class="c0">in each inspection window and </span></p><p class="c13 c57"><span class="c0">sums the total number of </span><span class="c1">True </span><span class="c0">for the overall time period. </span></p><p class="c123"><span class="c0">Theorem 1. </span><span class="c1">In a flattened context tree T</span><span class="c14">F</span><span class="c1">, a node n</span><span class="c17">&nbsp;&#772;</span><span class="c14">p </span><span class="c1">records the target transition probability time series of path </span><span class="c0">&nbsp;&#772;</span><span class="c1">p. </span><span class="c0">&nbsp;&#772;</span><span class="c1">p</span><span class="c27">&prime; </span><span class="c1">denotes a suffix string of </span><span class="c0">&nbsp;&#772;</span><span class="c1">p. n</span><span class="c17">&nbsp;&#772;</span><span class="c14">p </span><span class="c1">in T</span><span class="c14">F </span><span class="c1">can be pruned if n</span><span class="c12">&nbsp;&#772;</span><span class="c2">p</span><span class="c5">&prime; </span><span class="c1">(node corresponding to </span><span class="c0">&nbsp;&#772;</span><span class="c1">p</span><span class="c27">&prime;</span><span class="c1">) can be pruned. </span></p><p class="c89"><span class="c0">Proof. If a path &nbsp;&#772;</span><span class="c1">p </span><span class="c0">is visited, its suffix path &nbsp;&#772;</span><span class="c1">p</span><span class="c27">&prime; </span><span class="c0">is visited. And two different paths &nbsp;&#772;</span><span class="c1">p</span><span class="c17">1 </span><span class="c0">and &nbsp;&#772;</span><span class="c1">p</span><span class="c17">2 </span><span class="c0">can share the same suffix path &nbsp;&#772;</span><span class="c1">p</span><span class="c27">&prime;</span><span class="c0">. So </span><span class="c1">V </span><span class="c0">( &#772;</span><span class="c1">p</span><span class="c27">&prime;</span><span class="c0">) </span><span class="c1">&ge; V </span><span class="c0">( &#772;</span><span class="c1">p</span><span class="c0">) where </span><span class="c1">V </span><span class="c0">( &#772;</span><span class="c1">p</span><span class="c0">) is the number of path &nbsp;&#772;</span><span class="c1">p </span><span class="c0">visits. Given </span><span class="c1">T</span><span class="c14">pv </span><span class="c0">as the pruning threshold for path visits, </span><span class="c1">V </span><span class="c0">( &#772;</span><span class="c1">p</span><span class="c0">) </span><span class="c1">&lt; T</span><span class="c2">pv </span><span class="c7">holds if </span><span class="c8">V </span><span class="c7">( &#772;</span><span class="c8">p</span><span class="c14">&prime;</span><span class="c7">) </span><span class="c8">&lt; T</span><span class="c2">pv</span><span class="c7">. </span></p><p class="c50"><span class="c0">If one restructures a flattened context tree </span><span class="c1">T</span><span class="c2">F </span><span class="c7">back to </span><span class="c0">a regular context tree </span><span class="c1">T</span><span class="c14">C</span><span class="c0">, Theorem 1 guarantees that all children of a branch node are pruned away before the branch node is pruned. It is consistent with the standard pruning strategy presented in Section 2.2.1. </span></p><p class="c51"><span class="c10">Time-variant capability </span><span class="c0">Time series information is em- bedded into each node </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">p </span><span class="c7">in </span><span class="c8">T</span><span class="c2">F</span><span class="c7">, so </span><span class="c8">T</span><span class="c2">F </span><span class="c7">reflects the change </span><span class="c0">of the corresponding Markov model through time. Change of </span><span class="c1">E</span><span class="c14">M </span><span class="c0">(discussed in Section 2.1) is distributed across &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) in each node. Changes of </span><span class="c1">V</span><span class="c2">M </span><span class="c7">(discussed in Section 2.1) are </span><span class="c0">also stored in new or obsolete nodes if not pruned. </span><span class="c32">2.3 Growing the Flattened Context Tree </span></p><p class="c90"><span class="c0">A flattened context tree </span><span class="c1">T</span><span class="c14">F </span><span class="c0">grows through time. We use a sliding window </span><span class="c1">w </span><span class="c0">to aggregate sessions through time and yield transition matrices of our time-variant Markov model at different times. Time series yielded from nodes in the flattened context tree are extended when new sessions are consumed and the tree has grown. </span></p><p class="c91"><span class="c65">2.3.1 Session Batch </span></p><p class="c106"><span class="c1">Session batch </span><span class="c0">is a set of sessions. It is the smallest sliding unit for </span><span class="c1">w</span><span class="c0">. Sessions are batched according to the timestamp of its first visited site. A session may last across several batch time periods, but the </span><span class="c1">entire </span><span class="c0">session is recorded only once in the first batch it appears</span><span class="c20">2</span><span class="c0">. The timestamp of the session batch is the start of the session batch. </span></p><p class="c79"><span class="c0">Session batches do not interference with each other, and they can be preprocessed in parallel to facilitate the tree construction. In each session batch: </span></p><p class="c103"><span class="c0">i) All paths at different lengths are identified (through </span><span class="c1">n</span><span class="c0">-gram with variable-</span><span class="c1">n</span><span class="c0">) and parsed into tuples ( &#772;</span><span class="c1">c, &tau;</span><span class="c0">). ii) The counts of each tuple are accumulated. iii) A set of 4-tuples ( &#772;</span><span class="c1">c,&tau;,t</span><span class="c2">b</span><span class="c8">,&eta;</span><span class="c12">( &#772;</span><span class="c2">c,&tau;</span><span class="c12">)</span><span class="c7">) is yielded as the session </span><span class="c0">batch digest where </span><span class="c1">t</span><span class="c2">b </span><span class="c7">is the session batch timestamp </span><span class="c0">and </span><span class="c1">&eta;</span><span class="c12">( &#772;</span><span class="c2">c,&tau;</span><span class="c12">) </span><span class="c0">is the count of tuple ( &#772;</span><span class="c1">c, &tau;</span><span class="c0">) in the batch. </span></p><p class="c47"><span class="c65">2.3.2 Sliding Window </span></p><p class="c23"><span class="c0">The sliding window </span><span class="c1">w </span><span class="c0">covers a fixed number of session batches and each slide takes in a new session batch and abandons the earliest batch in the previous </span><span class="c1">w</span><span class="c0">. </span></p><p class="c58"><span class="c0">In each sliding position, three operations are performed: </span></p><p class="c110"><span class="c0">i) 4-tuples ( &#772;</span><span class="c1">c,&tau;,t</span><span class="c14">w</span><span class="c1">,&eta;</span><span class="c12">( &#772;</span><span class="c2">c,&tau;</span><span class="c12">)</span><span class="c7">) are accumulated from session </span><span class="c0">batch digests where </span><span class="c1">t</span><span class="c2">w </span><span class="c7">is the timestamp of the earliest </span><span class="c0">session batch in the window. ii) 3-tuples ( &#772;</span><span class="c1">c, t</span><span class="c14">w</span><span class="c1">,&eta;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c</span><span class="c0">) are accumulated from the 4-tuples </span></p><p class="c99"><span class="c0">where </span><span class="c1">&eta;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">is the count of context &nbsp;&#772;</span><span class="c8">c </span><span class="c7">in the window. </span><span class="c24">2</span><span class="c7">Our current design does not support streaming because it requires the entire user session to finish before it can be sessionized and batched. </span></p><p class="c72"><span class="c68">575 </span></p><p class="c126"><span class="c10">Table 3: Description of Spark Runtime Stages of our DECT Prototype Functionality #(SS) Description </span></p><p class="c69"><span class="c0">Input handling 1 reading user session data from HDFS Modeling 19 </span><span class="c1">n</span><span class="c0">-gram generation, batching, in-window aggregation, probability calculation, pruning Time series generation 9 assembling time series and storing them onto HDFS Statistics generation 3 generating and yielding statistics throughout the entire processing procedure </span></p><p class="c48"><span class="c0">#(SS): number of Spark runtime stages </span></p><p class="c49"><span class="c0">iii) A set of 4-tuples ( &#772;</span><span class="c1">c,&tau;,t</span><span class="c2">w</span><span class="c8">,P</span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">)) is yielded as the win- </span></p><p class="c19"><span class="c0">dow digest where </span><span class="c1">P</span><span class="c0">(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) = </span><span class="c4">&eta;</span><span class="c17">( &#772;</span><span class="c14">c,&tau;</span><span class="c17">) </span><span class="c1">&eta;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c </span><span class="c39">. </span></p><p class="c77"><span class="c65">2.3.3 Flattened Context Tree Update </span></p><p class="c15"><span class="c0">Digests of </span><span class="c1">w </span><span class="c0">at different positions are aggregated accord- ing to tuple ( &#772;</span><span class="c1">c, &tau;</span><span class="c0">) in the window digest. Each tuple forms a depth-1 node </span><span class="c1">n</span><span class="c17">&nbsp;&#772;</span><span class="c14">p </span><span class="c0">in the flattened context tree </span><span class="c1">T</span><span class="c14">F </span><span class="c0">. The time series at each node (&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) at node </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">p </span><span class="c7">where &nbsp;&#772;</span><span class="c8">p </span><span class="c7">= ( &#772;</span><span class="c8">c, &tau;</span><span class="c7">)) </span><span class="c0">is extended when a new window position is processed. </span><span class="c1">w </span><span class="c0">at different positions of a single node can be computed in parallel if all session batches are known. </span></p><p class="c42"><span class="c0">Pruning of </span><span class="c1">T</span><span class="c14">F </span><span class="c0">can be performed at any time based on the generated time series at nodes. As discussed in Section 2.2.2, pruning is performed at nodes that are rarely visited. If </span><span class="c1">n</span><span class="c17">&nbsp;&#772;</span><span class="c14">p </span><span class="c0">is pruned, &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) prior to the pruning action is lost. </span><span class="c1">n</span><span class="c12">&nbsp;&#772;</span><span class="c2">p </span><span class="c7">can </span><span class="c0">be added back to </span><span class="c1">T</span><span class="c2">F </span><span class="c7">if it becomes popular in the future, but </span><span class="c0">without the segment of &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) when it is pruned away. </span></p><p class="c74"><span class="c65">2.3.4 Time Series Production and its Applications </span></p><p class="c78"><span class="c1">T</span><span class="c14">F </span><span class="c0">records the user behavior pattern evolvement and it can be consumed by a variety of time series analysis tools (e.g., anomaly detection, path prediction). </span><span class="c10">User behavior evolvement data generation. </span><span class="c0">The user behavior evolvement data are yielded in three major forms for post-processing and analytics: </span></p><p class="c121"><span class="c1">&bull; </span><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">): individual time series for each ( &#772;</span><span class="c1">c, &tau;</span><span class="c0">) pair </span></p><p class="c111"><span class="c1">&bull; {</span><span class="c0">&Psi;(</span><span class="c1">&tau;</span><span class="c14">i</span><span class="c1">|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) </span><span class="c1">| </span><span class="c0">0 </span><span class="c1">&le; i &le; &kappa;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c</span><span class="c1">}</span><span class="c0">: high-dimensional time series for all targets of a context &nbsp;&#772;</span><span class="c1">c </span><span class="c0">where </span><span class="c1">&kappa;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c </span><span class="c7">is the total number </span><span class="c0">of reachable targets of context &nbsp;&#772;</span><span class="c1">c</span><span class="c0">. </span></p><p class="c115"><span class="c1">&bull; {</span><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c2">i</span><span class="c7">) </span><span class="c8">| </span><span class="c7">0 </span><span class="c8">&le; i &le; &rho;</span><span class="c2">&tau;</span><span class="c8">}</span><span class="c7">: a collection of time series for </span><span class="c0">a target </span><span class="c1">&tau; </span><span class="c0">where </span><span class="c1">&rho;</span><span class="c14">&tau; </span><span class="c0">is the total number of contexts which can reach the target </span><span class="c1">&tau;</span><span class="c0">. </span><span class="c1">{</span><span class="c0">&Psi;(</span><span class="c1">&tau;</span><span class="c2">i</span><span class="c8">|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">) </span><span class="c8">| </span><span class="c7">0 </span><span class="c8">&le; i &le; &kappa;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c</span><span class="c8">} </span><span class="c7">forms a high-dimensional time se- </span><span class="c0">ries where </span><span class="c1">i &le; &rho;</span><span class="c2">&tau;</span><span class="c8">} </span><span class="c0">dent of each </span><span class="c7">as a </span><span class="c0">dimension is &Psi;(</span><span class="c1">&tau;</span><span class="c14">i</span><span class="c1">|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">). </span><span class="c7">collection because each </span><span class="c0">We write </span><span class="c7">&Psi;(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c14">&prime;</span><span class="c7">) </span><span class="c1">{</span><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c14">i</span><span class="c0">) </span><span class="c1">| </span><span class="c0">0 </span><span class="c1">&le; </span><span class="c7">is not indepen- </span><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) where &nbsp;&#772;</span><span class="c1">c</span><span class="c27">&prime; </span><span class="c0">is a suffix of &nbsp;&#772;</span><span class="c1">c</span><span class="c0">, yet it is quite useful to compare &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) with &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c27">&prime;</span><span class="c0">). </span><span class="c10">User behavior evolvement data analysis. </span><span class="c0">Three most important components of an aggregated user behavior time series are </span><span class="c1">trend</span><span class="c0">, </span><span class="c1">seasonality</span><span class="c0">, and </span><span class="c1">irregular component</span><span class="c0">. </span></p><p class="c116"><span class="c10">Trend </span><span class="c0">&Psi;</span><span class="c14">T</span><span class="c0">(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) describes long-term movement without </span></p><p class="c28"><span class="c0">calendar related and irregular effects. </span><span class="c10">Seasonality </span><span class="c0">&Psi;</span><span class="c2">S</span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">) characterizes regular cyclic move- </span></p><p class="c56"><span class="c0">ments influenced by seasonal factors. </span><span class="c10">Irregular component </span><span class="c0">&Psi;</span><span class="c14">I</span><span class="c0">(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) records non-systematic and unpredictable component(s) after trend and sea- sonal components are removed from the signal. Many user behavior time series &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) can be very well </span></p><p class="c13 c25"><span class="c0">decomposed into the three components as described in (1). </span></p><p class="c114"><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">)=&Psi;</span><span class="c2">T </span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">)+&Psi;</span><span class="c2">S</span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">)+&Psi;</span><span class="c2">I</span><span class="c7">(</span><span class="c8">&tau;|</span><span class="c7">&nbsp;&#772;</span><span class="c8">c</span><span class="c7">) (1) </span></p><p class="c92"><span class="c0">&Psi;</span><span class="c14">S</span><span class="c0">(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) can be further divided into daily and weekly sea- sonal components as found in our experiments. </span></p><p class="c54"><span class="c0">Two major applications of our model are described next. </span><span class="c10">Anomaly Detection </span><span class="c0">aims to discover anomalous user behavior with respect to specific visiting paths. A </span><span class="c1">spike </span><span class="c0">or a </span><span class="c1">ravine </span><span class="c0">in a time series could indicate breaking news, flash crowds, Denial-of-Service attacks, service failures, etc. A plateau appearing in the </span><span class="c1">trend </span><span class="c0">component of a time series may indicate a persistent attack or a test for a new feature. User behavior evolvement data &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) and </span><span class="c1">{</span><span class="c0">&Psi;(</span><span class="c1">&tau;</span><span class="c14">i</span><span class="c1">|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) </span><span class="c1">| </span><span class="c0">0 </span><span class="c1">&le; i &le; &kappa;</span><span class="c12">&nbsp;&#772;</span><span class="c2">c</span><span class="c8">} </span><span class="c7">are yielded for anomaly detection. </span></p><p class="c40"><span class="c10">Ad Click Prediction </span><span class="c0">is an application to predict how likely a user will click an ad on her current visiting site given her visiting path of the current session. Different visiting paths leading to the same site may give different ad click rates, and the probability trends of different paths may be different. User behavior evolvement data &Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) and </span><span class="c1">{</span><span class="c0">&Psi;(</span><span class="c1">&tau;|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c14">i</span><span class="c0">) </span><span class="c1">| </span><span class="c0">0 </span><span class="c1">&le; i &le; &rho;</span><span class="c14">&tau;</span><span class="c1">} </span><span class="c0">are yielded for ad click prediction. </span></p><p class="c118"><span class="c32">3. IMPLEMENTATION </span></p><p class="c23"><span class="c0">We implement DECT via Apache Spark using Scala. We deploy DECT on top of Yahoo! infrastructure to support anomaly detection and other services on Yahoo! network. </span></p><p class="c113"><span class="c0">Our DECT implementation is open-sourced on github [19]. The implementation takes advantage of scalable and robust transformations on resilient distributed dataset (RDD) in Spark, e.g., mapValues and join. DECT compiles to 32 Spark stages at JVM runtime (shown in Table 3). </span></p><p class="c43"><span class="c0">Our implementation consumes plaintext session data stored on HDFS where each line records a user session</span><span class="c20">3</span><span class="c0">. A user ses- sion consists of a timestamp </span><span class="c1">t</span><span class="c14">s </span><span class="c0">and a sequence of visited sites </span><span class="c1">E </span><span class="c0">= </span><span class="c1">{s</span><span class="c12">0</span><span class="c8">,s</span><span class="c12">1</span><span class="c8">,...}</span><span class="c7">. DECT digests the plaintext session data </span><span class="c0">and yields two types of information: </span><span class="c1">i) </span><span class="c0">time series harvested from the flattened context tree, stored on HDFS, and </span><span class="c1">ii) </span><span class="c0">statistics on processed data, e.g., total number of </span><span class="c1">i</span><span class="c0">th-order time series, printed to Spark log. </span></p><p class="c108"><span class="c0">Our realization is optimized from the following aspects: </span></p><p class="c22"><span class="c0">1. Session and path (</span><span class="c1">n</span><span class="c0">-gram) data are aggregated at early stages to minimize unnecessary duplicate data process- ing. For example, before generating and counting </span><span class="c1">n</span><span class="c0">- grams in each session </span><span class="c1">E</span><span class="c0">, same </span><span class="c1">E </span><span class="c0">with the same session batch timestamp </span><span class="c1">t</span><span class="c2">b </span><span class="c7">are counted and deduplicated. </span><span class="c0">2. Compact data structures are used to reduce storage and transmitting overhead, e.g., a context as a single JVM string, instead of an array of sites (JVM strings). </span></p><p class="c96"><span class="c24">3</span><span class="c7">We employ a Pig script to retrieve, sessionize and store raw user event data from HCatalog onto HDFS prior to DECT. </span></p><p class="c72"><span class="c68">576 </span></p><p class="c13"><span class="c0">W </span><span class="c39">W otnoitisnartfoytilibabor</span><span class="c0">P0.20.1 0 </span></p><p class="c13"><span class="c0">X-W </span></p><p class="c33"><span class="c0">0.2 0.1 </span><span class="c7">0 </span></p><p class="c13"><span class="c0">Y-X-W </span></p><p class="c33"><span class="c0">0.2 0.1 0 </span></p><p class="c13"><span class="c0">0 7 14 21 28 </span></p><p class="c13"><span class="c0">Day index </span></p><p class="c13"><span class="c10">Figure 3: Higher-order path time series anomaly detection</span><span class="c98">5</span><span class="c10">. </span></p><p class="c13"><span class="c0">3. Job parameters are broadcasted, e.g., string splitter. 4. Partitioning strategies are manually specified to reduce </span></p><p class="c13"><span class="c0">data movement among worker nodes. </span></p><p class="c13"><span class="c32">4. EVALUATION </span></p><p class="c13"><span class="c0">We conduct experiments on two Yahoo! daily user session datasets to answer the following key questions: </span></p><p class="c13"><span class="c0">1. What do we benefit from our time-variant user behav- </span></p><p class="c30"><span class="c0">ior model over existing static stochastic models? 2. Is our design scalable to handle enterprise-wide tasks </span></p><p class="c13"><span class="c0">consisting of billions of sessions? We evaluate DECT with all data collected through Yahoo! data highway. We analyze Yahoo! user activities within the first half of 2015. In the evaluation, we focus on user sessions within a single product, e.g., Yahoo! mail. Visits to alien sites during sessions are ignored</span><span class="c20">4</span><span class="c0">. </span></p><p class="c9"><span class="c0">We process user session data of Yahoo! US websites (En- glish version) within two products separately: Yahoo! mail and Yahoo! finance</span><span class="c20">5</span><span class="c0">. Each site in a session is roughly a view in the model-view-controller (MVC) web architecture, and it has a unique URL. </span></p><p class="c13"><span class="c32">4.1 Case Study: Anomaly Detection </span></p><p class="c13"><span class="c0">Time series of site visits are commonly used as anomaly detection signals. However, if no context information is specified, anomaly signals of specific visiting paths are masked out by other signals. Therefore, it causes false negatives. </span></p><p class="c9"><span class="c0">We pick a typical Yahoo! mail site W (i.e., </span><span class="c1">&tau; </span><span class="c0">in Sec- tion 2)</span><span class="c20">5 </span><span class="c0">and show that anomalies in higher-order path sig- nals are significant and can be revealed by DECT. We use DECT to compute visiting probabilities of W for all con- texts </span><span class="c1">{</span><span class="c0">&nbsp;&#772;</span><span class="c1">c} </span><span class="c0">that exist. We then fed time series </span><span class="c1">{</span><span class="c0">&Psi;(</span><span class="c1">&tau;</span><span class="c14">i</span><span class="c1">|</span><span class="c0">&nbsp;&#772;</span><span class="c1">c</span><span class="c0">) </span><span class="c1">| </span><span class="c0">0 </span><span class="c1">&le; </span></p><p class="c13"><span class="c24">4</span><span class="c7">DECT can be deployed at the client/browser side to model and analyze Internet-wide user behavior. </span><span class="c24">5</span><span class="c7">According to Yahoo! data privacy requirements, </span><span class="c8">i) </span><span class="c7">detailed data statistics are not provided; </span><span class="c8">ii) </span><span class="c7">probabilities in figures are disguised while their relative positions are preserved. </span></p><p class="c30"><span class="c0">0.9 </span><span class="c39">y tilibaborpkcilcd</span><span class="c0">A0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 </span></p><p class="c13"><span class="c0">0 2 4 6 8 10 12 14 </span></p><p class="c13"><span class="c0">Day index </span></p><p class="c9"><span class="c10">Figure 4: Ad click probabilities given different paths. The bold dotted line denotes the overall ad click rate of users on a site. Each thin line denotes ad click rates of users on this site coming from one specific visiting path</span><span class="c98">5</span><span class="c10">. </span></p><p class="c13"><span class="c0">0.9 </span><span class="c39">y tilibaborpkcilcd</span><span class="c0">A0.1 0.8 </span></p><p class="c13"><span class="c0">1 2 3 4 5 6 7 8 9 10 </span></p><p class="c13"><span class="c0">#(viewing actions) before clicking an Ad </span></p><p class="c13"><span class="c10">Figure 5: Ad click probability of a wanderlust</span><span class="c98">5</span><span class="c10">. </span></p><p class="c9"><span class="c1">i &le; &kappa;</span><span class="c17">&nbsp;&#772;</span><span class="c14">c</span><span class="c1">} </span><span class="c0">yielded by DECT into EGADS for anomaly detec- tion. EGADS is a generic and scalable framework for auto- mated anomaly detection on large scale time-series data [10]. The entire anomaly detection application consists of DECT (time-variant user behavior modeling) and EGADS (time series anomaly detection). </span></p><p class="c9"><span class="c0">Fig. 3 shows two higher-order anomalous time series iden- tified by EGADS. The upper subfigure, a common seasonal time series across a month, is the visiting probability of W across all Yahoo! mail sites. One anomalous time series (site X to W) is detected during that month (several spikes in the middle subfigure). Another anomaly is found on the 8th day of visiting path &ldquo;Y to X to W&rdquo; in the lower subfigure. Any anomaly (spike) with respect to a higher-order path may be hidden in the time series of its suffix path. </span></p><p class="c13"><span class="c32">4.2 Case Study: Ad Click Prediction </span></p><p class="c9"><span class="c0">Existing ad click prediction techniques do not take his- torically visited paths into account. We run DECT on the Yahoo! finance dataset to show that such information is useful in distinguishing probabilities of ad clicks. </span></p><p class="c13"><span class="c0">We draw the overall ad click rate on a Yahoo! finance site</span><span class="c20">5 </span><span class="c0">in Fig. 4 with the bold dotted line. We then use DECT to </span></p><p class="c13"><span class="c68">577 </span></p><p class="c9"><span class="c0">0.7 0.6 0.5 0.4 0.3 0.2 </span></p><p class="c13"><span class="c0">700 </span><span class="c39">) sdnoces(emitgnissecor</span><span class="c0">POrder limit: 2nd 600 </span></p><p class="c13"><span class="c0">Order limit: 4th </span></p><p class="c13"><span class="c0">500 </span></p><p class="c13"><span class="c0">400 </span></p><p class="c13"><span class="c0">300 </span></p><p class="c13"><span class="c0">200 </span></p><p class="c13"><span class="c0">100 </span></p><p class="c13"><span class="c0">2110 4210 9010 16510 33010 66010 </span></p><p class="c13"><span class="c0">Number of vCores allocated </span></p><p class="c13"><span class="c10">Figure 6: Performance pivot discovery of DECT. </span></p><p class="c13"><span class="c39">) sdnoces(emitgnissecor</span><span class="c0">P2048 128 1024 </span></p><p class="c13"><span class="c0">512 </span></p><p class="c13"><span class="c0">256 </span></p><p class="c13"><span class="c0">0th 2nd 4th 6th 8th </span></p><p class="c13"><span class="c0">Order limit of DECT </span></p><p class="c13"><span class="c10">Figure 7: Order impact on computation complexity. </span></p><p class="c9"><span class="c0">investigate three ad click rate time series, each of which has a site previously visited (one-time context) before the target site. Fig. 4 shows that the click rate of users coming from one site can be 5 times higher than that of another. </span></p><p class="c9"><span class="c0">Besides the finding that </span><span class="c1">ad click rates are related to user visiting paths</span><span class="c0">, another interesting conclusion we reached is that </span><span class="c1">the more a user views articles on a site, the less likely she will click an ad on that site. </span><span class="c0">We illustrate the decrease of ad click rates on a Yahoo! finance site</span><span class="c20">5 </span><span class="c0">in Fig. 5. We explain the phenomenon that frequent readers tend to con- tinuously consume target information, e.g., stock values, and ignore ads. Ads could be less effective and more annoying to frequent readers than normal visitors. This work is being deployed at Yahoo! for better ad-targeting. </span></p><p class="c13"><span class="c32">4.3 Performance analysis </span></p><p class="c13"><span class="c0">We demonstrate the performance of our implementation by processing a subset of Yahoo! mail data (around 0.1 billion user sessions, 10GB storage size on HDFS)</span><span class="c20">5</span><span class="c0">. </span><span class="c10">Scalability and Performance Pivot. </span><span class="c0">Our realization of DECT is based on the scalable Apache Spark framework. A distributed system results in an increasing amount of com- municating/scheduling overhead when scaling out. We are interested in discovering performance pivots and parameter tuning on real-world datasets. </span></p><p class="c13"><span class="c0">We conduct several groups of experiments with DECT </span></p><p class="c13"><span class="c0">running on different numbers of worker nodes. We measure the degree of parallelism via the maximum number of pro- cessing units (vCore)</span><span class="c20">6 </span><span class="c0">concurrently allocated at any execu- tion stage. Fig. 6 shows that our implementation scales out well before reaching a performance pivot. Performance piv- ots are reached for DECT with order limit 4 at 9010 vCores and order limit 2 at 4210 vCores. Increasing the number of processing units after the pivots wastes more in overhead than gaining better performance. The more complex the computation is, e.g., higher order limit, the larger amount of processing units are required to reach the pivot. </span><span class="c10">Magnitude of frequently visited higher-order paths. </span><span class="c0">DECT is a variable-order Markov model. It employs a prun- ing procedure to remove time series of rarely visited higher- order paths. We are interested in the order impact on the overall computational complexity. </span></p><p class="c9"><span class="c0">We execute DECT with various order limits. Because the total number of possible paths is exponential in path order, the results in Fig. 7 show that: </span><span class="c1">i) </span><span class="c0">the processing time increases exponentially with the increase of the order limit, and </span><span class="c1">ii) </span><span class="c0">the pruning procedure reduces the number of time series </span><span class="c1">by a constant factor </span><span class="c0">on Yahoo! mail dataset. </span></p><p class="c13"><span class="c32">5. RELATED WORK </span></p><p class="c13"><span class="c0">Our work is motivated by time-homogeneous Markov user behavior modeling, time series analysis, and evolutionary network analysis. </span><span class="c10">Time-homogeneous Markov modeling. </span><span class="c0">Web user be- havior has been studied for various purposes, such as PageR- ank [13], link prediction [17], document prefetching [23]. A variety of time-homogeneous Markov models have been tested to describe Internet user behavior [5]. The time- homogeneous indicates that the transition matrix of the Markov model does not change through time. We list some existing models classified by their Markov orders below. </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">First-order Markov model: [12,13] </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">Second-order Markov model: [23] </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">Higher-order Markov model: [15] </span></p><p class="c13"><span class="c1">&bull; </span><span class="c0">Variable-order Markov model: [2,5,6] Variable-order Markov models compute different orders for different paths to reduce storage expenses. The idea was proposed by B&uuml;hlmann and Wyner [3]. There exist two generic approaches to construct variable-order models. </span></p><p class="c13"><span class="c10">Pruning-based approach: </span><span class="c0">starting with a complete </span></p><p class="c30"><span class="c0">higher-order model and iteratively pruning low-entropy branches to get a incomplete tree, e.g., [6]. </span><span class="c10">Growing-based approach: </span><span class="c0">starting with a first-order Markov model and expanding leaves with inconsistent distribution into branches, e.g., [2]. Our design follows the former approach for straightfor- ward parallel design. The operations of growing higher-order paths, i.e., slicing and clustering, are computational heavy and the results cannot be efficiently reused over time. </span><span class="c10">Time series analysis. </span><span class="c0">A time series denotes the change of a variable over time [8]. Time series analysis has been applied to many fields including signal forecasting [9], data feature extraction [7] and anomaly detection [4,10,11,20]. </span></p><p class="c13"><span class="c0">Time series analysis is widely used to detect anomalous </span></p><p class="c13"><span class="c24">6</span><span class="c7">The number of workers is linear to the number of vCores. </span></p><p class="c13"><span class="c68">578 </span></p><p class="c95"><span class="c0">user events in the industry. However, studied variables in existing systems are mostly primitive, e.g., counts of site visits. They only represent zeroth-order or first-order (one- hop) paths [10]. The prediction is fast but loses rich context information. DECT, in contrast, utilizes historical site visit- ing information to provide more detailed signals for anomaly detection and ad click rate prediction as shown in Section 4. </span><span class="c10">Evolutionary network analysis. </span><span class="c0">Dynamic networks ap- pear in social networks, wireless sensor networks, Internet of Things, and the Web. The analysis of evolving networks provides a comprehensive understanding of such networks [1] and enables applications such as link prediction [18] and anomaly detection [16]. </span></p><p class="c42"><span class="c0">Graphs are generic models for dynamic network repre- sentation [1]. More specifically, dynamic networks usually generate complex cyclic graphs, and evolutionary network analysis heavily relies on unique properties of such graphs, e.g., community discovery [14]. Compared to cyclic graphs, variable-order Markov models are tree-equivalent structures. In our model, we bring some concepts from evolutionary net- work analysis, e.g., </span><span class="c1">change of V</span><span class="c14">M </span><span class="c0">and </span><span class="c1">change of E</span><span class="c14">M</span><span class="c0">. But, in general, it is currently unclear how evolutionary network analysis methods can be applied to dynamic web user be- havior modeling. </span></p><p class="c45"><span class="c32">6. CONCLUSIONS AND FUTURE WORK </span></p><p class="c15"><span class="c0">This paper presents DECT, a scalable time-variant web user behavior model. It characterizes the changing nature of Internet user behavior with a time-variant variable-order Markov model. DECT can be efficiently realized on scalable distributed frameworks, e.g., Apache Spark, to process large volumes of user behavior data. DECT enables time series analysis on individual or related sets of long (higher-order) user paths. We open-sourced DECT and deployed it at Ya- hoo! to support path time series analysis such as anomaly detection, click probability prediction and path trend dis- covery. In the future work, we plan to work on streaming pruning strategies to enable streaming user behavior pro- cessing using DECT. </span></p><p class="c87"><span class="c32">7. REFERENCES </span></p><p class="c44"><span class="c0">[1] C. Aggarwal and K. Subbian. Evolutionary network </span></p><p class="c125"><span class="c0">analysis: A survey. </span><span class="c1">ACM Computer Surveys</span><span class="c0">, 47(1):10:1&ndash;10:36, May 2014. [2] J. Borges and M. Levene. Evaluating variable-length </span></p><p class="c88"><span class="c0">Markov chain models for analysis of user web navigation sessions. </span><span class="c1">IEEE Transaction on Knowledge and Data Engineering</span><span class="c0">, 19(4):441&ndash;452, April 2007. [3] P. B&uuml;hlmann and A. J. Wyner. Variable length </span></p><p class="c86"><span class="c0">Markov chains. </span><span class="c1">The Annals of Statistics</span><span class="c0">, 27(2):480&ndash;513, April 1999. [4] V. Chandola, A. Banerjee, and V. Kumar. Anomaly </span></p><p class="c67"><span class="c0">detection: A survey. </span><span class="c1">ACM Computer Surveys</span><span class="c0">, 41(3):1&ndash;58, July 2009. [5] F. Chierichetti, R. Kumar, P. Raghavan, and </span></p><p class="c117"><span class="c0">T. Sarlos. Are web users really Markovian? In </span><span class="c1">Proceedings of World Wide Web Conference</span><span class="c0">, pages 609&ndash;618, New York, NY, USA, 2012. [6] M. Deshpande and G. Karypis. Selective Markov </span></p><p class="c73"><span class="c0">models for predicting web page accesses. </span><span class="c1">ACM Transactions on Internet Technology</span><span class="c0">, 4(2):163&ndash;184, May 2004. </span></p><p class="c13 c129"><span class="c0">[7] P. Esling and C. Agon. Time-series data mining. </span><span class="c1">ACM </span></p><p class="c64"><span class="c1">Computing Surveys</span><span class="c0">, 45(1):12, 2012. [8] J. D. Hamilton. </span><span class="c1">Time series analysis</span><span class="c0">, volume 2. </span></p><p class="c94"><span class="c0">Princeton university press Princeton, 1994. [9] R. J. Hyndman and A. B. Koehler. Another look at measures of forecast accuracy. </span><span class="c1">International Journal of Forecasting</span><span class="c0">, 22(4):679&ndash;688, 2006. [10] N. Laptev, S. Amizadeh, and I. Flint. Generic and </span></p><p class="c130"><span class="c0">scalable framework for automated time-series anomaly detection. In </span><span class="c1">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</span><span class="c0">, pages 1939&ndash;1947, 2015. [11] N. Laptev, R. Hyndman, and E. Wang. Large-scale </span></p><p class="c93"><span class="c0">unusual time series detection. In </span><span class="c1">Proceedings of IEEE International Conference on Data Mining</span><span class="c0">, 2015. [12] Z. Li and J. Tian. Testing the suitability of Markov </span></p><p class="c102"><span class="c0">chains as web usage models. In </span><span class="c1">Proceedings of Annual International Computers Software and Applications Conference</span><span class="c0">, pages 356&ndash;361, November 2003. [13] L. Page, S. Brin, R. Motwani, and T. Winograd. The </span></p><p class="c54"><span class="c0">PageRank citation ranking: bringing order to the web. Technical Report 1999-66, Stanford InfoLab, 1999. [14] S. Parthasarathy, Y. Ruan, and V. Satuluri. </span></p><p class="c46"><span class="c0">Community discovery in social networks: Applications, methods and emerging trends. In C. C. Aggarwal, editor, </span><span class="c1">Social Network Data Analytics</span><span class="c0">, pages 79&ndash;113. Springer US, 2011. [15] P. Pirolli and J. Pitkow. Distributions of surfers&rsquo; paths </span></p><p class="c84"><span class="c0">through the World Wide Web: Empirical characterizations. </span><span class="c1">World Wide Web</span><span class="c0">, 2(1-2):29&ndash;45, 1999. [16] S. Ranshous, S. Shen, D. Koutra, S. Harenberg, </span></p><p class="c54"><span class="c0">C. Faloutsos, and N. F. Samatova. Anomaly detection in dynamic networks: a survey. </span><span class="c1">Wiley Interdisciplinary Reviews: Computational Statistics</span><span class="c0">, 7(3):223&ndash;247, 2015. [17] R. R. Sarukkai. Link prediction and path analysis </span></p><p class="c53"><span class="c0">using Markov chains. </span><span class="c1">Computer Networks</span><span class="c0">, 33(1):377&ndash;386, 2000. [18] R. R. Sarukkai. Link prediction and path analysis </span></p><p class="c21"><span class="c0">using Markov chains. </span><span class="c1">Computer Networks</span><span class="c0">, 33(1&ndash;6):377&ndash;386, 2000. [19] X. Shu. Distributed evolving context tree (DECT), </span></p><p class="c61"><span class="c0">https://github.com/subbyte/DECT. [20] O. Vallis, J. Hochenbaum, and A. Kejariwal. A novel technique for long-term anomaly detection in the cloud. In </span><span class="c1">Proceedings of USENIX HotCloud Workshop</span><span class="c0">, pages 15&ndash;15, Philadelphia, PA, June 2014. [21] Y. Xie and S. zheng Yu. Monitoring the </span></p><p class="c38"><span class="c0">application-layer DDoS attacks for popular websites. </span><span class="c1">IEEE/ACM Transactions on Networking</span><span class="c0">, 17(1):15&ndash;25, Feb 2009. [22] S. Yu, G. Zhao, S. Guo, Y. Xiang, and A. Vasilakos. </span></p><p class="c124"><span class="c0">Browsing behavior mimicking attacks on popular web sites for large botnets. In </span><span class="c1">IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)</span><span class="c0">, pages 947&ndash;951, April 2011. [23] I. Zukerman, D. W. Albrecht, and A. E. Nicholson. </span></p><p class="c62"><span class="c0">Predicting users&rsquo; requests on the WWW. In </span><span class="c1">Proceedings of the 7th International Conference on User Modeling</span><span class="c0">, pages 275&ndash;284, Secaucus, NJ, USA, 1999. Springer. </span></p><p class="c82"><span class="c68">579 </span></p></body></html>