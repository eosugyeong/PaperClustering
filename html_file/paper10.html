<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c47{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.1pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Arial";font-style:normal}.c66{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.6pt;font-family:"Arial";font-style:normal}.c101{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c71{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.5pt;font-family:"Arial";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.8pt;font-family:"Arial";font-style:normal}.c26{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.2pt;font-family:"Arial";font-style:normal}.c98{margin-left:-27.1pt;padding-top:1pt;text-indent:36.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.4pt}.c69{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.7pt;font-family:"Arial";font-style:normal}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.2pt;font-family:"Arial";font-style:normal}.c73{margin-left:-18.1pt;padding-top:1.2pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.6pt}.c99{margin-left:-18.1pt;padding-top:1.2pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-12.5pt}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.3pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.5pt;font-family:"Times New Roman";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c52{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11.6pt;font-family:"Arial";font-style:normal}.c97{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c57{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.6pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c65{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.2pt;font-family:"Arial";font-style:normal}.c80{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c75{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c24{margin-left:-18.1pt;padding-top:1pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c87{margin-left:-27.1pt;padding-top:1.7pt;text-indent:36.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15pt}.c88{margin-left:-26.2pt;padding-top:59.3pt;text-indent:28.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.8pt;font-family:"Arial";font-style:normal}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.6pt;font-family:"Arial";font-style:normal}.c72{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8.5pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.6pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.4pt;font-family:"Arial";font-style:normal}.c53{margin-left:-26.2pt;padding-top:3.8pt;text-indent:35.3pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15.9pt}.c74{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.2pt;font-family:"Courier New";font-style:normal}.c48{margin-left:-18.1pt;padding-top:1pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-7.4pt}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c76{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:11.6pt;font-family:"Arial";font-style:normal}.c46{margin-left:-27.1pt;padding-top:1.7pt;text-indent:36.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15pt}.c90{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:9.7pt;font-family:"Arial";font-style:normal}.c67{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.5pt;font-family:"Arial";font-style:normal}.c50{margin-left:-18.1pt;padding-top:1pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23.8pt}.c51{margin-left:-27.1pt;padding-top:1.4pt;text-indent:36.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.9pt}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.7pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12.6pt;font-family:"Arial";font-style:normal}.c37{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.8pt;font-family:"Arial";font-style:normal}.c61{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.3pt;font-family:"Arial";font-style:normal}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.3pt;font-family:"Times New Roman";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c58{margin-left:-27.1pt;padding-top:3.8pt;text-indent:36.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15pt}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10.5pt;font-family:"Times New Roman";font-style:normal}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10.6pt;font-family:"Arial";font-style:normal}.c83{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Courier New";font-style:normal}.c40{margin-left:-17.1pt;padding-top:9.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:21.1pt}.c78{margin-left:-9.4pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.4pt}.c70{margin-left:-18.1pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-22.1pt}.c35{margin-left:-27.1pt;padding-top:12.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.1pt}.c94{margin-left:-25.9pt;padding-top:8.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:67.4pt}.c85{margin-left:-18.1pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.4pt}.c82{margin-left:-18.1pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.3pt}.c62{margin-left:-23pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-11.4pt}.c89{margin-left:-18.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:4.8pt}.c59{margin-left:-18.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.3pt}.c92{margin-left:-17.1pt;padding-top:4.1pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-27.6pt}.c93{margin-left:-26.2pt;padding-top:13.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:107pt}.c100{margin-left:-17pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-17.6pt}.c43{margin-left:-23.8pt;padding-top:55.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24pt}.c81{margin-left:-14pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-3.8pt}.c12{margin-left:-18.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-17.3pt}.c91{margin-left:-18.1pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-23.8pt}.c27{margin-left:-27.1pt;padding-top:9.4pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-15pt}.c60{margin-left:-18.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-22.8pt}.c96{margin-left:56.9pt;padding-top:28.6pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:55.7pt}.c68{margin-left:-18.1pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.8pt}.c56{margin-left:-18.1pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.6pt}.c49{margin-left:-14pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-23.8pt}.c79{margin-left:-16.2pt;padding-top:13pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:75.6pt}.c63{margin-left:-18.1pt;padding-top:1pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c84{margin-left:218.2pt;padding-top:61.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c64{margin-left:-23pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-9.9pt}.c33{margin-left:-5.5pt;padding-top:19.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-4.6pt}.c95{margin-left:-26.2pt;padding-top:14.6pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c55{margin-left:-14pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-14.6pt}.c44{padding-top:1.7pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c54{padding-top:1.4pt;text-indent:26.2pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c34{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c38{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c32{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c8{margin-left:-14pt;margin-right:7.7pt}.c25{margin-left:-17.1pt;margin-right:-25pt}.c77{margin-right:-12.2pt}.c86{margin-right:-18.5pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c32"><p class="c33"><span class="c80">Query Workload-based RDF Graph Fragmentation and Allocation </span></p><p class="c96"><span class="c2">Peng Peng</span><span class="c14">1</span><span class="c2">, Lei Zou</span><span class="c14">1,3&lowast;</span><span class="c2">, Lei Chen</span><span class="c14">2</span><span class="c2">, Dongyan Zhao</span><span class="c14">1,3 </span><span class="c3">1</span><span class="c75">Peking University, China; </span><span class="c76">2 </span><span class="c75">Hong Kong University of Science and Technology, China; </span><span class="c76">3 </span><span class="c75">Key Laboratory of Computational Linguistics (PKU), Ministry of Education, China </span><span class="c6">{ </span><span class="c97">pku09pp,zoulei,zhaodongyan</span><span class="c6">}</span><span class="c97">@pku.edu.cn, leichen@cse.ust.hk </span></p><p class="c95"><span class="c2">ABSTRACT </span><span class="c6">As the volume of the RDF data becomes increasingly large, it is essential for us to design a distributed database system to manage it. For distributed RDF data design, it is quite common to partition the RDF data into some parts, called fragments, which are then dis- tributed. Thus, the distribution design consists of two steps: frag- mentation and allocation. In this paper, we propose a method to explore the intrinsic similarities among the structures of queries in a workload for fragmentation and allocation, which aims to reduce the number of crossing matches and the communication cost during SPARQL query processing. Specifically, we mine and select some frequent access patterns to reflect the characteristics of the work- load. Based on the selected frequent access patterns, we propose two fragmentation strategies, vertical and horizontal fragmentation strategies, to divide RDF graphs while meeting different kinds of query processing objectives. Vertical fragmentation is for better throughput and horizontal fragmentation is for better performance. After fragmentation, we discuss how to allocate these fragments to various sites. Finally, we discuss how to process a query based on the results of fragmentation and allocation. Extensive experiments confirm the superior performance of our proposed solutions. </span></p><p class="c93"><span class="c2">1. INTRODUCTION </span></p><p class="c53"><span class="c6">As a standard model for publishing and exchanging data on the Web, Resource Description Framework (RDF) has been widely used in various applications to expose, share, and connect pieces of data on the Web. In RDF, data is represented as triples of the form &#12296;subject, property, object&#12297;. An RDF dataset can be naturally seen as a graph, where subjects and objects are vertices connected by named relationships (i.e., properties). SPARQL is a structured query language proposed by W3C to access RDF repository. As we know, answering a SPARQL query Q is equivalent to finding subgraph matches of query graph Q over an RDF graph G [31]. Figures 1 and 2 show an RDF graph and a set of SPARQL query graphs used as the running example in this paper. </span></p><p class="c100"><span class="c6">As RDF repositories increase in size, evaluating SPARQL queries </span></p><p class="c94"><span class="c83">*</span><span class="c0">corresponding author: zoulei@pku.edu.cn </span></p><p class="c88"><span class="c6">c </span><span class="c5">2016, Copyright is with the authors. Published in Proc. 19th Inter- national Conference on Extending Database Technology (EDBT), March 15-18, 2016 - Bordeaux, France: ISBN 978-3-89318-070-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c7 c25"><span class="c6">is beyond the capacity of a single machine. For example, DBpedia, a project aiming to extract structured content from Wikipedia, con- sists of 2.46 billion RDF triples [4]; according to the W3C, the numbers of triples in some commercial RDF datasets have been more than 1 trillion [6]. The large-scale of RDF data volume in- creases the demand of designing the high performance distributed RDF database system. </span></p><p class="c25 c54"><span class="c6">In distributed database design, the first issue is &ldquo;data fragmenta- tion and allocation&rdquo; [18]. We need to divide an RDF graph into sev- eral parts, called fragments, and then distribute them among sites. One important issue during data fragmentation and allocation in a distributed system is how to reduce the communication cost be- tween different fragments during distributed query evaluation (as- suming different fragments are resident at different sites). To min- imize the communication cost, many existing graph fragmentation strategies maximize the global goal (such as min-cut [12]). How- ever, evaluating a SPARQL query is a subgraph (homomorphism) match problem. The subgraph match computation often does not involve all vertices in graph G, and the communication cost of sub- graph match computation depends on not only the RDF graph but also the query graph. In other words, subgraph match computa- tion exhibits strong locality. There is no direct relation between minimizing the communication cost (in subgraph match computa- tion) and maximizing the global goal. Hence, we propose a local pattern-based fragmentation strategy in this paper, which can re- duce the communication cost of subgraph match computation. </span></p><p class="c25 c44"><span class="c6">The intuition behind the local pattern-based fragmentation is as follows: if a query &ldquo;satisfies&rdquo; a local pattern and all its matches are in a single fragment, then the query can be evaluated on the single fragment and no communication cost is needed to answering the query. The key issue in local pattern-based fragmentation is how to define the &ldquo;local patterns&rdquo;. Different from the existing methods, we consider the query workload-driven &ldquo;local pattern&rdquo; definition. </span></p><p class="c40"><span class="c2">1.1 Why Query Workload Matters ? </span></p><p class="c92"><span class="c6">The workload-driven distributed data fragmentation has been well studied in relational databases [18]. However, few RDF data frag- mentation proposals consider the query workload except for [8, 6]. We will review these related papers in Section 9. Here, we discuss why the query workloads is important for RDF data fragmentation. We study one real SPAQRL query workload, the DBpedia query workload, which records 8,151,238 SPARQL queries issued in 14 days of 2012</span><span class="c14">1</span><span class="c6">. For this workload, if we set the minimum support threshold as 0.1% of the total number of queries, we mine 163 fre- quent subgraph patterns. The most surprising is that 97% query graphs are isomorphic to one of the 163 frequent subgraph pat- </span></p><p class="c79"><span class="c9">1</span><span class="c0">http://aksw.org/Projects/DBPSB.html </span></p><p class="c43"><span class="c42">Series ISSN: 2367-2005 377 </span><span class="c101">10.5441/002/edbt.2016.35 </span></p><p class="c4"><span class="c11">Religion </span></p><p class="c4"><span class="c11">mainInterest </span></p><p class="c4"><span class="c11">Italy </span></p><p class="c4"><span class="c11">&quot;Boethius&quot; 341 00name </span></p><p class="c4"><span class="c16">postalCode </span></p><p class="c4"><span class="c11">influencedBy </span></p><p class="c4"><span class="c11">Aristotle </span></p><p class="c4"><span class="c11">Plato </span></p><p class="c4"><span class="c11">Chalkida .JPG </span></p><p class="c4"><span class="c11">imageSkyline 27100Boethius </span></p><p class="c4"><span class="c11">Chalcis </span></p><p class="c4"><span class="c11">country Greece </span><span class="c16">postalCode </span></p><p class="c4"><span class="c11">placeOfDeath </span></p><p class="c4"><span class="c11">Pavia </span></p><p class="c4"><span class="c11">viaf country </span></p><p class="c4"><span class="c11">placeOfDeath </span></p><p class="c4"><span class="c11">Template:Planetmath </span></p><p class="c4"><span class="c11">wikiPageUsesTemplate </span></p><p class="c4"><span class="c29">100218964 </span></p><p class="c4"><span class="c11">name </span></p><p class="c4"><span class="c29">mainInterest </span><span class="c11">Ethics 99401</span><span class="c61">&ndash;</span><span class="c11">99441 </span></p><p class="c4"><span class="c11">postalCode </span></p><p class="c4"><span class="c11">influencedBy</span><span class="c16">influencedBy </span><span class="c11">&quot;Aristotle&quot; </span></p><p class="c4"><span class="c11">&quot;Friedrich Nietzsche&quot; </span></p><p class="c34"><span class="c11">Weimar.svg Wappen </span></p><p class="c4"><span class="c11">wappen </span></p><p class="c4"><span class="c11">country </span></p><p class="c4"><span class="c11">Weimar Ethics </span><span class="c16">placeOfDeath</span><span class="c29">mainInterest </span></p><p class="c4"><span class="c11">Friedrich_Nietzsche influencedBy name </span></p><p class="c4"><span class="c29">Social_theory </span></p><p class="c4"><span class="c29">Germany </span></p><p class="c4"><span class="c11">Karl_Marx country </span></p><p class="c4"><span class="c16">influencedBy </span></p><p class="c4"><span class="c29">placeOfDeath </span><span class="c16">Max_Horkheimer </span></p><p class="c4"><span class="c11">name &quot;Max Horkheimer&quot; postalCodeNurembergCounter-Enlightenment 90000-90491 </span></p><p class="c4"><span class="c11">Template:Persondata </span></p><p class="c4"><span class="c6">Figure 1: Example RDF Graph </span></p><p class="c4"><span class="c6">Figure 2: Example SPARQL Query Graphs </span></p><p class="c7"><span class="c6">terns. Thus, if we use these frequent subgraph patterns as the basic fragmentation units, 97% SPARQL queries do not lead to commu- nication cost, since their matches are resident at one fragment. </span></p><p class="c4"><span class="c2">1.2 Our Solution </span></p><p class="c4"><span class="c6">According to the above motivation, we propose a workload-driven data fragmentation for distributed RDF graph systems. Specifi- cally, we first mine frequent subgraph patterns, named frequent ac- cess patterns, in the query workload. We treat these frequent access patterns as the implicit schemas for the underlying RDF data. Then, we propose two fragmentation strategies based on these implicit schemas. We study the following technical issues in this paper. </span></p><p class="c7"><span class="c6">Frequent Access Pattern Selection. Given a frequent access pat- tern, we build a fragment by collecting all its matches in the RDF graph. In this way, we can reduce the communication cost (i.e., improve query performance) if a SPARQL query satisfies the fre- quent access pattern. However, if we simply select all frequent access patterns as the implicit schemas, it may lead to expensive space cost due to the data replication, since different frequent ac- cess patterns may involve share the same edges. In other words, we have a tradeoff between performance gain and space cost during se- lecting frequent access patterns. We formalize the frequent access pattern selection problem (Section 4.1) and prove that it is a NP- hard problem (Theorem 1). Thus, we propose a heuristic algorithm which can guarantee the data integrity and the approximation ratio (Theorem 2). This algorithm also achieves the good performance (See experiments in Section 8). </span></p><p class="c4"><span class="c6">Vertical and Horizontal Fragmentation. Based on the selected frequent access patterns (i.e., implicit schemas), we design two </span></p><p class="c4"><span class="c11">mainInterest </span></p><p class="c4"><span class="c11">mainInterest wikiPageUsesTemplate </span></p><p class="c7"><span class="c6">fragmentation strategies, i.e, vertical and horizontal fragmentation. These two fragmentation strategies are adaptive to different query processing objectives. The objective of vertical fragmentation strat- egy is to improve the query throughout, and requires that all struc- tures involved by one frequent access pattern should be placed to the same fragment. Instead, the horizontal fragmentation strategy distributes the structures involved by one frequent access pattern among different fragments to maximize the parallelism of query evaluation, namely, reducing the query response time for a single query. To perform the horizontal fragmentation over RDF graphs, we extend the concept of &ldquo;minterm predicate&rdquo; in [18] to &ldquo;structural minterm predicate&rdquo; (see Section 5.2), which consider the structures of both RDF graphs and workloads. Different applications have different requirements, so we provide customizable options that can be used for different RDF graphs and SPARQL query workloads. </span></p><p class="c7"><span class="c6">Query Decomposition. As we know, the query decomposition always depends on the fragmentation. In traditional vertical and horizontal fragmentation in RDBMS and XML, the query decom- position is unique, since there is no overlap between different frag- ments. As mentioned before, there are some data replications in our fragmentation strategies for RDF graphs. Thus, we may have multiple decomposition results for a query. A cost model driven selection is proposed in this paper. </span></p><p class="c4"><span class="c6">The contributions of this paper can be summarized as follows: </span></p><p class="c7"><span class="c6">&bull; We analyze the characteristics of the real SPARQL query workload and use the intrinsic similarities of queries in the workload to mine and select some frequent access patterns for distributed RDF data design. Although we prove that the problem of frequent access pattern selection is NP-hard, we propose a heuristic method to achieve the good performance. </span></p><p class="c7"><span class="c6">&bull; Based on the above scheme, we propose two fragmentation strategies, vertical and horizontal fragmentation, to divide the RDF graph into many fragments and a cost-aware allo- cation algorithm to distribute fragments among sites. The two fragmentation strategies provide customizable options that are adaptive to different applications. </span></p><p class="c7"><span class="c6">&bull; We propose a cost-aware query optimization method to de- compose a SPARQL query and generate a distributed exe- cution plan. With the decomposition results and execution plan, we can efficiently evaluate the SPARQL query. </span></p><p class="c4"><span class="c6">&bull; We do experiments over both real and synthetic RDF datasets and SPARQL query workloads to verify our methods. </span></p><p class="c4"><span class="c2">2. PRELIMINARIES </span></p><p class="c4"><span class="c6">In this section, we review the terminologies used in this paper and formally define the problem to be addressed. </span><span class="c2">2.1 RDF and SPARQL </span></p><p class="c4"><span class="c6">RDF data can be represented as a graph according to the follow- ing definition. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">1. (RDF Graph) An RDF graph is denoted asG = {V(G), E(G), L}, where (1) V(G) is a set of vertices that correspond to all subjects and objects in RDF data; (2) E(G) &sube; V(G)&times;V(G) is a set of directed edges that correspond to all triples in RDF data; and (3) L is a set of edge labels. For each edge e &isin; E(G), its edge label is its corresponding property. </span></p><p class="c7"><span class="c6">Similarly, a SPARQL query can also be represented as a query graph Q. For simplicity, we ignore FILTER statements in SPARQL syntax in this paper. </span></p><p class="c4"><span class="c42">378 </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">2. (SPARQL Query) A SPARQL query is denoted as Q = {V(Q), E(Q), L }, where (1) V(Q) &sube; V(G) &cup; V</span><span class="c10">Var </span><span class="c0">is a set </span><span class="c6">of vertices, where V(G) denotes vertices in RDF graph G and V</span><span class="c10">Var </span><span class="c0">is a set of variables; (2) E(Q) &sube; V(Q) &times; V(Q) is a set of edges in </span><span class="c6">Q; and (3) L is also a set of edge labels, and each edge e in E(Q) either has an edge label in L (i.e., property) or the edge label is a variable. </span></p><p class="c4"><span class="c6">In this paper, we assume that Q is a connected graph; otherwise, all connected components of Q are considered separately. Given a SPARQL query Q over RDF graph G, a SPARQL match is a subgraph of G that is homomorphic to Q [31]. Thus, answering a SPARQL query is equivalent to finding all subgraph matches of Q over RDF graph G. The set of all matches for Q over G is denoted as Q </span><span class="c10">G </span><span class="c0">In this work, we study a query workload-driven fragmentation. </span><span class="c6">A query workload Q = {Q</span><span class="c10">1</span><span class="c0">, Q</span><span class="c10">2</span><span class="c0">, ..., Q</span><span class="c10">q</span><span class="c0">} is a set of queries that users </span><span class="c6">input in a given period. </span><span class="c2">2.2 Fragmentation </span><span class="c6">&amp; </span><span class="c2">Allocation </span></p><p class="c7"><span class="c6">In this paper, we study an efficient distributed SPARQL query engine. There are many issues related to distributed database sys- tem design, but, the focus of this work is &ldquo;data fragmentation and allocation&rdquo; for RDF repository. We formalize two important prob- lems as follows. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">3. (Fragmentation) Given an RDF graph G, a fragmentation F of G is a set of graphs F = {F</span><span class="c10">1</span><span class="c0">, ..., F</span><span class="c10">n</span><span class="c0">} such that: </span><span class="c6">(1) each F</span><span class="c10">i </span><span class="c6">is a subgraph of G and called as a fragment of RDF graph G; (2) E(F</span><span class="c10">1</span><span class="c0">) &cup; ... &cup; E(F</span><span class="c10">n</span><span class="c0">) = E(G); and (3) V(F</span><span class="c10">1</span><span class="c0">) &cup; ... &cup; </span><span class="c6">V(F</span><span class="c10">n</span><span class="c0">) = V(G), where E(F</span><span class="c10">i</span><span class="c0">) and V(F</span><span class="c10">i</span><span class="c0">) denote the edges and ver- </span><span class="c6">tices in F</span><span class="c10">i </span><span class="c0">(i = 1, ..,n). </span></p><p class="c7"><span class="c6">In our work, we allow the overlaps between different fragments. Given a fragmentation F , the next issue is how to distribute these fragments among different sites (i.e., computing nodes). This is called allocation. </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">4. (Allocation) Given a fragmentationF = {F</span><span class="c10">1</span><span class="c0">, ..., </span><span class="c6">F</span><span class="c10">n</span><span class="c0">} over an RDF graph G and a set of sites S = {S </span><span class="c10">1</span><span class="c0">, S </span><span class="c10">2</span><span class="c0">, ..., S </span><span class="c10">m</span><span class="c0">} </span><span class="c6">(usually m &lt; n), an allocation A = {A</span><span class="c10">1</span><span class="c0">, ..., A</span><span class="c10">m</span><span class="c0">} of fragments in F </span><span class="c6">to S is a partitioning of F such that (1) A</span><span class="c10">j </span><span class="c0">&sube; F , where 1 &le; j &le; m; </span><span class="c6">(2) A</span><span class="c10">j</span><span class="c23">1 </span><span class="c6">&cap; A</span><span class="c10">j</span><span class="c23">2 </span><span class="c6">= &empty;, where 1 &le; j</span><span class="c10">1 </span><span class="c0">j</span><span class="c10">2 </span><span class="c0">&le; m; (3) A</span><span class="c10">1 </span><span class="c0">&cup; ... &cup; A</span><span class="c10">m </span><span class="c0">= F ; </span><span class="c6">and (4) All fragments in A</span><span class="c10">j </span><span class="c0">are stored at site S </span><span class="c10">j</span><span class="c0">, where 1 &le; j &le; m. </span></p><p class="c7"><span class="c6">Given an RDF graph G, a query workload Q and a distributed system consisting of sites S, the goal of this paper is to first de- compose G into a fragmentation F and then finding the allocation A of F to S. </span></p><p class="c4"><span class="c2">3. OVERVIEW </span></p><p class="c7"><span class="c6">This paper studies a SPARQL query workload-driven data frag- mentation and allocation problem. Some observations on the real query workload tell us that some RDF properties have few ac- cess frequencies. For example, few users input queries contain the properties like imageS kyline and wikiPageUsesTemplate in Fig- ure 1. As well, the classical distributed database design suggests a &ldquo;80/20&rdquo; rule, meaning the active &ldquo;20%&rdquo; of query patterns account for &ldquo;80%&rdquo; of the total query input [24]. Therefore, we divide the whole RDF repository into two parts: &ldquo;hot graph&rdquo; and &ldquo;cold graph&rdquo; as follows. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">5. (Infrequent and Frequent Property) Given a query workload Q = {Q</span><span class="c10">1</span><span class="c0">, ...Q</span><span class="c10">n</span><span class="c0">}, if a property p occurs in less than </span><span class="c6">&theta; queries in Q, where &theta; is an user specified parameter, p is an infrequent property; otherwise, p is a frequent property. </span></p><p class="c4"><span class="c61">Site Site Site Site </span></p><p class="c4"><span class="c6">Figure 3: System Architecture </span></p><p class="c4"><span class="c0">&minus;&minus;&rarr;u</span><span class="c10">i</span><span class="c0">u</span><span class="c6">D</span><span class="c26">EFINITION </span><span class="c10">j </span><span class="c6">6. (Hot </span><span class="c0">&isin; E(G) with property </span><span class="c6">and Cold Graphs) Given an edge e </span><span class="c0">p, if property p is a frequent property, </span><span class="c6">= </span><span class="c0">e </span><span class="c6">is a hot edge; otherwise, e is a cold edge. </span></p><p class="c7"><span class="c6">Given an RDF graph G, it is divided into two parts: hot graph H and cold graph C, where H consists of all hot edges and C consists of all cold edges. </span></p><p class="c7"><span class="c6">The goal of this work is how to partition &ldquo;hot graph&rdquo; to achieve performance improvement. We regard the cold graph as a &ldquo;black block&rdquo;. The cold graph does not overlap to the hot graph, since the cold graph contains different edges with different kinds of proper- ties from the hot graph. Any existing approach can be utilized for the cold graph. We only consider the cold graph in the SPARQL query processing (Section 7), since some queries may involve &ldquo;in- frequent&rdquo; properties. Moreover, both the cold graph and the hot graph may be disconnected. </span></p><p class="c7"><span class="c6">Figure 3 illustrates our system architecture. In the offline phase, we mine the frequent access patterns (see Section 4) in the work- load. Each frequent access pattern can correspond to one or more fragments. Generating a fragment from all matches of a frequent access pattern make many queries be answered efficiently without cross-fragments joins, while it may also replicate some hot edges and increase the space cost. Thus, we should select an appropriate subset of frequent access patterns to balance the efficiency and the space cost. Since we find out that selecting an appropriate set of patterns is a NP-hard problem (Section 4.1), we propose a heuristic pattern selection solution while guaranteeing both the data integrity and the approximation ratio. Based on these selected frequent ac- cess patterns, we study two different data fragmentation strategies, i.e., vertical and horizontal fragmentation (Section 5). The vertical fragmentation is to improve the query throughput, and the hori- zontal fragmentation is to reduce a single query&rsquo;s response time. Fragments are distributed among different sites. Meanwhile, we maintain the metadata in a data dictionary. </span></p><p class="c7"><span class="c6">In the online phase, we study how to decompose a query into several subqueries on different fragments and generate an efficient execution plan. A cost model for guiding decomposition is pro- posed (Section 7.2). Finally, we execute the plan and return the matches of the query. </span></p><p class="c4"><span class="c2">4. FREQUENT ACCESS PATTERNS </span></p><p class="c38"><span class="c6">As mentioned before, we believe that a query often contains some patterns in the previously issued queries, so we mine some patterns with high access frequencies and use these patterns as the fragmentation units. Then, if a query Q can be decomposed to some subgraphs isomorphic to the frequent access patterns, Q can be answered while avoiding some joins across multiple fragments. Before we mine frequent access patterns, we first normalize the query graphs in the workload to avoid overfitting. For each SPARQL query, we remove all constants (strings and URIs) at subjects and </span></p><p class="c4"><span class="c42">379 </span></p><p class="c4"><span class="c37">Workload </span></p><p class="c4"><span class="c37">Frequent </span></p><p class="c4"><span class="c37">Vertical Fragmentation / Access Pattern </span></p><p class="c4"><span class="c37">Horizontal Fragmentation </span></p><p class="c4"><span class="c26">offline </span></p><p class="c4"><span class="c37">Graph </span></p><p class="c4"><span class="c37">Data Dictionary </span></p><p class="c4"><span class="c26">online </span><span class="c72">Query Query Decomposition </span><span class="c74">...... </span></p><p class="c4"><span class="c37">Execution Plan </span></p><p class="c4"><span class="c37">Matches </span></p><p class="c4"><span class="c26">Server Clients </span></p><p class="c4"><span class="c67">pp</span><span class="c47">1</span><span class="c71">: p</span><span class="c47">2</span><span class="c71">: </span></p><p class="c4"><span class="c9">?x1?c </span></p><p class="c4"><span class="c14">?x1 </span></p><p class="c4"><span class="c10">country </span></p><p class="c4"><span class="c9">postalCode </span></p><p class="c4"><span class="c9">country </span></p><p class="c4"><span class="c9">?n </span></p><p class="c4"><span class="c9">name </span></p><p class="c4"><span class="c47">3</span><span class="c71">: </span></p><p class="c38"><span class="c9">?x2 mainInterest ?x name ?n ?x </span></p><p class="c4"><span class="c9">?y placeOfDeath </span></p><p class="c4"><span class="c9">?x </span></p><p class="c4"><span class="c9">influencedBy </span></p><p class="c4"><span class="c9">?x1 </span></p><p class="c4"><span class="c6">Figure 4: Example Frequent Access Patterns </span></p><p class="c7"><span class="c6">objects and replace them with variables. The FILTER expressions are also removed. By doing this, we extract a general representa- tion of a SPARQL query from the workload. Figure 4 shows the generalized query graphs of query graphs in Figure 2. We assume that the generalized query in Figure 4 graphs are also frequent ac- cess patterns. </span></p><p class="c7"><span class="c6">To mine patterns with high access frequencies, we need to first count the number of queries in the workload where a pattern p is a subgraph. We define the frequent access pattern usage value to record the access frequencies of the frequent access patterns. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">7. (Frequent Access Pattern Usage Value) Given a SPARQL query Q and a frequent access pattern p, we associate a frequent access pattern usage value, denoted as use(Q, p), and defined as follows: </span></p><p class="c4"><span class="c6">use(Q, p) = </span></p><p class="c4"><span class="c6">{ </span><span class="c0">1 if pattern p is a subgraph of Q </span><span class="c6">0 otherwise </span></p><p class="c7"><span class="c6">Then, given a workload Q = {Q</span><span class="c10">1</span><span class="c0">, Q</span><span class="c10">2</span><span class="c0">, ..., Q</span><span class="c10">q</span><span class="c0">} and a pattern p, we </span><span class="c6">define the access frequency, acc(p), as the number of queries in Q where a pattern p is a subgraph. </span></p><p class="c4"><span class="c0">&sum;</span><span class="c9">q</span><span class="c6">acc(p) = </span></p><p class="c4"><span class="c10">k=1 </span></p><p class="c4"><span class="c6">use(Q</span><span class="c10">k</span><span class="c0">, p) </span></p><p class="c4"><span class="c6">A pattern p is frequent access pattern if its access frequency is no less than a threshold, minSup. </span></p><p class="c4"><span class="c6">The frequent access patterns can be easily generated by exist- ing frequent graph mining algorithms [17]. Given a workload of SPARQL queries Q = {Q</span><span class="c10">1</span><span class="c0">, Q</span><span class="c10">2</span><span class="c0">, ..., Q</span><span class="c10">q</span><span class="c0">} in a given period, we denote </span><span class="c6">the set of frequent access patterns that we find as P = {p</span><span class="c10">1</span><span class="c0">, p</span><span class="c10">2</span><span class="c0">, ..., p</span><span class="c10">x</span><span class="c0">}. </span><span class="c6">In practice, the size of P is often limited. For example, if we set minSup as 0.1% of the total access frequency, there are only 163 frequent access patterns for DBPedia. </span><span class="c2">4.1 Frequent Access Pattern Selection </span></p><p class="c7"><span class="c6">Obviously, it is not necessary to generate fragments from all fre- quent access patterns due to high space cost. For two similar fre- quent access patterns p and p , if they are contained by similar queries of the workload, then selecting both p and p for building fragments will not be able to provide more information than select- ing one of p and p . Hence, it is often sufficient to only select a subset of all frequent access patterns to generate fragments. </span></p><p class="c4"><span class="c6">To select a subset of all frequent access patterns, there are two factors that we should consider. </span></p><p class="c7"><span class="c6">1. (Hitting the Whole Workload) We should select frequent ac- cess patterns to hit the query workload as much as possible. This is because that when we select a frequent access pattern to generate a fragment, all queries isomorphic to this pattern can be answered directly, which improve the efficiency. </span></p><p class="c7"><span class="c6">2. (Satisfying the Storage Constraint) The total storage of the system in real applications is limited, so selecting too many frequent access patterns is not desirable. </span></p><p class="c7"><span class="c6">The above two factors contradict each other. Hitting the whole workload requires to select as many frequent access patterns as pos- sible, while the storage constraint requires to select not too many frequent access patterns. There should be a tradeoff between the two factors. </span></p><p class="c4"><span class="c6">In the following, we propose a cost model to combine these two factors for selecting a subset of all frequent access patterns. </span></p><p class="c4"><span class="c30">4.1.1 Hitting the Whole Workload </span></p><p class="c7"><span class="c6">If a fragment is generated from the graph induced by matches of a frequent access pattern, then evaluating all queries containing the pattern can be speeded up by using this fragment. The more queries a frequent access pattern hits, the more gains we obtain during query processing. Therefore, the benefit of selecting a fre- quent access pattern to generate its corresponding fragment should be defined based on the number of queries that the frequent access pattern hits. </span></p><p class="c7"><span class="c6">In addition, if two similar frequent access patterns are contained by the same set of queries in the workload, it is probably wise to include only one of them. Generally speaking, among similar fre- quent access patterns contained by the same number of queries, it is often sufficient to materialize only the largest frequent access pat- tern. That is to say, if p , a subgraph of p, is contained by the same set of queries as p, p is more beneficial than p to be selected as building fragments. This is because that if we select the larger pat- tern, a query is more probable to be decomposed to fewer number of subqueries during query processing. Fewer subqueries can avoid some distributed joins, which can improve the efficiency of query processing. </span></p><p class="c7"><span class="c6">The above observation implies that larger frequent access pat- terns are more beneficial to be selected as building fragments. This above criterion on the selection of frequent access patterns is for- mally defined as size-increasing benefit. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">8. (Size-increasing Benefit) Given a frequent ac- cess pattern p, the benefit of selecting p for hitting the query Q, Bene f it(p, Q), is denoted as follows. </span></p><p class="c4"><span class="c6">Bene f it(p, Q) = |E(p)| &times; use(Q, p) </span></p><p class="c7"><span class="c6">Furthermore, a query in the workload may contain multiple se- lected frequent access patterns. This means that the query can be decomposed into multiple sets of subqueries if we evaluate the query. Each set of subqueries can map to an execution plan. Since only one execution plan is finally selected to evaluate the query, a query in the workload should only be limited to contribute to the benefits of some particular frequent access patterns once. Based on this observation, we limit a query to only contribute the largest frequent access pattern that the query contains. </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">9. (Benefit of a Frequent Access Pattern Set) Given a set of frequent access patterns P &sube; P, the benefit of selection of P over the workload Q is the sum of the maximum benefit of its frequent access patterns over Q. </span></p><p class="c4"><span class="c6">Bene f it(P , Q) = </span><span class="c28">&sum;</span><span class="c9">Q&isin;Q</span><span class="c28">max </span><span class="c9">p&isin;P </span><span class="c28">{Bene f it(p, Q)} </span></p><p class="c4"><span class="c30">4.1.2 Satisfying the Storage Constraint </span></p><p class="c7"><span class="c6">Furthermore, the total storage of the system in real applications is limited, so selecting too many frequent access patterns is not desirable. The selection of frequent access patterns should meet some constraints. When the size of all fragments is larger than the storage constraint, we cannot further select any more frequent </span></p><p class="c4"><span class="c42">380 </span></p><p class="c4"><span class="c6">access patterns. We normalize the storage capacity of the system to a value SC. Then, we have </span><span class="c0">&sum;</span><span class="c6">the constraint as: </span><span class="c10">p&isin;P </span></p><p class="c4"><span class="c6">|E( p </span><span class="c10">G</span><span class="c0">)| &le; SC </span></p><p class="c7"><span class="c6">Here, we assume that SC is larger than the number of edges in the hot graph, so each hot edge can have at least one copy. This assumption guarantees the completeness of the RDF graph. </span></p><p class="c4"><span class="c30">4.1.3 Combining the Two Factors </span></p><p class="c7"><span class="c6">Then, our optimization objective is to maximize the benefit sub- ject to the storage constraint. We can prove that this benefit function (Definition 9) is submodular as follows, so this problem is NP-hard. </span></p><p class="c4"><span class="c6">T</span><span class="c26">HEOREM </span><span class="c6">1. Finding a set of frequent access patterns with the largest benefit while subject to the storage constraint is NP-hard. </span></p><p class="c4"><span class="c0">&sum;</span><span class="c6">for </span><span class="c10">Q&isin;Q </span><span class="c6">P</span><span class="c26">ROOF</span><span class="c6">. every maxP</span><span class="c10">p&isin;P 1 </span><span class="c6">Here, </span><span class="c0">&sube; {|E(p)| P</span><span class="c10">2 </span><span class="c6">we </span><span class="c0">and &times; </span><span class="c6">prove </span><span class="c0">a use(Q, frequent </span><span class="c6">that </span><span class="c0">p)} </span><span class="c6">the </span><span class="c0">access is </span><span class="c6">benefit </span><span class="c0">submodular. pattern </span><span class="c6">function </span><span class="c0">p </span><span class="c6">Bene f it(P , Q) = </span><span class="c0">In other words, </span></p><p class="c4"><span class="c0">P</span><span class="c10">2</span><span class="c0">, we need to </span><span class="c6">prove that &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">1</span><span class="c0">) &ge; &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">2</span><span class="c0">). </span></p><p class="c7"><span class="c6">For pattern p, we assume that Q is the set of queries containing p in the workload. There are three kinds of queries in Q : the set Q</span><span class="c10">1 </span><span class="c0">of queries not containing any patterns in P</span><span class="c10">2</span><span class="c6">, the set Q</span><span class="c10">2 </span><span class="c6">of queries containing patterns in (P</span><span class="c10">2 </span><span class="c0">&minus; P</span><span class="c10">1</span><span class="c0">), and the set Q</span><span class="c10">3 </span><span class="c0">of queries only </span><span class="c6">containing patterns in P</span><span class="c10">1</span><span class="c0">. </span></p><p class="c38"><span class="c6">Since any query in Q</span><span class="c10">1 </span><span class="c0">and Q</span><span class="c10">3 </span><span class="c0">does not concern patterns in (P</span><span class="c10">2 </span><span class="c0">&minus; </span><span class="c6">P</span><span class="c10">1</span><span class="c0">), Bene f it({p}&cup;P</span><span class="c10">1</span><span class="c0">,Q</span><span class="c10">1</span><span class="c0">&cup;Q</span><span class="c10">3</span><span class="c0">) = Bene f it({p}&cup;P</span><span class="c10">2</span><span class="c0">,Q</span><span class="c10">1</span><span class="c0">&cup;Q</span><span class="c10">3</span><span class="c0">). Hence, </span><span class="c6">the marginal gains of p for P</span><span class="c10">1 </span><span class="c0">and P</span><span class="c10">2 </span><span class="c0">over Q</span><span class="c10">1 </span><span class="c0">and Q</span><span class="c10">3 </span><span class="c0">are the same. </span><span class="c6">For query QQ</span><span class="c14">&lowast; </span><span class="c10">2</span><span class="c0">, </span><span class="c6">meeting </span><span class="c0">&#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c6">all </span><span class="c10">1</span><span class="c0">) &gt; &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">2</span><span class="c0">), if there exist at least one </span><span class="c6">the two following conditions: 1) the largest pattern contained by Q</span><span class="c14">&lowast; </span><span class="c6">over P</span><span class="c10">2 </span><span class="c0">is in (P</span><span class="c10">2 </span><span class="c0">&minus; P</span><span class="c10">1</span><span class="c0">) and has larger size </span><span class="c6">than p; 2) the largest pattern contained by Q</span><span class="c14">&lowast; </span><span class="c6">over P</span><span class="c10">1 </span><span class="c0">has smaller </span><span class="c6">size than p. The above two conditions mean that p can only in- crease the benefit of P</span><span class="c10">1 </span><span class="c0">over Q</span><span class="c10">2 </span><span class="c0">but not the benefit of P</span><span class="c10">2 </span><span class="c0">over Q</span><span class="c10">2</span><span class="c0">. </span><span class="c6">Otherwise, for Q</span><span class="c10">2</span><span class="c0">, &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">1</span><span class="c0">) = &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">2</span><span class="c0">). </span></p><p class="c7"><span class="c6">In conclusion, &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">1</span><span class="c0">) &ge; &#9651;</span><span class="c10">Bene f it</span><span class="c0">(p|P</span><span class="c10">2</span><span class="c0">) and the function </span><span class="c6">Bene f it(P ,Q) is submodular. Since the problem of maximizing submodular functions is NP-hard [3], the problem is NP-hard. </span></p><p class="c4"><span class="c30">4.1.4 Our Solution </span></p><p class="c7"><span class="c6">As proved in Theorem 1, frequent access pattern selection is NP- complete problem. We propose a greedy algorithm as outlined in Algorithm 1. Note that, to guarantee data integrity of distributed RDF data fragmentation, each hot edge should be contained in at least one fragment. Hence, we initialize a pattern of one edge for each frequent property and compute out its corresponding fragment (Line 3-6). </span></p><p class="c7"><span class="c6">After we select all patterns with one edge, we enumerate all fea- sible frequent access pattern sets containing one pattern of more than one edge. Let P</span><span class="c10">1 </span><span class="c0">be a feasible set of cardinality one that </span><span class="c6">has the largest benefit (Line 7). Then, we iteratively select one of the remaining frequent access patterns p to maximize the value of </span><span class="c14">Bene f it({p </span><span class="c6">cannot find </span><span class="c14">}&cup;P ,Q)&minus;Bene </span><span class="c9">|E( </span><span class="c6">a frequent </span><span class="c9">p </span><span class="c23">G</span><span class="c9">)| </span><span class="c14">f it(P ,Q) </span></p><p class="c38"><span class="c28">until we meet the storage constraint or </span><span class="c6">access pattern to increase the benefit (Line 8- 14). Let P</span><span class="c10">2 </span><span class="c6">be the solution obtained in the iterative phase. Finally, the algorithm outputs P &cup;P</span><span class="c10">1 </span><span class="c0">if Bene f it(P &cup;P</span><span class="c10">1</span><span class="c0">, Q) &ge; Bene f it(P &cup; </span><span class="c6">P</span><span class="c10">2</span><span class="c0">,Q) and P &cup; P</span><span class="c10">2 </span><span class="c0">otherwise (Line 15-17). </span></p><p class="c4"><span class="c6">T</span><span class="c26">HEOREM </span><span class="c6">2. Algorithm 1 obtains a set of frequent access pat- terns of benefit at of an optimal solution. </span></p><p class="c4"><span class="c6">least min{ </span><span class="c9">(max</span><span class="c23">p&isin;P </span><span class="c14">1 </span></p><p class="c4"><span class="c9">|E(p)|)</span><span class="c28">, </span><span class="c14">1</span><span class="c9">2</span><span class="c28">(1 &minus; </span><span class="c14">1</span><span class="c9">e</span><span class="c28">)} times the value </span></p><p class="c4"><span class="c6">P</span><span class="c26">ROOF</span><span class="c6">. There are two parts in Algorithm 1: initialization and greedy selection of frequent access patterns. </span></p><p class="c4"><span class="c6">Algorithm 1: Frequent Access Pattern Selection Algorithm </span></p><p class="c4"><span class="c5">Input: A set of frequent access patterns P = {p</span><span class="c10">1</span><span class="c5">, p</span><span class="c10">2</span><span class="c5">, ..., p</span><span class="c10">x</span><span class="c5">} Output: A set P &sube; P to generate fragments </span><span class="c3">1 </span><span class="c5">P &larr; &empty;; </span><span class="c3">2 </span><span class="c5">T otalS ize &larr; 0; </span><span class="c3">3 </span><span class="c5">for each p &isin; P and p has only one edge do </span><span class="c3">4 </span><span class="c5">P &larr; P &cup; {p}; </span><span class="c3">5 </span><span class="c5">P &larr; P &minus; {p}; </span><span class="c3">6 </span><span class="c5">T otalS ize &larr; T otalS ize + |E( p </span><span class="c10">G</span><span class="c17">)|; </span><span class="c3">7 </span><span class="c5">P</span><span class="c10">1 </span><span class="c5">&larr; argmax{ </span><span class="c14">Bene f it({p</span><span class="c22">i</span><span class="c14">},Q) </span></p><p class="c4"><span class="c9">|E( p</span><span class="c23">i G</span><span class="c9">)| </span><span class="c31">: p</span><span class="c9">i </span><span class="c31">&isin; P, |E( p</span><span class="c9">i G</span><span class="c31">)| + T otalS ize &le; </span><span class="c5">SC &and; |E(p</span><span class="c10">i</span><span class="c17">)| &gt; 1}; </span><span class="c3">8 </span><span class="c5">P</span><span class="c10">2 </span><span class="c17">&larr; &empty;; </span><span class="c3">9 </span><span class="c5">T otalS ize &larr; 0; </span><span class="c3">10 </span><span class="c5">while T otalS ize &le; SC &minus; T otalS ize do </span><span class="c3">11 </span><span class="c5">Find the frequent access pattern p &isin; P &minus; P with the largest </span></p><p class="c4"><span class="c5">additional value of </span><span class="c14">Bene f it({p }&cup;P ,Q)&minus;Bene f it(P ,Q) </span></p><p class="c4"><span class="c9">|E( p </span><span class="c23">G</span><span class="c10">)| </span><span class="c5">; </span><span class="c3">12 </span><span class="c5">P</span><span class="c10">2 </span><span class="c17">&larr; P</span><span class="c10">2 </span><span class="c17">&cup; {p }; </span><span class="c3">13 </span><span class="c5">P &larr; P &minus; {p }; </span><span class="c3">14 </span><span class="c5">T otalS ize &larr; T otalS ize + |E( p </span><span class="c10">G</span><span class="c5">)|; </span><span class="c3">15 </span><span class="c5">if Bene f it(P &cup; P</span><span class="c10">1</span><span class="c17">, Q) &ge; Bene f it(P &cup; P</span><span class="c10">2</span><span class="c17">,Q) then </span><span class="c3">16 </span><span class="c5">Return P &cup; P</span><span class="c10">1</span><span class="c5">; </span><span class="c3">17 </span><span class="c5">Return P &cup; P</span><span class="c10">2</span><span class="c17">; </span></p><p class="c4"><span class="c6">For initialization (Line 3-6 in Algorithm 1), all selected patterns only contain one edge, so |E(p)| = 1. Therefore, the benefit of pat- terns only having one edge of a frequent property is</span><span class="c28">&sum;</span><span class="c9">Q&isin;Q </span><span class="c28">max</span><span class="c9">p&isin;P </span><span class="c6">{1&times; use(Q, p)}. Since the hot edges hit almost all queries in the work- load, </span><span class="c28">&sum;</span><span class="c9">Q&isin;Q </span><span class="c28">max</span><span class="c9">p&isin;P </span><span class="c6">{1&times;use(Q, p)} is approximately equal to the size of the workload, |Q|. On the other hand, in the worst case, the op- timal solution is that all queries in the workload contain the largest frequent access pattern. Then, the benefit of the optimal solution is </span><span class="c28">&sum;</span><span class="c9">Q&isin;Q</span><span class="c28">{|E(p</span><span class="c9">max</span><span class="c6">)| &times; use(Q, p)}, where p</span><span class="c10">max </span><span class="c0">is the frequent pattern </span><span class="c6">with the largest size. Hence, the benefit of the selected patterns in the initial phase is at least </span><span class="c14">1 </span></p><p class="c4"><span class="c9">(max</span><span class="c23">p&isin;P </span><span class="c9">|E(p)|) </span><span class="c28">of the optimal benefit. </span><span class="c6">For the phase of greedily selecting frequent access patterns (Line 7-14 in Algorithm 1), since the problem of selecting the optimal set of frequent access patterns is a problem of maximizing a submod- ular set function subject to a knapsack constraint as discussed in Theorem 1, we directly apply the greedy algorithm in [11] to iter- atively select frequent access patterns. [11] proves that the worst- case performance guarantee of the greedy algorithm is </span><span class="c14">1</span><span class="c9">2</span><span class="c28">(1&minus; </span><span class="c14">1</span><span class="c9">e</span><span class="c28">), so </span><span class="c6">the benefit of the selected patterns in this phase is at least </span><span class="c14">1</span><span class="c9">2</span><span class="c28">(1 &minus; </span><span class="c14">1</span><span class="c9">e</span><span class="c28">) </span><span class="c6">of the optimal benefit. </span></p><p class="c4"><span class="c6">In summary, the final performance guarantee of our algorithm is min{ </span><span class="c14">1 </span></p><p class="c4"><span class="c9">(max</span><span class="c23">p&isin;P </span><span class="c10">|E(p)|)</span><span class="c6">, </span><span class="c14">1</span><span class="c9">2</span><span class="c28">(1 &minus; </span><span class="c14">1</span><span class="c9">e</span><span class="c28">)}. </span></p><p class="c4"><span class="c2">5. FRAGMENTATION </span></p><p class="c4"><span class="c6">In this section, we present two fragmentation strategies: vertical and horizontal. </span></p><p class="c4"><span class="c2">5.1 Vertical Fragmentation </span></p><p class="c7"><span class="c6">For vertical fragmentation, we put matches homomorphic to the same frequent access pattern into the same fragment. Because a query graph often only contains a few frequent access patterns and matches of one frequent access pattern are put together, other ir- relevant fragments can be filtered out during query evaluation and only sites stored relevant fragments need to be accessed to find matches. Filtering out irrelevant fragments can improve the query performance. Furthermore, sites not storing relevant fragments can be used to evaluate other queries in parallel, which improves the total throughput of the system. In summary, the vertical fragmen- tation strategy utilizes the locality of SPARQL queries to improve </span></p><p class="c4"><span class="c42">381 </span></p><p class="c4"><span class="c6">E</span><span class="c26">XAMPLE </span><span class="c6">both query response time and throughput. Experimental results in </span></p><p class="c4"><span class="c6">2. Let us consider the query graph Q</span><span class="c10">3 </span><span class="c0">in Figure </span><span class="c6">Section 8 also confirm the above argument. </span></p><p class="c4"><span class="c6">2 and its corresponding frequent access pattern p</span><span class="c10">3 </span><span class="c0">in Figure 4. </span><span class="c6">Given a frequent access pattern p, it can then be transformed </span></p><p class="c4"><span class="c6">We can generate four structural simple predicates: (1). sp</span><span class="c10">1 </span><span class="c0">: </span><span class="c6">into a SPARQL query, resulting in a vertical fragment of the RDF </span></p><p class="c4"><span class="c6">p</span><span class="c10">3</span><span class="c0">(?x1) = Aristotle; (2). sp</span><span class="c10">2 </span><span class="c0">: p</span><span class="c10">3</span><span class="c0">(?x1) Aristotle; (3). sp</span><span class="c10">3 </span><span class="c0">: </span><span class="c6">graph. We use the results p </span><span class="c10">G </span><span class="c0">of a selection operation based on </span></p><p class="c4"><span class="c6">p</span><span class="c10">3</span><span class="c0">(?x2) = Ethics; (4). sp</span><span class="c10">4 </span><span class="c0">: p</span><span class="c10">3</span><span class="c0">(?x2) Ethics. </span><span class="c6">p to generate a vertical fragment. All vertical fragments generated from our selected frequent access patterns construct a vertical frag- mentation. Given a set of frequent access patterns P, we formally define its corresponding vertical fragmentation over an RDF graph G as follows. </span></p><p class="c38"><span class="c6">Then, we define the structural minterm predicate as the conjunc- tion of structural simple predicates of the same frequent access pat- tern. We can obtain all structural minterm predicates by enumerat- ing all possible combinations of structural simple predicates. Given a set of structural simple predicates SP = {sp</span><span class="c10">1</span><span class="c0">, sp</span><span class="c10">2</span><span class="c0">, ..., , sp</span><span class="c10">y</span><span class="c0">} for </span><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">10. (Vertical Fragmentation) Given an RDF graph </span></p><p class="c4"><span class="c6">frequent access pattern p, the set of structural minterm predicates G and a frequent access pattern p, a vertical fragment F generated </span></p><p class="c4"><span class="c6">M = {mp</span><span class="c10">1</span><span class="c0">,mp</span><span class="c10">2</span><span class="c0">, ...,mp</span><span class="c10">z</span><span class="c0">} for p is defined as follows. </span><span class="c6">from p is defined as F = {V(F), E(F), L }, where (1) V(F) &sube; V(G) is the set of vertices occurring in p </span><span class="c10">G</span><span class="c0">; (2) E(F) &sube; E(G) is the set </span><span class="c6">M = {mp</span><span class="c10">i</span><span class="c6">| of edges occurring in p </span><span class="c10">G</span><span class="c0">; and (3) L &sube; L is the set of edge labels </span></p><p class="c4"><span class="c28">&and; </span></p><p class="c38"><span class="c6">sp</span><span class="c14">&lowast;</span><span class="c9">k</span><span class="c28">, 1 &le; k &le; y} </span><span class="c9">sp</span><span class="c23">k</span><span class="c9">&isin;SP </span><span class="c6">occurring in p </span><span class="c10">G</span><span class="c0">. </span></p><p class="c4"><span class="c6">Then, given a set of frequent access patterns P = {p</span><span class="c10">1</span><span class="c0">, p</span><span class="c10">2</span><span class="c0">, ..., p</span><span class="c10">x</span><span class="c0">}, </span></p><p class="c38"><span class="c6">where cate can spoccur </span><span class="c14">&lowast;</span><span class="c9">k </span><span class="c28">= sp</span><span class="c6">in </span><span class="c9">k </span><span class="c6">a or structural sp</span><span class="c14">&lowast;</span><span class="c9">k </span><span class="c28">= &not;sp</span><span class="c9">k</span><span class="c6">. minterm So each structural simple predi- predicate either in its natural the corresponding vertical fragmentation is F = {F</span><span class="c10">i</span><span class="c0">|0 &le; i &le; x and </span></p><p class="c4"><span class="c6">form or its negated form. F</span><span class="c10">i </span><span class="c0">is the vertical fragment generated from p</span><span class="c10">i</span><span class="c0">.} </span></p><p class="c38"><span class="c6">Similar to the frequent access pattern, we can also define the structural minterm predicate usage value and access frequency to E</span><span class="c26">XAMPLE </span><span class="c6">1. Given the frequent access pattern p</span><span class="c10">3 </span><span class="c0">in Figure 4, </span></p><p class="c4"><span class="c6">record the access frequency of a structural minterm predicate. We Figure 5 shows the corresponding vertical fragment. </span></p><p class="c4"><span class="c6">can prune the minterm predicates with small access frequencies. </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">11. (Structural Minterm Predicate Usage Value) </span></p><p class="c4"><span class="c1">&quot;Boethius&quot; </span></p><p class="c4"><span class="c1">Ethics&quot;Friedrich Nietzsche&quot; </span></p><p class="c4"><span class="c6">Given a SPARQL query Q and a structural minterm predicate mp, </span></p><p class="c4"><span class="c1">name </span></p><p class="c4"><span class="c19">mainInterest </span></p><p class="c4"><span class="c6">we associate a structural minterm predicate usage value, denoted </span></p><p class="c4"><span class="c1">Boethius </span></p><p class="c4"><span class="c1">Religion </span></p><p class="c4"><span class="c1">Aristotle </span></p><p class="c4"><span class="c6">as use(Q,mp), and defined as follows: </span></p><p class="c4"><span class="c1">Max_Horkheimer </span></p><p class="c4"><span class="c6">use(Q,mp) = </span></p><p class="c4"><span class="c6">{</span><span class="c0">1 </span><span class="c6">0 </span><span class="c0">if predicate mp is a subgraph of Q </span><span class="c6">otherwise </span></p><p class="c4"><span class="c1">Ethics </span></p><p class="c4"><span class="c6">Then, given a set of SPARQL queries Q = {Q</span><span class="c10">1</span><span class="c0">, Q</span><span class="c10">2</span><span class="c0">, ..., Q</span><span class="c10">q</span><span class="c0">}, we </span><span class="c6">define the access frequency of a structural minterm predicate mp as </span></p><p class="c4"><span class="c6">Figure 5: Example Vertical Fragment </span></p><p class="c34"><span class="c6">follows. </span><span class="c0">&sum;</span><span class="c9">k=q</span><span class="c2">5.2 Horizontal Fragmentation </span></p><p class="c4"><span class="c6">For horizontal fragmentation, we put matches of one frequent ac- </span></p><p class="c4"><span class="c6">acc(mp) = </span></p><p class="c4"><span class="c10">k=1 </span></p><p class="c7"><span class="c6">cess pattern into the different fragments and distribute them among different sites. Then, a query may involve many fragments and each fragment has a few matches. The size of a fragment is often much smaller than the size of the whole data, so finding matches of a query over a fragment explores smaller search space than finding matches over the whole data. If the fragments involved by a query are allocated to different sites, then each site finds a few matches over some fragments with the smaller size than the whole data. This strategy is to utilize the parallelism of clusters of sites to reduce the query response time. The above argument is also confirmed by the experimental results in Section 8. </span></p><p class="c7"><span class="c6">In this section, we extend the concepts of simple predicate and minterm predicate originally developed for relational systems [18] to divide the RDF graph horizontally. </span></p><p class="c4"><span class="c30">5.2.1 Structural Minterm Predicate </span></p><p class="c7"><span class="c6">First, we define the structural simple predicate. Each structural simple predicate corresponds to a frequent access pattern with a single (in)equality. Given a frequent access pattern p with variables set {var</span><span class="c10">1</span><span class="c0">,var</span><span class="c10">2</span><span class="c0">, ..., var</span><span class="c10">n</span><span class="c0">}, a structural simple predicate sp defined on </span><span class="c6">D has the following form. </span></p><p class="c4"><span class="c6">sp : p(var</span><span class="c10">i</span><span class="c0">) &theta; Value </span></p><p class="c4"><span class="c6">where &theta; &isin; {=, } and Value is a constant constraint for var</span><span class="c10">i </span><span class="c6">chosen from a query containing p in Q. </span></p><p class="c4"><span class="c1">name &quot;Aristotle&quot; </span></p><p class="c4"><span class="c1">Friedrich_Nietzsche </span></p><p class="c4"><span class="c1">Counter-Enlightenment </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">name </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">Plato </span></p><p class="c4"><span class="c1">Karl_Marx </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">&quot;Max name </span></p><p class="c4"><span class="c1">Horkheimer&quot; </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">Social_theory </span></p><p class="c4"><span class="c6">use(Q</span><span class="c10">k</span><span class="c0">,mp) </span></p><p class="c7"><span class="c6">In practice, there may exist many minterm predicates. It is too expensive to enumerate all minterm predicates. Therefore, we prune some minterm predicates with too small access frequencies. </span></p><p class="c7"><span class="c6">Given a structural minterm predicate mp, it can then be trans- formed into SPARQL queries, resulting in a horizontal fragment of the RDF graph. We use the results mp </span><span class="c10">G </span><span class="c0">of a selection opera- </span><span class="c6">tion based on mp to generate a horizontal fragment. All horizontal fragments generated from the structural minterm predicates that we obtain construct a horizontal fragmentation. Given a set of minterm predicates M, we formally define its corresponding horizontal frag- mentation over an RDF graph G as follows. </span></p><p class="c7"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">12. (Horizontal Fragmentation) Given an RDF graph G and a structural minterm predicate mp, a horizontal frag- ment F generated from mp is defined as F = {V(F), E(F), L }, where (1) V(F) &sube; V(G) is the set of vertices occurring in mp </span><span class="c10">G</span><span class="c0">; </span><span class="c6">(2) E(F) &sube; E(G) is the set of edges occurring in mp </span><span class="c10">G</span><span class="c0">; and (3) </span><span class="c6">L &sube; L is the set of edge labels occurring in mp </span><span class="c10">G</span><span class="c0">. </span></p><p class="c4"><span class="c6">Then, given a set of structural minterm predicates M = {mp</span><span class="c10">1</span><span class="c0">, mp</span><span class="c10">2</span><span class="c0">, </span><span class="c6">..., mp</span><span class="c10">y</span><span class="c0">}, the corresponding horizontal fragmentationisF = {F</span><span class="c10">i</span><span class="c0">|0 &le; </span><span class="c6">i &le; y and F</span><span class="c10">i </span><span class="c0">is the vertical horizontal generated from mp</span><span class="c10">i</span><span class="c0">.} </span></p><p class="c7"><span class="c6">E</span><span class="c26">XAMPLE </span><span class="c6">3. Given the structural simple predicates in Exam- ple 2, we can get all structural minterm predicates from frequent access pattern p</span><span class="c10">3 </span><span class="c6">as follows: (1). mp</span><span class="c10">1 </span><span class="c6">: p</span><span class="c10">3</span><span class="c6">(?x0) = Aristotle &and; p</span><span class="c10">3</span><span class="c0">(?x1) = Ethics; (2) mp</span><span class="c10">2 </span><span class="c0">: p</span><span class="c10">3</span><span class="c0">(?x0) = Aristotle &and; p</span><span class="c10">3</span><span class="c0">(?x1) </span></p><p class="c4"><span class="c42">382 </span></p><p class="c4"><span class="c1">Karl_Marx </span></p><p class="c4"><span class="c1">eimer&quot; </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">Counter-Enlightenment </span></p><p class="c4"><span class="c6">(c) Example Horizontal Frag- </span><span class="c0">ment Generated from mp</span><span class="c10">3 </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">heory </span></p><p class="c4"><span class="c6">(d) Example Horizontal Fragment Gen- </span><span class="c0">erated from mp</span><span class="c10">4 </span></p><p class="c4"><span class="c6">Figure 6: Example Horizontal Fragments </span></p><p class="c4"><span class="c6">Ethics; (3). mp</span><span class="c10">3 </span><span class="c0">: p</span><span class="c10">3</span><span class="c0">(?x0) Aristotle &and; p</span><span class="c10">3</span><span class="c0">(?x1) = Ethics; (4). </span><span class="c6">mp</span><span class="c10">4 </span><span class="c0">: p</span><span class="c10">3</span><span class="c0">(?x0) Aristotle &and; p</span><span class="c10">3</span><span class="c0">(?x1) Ethics. </span></p><p class="c4"><span class="c6">Figure 6 shows all horizontal fragments generated from the above structural minterm predicates. </span></p><p class="c4"><span class="c2">6. ALLOCATION </span></p><p class="c7"><span class="c6">After fragmenting the RDF graph, the next step is to allocate all fragments on several sites. In real applications, some frequent ac- cess patterns or structural minterm predicates are usually accessed together, so their corresponding fragments should be placed in one site to further avoid the cross-fragments joins. There is a need for some measures evaluating precisely the notion of &ldquo;together- ness&rdquo;. This measure is the affinity of fragments, which indicates how closely related the fragments are. </span></p><p class="c7"><span class="c6">We define fragment affinity metric to measure the togetherness between two frequent access patterns or structural minterm predi- cates as follows: </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">13. (Fragment Affinity Metric) The fragment affin- ity metric between two fragments F and F with respect to the workload &bull; af vertical f(F, Q = F fragments {Q) </span><span class="c10">1</span><span class="c0">, </span><span class="c6">= </span><span class="c0">Q</span><span class="c28">&sum;</span><span class="c10">2</span><span class="c0">, </span><span class="c9">q</span><span class="c10">k=1 </span><span class="c0">..., </span><span class="c6">generated use(Q</span><span class="c0">Q</span><span class="c10">q</span><span class="c0">} is </span><span class="c10">k</span><span class="c0">, defined p) </span><span class="c6">from </span><span class="c0">&times; use(Q</span><span class="c6">frequent </span><span class="c0">as follows </span></p><p class="c38"><span class="c10">k</span><span class="c0">, p ), </span><span class="c6">access </span><span class="c0">if F and F </span><span class="c6">patterns </span><span class="c0">are </span><span class="c6">p and p ; </span></p><p class="c4"><span class="c6">&bull; af f(F, F ) are horizontal = </span><span class="c28">&sum;</span><span class="c6">fragments </span><span class="c9">q</span><span class="c10">k=1 </span><span class="c6">use(Q</span><span class="c10">k</span><span class="c0">,mp) </span><span class="c6">generated </span><span class="c0">&times; use(Q</span><span class="c6">from </span><span class="c10">k</span><span class="c0">, </span><span class="c6">structural </span><span class="c0">mp ), if F </span><span class="c6">minterm </span><span class="c0">and F </span></p><p class="c4"><span class="c6">predicates mp and mp ; </span></p><p class="c7"><span class="c6">Based on the fragment affinity metric, we can show how closely related the fragments are. If the affinity metric of two fragments is large, it means that these two fragments are often involved by the same query. Some fragments are so related that they should be placed together to reduce the number of cross-sites joins. Here, we group all fragments into some clusters. The result of clustering corresponds to an allocation A, and each cluster corresponds to an element of A, which means that all fragments in the cluster are placed into the same site. </span></p><p class="c7"><span class="c6">There are many clustering algorithms to cluster all fragments and we need to select one of them. In this paper, we extend a graph clustering algorithm, PNN [5], to cluster all fragments into an allo- cation A = {A</span><span class="c10">1</span><span class="c6">, A</span><span class="c10">2</span><span class="c6">, ..., A</span><span class="c10">m</span><span class="c6">}. All fragments of the same cluster are put into one site. </span></p><p class="c4"><span class="c1">M </span></p><p class="c4"><span class="c6">(a) Example Horizontal Frag- </span><span class="c0">ment Generated from mp</span><span class="c10">1 </span></p><p class="c4"><span class="c1">Ethics </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">Plato </span></p><p class="c4"><span class="c1">Aristotle </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">Friedrich_Nietzsche </span></p><p class="c4"><span class="c1">Ma </span></p><p class="c4"><span class="c6">(b) Example Horizontal Frag- </span><span class="c0">ment Generated from mp</span><span class="c10">2 </span></p><p class="c4"><span class="c1">Aristotle </span></p><p class="c4"><span class="c1">Ethics </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">name </span></p><p class="c4"><span class="c1">&quot;Friedrich Nietzsche&quot; </span></p><p class="c4"><span class="c1">&quot;Aristotle&quot; </span></p><p class="c4"><span class="c1">name </span></p><p class="c4"><span class="c1">s</span><span class="c19">he&quot; </span></p><p class="c4"><span class="c1">KaReligion </span></p><p class="c4"><span class="c19">inf </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c1">Friedrich_Nietzsche </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">Max_Horkheimer </span></p><p class="c4"><span class="c1">&quot;Boethius&quot; </span></p><p class="c4"><span class="c1">name </span></p><p class="c4"><span class="c1">Boethius </span></p><p class="c4"><span class="c1">influencedBy </span></p><p class="c4"><span class="c1">Aristotle </span></p><p class="c4"><span class="c6">First, we build the allocation graph as follows. </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">14. (Allocation Graph) Given a fragmentation F = {F</span><span class="c10">1</span><span class="c0">, F</span><span class="c10">2</span><span class="c0">, ..., F</span><span class="c10">n</span><span class="c0">}, the corresponding allocation graph AG = {V(AG), </span><span class="c6">E(AG), f</span><span class="c10">W</span><span class="c0">} is defined as follows: </span></p><p class="c4"><span class="c6">&bull; V(AG) is a set of vertices that map to all fragments; </span></p><p class="c38"><span class="c6">&bull; E(AG) is a set of undirected edges that vv &isin; E(VG) if and only if the fragment affinity metric between the correspond- </span><span class="c1">Ethic </span></p><p class="c4"><span class="c6">ing fragments of v and v is larger than 0; </span></p><p class="c4"><span class="c1">ma </span></p><p class="c4"><span class="c6">&bull; f</span><span class="c10">W </span><span class="c0">is a weight function f</span><span class="c10">W </span><span class="c0">: E(AG) &rarr; N</span><span class="c9">+</span><span class="c0">. If v and v </span><span class="c6">correspond to fragments F and F , f</span><span class="c10">W</span><span class="c0">(vv ) = af f(F, F ). </span></p><p class="c7"><span class="c6">Then, the allocation problem is equivalent to cluster all frag- ments in m clusters, and all fragments in a cluster are connected in AG. We define the density of a cluster A</span><span class="c10">i </span><span class="c0">in AG to rate the qual- </span><span class="c6">ity of A</span><span class="c10">i </span><span class="c0">as follows. </span></p><p class="c4"><span class="c6">&delta;(A</span><span class="c10">i</span><span class="c6">) = </span></p><p class="c34"><span class="c6">&sum; </span><span class="c9">v</span><span class="c23">i</span><span class="c9">&isin;A</span><span class="c23">i</span><span class="c9">&and;v</span><span class="c23">j</span><span class="c9">&isin;A</span><span class="c23">i</span><span class="c9">&and;v</span><span class="c23">i</span><span class="c9">v</span><span class="c23">j</span><span class="c9">&isin;E(AG) </span><span class="c28">f</span><span class="c9">W</span><span class="c6">(v</span><span class="c10">i</span><span class="c0">v</span><span class="c10">j</span><span class="c0">) </span><span class="c6">( </span><span class="c0">|A</span><span class="c10">i</span><span class="c0">|2 </span></p><p class="c4"><span class="c6">) </span></p><p class="c4"><span class="c6">where </span><span class="c28">&sum; </span></p><p class="c4"><span class="c9">v</span><span class="c23">i</span><span class="c10">&isin;A</span><span class="c23">i</span><span class="c10">&and;v</span><span class="c23">j</span><span class="c10">&isin;A</span><span class="c23">i</span><span class="c10">&and;v</span><span class="c23">i</span><span class="c10">v</span><span class="c23">j</span><span class="c10">&isin;E(AG) </span><span class="c6">f</span><span class="c10">W</span><span class="c0">(v</span><span class="c10">i</span><span class="c0">v</span><span class="c10">j</span><span class="c0">) is the sum of weights of all edges </span></p><p class="c4"><span class="c6">in A</span><span class="c10">i </span><span class="c0">and </span></p><p class="c4"><span class="c6">( </span><span class="c0">|A</span><span class="c10">i</span><span class="c0">| </span></p><p class="c4"><span class="c6">2 </span></p><p class="c4"><span class="c6">) </span></p><p class="c4"><span class="c6">is the maximum possible number of edges. </span></p><p class="c7"><span class="c6">The objective of our allocation algorithm is to search for m sub- graphs of AG that have the highest densities. Unfortunately, this problem is NP-complete [20], so we propose a heuristic solution as Algorithm 2. Algorithm 2 is a variant of PNN and picks the locally optimal choice of merging two vertices in AG at each step. Because our objective function can guarantee the locally optimal choice is also the optimal choice for the overall solution, Algorithm 2 can find out the optimal clustering result of AG. </span></p><p class="c7"><span class="c6">Generally speaking, we initialize a cluster for each fragment. Then, we repeatedly picks the two clusters (singletons or larger) that have the highest weight value to be merged. The weight be- tween two clusters are the density value of merging them. Such merging is iterated until the size of the allocation graph has been reduced to m. </span></p><p class="c4"><span class="c6">Algorithm 2: Allocation Algorithm </span></p><p class="c4"><span class="c5">Input: The allocation graph AG and the preset threshold &theta; </span><span class="c3">1 2 3 4 </span><span class="c5">Output: for each Find Athe </span><span class="c10">i </span><span class="c5">Initialize An allocation </span><span class="c17">&larr; </span><span class="c5">edge vertex AG </span><span class="c17">{v</span><span class="c10">i</span><span class="c17">}; </span></p><p class="c4"><span class="c5">ethat </span><span class="c10">max </span><span class="c5">v</span><span class="c10">i </span><span class="c5">A </span><span class="c17">in V(VG) </span><span class="c5">= </span><span class="c17">do </span></p><p class="c4"><span class="c5">{A</span><span class="c10">1</span><span class="c5">, A</span><span class="c10">2</span><span class="c5">, ..., A</span><span class="c10">m</span><span class="c5">} </span></p><p class="c4"><span class="c5">with the highest weight in is the same to AG; </span></p><p class="c4"><span class="c5">E(AG); </span></p><p class="c4"><span class="c3">5 </span><span class="c5">while |V(AG )| m do </span><span class="c3">6 7 </span><span class="c1">Friedrich inf </span></p><p class="c4"><span class="c1">Friedrich </span></p><p class="c4"><span class="c1">inf </span></p><p class="c4"><span class="c1">Social_theory </span></p><p class="c4"><span class="c5">Generating AG from AG by merging for each A</span><span class="c10">k </span><span class="c17">adjacent to A</span><span class="c10">ij </span><span class="c17">in </span><span class="c9">&sum; </span></p><p class="c4"><span class="c17">E(AG ) </span><span class="c5">e</span><span class="c17">do </span></p><p class="c4"><span class="c10">max </span><span class="c5">= A</span><span class="c10">i</span><span class="c5">A</span><span class="c10">j </span><span class="c5">to A</span><span class="c10">ij</span><span class="c5">; </span></p><p class="c4"><span class="c3">8 </span><span class="c5">f</span><span class="c10">W</span><span class="c17">(A</span><span class="c10">k</span><span class="c17">A</span><span class="c10">ij</span><span class="c17">) &larr; </span></p><p class="c38"><span class="c22">v</span><span class="c23">i</span><span class="c22">&isin;A</span><span class="c23">k</span><span class="c22">&and;(v </span><span class="c23">j</span><span class="c22">&isin;A</span><span class="c23">i</span><span class="c22">&or;v </span><span class="c23">j</span><span class="c9">&#63723;</span><span class="c10">&#63724;&#63724;&#63724;&#63724;&#63724;&#63725; </span><span class="c22">&isin;A</span><span class="c5">|A 2 </span><span class="c23">j</span><span class="c22">)&and;v</span><span class="c10">k</span><span class="c1">&quot;Max Horkheimer&quot; name </span></p><p class="c4"><span class="c1">mainInterest </span></p><p class="c4"><span class="c23">i</span><span class="c5">| </span><span class="c22">v </span><span class="c23">j</span><span class="c9">&#63734;</span><span class="c10">&#63735;&#63735;&#63735;&#63735;&#63735;&#63736; </span></p><p class="c4"><span class="c22">&isin;E(AG) </span><span class="c14">f</span><span class="c22">W</span><span class="c14">(v</span><span class="c22">i</span><span class="c14">v</span><span class="c22">j</span><span class="c14">) </span></p><p class="c4"><span class="c3">9 </span><span class="c5">Find the edge e</span><span class="c10">max </span><span class="c17">with the highest weight in E(AG ); </span></p><p class="c4"><span class="c2">7. DISTRIBUTED QUERY PROCESSING </span></p><p class="c7"><span class="c6">In this section, we discuss how to process a SPARQL query. For query processing, the metadata is necessary and we introduce how to maintain the metadata in a data dictionary in Section 7.1. Then, we discuss how to decompose a query into some subqueries in Sec- tion 7.2. Last, we discuss how to produce a distributed execution plan and execute all subqueries based on the plan in Section 7.3. </span></p><p class="c4"><span class="c42">383 </span></p><p class="c4"><span class="c36">qQ</span><span class="c41">4 </span></p><p class="c4"><span class="c41">21 </span></p><p class="c4"><span class="c36">q</span><span class="c41">23 </span></p><p class="c4"><span class="c36">q</span><span class="c41">22 </span></p><p class="c4"><span class="c6">(c) Valid Decomposition D</span><span class="c10">2 </span><span class="c6">Figure 7: A New Input Query and Its Example Valid Decompositions </span></p><p class="c4"><span class="c2">7.1 Data Dictionary </span></p><p class="c7"><span class="c6">After fragmentation and allocation, the results of fragmentation and allocation need to be stored and maintained by the system. This information is necessary during distributed query processing. This information is stored in a data dictionary. The data dictio- nary stores a global statistics file generated at fragmentation and allocation time. It contains the following information: fragment definitions, their sizes, site mappings, access frequencies and so on.</span><span class="c0">Since each fragment corresponds to a frequent access pattern or a </span><span class="c6">structural minterm predicate, the data dictionary uses the frequent access pattern with/without constraints as the representative of a fragment. Each frequent access pattern with/without constraints corresponds to a fragment and is associated with all statistics of the fragment. The data dictionary need to fast retrieve all frequent access patterns with/without constraints to determine the relevant frequent access pattern for a query. </span></p><p class="c7"><span class="c6">We build a hash table to achieve the above objective. We first use the DFS coding [26] to translates frequent access patterns into sequences. With the DFS code of a frequent access pattern, we can map any frequent access pattern to an integer by hashing its canon- ical label. Then, we use the hash table to locate frequent access patterns and retrieve the statistics of their corresponding fragments </span><span class="c2">7.2 Query Decomposition </span></p><p class="c7"><span class="c6">When users input a query Q, the system first uses the data dic- tionary to determine which fragments are involved in the query and decomposes the query into some subqueries on fragments. </span></p><p class="c4"><span class="c6">Given a query Q, a decomposition of Q is a set of subqueries D = {q</span><span class="c10">1</span><span class="c0">,q</span><span class="c10">2</span><span class="c0">, ..., q</span><span class="c10">t</span><span class="c0">} such that (1) each q</span><span class="c10">i </span><span class="c0">is a subgraph of Q and q</span><span class="c10">i </span><span class="c0">maps to a frequent access pattern or structural minterm predicate; </span><span class="c6">(2) V(q</span><span class="c10">1</span><span class="c0">)&cup;...&cup;V(q</span><span class="c10">t</span><span class="c0">) = V(Q); and (3) E(q</span><span class="c10">1</span><span class="c0">)&cup;...&cup;E(q</span><span class="c10">t</span><span class="c0">) = E(Q)&and;&forall;i </span><span class="c6">j, E(q</span><span class="c10">i</span><span class="c0">) &cap; E(q</span><span class="c10">j</span><span class="c0">) = &empty;. </span></p><p class="c7"><span class="c6">Since we partition the RDF graph based on the frequent access patterns, we also decompose the query based on the frequent access patterns. In other words, we decompose the query into subqueries that are homomorphic to frequent access patterns. If a query in- volves infrequent properties that cannot be decomposed into sub- queries homomorphic to any frequent access patterns, then each connected subgraph of the query that only contains infrequent prop- erties corresponds to a subquery. We define the valid decomposi- tion as follows. </span></p><p class="c4"><span class="c6">D</span><span class="c26">EFINITION </span><span class="c6">15. (Valid Decomposition) Given a SPARQL query Q, a valid decomposition D = {q</span><span class="c10">1</span><span class="c0">,q</span><span class="c10">2</span><span class="c0">, ..., q</span><span class="c10">t</span><span class="c0">} of Q should meet the </span><span class="c6">following constraint: if q</span><span class="c10">i </span><span class="c0">(1 &le; i &le; t) is not homomorphic to any </span><span class="c6">frequent access patterns, all edges in q</span><span class="c10">i </span><span class="c0">should be cold edges. </span></p><p class="c4"><span class="c6">There exist at least one valid decompositions. A possible decom- position is the decomposition of all subqueries of a single edge. </span></p><p class="c4"><span class="c13">ligion </span></p><p class="c4"><span class="c13">?c</span><span class="c21">placeOfDeath</span><span class="c13">mainInterest </span></p><p class="c4"><span class="c13">Religion </span></p><p class="c4"><span class="c13">?x </span></p><p class="c34"><span class="c13">?x name ?n </span><span class="c21">?x </span></p><p class="c4"><span class="c13">influencedBy </span></p><p class="c4"><span class="c13">?t </span></p><p class="c4"><span class="c13">viaf </span></p><p class="c4"><span class="c13">Aristotle </span></p><p class="c7"><span class="c6">Because we select all frequent access patterns of one edge, the de- composition of all subqueries of a single edge is valid. Besides the valid decomposition, there may also exist some other valid decom- positions. Hence, we propose a cost-model driven selection and the best valid decomposition is the valid decomposition with the smallest cost. </span></p><p class="c7"><span class="c6">Here, we assume that the cost of a decomposition is the cost of joining all matches of the subqueries in D and each pair of sub- queries&rsquo; matches can join together. The assumption is the worst case, so that we can quantify the worst-case performance. Then, we define the cost of a decomposition as follows. </span></p><p class="c4"><span class="c6">cost(D) = </span><span class="c28">&prod;</span><span class="c9">q</span><span class="c23">i</span><span class="c9">&isin;D </span></p><p class="c4"><span class="c6">card(q</span><span class="c10">i</span><span class="c0">) </span></p><p class="c4"><span class="c6">where card(q</span><span class="c10">i</span><span class="c0">) is the number of matches for q</span><span class="c10">i</span><span class="c0">, which can be esti- </span><span class="c6">mated by looking up the data dictionary. </span></p><p class="c38"><span class="c6">E</span><span class="c26">XAMPLE </span><span class="c6">4. Assume that an user inputs a new query Q</span><span class="c10">4 </span><span class="c0">as </span><span class="c6">shown in Figure 7(a). Given frequent access patterns in Figure 4, there can be two valid decompositions D</span><span class="c10">1 </span><span class="c0">and D</span><span class="c10">2 </span><span class="c0">as shown in </span><span class="c6">Figures 7(b) and 7(c). For vertical fragmentation, q</span><span class="c10">23 </span><span class="c0">in D</span><span class="c10">2 </span><span class="c0">is </span><span class="c6">evaluated on the vertical fragment of p</span><span class="c10">3 </span><span class="c0">(Figure 5); for horizontal </span><span class="c6">fragmentation, q</span><span class="c10">23 </span><span class="c6">is evaluated on the horizontal fragment of mp</span><span class="c10">2 </span><span class="c0">(Figure 6(b)). </span><span class="c6">Whether in vertical or in horizontal fragmentation, it is obvious that D</span><span class="c10">2 </span><span class="c0">has fewer subqueries than D</span><span class="c10">1 </span><span class="c0">and card(q</span><span class="c10">23</span><span class="c0">) &lt; card(q</span><span class="c10">13</span><span class="c0">) &times; </span><span class="c6">card(q</span><span class="c10">14</span><span class="c0">) &times; card(q</span><span class="c10">15</span><span class="c0">). Hence, cost(D</span><span class="c10">2</span><span class="c0">) is smaller than cost(D</span><span class="c10">1</span><span class="c0">), </span><span class="c6">and D</span><span class="c10">2 </span><span class="c0">is more of a priority as the final decomposition. </span></p><p class="c7"><span class="c6">Based on the above definitions, we propose the query decom- position algorithm as Algorithm 3. Because the SPARQL query graphs in real applications usually contain 10 or fewer edges, we can use a brute-force implementation to enumerate all possible de- compositions and find the decomposition with the smallest cost. </span></p><p class="c4"><span class="c6">Algorithm 3: Query Decomposition Algorithm </span></p><p class="c4"><span class="c5">Input: A query Q </span><span class="c3">1 </span><span class="c5">Output: A valid MinCost &larr; +&infin;; </span></p><p class="c4"><span class="c5">decomposition D = {q</span><span class="c10">1</span><span class="c17">, q</span><span class="c10">2</span><span class="c17">, ...,q</span><span class="c10">t</span><span class="c17">} of query Q </span></p><p class="c4"><span class="c3">2 </span><span class="c5">Initialize D as the decomposition of all subqueries of a single edge; </span><span class="c3">3 4 </span><span class="c5">for each possible valid CurrentCost &larr; 1; </span></p><p class="c4"><span class="c5">decomposition D = {q</span><span class="c10">1</span><span class="c17">, ...,q</span><span class="c10">t</span><span class="c17">} do </span></p><p class="c4"><span class="c3">5 6 </span><span class="c5">for each Estimate query the q</span><span class="c10">i </span><span class="c5">number </span><span class="c17">in D </span><span class="c5">data dictionary; </span></p><p class="c4"><span class="c17">do </span></p><p class="c4"><span class="c5">of results for q</span><span class="c10">i </span><span class="c17">as card(q</span><span class="c10">i</span><span class="c17">) based on the </span></p><p class="c4"><span class="c3">7 </span><span class="c5">CurrentCost &larr; CurrentCost &times; card(q</span><span class="c10">i</span><span class="c17">) </span><span class="c3">8 </span><span class="c5">if MinCost &gt; CurrentCost then </span><span class="c3">9 </span><span class="c5">D&larr;D ; </span><span class="c3">10 </span><span class="c5">MinCost &larr; CurrentCost; </span><span class="c3">11 </span><span class="c5">Return D; </span></p><p class="c4"><span class="c42">384 </span></p><p class="c4"><span class="c13">?c</span><span class="c21">?t </span></p><p class="c4"><span class="c6">(a) A New Input Query Q</span><span class="c10">4 </span></p><p class="c4"><span class="c13">placeOfDeath </span></p><p class="c4"><span class="c13">viaf </span></p><p class="c4"><span class="c13">Religion </span></p><p class="c4"><span class="c13">mainInterest </span></p><p class="c4"><span class="c13">?x ?n name </span></p><p class="c4"><span class="c13">influencedBy </span></p><p class="c4"><span class="c13">Aristotle </span></p><p class="c4"><span class="c36">q</span><span class="c41">1</span><span class="c65">q</span><span class="c41">2 </span></p><p class="c4"><span class="c36">qq</span><span class="c41">11 </span></p><p class="c4"><span class="c41">13 </span></p><p class="c4"><span class="c13">?c?c</span><span class="c21">placeOfDeath</span><span class="c36">q</span><span class="c41">14 </span></p><p class="c4"><span class="c36">q</span><span class="c41">12 </span></p><p class="c4"><span class="c21">pl </span></p><p class="c4"><span class="c21">?x </span></p><p class="c4"><span class="c36">q</span><span class="c41">15 </span></p><p class="c4"><span class="c13">?t </span></p><p class="c4"><span class="c13">?t </span></p><p class="c4"><span class="c6">(b) Valid Decomposition D</span><span class="c10">1 </span></p><p class="c4"><span class="c13">viaf </span></p><p class="c4"><span class="c13">?x </span></p><p class="c4"><span class="c13">Religion mainInterest ?x </span></p><p class="c4"><span class="c13">?x name?n ?x</span><span class="c21">influencedBy </span></p><p class="c4"><span class="c21">Aristotle </span></p><p class="c4"><span class="c13">?n </span></p><p class="c4"><span class="c2">7.3 Query Optimization and Execution </span></p><p class="c7"><span class="c6">After decomposing the query, the next step is to find an execution plan for the query which is close to optimal. In this section, we dis- cuss the major optimization issue of finding execution plan, which deals with the join ordering of subqueries. We extend the algorithm of System-R [2] to find the optimal execution plan for distributed SPARQL queries. The algorithm is described in Algorithm 4. </span></p><p class="c7"><span class="c6">Generally speaking, Algorithm 4 is a variant of System-R style dynamic programming algorithm. It firstly generates the best exe- cution plan of n &minus; 1 subqueries, and then join the matches of n &minus; 1 subqueries with the matches of n-th subquery. The cost of an execu- tion plan can also be estimated based on the number of subqueries&rsquo; results, which is stored in the data dictionary. </span></p><p class="c7"><span class="c6">Finally, each subquery is executed in the corresponding sites in parallel. The optimization of each subquery uses the existing meth- ods in centralized RDF database systems. After the matches of all subqueries are generated, we join them together according to the optimal execution plan. </span></p><p class="c4"><span class="c6">Algorithm 4: Query Optimization Algorithm </span></p><p class="c4"><span class="c5">Input: A decomposition D = {q</span><span class="c10">1</span><span class="c17">, q</span><span class="c10">2</span><span class="c17">, ..., q</span><span class="c10">t</span><span class="c17">} of query Q </span><span class="c5">Output: An execution plan (...((q</span><span class="c10">i1 </span><span class="c17">q</span><span class="c10">i2</span><span class="c17">) q</span><span class="c10">i3</span><span class="c17">) ... q</span><span class="c10">it</span><span class="c17">) </span><span class="c3">1 </span><span class="c5">for each two subqueries (q</span><span class="c10">i</span><span class="c5">) and (q</span><span class="c10">j</span><span class="c5">) where 1 &le; i j &le; t do </span><span class="c3">2 </span><span class="c5">Initialize an execution plan q</span><span class="c10">i </span><span class="c17">q</span><span class="c10">j </span><span class="c17">and estimate its cost; </span><span class="c3">3 </span><span class="c5">Store all execution plans and their costs in a table T</span><span class="c10">2</span><span class="c17">; </span><span class="c3">4 </span><span class="c5">for i = 3 to t do </span><span class="c3">5 </span><span class="c5">for each execution plan pl</span><span class="c10">j </span><span class="c17">in T</span><span class="c10">i&minus;1 </span><span class="c17">do </span><span class="c3">6 </span><span class="c5">for each subquery q</span><span class="c10">k </span><span class="c5">that is not contained by pl</span><span class="c10">j </span><span class="c5">do </span><span class="c3">7 </span><span class="c5">Build execution plan pl</span><span class="c10">j </span><span class="c17">q</span><span class="c10">k </span><span class="c17">and estimate its cost; </span><span class="c3">8 </span><span class="c5">Store this execution plan and its costs in a table T</span><span class="c10">i</span><span class="c17">; </span><span class="c3">9 </span><span class="c5">for each two plans pl</span><span class="c10">j </span><span class="c17">and pl</span><span class="c10">k </span><span class="c17">in T</span><span class="c10">i </span><span class="c17">do </span><span class="c3">10 </span><span class="c5">if pl</span><span class="c10">j </span><span class="c17">and pl</span><span class="c10">k </span><span class="c17">map to the same set of subqueries then </span><span class="c3">11 </span><span class="c5">Eliminate one of pl</span><span class="c10">j </span><span class="c5">and pl</span><span class="c10">k </span><span class="c5">that has the larger cost; </span><span class="c3">12 </span><span class="c5">Return the execution plan with the minimum cost; </span></p><p class="c4"><span class="c2">8. EXPERIMENTAL EVALUATION </span></p><p class="c4"><span class="c6">We conducted extensive experiments to test the effectiveness of our proposed techniques on a real dataset, DBPedia, and a synthetic dataset, WatDiv. In this section, we report the setting of test data and various performance results. </span><span class="c2">8.1 Setting </span></p><p class="c4"><span class="c6">DBPedia. DBPedia</span><span class="c14">2 </span><span class="c6">is an RDF dataset extracted from Wikipedia. The DBPedia contains 163,977,110 triples. We use the DBpe- dia SPARQL query-log as the workload. This workload contains queries posed to the official DBpedia SPARQL endpoint in 14 days of 2012. After removing some queries that cannot be handled, there are 8, 151,238 queries in the workload. </span></p><p class="c7"><span class="c6">WatDiv. WatDiv [1] is a benchmark that enable diversified stress testing of RDF data management systems. In WatDiv, instances of the same type can have the different sets of attributes. For testing our methods, we generate five datasets varying sizes from 50 mil- lion to 250 million triples. By default, we use the RDF dataset with 100 million triples. In addition, WatDiv can generate a workload by instantiating some templates with actual RDF terms from the dataset. WatDiv provides 20 templates to generate test queries. We use these benchmark templates to generate a workload with 2000 test queries. </span></p><p class="c7"><span class="c6">We conduct all experiments on a cluster of 10 machines running Linux, each of which has one CPU with four cores of 3.06GHz. Each site has 16GB memory and 150GB disk storage. We select one of these sites as a control site. At each site, we install gStore </span></p><p class="c4"><span class="c9">2</span><span class="c0">http://km.aifb.kit.edu/projects/btc-2012/dbpedia/ </span></p><p class="c4"><span class="c6">[31] to find matches. We use MPICH-3.0.4 running on C++ to join the results generated by subqueries. </span></p><p class="c7"><span class="c6">For fair performance comparison, we use gStore and MPICH- 3.0.4 to re-implement two recent distributed RDF fragmentation strategies. The first one is SHAPE [14], which defines a vertex and its neighbors as a triple group and assigns the triple groups according to the value of its center vertices. There are many dif- ferent kinds of triple groups in [14] and we use the subject-object- based triple groups in this paper. The second one is WARP [8]. WARP first uses METIS [12] to divide the RDF graph into frag- ments. Then, it replicates all matches of a query pattern that cross two fragments in one fragment. We use all frequent access patterns to extend the fragments in WARP. </span></p><p class="c4"><span class="c2">8.2 Parameter Setting </span></p><p class="c7"><span class="c6">Our frequent access patterns selection method uses a parameter: minSup. In this subsection, we discuss how to set up minSup to optimize query processing. Note that, since the numbers of query templates and queries per query template in WatDiv are specified by users, the parameters can also be determined beforehand. Thus, we only discuss how to set the parameters for DBPedia. </span></p><p class="c7"><span class="c6">Given a workload Q, we set the support threshold, minSup, to find patterns whose access frequencies are larger than minSup. It is clear that the smaller minSup is, the larger number of frequent access patterns there are. More frequent access patterns mean that a query in the workload may have a higher possibility to contain some frequent access patterns. </span></p><p class="c4"><span class="c69">200 </span></p><p class="c34"><span class="c69">0.1% 0.5% 1% minSup </span><span class="c6">(a) minSup </span></p><p class="c4"><span class="c3">100% </span></p><p class="c4"><span class="c69">150 </span></p><p class="c4"><span class="c52">e garevo</span><span class="c3">C80% </span></p><p class="c34"><span class="c3">Number of FAPs </span><span class="c6">(b) Workload Hitting Ratio </span></p><p class="c4"><span class="c6">Figure 8: Effect of Frequent Access Patterns Figure 8(a) shows the impact of minSup. As minSup increases, the number of frequent access patterns (FAPs) decreases. Hence, when we set minSup as 0.1% of the total number of queries in the workload, there are 163 frequent access patterns for DBPedia. When minSup is 1% of the total number of queries, the number of frequent access patterns is reduced to 44 for DBPedia. Further- more, fewer frequent access patterns means that fewer queries in the workload are hit, as shown in Figure 8(b). </span></p><p class="c7"><span class="c6">Even if we set minSup as 0.1% of the total number of queries, the number of frequent access patterns is not large. Hence, in the following, we set minSup as 0.1% of the total number of queries for DBPedia by default. </span></p><p class="c4"><span class="c2">8.3 Throughput </span></p><p class="c7"><span class="c6">In this experiment, we test the throughput of different fragmen- tation strategies. We sample 1% of all queries in the workload and measure the throughput in queries per minute. Figure 9 shows the number of queries answered in one minute of different fragmenta- tion strategies. </span></p><p class="c7"><span class="c6">For SHAPE and WARP, each query concerns all fragments, so queries are still processed sequentially. Since WARP is more bal- anced than SHAPE, the throughput of WARP is a little better than SHAPE. WARP can handle about 32 and 82 queries in one minute </span></p><p class="c4"><span class="c42">385 </span></p><p class="c4"><span class="c3">60% </span><span class="c69">100 </span></p><p class="c4"><span class="c3">40% </span></p><p class="c4"><span class="c69">50 </span></p><p class="c4"><span class="c3">20% </span></p><p class="c4"><span class="c52">0% </span></p><p class="c4"><span class="c3">50 100 150 200 </span></p><p class="c38"><span class="c13">25</span><span class="c66">e tuniMrePseireu</span><span class="c13">Q</span><span class="c66">45 403530</span><span class="c6">(a) DBPedia </span></p><p class="c4"><span class="c13">500 </span></p><p class="c4"><span class="c6">(b) WatDiv </span></p><p class="c4"><span class="c6">Figure 9: Throughput Comparison </span></p><p class="c4"><span class="c6">for DBPedia and WatDiv, while SHAPE can handle 24 and 75 queries. </span></p><p class="c4"><span class="c6">For the vertical fragmentation strategy (VF), since a query of- ten only contains a few frequent access patterns, it only involves a few fragments. Two queries involving different fragments can be evaluated in parallel. Hence, about 46 queries and 533 queries can be answered in one minute for DBPedia and WatDiv, respec- tively. For the horizontal fragmentation strategy (HF), each fre- quent access pattern specified by the query may map to many struc- tural minterm predicates and the corresponding fragments of these structural minterm predicates may be allocated to different sites. Hence, the throughput of the horizontal fragmentation strategy is a little worse than the vertical fragmentation strategy, and 38 and 385 queries can be answered in one minute for DBPedia and WatDiv. </span><span class="c2">8.4 Response Time </span></p><p class="c7"><span class="c6">In this experiment, we test the query performance of different fragmentation strategies. We also sample 1% of all queries in the workload and compute the average query response time of a query. Figure 10 shows the performance results. </span></p><p class="c7"><span class="c6">SHAPE and WARP partition the RDF graph into some subgraphs, and distributes these subgraphs among different sites. The query should be processed in many sites in parallel. Hence, SHAPE is less balanced and sometime need cross-fragment joins, so SHAPE needs about 2.5 and 0.79 seconds to answer a query for DBPedia and WatDiv, while WARP takes 1.8 and 0.72 seconds. </span></p><p class="c7"><span class="c6">For the vertical fragmentation strategy, only relevant fragments are searched for matches and the search space is reduced. There- fore, a query can be answered in about 0.8 seconds for DBPedia and 0.3 seconds for WatDiv. For the horizontal fragmentation strategy, we can filter out all irrelevant fragments mapping to the structural minterm predicates not specified by the query, which can further re- duce the search space. Hence, a query can be answered with about 0.6 seconds for DBPedia and 0.15 seconds for WatDiv. </span></p><p class="c4"><span class="c13">SHAPE WARP VF HF </span></p><p class="c4"><span class="c13">400 </span></p><p class="c4"><span class="c13">300 </span></p><p class="c4"><span class="c13">200 </span></p><p class="c4"><span class="c13">100 </span></p><p class="c4"><span class="c13">SHAPE WARP VF HF </span></p><p class="c4"><span class="c66">0 </span><span class="c13">SHAPE WARP VF HF </span><span class="c66">) s(yreuQrePemiTegarev</span><span class="c13">A2.5</span><span class="c66">3 </span></p><p class="c4"><span class="c6">(a) DBPedia </span></p><p class="c4"><span class="c13">0.8 </span></p><p class="c4"><span class="c13">0.6 </span></p><p class="c4"><span class="c66">2 </span></p><p class="c4"><span class="c13">0.4 </span></p><p class="c4"><span class="c13">1.50.2 </span></p><p class="c4"><span class="c66">0 </span><span class="c13">SHAPE WARP VF HF </span><span class="c6">(b) WatDiv </span></p><p class="c4"><span class="c6">Figure 10: Performance Comparison </span></p><p class="c4"><span class="c2">8.5 Scalability Test </span></p><p class="c7"><span class="c6">In this experiment, we investigate the impact of dataset size on our fragmentation strategies. We generate five WatDiv datasets varying the from 50 million to 250 million triples to test our strate- </span></p><p class="c7"><span class="c6">gies. Figure 11 shows the results. Generally speaking, as the size of RDF datasets gets larger, the average response times of one query increase and the numbers of queries answered in one minute de- crease accordingly. However, the rates of increase and decrease are slow, and we can say that the query performance and throughput are scalable with RDF graph size on the datasets. </span></p><p class="c4"><span class="c45">) s(yreuQrePemiTegarev</span><span class="c20">A</span><span class="c45">VF</span><span class="c20">HF </span></p><p class="c4"><span class="c20">50M 100M 150M 200M 250M </span></p><p class="c4"><span class="c6">(a) Performance </span></p><p class="c4"><span class="c20">VF</span><span class="c90">HF </span></p><p class="c4"><span class="c6">(b) Throughput </span></p><p class="c4"><span class="c6">Figure 11: Varying Size of Datasets </span></p><p class="c4"><span class="c2">8.6 Redundancy </span></p><p class="c7"><span class="c6">Table 1 shows the redundancy ratio of the number of edges in all generated fragments to the total number of edges in the original RDF graph for each fragmentation strategy. For SHAPE, if a frag- ment contains a vertex with high degree, all adjacent edges of the high degree vertex are introduced. Most of these introduced edges are redundant, and cause the redundancy ratios of SHAPE nearly 3 for DBPedia and 1.74 for WatDiv. WARP divides the RDF graph while minimizing the edge cut, so the number of edges crossing two fragments for WARP is smaller than the number for SHAPE. Therefore, the redundancy ratio of WARP is smaller. Note that, WatDiv is much denser than DBPedia, so the minimum cut-set for WatDiv contains a higher proportion of edges. Hence, the redun- dancy ratio of WatDiv is 1.54, but the ratio of DBPedia is only 1.01. </span></p><p class="c38"><span class="c3">DBPedia WatDiv SHAPE 2.99 1.74 WARP 1.01 1.54 VF 1.38 1.04 HF 1.42 1.06 </span></p><p class="c4"><span class="c6">Table 1: Redundancy (Ratio to original dataset) Our fragmentation strategies find and materialize some frequent access patterns (or structural minterm predicates). As discussed in Section 8.2, the number of frequent access patterns is limited. Hence, the redundancy ratios of our fragmentation strategies are limited. Note that, the horizontal strategy has a little larger redun- dancy ratio than the vertical fragmentation strategy. This is because that different structural minterm predicates derived from the same frequent access patterns share some common triple patterns. These common triple patterns may cause more redundant edges. </span><span class="c2">8.7 Offline Performance </span></p><p class="c4"><span class="c6">Table 2 shows the data partitioning and loading time of the datasets for different fragmentation strategies. Although SHAPE has an al- most perfect uniform distribution, its redundancy ratio is too large and each fragment contains too many redundant edges. Hence, loading fragments in SHAPE also takes much time. WARP uses METIS [12]. Since DBPedia is sparse (i.e. |(E(G)|/|V(G)| &asymp; 1), METIS can guarantee that there are a few redundant edges and all fragments have a nearly uniform distribution. Then, WARP has less loading time than SHAPE. However, for WatDiv, the data graph is dense (i.e. |(E(G)|/|V(G)| &#8811; 1), so the fragmentation result of </span></p><p class="c4"><span class="c42">386 </span></p><p class="c4"><span class="c20">1,000 </span></p><p class="c4"><span class="c20">0.6 </span></p><p class="c38"><span class="c45">e tuniMrePseireu</span><span class="c20">Q800 </span><span class="c20">0.4 </span></p><p class="c4"><span class="c20">600 </span></p><p class="c4"><span class="c20">400 </span><span class="c20">0.2 </span></p><p class="c4"><span class="c20">200 </span></p><p class="c4"><span class="c20">50M 100M 150M 200M 250M </span><span class="c20">Size of Datasets </span></p><p class="c4"><span class="c20">Size of Datasets </span></p><p class="c4"><span class="c57">0</span><span class="c15">) s(emiTesnopseRyreu</span><span class="c57">Q</span><span class="c15">3 </span><span class="c57">SHAPE </span><span class="c18">WARP </span><span class="c15">2</span><span class="c18">VFHF </span></p><p class="c4"><span class="c15">1</span><span class="c57">S </span><span class="c39">1 </span><span class="c18">S </span><span class="c39">2 </span><span class="c18">S </span><span class="c39">3 </span><span class="c18">S </span><span class="c39">4 </span><span class="c18">S </span><span class="c39">5 </span><span class="c18">S </span><span class="c39">6 </span><span class="c18">S </span><span class="c39">7 </span><span class="c18">L</span><span class="c39">1 </span><span class="c18">L</span><span class="c39">2 </span><span class="c18">L</span><span class="c57">Queries </span></p><p class="c4"><span class="c39">3 </span><span class="c18">L</span><span class="c39">4 </span><span class="c18">L</span><span class="c39">5 </span><span class="c18">F</span><span class="c39">1 </span><span class="c18">F</span><span class="c39">2 </span><span class="c18">F</span><span class="c39">3 </span><span class="c18">F</span><span class="c39">4 </span><span class="c18">F</span><span class="c39">5 </span><span class="c18">C</span><span class="c39">1 </span><span class="c18">C</span><span class="c39">2 </span><span class="c18">C</span><span class="c39">3 </span></p><p class="c4"><span class="c6">Figure 12: Query Performance of Benchmark Queries </span></p><p class="c4"><span class="c6">METIS is unbalanced. Then, WARP takes more loading time than SHAPE to load the largest fragments. </span></p><p class="c7"><span class="c6">Since nearly half of all edges for DBPedia are infrequent edges, loading the cold graph of DBPedia is the bottleneck in our fragmen- tation strategies. However, in WatDiv, there are not so many infre- quent edges. Then, the loading time of our fragmentation strategies for WatDiv is more acceptable. Note that, because the structural minterm predicates are derived from the frequent access patterns, the cold graphs for the vertical and horizontal fragmentation strate- gies are the same. Thus, the loading times for the vertical and hor- izontal fragmentation strategies are the same. </span></p><p class="c4"><span class="c3">DBPedia WatDiv Strategies Partitioning Loading Total Partitioning Loading Total SHAPE 41 30 71 20 19 49 WARP 43 28 71 33 46 79 VF 50 97 147 31 28 59 HF 58 97 139 34 28 62 </span></p><p class="c4"><span class="c6">Table 2: Partitioning and Loading Time (in min) </span><span class="c2">8.8 Experiments for Benchmark Queries </span></p><p class="c7"><span class="c6">In this experiment, we compare our methods with other fragmen- tation strategies on benchmark queries provided by WatDiv. There are 20 benchmark queries in WatDiv, and these queries can be clas- sified into 4 structural categories: linear (L), star (S), snowflake (F) and complex (C). Figure 12 shows the performance of different ap- proaches. Generally speaking, we find out that our methods outper- forms other two methods in most cases. This is because that each benchmark query can be decomposed into some frequent access patterns or structural minterm predicates. Hence, our fragmenta- tion strategies can filter out many irrelevant fragments. In contrast, SHAPE and WARP always concern all fragments, and SHAPE fur- ther needs some cross-fragment joins for complex queries. </span></p><p class="c7"><span class="c6">Let us look deeper into Figure 12 and analyze each individual fragmentation strategy. SHAPE has to involve all fragments for any queries, so its performance is always worse than our fragmentation strategies. In particular, for star queries (S </span><span class="c10">1 </span><span class="c0">to S </span><span class="c10">7</span><span class="c0">), the difference </span><span class="c6">between the query response times of SHAPE and our fragmentation strategies is not very large, because the subject-object-based triple groups that we use can guarantee that there is no intermediate re- sult and all star queries can be answered at each fragment locally. However, for other shapes of queries, SHAPE has to decompose the queries and do cross-fragment joins to merge the intermediate results. Then, the performance of SHAPE decreases greatly. Es- pecially for the unselective queries (L</span><span class="c10">1</span><span class="c0">, F</span><span class="c10">1</span><span class="c0">, F</span><span class="c10">2</span><span class="c0">, F</span><span class="c10">3</span><span class="c0">, F</span><span class="c10">4</span><span class="c0">, F</span><span class="c10">5</span><span class="c0">, C</span><span class="c10">1 </span><span class="c0">and </span><span class="c6">C</span><span class="c10">2</span><span class="c0">), the performance of SHAPE is an order of magnitude worse </span><span class="c6">than our fragmentation strategies. </span></p><p class="c7"><span class="c6">Since WARP also use patterns to replicate triples for avoiding cross-fragment joins in complex queries, WARP has better perfor- mance that SHAPE in most case. However, WARP still always concerns all fragments in all sites for any kind of queries. The </span></p><p class="c7"><span class="c6">search space of WARP for a query is higher than our fragmenta- tion strategies. Thus, our fragmentation strategies always result in better performance. Especially for the query of very complex structure (C</span><span class="c10">2</span><span class="c0">), our fragmentation strategies can filter out many ir- </span><span class="c6">relevant fragments, which can result in much smaller search space than WARP. Hence, for C</span><span class="c10">2</span><span class="c0">, our strategies is twice as fast as WARP. </span></p><p class="c4"><span class="c6">Since all benchmark queries are generated from instantiating bench- mark templates with actual RDF terms, these benchmark queries al- ways correspond to a limited number of minterm predicates.Hence, the horizontal fragmentation is always faster than the vertical frag- mentation. </span><span class="c2">9. RELATED WORK </span></p><p class="c7"><span class="c6">For both the general graph and the RDF graph, as the graph size grows beyond the capability of a single machine, many works [6, 8, 9, 10, 29, 14, 15, 7, 23, 12, 30, 22, 25] have been proposed about graph fragmentation and allocation. We can divide all these meth- ods into two categories: global goal-oriented graph fragmentation methods and local pattern-based graph fragmentation methods. </span></p><p class="c7"><span class="c6">Global Goal-Oriented Graph Fragmentation. For this kind of methods [12, 9, 30, 22, 16], they divide G into several fragments while maximizing some goal function. They first transform a large graph into a small graph; then, apply some graph partitioning al- gorithms on the small graph; finally, the partitions on the small graph are projected back to the original graph. These methods of- ten apply some existing methods (such as KL [13]) directly on the transformed graph in the second step. If we track the transforming step, the partitions on the small graph can be easily projected back to the original graphs in the third step. Hence, the largest difference among different graph coarsening-based methods is how to coarsen the original graph into a small graph. </span></p><p class="c7"><span class="c6">In particular, METIS [12] uses the maximal matching to coarsen the graph. A matching of a graph is a set of edges that no two edges share an endpoint. A maximal matching of a graph is a matching to which no more edges can be added and remain a matching. Graph- Partition [9] directly uses METIS in the RDF graph. WARP [8] uses some frequent structures in workload to further extend the re- sults of GraphPartition. EAGRE [30] coarsens the RDF graph by using the entity concept in RDF data. It considers an entity to be a subject and its complete description. By grouping the entities of the same class, an RDF graph can be compressed as a compressed RDF entity graph. MLP [22] designs a method to coarsen the graph by label propagation. Vertices with the same label after the label prop- agation are coarsened to a vertex in the coarsened graph. Sheep [16] transform the graph into a elimination tree via a distributed map-reduce operation, and then partition this tree while reducing communication volume. Tomaszuk et. al. [21] briefly survey how to apply existing graph fragmentaion solutions from the theory of graphs to RDF graphs. </span></p><p class="c4"><span class="c6">Global goal-oriented graph fragmentation methods assume that if there are few edges crossing different fragments, the communi- </span></p><p class="c4"><span class="c42">387 </span></p><p class="c27"><span class="c6">cation cost is little. If an application involves nearly all vertices in the graph, few cross-fragments edges indeed result in little commu- nication. A typical application suitable for graph coarsening-based methods is PageRank. </span></p><p class="c51"><span class="c6">In some applications, one static fragmentation cannot fit all. Hence, Sedge [28] maintains many fragmentations with different crossing edges, while Shang et. al. [19] move some vertices of one frag- ment to another fragment during graph computing according to the workload. Yan et. al. [27] propose a indexing scheme based on fragmentation to help query engine fast locate the instances. </span></p><p class="c46"><span class="c6">Local Pattern-based Graph Fragmentation. For this kind of methods [10, 29, 14, 15, 7, 23, 25] , they first find certain patterns as the fragmentation units to cover the whole graph; then, they dis- tribute these patterns into sites. The local pattern-based methods mainly differ in their definitions of the fragmentation unit. </span></p><p class="c46"><span class="c6">HadoopRDF [10] groups triples with the same property together and each group corresponds to a fragmentation unit. Then, they store all fragmentation units over HDFS. Yang et. al.[29] define some special query patterns, and subgraphs of a pattern are con- sidered as a fragmentation unit. Lee et. al. [14, 15] define the fragmentation unit as a vertex and its neighbors, which they call a triple group. The triple groups are distributed based on some heuristic rules. For each vertex, SketchCluster [23] identifies the set of labeled vertices reachable within its one-hop neighborhood as its features and employs the KModes algorithm to group related vertices based on the features. Partout [6] extends the concepts of minterm predicates in relational database systems, and uses the re- sults of minterm predicates as the fragmentation units. TriAD [7] uses METIS [12] to divide the RDF graph into many partitions. Then, each result partition is considered as a unit and distributed among different sites based on a hash function. PathPartitioning [25] uses paths in RDF graphs as fragmentation units. </span></p><p class="c87"><span class="c6">Local pattern-based graph fragmentation methods assume that some real applications only concerns a part of the whole graph. If an application only concerns the vertices of some certain patterns, these methods only access the relevant fragments and reduce the communication cost across fragments. A typical example applica- tion is subgraph homomorphism checking. </span><span class="c2">10. CONCLUSION </span></p><p class="c58"><span class="c6">In this paper, we discuss how to manage the large RDF graph in a distributed environment. First, we mine and select some fre- quent access patterns to partition the RDF graph into many smaller fragments. Then, we propose an allocation algorithm to distribute all fragments over different sites. Last, we discuss how process the query based on the results of fragmentation and allocation. Exten- sive experiments verify our approaches. </span></p><p class="c98"><span class="c5">Acknowledgement. This was supported by 863 project under Grant No. 2015AA015402, NSFC under Grant No. 61532010, 61370055, 61272344 and 61303073. Lei Chen&rsquo;s work is supported in part by the Hong Kong RGC Project N HKUST637/13, National Grand Fundamental Research 973 Program of China under Grant 2014CB340303 , NSFC Grant No. 61328202, NSFC Guang Dong Grant No. U1301253, Microsoft Research Asia Gift Grant and Google Faculty Award 2013 </span></p><p class="c35"><span class="c2">11. </span><span class="c17">[1] G. </span><span class="c2">REFERENCES </span><span class="c17">Alu&ccedil;, O. Hartig, M. T. &Ouml;zsu, and K. Daudjee. Diversified stress </span></p><p class="c62"><span class="c5">testing of RDF data management systems. In ISWC, pages 197&ndash;212, 2014. [2] M. M. Astrahan, H. W. Blasgen, D. D. Chamberlin, K. P. Eswaran, </span></p><p class="c64"><span class="c5">J. N. Gray, P. P. Griffiths, W. F. King, R. A. Lorie, J. W. Mehl, G. R. Putzolu, I. L. Traiger, B. W. Wade, and V. Watson. System R: Relational Approach to Database Management. ACM Transactions on Database Systems, 1:97&ndash;137, 1976. [3] L. Bordeaux, Y. Hamadi, and P. Kohli. Tractability: Practical </span></p><p class="c78"><span class="c5">Approaches to Hard Problems. Cambridge University Press, 2014. </span></p><p class="c4 c8"><span class="c5">[4] DBpedia. http://dbpedia.org/about. [5] P. Fr&auml;nti, O. Virmajoki, and V. Hautam&auml;ki. Fast PNN-based </span></p><p class="c81"><span class="c5">Clustering Using K-nearest Neighbor Graph. In ICDM, pages 525&ndash;528, 2003. [6] L. Galarraga, K. Hose, and R. Schenkel. Partout: A Distributed </span></p><p class="c49"><span class="c5">Engine for Efficient RDF Processing. In WWW (Companion Volume), pages 267&ndash;268, 2014. [7] S. Gurajada, S. Seufert, I. Miliaraki, and M. Theobald. TriAD: A Distributed Shared-nothing RDF Engine Based on Asynchronous Message Passing. In SIGMOD Conference, pages 289&ndash;300, 2014. [8] K. Hose and R. Schenkel. WARP: Workload-aware Replication and </span></p><p class="c55"><span class="c5">Partitioning for RDF. In ICDE Workshops, pages 1&ndash;6, 2013. [9] J. Huang, D. J. Abadi, and K. Ren. Scalable SPARQL Querying of </span></p><p class="c60"><span class="c5">Large RDF Graphs. PVLDB, 4(11):1123&ndash;1134, 2011. [10] M. F. Husain, J. P. McGlothlin, M. M. Masud, L. R. Khan, and B. M. </span></p><p class="c68"><span class="c5">Thuraisingham. Heuristics-Based Query Processing for Large RDF Graphs Using Cloud Computing. IEEE Trans. Knowl. Data Eng., 23(9):1312&ndash;1327, 2011. [11] R. K. Iyer and J. A. Bilmes. Submodular Optimization with </span></p><p class="c70"><span class="c5">Submodular Cover and Submodular Knapsack Constraints. CoRR, abs/1311.2106, 2013. [12] G. Karypis and V. Kumar. Analysis of Multilevel Graph Partitioning. </span></p><p class="c63"><span class="c5">In SC, 1995. [13] B. Kernighan and S. Lin. An Efficient Heuristic Procedure for </span></p><p class="c82"><span class="c5">Partitioning Graphs. The Bell Systems Technical Journal, 49(2), 1970. [14] K. Lee and L. Liu. Scaling Queries over Big RDF Graphs with </span></p><p class="c63"><span class="c5">Semantic Hash Partitioning. PVLDB, 6(14):1894&ndash;1905, 2013. [15] K. Lee, L. Liu, Y. Tang, Q. Zhang, and Y. Zhou. Efficient and </span></p><p class="c91"><span class="c5">customizable data partitioning framework for distributed big RDF data processing in the cloud. In IEEE CLOUD, pages 327&ndash;334, 2013. [16] D. W. Margo and M. I. Seltzer. A Scalable Distributed Graph </span></p><p class="c63 c77"><span class="c5">Partitioner. PVLDB, 8(12):1478&ndash;1489, 2015. [17] S. Nijssen and J. N. Kok. The Gaston Tool for Frequent Subgraph </span></p><p class="c48"><span class="c5">Mining. Electr. Notes Theor. Comput. Sci., 127(1):77&ndash;87, 2005. [18] M. T. &Ouml;zsu and P. Valduriez. Principles of Distributed Database </span></p><p class="c63 c86"><span class="c5">Systems, Third Edition. Springer, 2011. [19] Z. Shang and J. X. Yu. Catch the Wind: Graph Workload Balancing </span></p><p class="c24"><span class="c5">on Cloud. In ICDE, pages 553&ndash;564, 2013. [20] J. S&iacute;ma and S. E. Schaeffer. On the NP-Completeness of Some Graph </span></p><p class="c50"><span class="c5">Cluster Measures. CoRR, abs/cs/0506100, 2005. [21] D. Tomaszuk, L. Skonieczny, and D. Wood. RDF Graph Partitions: A </span></p><p class="c89"><span class="c5">Brief Survey. In BDAS, pages 256&ndash;264, 2015. [22] L. Wang, Y. Xiao, B. Shao, and H. Wang. How to Partition a </span></p><p class="c12"><span class="c5">Billion-node Graph. In ICDE, pages 568&ndash;579, 2014. [23] Y. Wang, S. Parthasarathy, and P. Sadayappan. Stratification Driven </span></p><p class="c59"><span class="c5">Placement of Complex Data: A Framework for Distributed Data Analytics. In ICDE, pages 709&ndash;720, 2013. [24] G. Wiederhold. Database Design, Second Edition. McGraw-Hill, </span></p><p class="c73"><span class="c5">1983. [25] B. Wu, Y. Zhou, P. Yuan, L. Liu, and H. Jin. Scalable SPARQL </span></p><p class="c99"><span class="c5">Querying using Path Partitioning. In ICDE, pages 795&ndash;806, 2015. [26] X. Yan, P. S. Yu, and J. Han. Graph Indexing: A Frequent </span></p><p class="c56"><span class="c5">Structure-based Approach. In SIGMOD Conference, pages 335&ndash;346, 2004. [27] Y. Yan, C. Wang, A. Zhou, W. Qian, L. Ma, and Y. Pan. Efficient Indices Using Graph Partitioning in RDF Triple Stores. In ICDE, pages 1263&ndash;1266, 2009. [28] S. Yang, X. Yan, B. Zong, and A. Khan. Towards Effective Partition Management for Large Graphs. In SIGMOD Conference, pages 517&ndash;528, 2012. [29] T. Yang, J. Chen, X. Wang, Y. Chen, and X. Du. Efficient SPARQL Query Evaluation via Automatic Data Partitioning. In DASFAA (2), pages 244&ndash;258, 2013. [30] X. Zhang, L. Chen, Y. Tong, and M. Wang. EAGRE: Towards </span></p><p class="c85"><span class="c5">Scalable I/O Efficient SPARQL Query Evaluation on the Cloud. In ICDE, pages 565&ndash;576, 2013. [31] L. Zou, M. T. &Ouml;zsu, L. Chen, X. Shen, R. Huang, and D. Zhao. gStore: A Graph-based SPARQL Query Engine. VLDB J., 23(4):565&ndash;590, 2014. </span></p><p class="c84"><span class="c42">388 </span></p></body></html>