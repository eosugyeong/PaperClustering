<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c43{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.3pt;font-family:"Arial";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.2pt;font-family:"Arial";font-style:normal}.c24{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.3pt;font-family:"Arial";font-style:normal}.c49{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c38{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Courier New";font-style:normal}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.9pt;font-family:"Courier New";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Arial";font-style:normal}.c44{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Courier New";font-style:normal}.c39{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Courier New";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Arial";font-style:normal}.c47{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Courier New";font-style:normal}.c48{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:7.5pt;font-family:"Arial";font-style:normal}.c46{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Courier New";font-style:normal}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c22{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:8.1pt;font-family:"Arial";font-style:normal}.c37{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c18{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c33{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c32{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Courier New";font-style:normal}.c27{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.5pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:4.9pt;font-family:"Arial";font-style:normal}.c45{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:8.6pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c26{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Courier New";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:13.3pt;font-family:"Arial";font-style:normal}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Courier New";font-style:normal}.c20{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.2pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c31{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c34{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:13.3pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c52{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c42{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Courier New";font-style:normal}.c36{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:6.5pt;font-family:"Arial";font-style:normal}.c40{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Courier New";font-style:normal}.c51{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Courier New";font-style:normal}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c23{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c50{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c50"><p class="c6"><span class="c37">Reconstruction Privacy: Enabling Statistical Learning </span></p><p class="c6"><span class="c31">Ke Wang </span><span class="c30">Simon Fraser University Singapore Management </span><span class="c32">wangk@cs.sfu.ca </span></p><p class="c6"><span class="c30">University </span><span class="c31">Chao Han </span><span class="c30">Simon Fraser University </span><span class="c32">hanchaoh@cs.sfu.ca </span></p><p class="c6"><span class="c31">Ada Waichee Fu </span><span class="c30">Chinese University of Hong Kong </span><span class="c32">adafu@cse.cuhk.edu.hk </span></p><p class="c6"><span class="c31">Raymond Chi Wing </span><span class="c32">Wong </span><span class="c30">Hong Kong University of </span><span class="c32">raywong@cse.ust.hk </span><span class="c30">Science and Technology </span><span class="c31">Philip S. Yu </span><span class="c30">University of Illinois at Chicago Institute for Data Science Tsinghua </span><span class="c32">psyu@cs.uic.edu </span><span class="c30">University (Beijing) </span><span class="c31">ABSTRACT </span><span class="c2">Non-independent reasoning (NIR) allows the information about one record in the data to be learnt from the information of other record- s in the data. Most posterior/prior based privacy criteria consider NIR as a privacy violation and require to smooth the distribution of published data to avoid sensitive NIR. The drawback of this ap- proach is that it limits the utility of learning statistical relationship- s. The differential privacy criterion considers NIR as a non-privacy violation, therefore, enables learning statistical relationships, but at the cost of potential disclosures through NIR. A question is whether it is possible to (1) allow learning statistical relationships, yet (2) prevent sensitive NIR about an individual. We present a data per- turbation and sampling method to achieve both (1) and (2). The enabling mechanism is a new privacy criterion that distinguishes the two types of NIR in (1) and (2) with the help of the law of large numbers. In particular, the record sampling effectively prevents the sensitive disclosure in (2) while having less effect on the statistical learning in (1). </span></p><p class="c6"><span class="c31">Categories and Subject Descriptors </span><span class="c2">H.2.7 [Database Management]: Database Administration&mdash;Secu- rity, integrity, and protection; H.2.8 [Database Applications]: Da- ta Mining </span></p><p class="c6"><span class="c31">General Terms </span><span class="c2">Algorithm, Data Privacy, Theory </span></p><p class="c6"><span class="c31">Keywords </span><span class="c2">Data Privacy, Differential Privacy </span></p><p class="c6"><span class="c31">1. INTRODUCTION </span></p><p class="c11"><span class="c10">(c) 2015, Copyright is with the authors. Published in Proc. 18th Inter- national Conference on Extending Database Technology (EDBT). March 23-27, 2015, Brussels, Belgium: ISBN 978-3-89318-067-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c6"><span class="c31">1.1 Motivation </span></p><p class="c11"><span class="c2">Many privacy definitions/criteria have been proposed in the lit- erature and many ways exist to categorize them, such as semantic methods vs syntactic methods, prior/posterior methods vs differen- tial methods, etc. See surveys [1][2][3] for details. Another way to categorize privacy definitions is by whether non-independent rea- soning (NIR) is considered as a privacy violation. In NIR, the in- formation about one record in the data can be learnt from the in- formation of other records in the data, under the assumption that these records follow the same underlying distribution. A classifier is a master example of NIR where the class information of a new instance is learnt from the distribution in a related training set. </span></p><p class="c11"><span class="c2">Most posterior/prior based privacy definitions consider NIR as a privacy violation, such as l-diversity [4], t-closeness [5], &#8674;</span><span class="c5">1</span><span class="c13">-&#8674;</span><span class="c5">2 </span><span class="c2">privacy [6], -likeness [7], small sum privacy [8] and</span><span class="c25">&#8710;</span><span class="c2">-growth [9]. These criteria quantify the risk to an individual by the information learnt from the subpopulation containing that individual. To avoid privacy violation, the information learnt is required to have a small change compared to a prior of an adversary, and this often requires to &ldquo;smooth&rdquo; the distribution in the published data. One drawback of this approach is that it is hard to model the prior of the attacker [10][11]. Another drawback is that it limits the desired utility of learning statistical relationships. For example, </span><span class="c25">&#8710;</span><span class="c2">-growth postulates that the distribution in each subpopulation should be close to the global distribution in the whole data set. This requirement makes it difficult to learn novel statistical relationships such as &ldquo;smokers tend to have lung cancer&rdquo; in the subpopulation of smokers. </span></p><p class="c11"><span class="c2">At the other side of the aisle, differential privacy [10] considers NIR as a non-privacy violation, as stated in [11] (page 4): &ldquo;We ex- plicitly consider non-independent reasoning as a non-violation of privacy; information that can be learned about a row from sources other than the row itself is not information that the row could hope to keep private&rdquo;. Instead of avoiding the occurrence of disclosures, the differential privacy criterion seeks to mask the impact of a s- ingle individual on such occurrences. A popularized claim is that, even if an attacker knows all but one records, the attacker will not learn much about the remaining tuple. As indicated above, this comes with the price of permitting disclosures through NIR. In- deed, the recent study in [12] suggests that disclosures could occur under differential privacy if records are correlated, and the study in [13] demonstrates that a Bayes classifier could be built using on- ly differentially private answers to predict the sensitive attribute of an individual. In this paper we propose that a sensitive disclosure of NIR could occur in more general cases: no correlation among </span></p><p class="c6"><span class="c29">469 10.5441/002/edbt.2015.41 </span></p><p class="c6"><span class="c2">Table 1: {Prof-school, Prof-specialty, White, Male} ! &gt;50K (Conf=83.83%) </span></p><p class="c23"><span class="c10">e = 0.01 (b = 200) e = 0.1 (b = 20) e = 0.5 (b = 4) Mean SE Mean SE Mean SE </span><span class="c51">Conf</span><span class="c52">0 </span><span class="c51">1.34392 1.36299 0.860966 0.0985138 0.832659 0.0645165 </span><span class="c40">|</span><span class="c44">ans</span><span class="c18">1 </span><span class="c40">|</span><span class="c44">ans</span><span class="c18">2 </span><span class="c46">- - ansans</span><span class="c33">0</span><span class="c18">1</span><span class="c33">0</span><span class="c18">2</span><span class="c40">|</span><span class="c44">/ans</span><span class="c40">|</span><span class="c44">/ans</span><span class="c18">1 2 </span><span class="c46">0.614742 0.533185 0.0693353 0.570118 0.983959 0.102247 0.0272098 0.0262412 0.0144438 0.0820627 0.069974 0.0636316 </span></p><p class="c11"><span class="c2">records is required and only two differentially private query an- swers are needed to infer the sensitive attribute value. The example below demonstrates such a disclosure. </span></p><p class="c11"><span class="c2">E</span><span class="c15">XAMPLE </span><span class="c2">1. Consider the ADULT data set [14] that contain- s 45,222 records (without missing values) from the 1994 Census database. We did not observe any record correlation in this data set. Consider the five attributes Education, Occupation, Race, Gen- der, and Income. The Income attribute has two values, &ldquo;&#63743;50K&rdquo;, for 75.22% of records, and &ldquo;&gt;50K&rdquo;, for 24.78% of records. We assume that learning the Income value for a record is sensitive. On the raw data, the following two count queries Q</span><span class="c5">1 </span><span class="c13">and Q</span><span class="c5">2 </span><span class="c13">return </span><span class="c2">the answers ans</span><span class="c5">1 </span><span class="c13">= 501 and ans</span><span class="c5">2 </span><span class="c13">= 420, respectively: </span></p><p class="c6"><span class="c2">Q</span><span class="c5">1</span><span class="c13">: &ldquo;Prof-school ^ Prof-specialty ^ White ^ Male&rdquo;, </span><span class="c2">Q</span><span class="c8">2</span><span class="c2">: &ldquo;Prof-school ^ Prof-specialty ^ White ^ Male ^ &gt;50K&rdquo;. </span></p><p class="c6"><span class="c2">These answers imply the following rule with the confidence Conf = </span><span class="c8">ans</span><span class="c5">ans</span><span class="c0">2 1 </span><span class="c2">= 0.8383. </span></p><p class="c6"><span class="c2">{Prof-school, Prof-specialty, White, Male} ! &gt;50K. </span></p><p class="c11"><span class="c2">Since this confidence is significantly higher than the overall fre- quency 24.78% of the value &ldquo;&gt;50K&rdquo;, this rule may violate the pri- vacy of the individuals matching the condition of Q</span><span class="c5">1</span><span class="c13">. While this </span><span class="c2">rule seems expected, it does demonstrate the potential risk of NIR on a real life data distribution. After all, truly sensitive data and findings are difficult to obtain and publish. </span></p><p class="c16"><span class="c2">The differential privacy mechanism will return the noisy answers ans</span><span class="c3">0</span><span class="c8">i </span><span class="c1">= ans</span><span class="c8">i </span><span class="c2">+ &xi;</span><span class="c5">i</span><span class="c13">, i = 1,2, where the noises &xi;</span><span class="c5">i</span><span class="c13">&rsquo;s follow some </span><span class="c2">tribution, and an adversary has to gauge Conf by Conf</span><span class="c3">0 </span><span class="c2">= </span><span class="c13">dis- </span><span class="c3">ans</span><span class="c5">ans</span><span class="c24">0</span><span class="c39">2 </span><span class="c28">0</span><span class="c0">1 </span><span class="c2">. Consider exp( would ensure </span><span class="c26">|</span><span class="c3">&#8672;</span><span class="c26">|</span><span class="c8">b </span><span class="c2">the widely used Laplace noise distribution Lap(b) = </span><span class="c3">1</span><span class="c8">2b </span><span class="c1">), where b is the scale factor. The setting of b = </span><span class="c19">&#8710;</span><span class="c1">/e </span><span class="c2">e-differential privacy for the sensitivity</span><span class="c25">&#8710; </span><span class="c2">of the query function. Let us set </span><span class="c25">&#8710; </span><span class="c2">= 2 to account for the two count queries. Note that the effect of a larger </span><span class="c25">&#8710; </span><span class="c2">can be simulated by the effect of a smaller e because b = </span><span class="c25">&#8710;</span><span class="c2">/e. Table 1 shows the mean of Conf</span><span class="c3">0 </span><span class="c13">of query answers over 10 trials of random </span><span class="c2">and the </span><span class="c13">noises, </span><span class="c2">relative </span><span class="c13">and </span><span class="c2">error </span><span class="c13">the standard </span></p><p class="c6"><span class="c26">|</span><span class="c3">ans</span><span class="c8">ans</span><span class="c28">i </span><span class="c3">ans</span><span class="c21">i </span><span class="c24">0</span><span class="c28">i</span><span class="c26">| </span></p><p class="c6"><span class="c2">error (SE) of the mean. Conf</span><span class="c3">0 </span><span class="c2">measures the disclosure (in red) and </span><span class="c4">|</span><span class="c8">ans</span><span class="c21">i </span><span class="c8">ans</span><span class="c2">higher </span><span class="c8">ans</span><span class="c24">0</span><span class="c28">i</span><span class="c26">| </span></p><p class="c23"><span class="c21">i </span><span class="c2">privacy measures the utility of query answers (in blue). At the level e = 0.01, Conf</span><span class="c3">0 </span><span class="c2">deviates substantially from Conf = 0.8383, but the utility of the noisy answers is also poor because of the large relative errors and SE. At the lower privacy level e = 0.5, the utility of noisy answers improves significantly, but Conf</span><span class="c3">0 </span><span class="c2">= 0.8327 is within 1% difference from Conf with a s- mall SE (i.e., 0.0645); in this case any instances of ans</span><span class="c3">0</span><span class="c8">1 </span><span class="c1">and ans</span><span class="c3">0</span><span class="c8">2 </span><span class="c13">are sufficient to gauge the income level of an individual. </span><span class="c47">2 </span></p><p class="c23"><span class="c2">To ensure a good utility, a fixed (and small) scale b of noises is essential. Indeed, improving utility through reducing noises is a major focus of the work on differential privacy (see [15] for a list). As the query answer becomes larger, such noises become less significant, which improves therefore, the accuracy of </span><span class="c3">ans</span><span class="c5">ans</span><span class="c24">0</span><span class="c39">2 </span><span class="c28">0</span><span class="c0">1 </span><span class="c2">the utility of noisy answers ans</span><span class="c3">0</span><span class="c8">i</span><span class="c1">, </span><span class="c2">. Thus, the good utility of ans</span><span class="c3">0</span><span class="c8">i </span></p><p class="c6"><span class="c2">comes together with the risk of disclosures. A general and quan- titative analysis on this type of attack will be presented in Section 2. Choosing a large noise scale (i.e., a smaller e) helps thwart such attacks, but it also hurts the utility for data analysis. In fact, as long as the noise scale stays fixed, the noises eventually become insignificant for large query answers. </span><span class="c31">1.2 Our Approach </span></p><p class="c11"><span class="c2">The question we study in this paper is how to (A) allow learn- ing statistical relationships (such as &ldquo;smokers tend to have lung cancer&rdquo;), and at the same time, (B) prevent learning sensitive in- formation about an individual (such as &ldquo;Bob likely has HIV&rdquo;). As discussed above, posterior/prior based privacy criteria provide (B) but not (A), whereas the differential privacy criterion provides (A) but not (B). The difficulty of providing (A) and (B) is that they both make use of NIR, one for utility and one for privacy violation. The key lies at distinguishing these two types of learning. The next example illustrates the ideas of our approach. </span></p><p class="c6"><span class="c2">E</span><span class="c15">XAMPLE </span><span class="c2">2. Consider a table D(Gender, J ob, Disease), where Gender and Job are public and Disease is sensitive. Assume that Disease has 10 possible values. To hide the Disease value, for each record in D, uniform perturbation [16] for a given retention prob- ability, say 20%, will retain the Disease value in the record with 20% probability and replace it with a value chosen uniformly from the 10 possible values of Disease at random with the remaining 80% probability. This can be implemented by tossing a biased coin with head probability 20%. Let D</span><span class="c3">&#8676; </span><span class="c2">denote the perturbed data. </span></p><p class="c23"><span class="c2">D</span><span class="c3">&#8676; </span><span class="c2">can be utilized to reconstruct the distribution of Disease in a given subset of records. Consider any subset S of D, the counter- part S</span><span class="c3">&#8676; </span><span class="c2">for D</span><span class="c3">&#8676;</span><span class="c2">, and any Disease value d. frequency and frequencies E[F </span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c2">of </span><span class="c1">] denote </span><span class="c2">are d in in S, </span><span class="c1">the </span><span class="c2">fraction. f</span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c1">expectation denote </span><span class="c2">The </span><span class="c1">the </span><span class="c2">following </span><span class="c1">(observed) of f</span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c2">Let f</span><span class="c1">frequency </span><span class="c5">d </span><span class="c13">denote the </span><span class="c1">of d </span><span class="c13">(actual) </span><span class="c1">in S</span><span class="c3">&#8676;</span><span class="c2">, </span><span class="c1">(over all coin tosses). All </span><span class="c2">equation follows from the perturbation operation applied to the data: </span></p><p class="c6"><span class="c2">E[F</span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c1">] = (0.2+0.8/10)f</span><span class="c8">d </span><span class="c2">+ (0.8/10)(1 f</span><span class="c5">d</span><span class="c13">) (1) </span></p><p class="c6"><span class="c2">Approximating the unknown estimate of f</span><span class="c5">d </span><span class="c13">as </span><span class="c2">estimator (MLE) </span><span class="c8">f</span><span class="c2">[16] </span><span class="c28">d </span><span class="c24">&#8676;</span><span class="c8">0.2 </span><span class="c3">0.08 </span></p><p class="c6"><span class="c2">computed </span><span class="c1">. </span><span class="c2">E[F</span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c1">] by the observed f</span><span class="c8">d</span><span class="c3">&#8676;</span><span class="c1">, we get an This estimate is the maximum likelihood </span></p><p class="c23"><span class="c2">using the perturbed S</span><span class="c3">&#8676;</span><span class="c2">. Given the published D</span><span class="c3">&#8676;</span><span class="c2">, suppose that an adversary tries to learn the likelihood that Bob, a male engineer with a record in D, has breast cancer or BC for short. One way is considering the subset S</span><span class="c8">me </span><span class="c2">subset for a for disease S</span><span class="c5">e </span><span class="c2">all </span><span class="c13">for </span><span class="c2">male d </span><span class="c13">all </span><span class="c2">in </span><span class="c13">engineers </span><span class="c2">Sengineers </span><span class="c5">me </span><span class="c13">and Sin </span><span class="c2">in </span><span class="c5">e</span><span class="c13">, D. </span><span class="c2">D, </span><span class="c13">respectively. Let </span><span class="c2">and </span><span class="c13">M</span><span class="c2">another </span><span class="c5">d </span><span class="c8">me </span><span class="c13">Two </span><span class="c2">and is </span><span class="c13">questions </span><span class="c2">Mconsidering </span><span class="c8">d </span><span class="c3">e</span><span class="c1">be the </span><span class="c13">can </span><span class="c1">MLE </span><span class="c2">the </span></p><p class="c16"><span class="c13">be </span><span class="c2">asked. quantify Question the 1: risk Which to Bob? of MS</span><span class="c8">me BC </span><span class="c3">me </span><span class="c2">contains </span><span class="c1">and M</span><span class="c8">BC </span><span class="c2">exactly </span><span class="c3">e</span><span class="c1">should be used to </span><span class="c2">the records that match all Bob&rsquo;s public information, whereas S</span><span class="c5">e </span><span class="c13">contains additional </span><span class="c2">records that do not belong to Bob. Without further information, Sas </span><span class="c5">me </span><span class="c2">the </span><span class="c13">is </span><span class="c2">risk </span><span class="c13">more </span><span class="c2">to </span><span class="c13">relevant </span><span class="c2">Bob. If the </span><span class="c13">to Bob </span><span class="c2">additional </span><span class="c13">than S</span><span class="c2">records </span><span class="c5">e</span><span class="c13">, so M</span><span class="c2">for </span><span class="c5">BC </span><span class="c8">me </span><span class="c2">female should engineers be used </span></p><p class="c6"><span class="c2">follow a different distribution on BC from those for male engineers, M </span><span class="c8">BC </span><span class="c3">e</span><span class="c1">most likely is not useful for inferring whether Bob has breast </span></p><p class="c6"><span class="c29">470 </span></p><p class="c23"><span class="c2">cancer. We will discuss the case where the additional records have the same distribution as Bob in Section 3.4. On the other hand, the may frequency be useful M for </span><span class="c8">d </span><span class="c3">e</span><span class="c1">for </span><span class="c2">data </span><span class="c1">some </span><span class="c2">analysis, </span><span class="c1">disease </span><span class="c2">such </span><span class="c1">d (e.g., </span><span class="c2">as learning </span><span class="c1">cervical </span><span class="c2">the </span><span class="c1">spondylosis) </span><span class="c2">statistical relationship that career engineers tend to have d. This leads to the next question. </span></p><p class="c23"><span class="c2">serving Mwith bers, more more </span><span class="c13">for </span><span class="c2">limit </span><span class="c25">2 </span><span class="c2">Question </span><span class="c8">d </span><span class="c3">me </span><span class="c13">estimating </span><span class="c2">the the fcoin accurate </span><span class="c8">d </span><span class="c3">&#8676;</span><span class="c1">and </span><span class="c2">the </span><span class="c1">is </span><span class="c2">observed accuracy toss). </span><span class="c1">closer M</span><span class="c2">2: accuracy </span><span class="c8">d </span><span class="c13">the </span><span class="c3">e</span><span class="c2">for How </span><span class="c1">were </span><span class="c2">Since </span><span class="c1">to </span><span class="c13">frequency </span><span class="c2">festimating of </span><span class="c8">d </span><span class="c1">E[F </span><span class="c3">&#8676;</span><span class="c1">caused </span><span class="c2">M</span><span class="c1">in </span><span class="c2">to Sof </span><span class="c8">d BC </span><span class="c3">me </span><span class="c1">Equation </span><span class="c3">&#8676;</span><span class="c8">e </span><span class="c3">&#8676;</span><span class="c2">limit </span><span class="c1">] </span><span class="c2">M</span><span class="c1">contains when while </span><span class="c13">of </span><span class="c1">by </span><span class="c8">d </span><span class="c3">e</span><span class="c2">the the </span><span class="c13">d </span><span class="c1">approximating for more </span><span class="c13">in </span><span class="c2">frequency </span><span class="c1">(1). preserving </span><span class="c2">accuracy </span><span class="c13">S</span><span class="c5">e</span><span class="c13">. </span><span class="c1">more data records From </span><span class="c13">We </span><span class="c1">records analysis? </span><span class="c13">can </span><span class="c2">of </span><span class="c1">the </span><span class="c2">of </span><span class="c1">the are the </span><span class="c13">leverage </span><span class="c2">d M</span><span class="c1">law than </span><span class="c2">in </span><span class="c1">accuracy randomized unknown </span><span class="c8">BC </span><span class="c3">me </span><span class="c2">S</span><span class="c1">The of </span><span class="c5">e </span><span class="c1">Slarge </span><span class="c13">than </span><span class="c1">while </span><span class="c8">me</span><span class="c13">this </span><span class="c3">&#8676;</span><span class="c1">errors , of E[F </span><span class="c13">gap </span><span class="c1">M</span><span class="c13">M</span><span class="c1">num- (i.e., Mpre- </span><span class="c8">d </span><span class="c3">e</span><span class="c5">d </span><span class="c8">me d d</span><span class="c1">of </span><span class="c3">&#8676;</span><span class="c13">to </span><span class="c3">e</span><span class="c1">is ] </span></p><p class="c6"><span class="c1">. </span></p><p class="c23"><span class="c2">This example illustrates two types of reconstruction for MLEs. The construction reconstruction because of it M aims </span><span class="c8">BC </span><span class="c3">me </span><span class="c2">at </span><span class="c1">based </span><span class="c2">a particular </span><span class="c1">on S</span><span class="c8">me </span><span class="c2">individual is called personal by matching re- </span></p><p class="c6"><span class="c2">all is called public aggregate attributes reconstruction of Bob; the reconstruction because it aims of Mat </span><span class="c8">d </span><span class="c3">e</span><span class="c2">a </span><span class="c1">based </span><span class="c2">large </span><span class="c1">on </span><span class="c2">pop- </span><span class="c1">S</span><span class="c8">e </span></p><p class="c11"><span class="c2">ulation without specifically targeting any individual. We argue (in Section 3.2) that personal reconstruction is the source of privacy concerns whereas aggregation reconstruction is the source of u- tility. The law of large numbers suggests that these two types of reconstruction respond differently to the reduction of record per- turbation. We leverage this gap to limit the accuracy of personal reconstruction while preserving the accuracy of aggregate recon- struction. </span></p><p class="c11"><span class="c2">The small count privacy and large count utility in [8] use the number of records involved to distinguish the reconstruction for privacy concern and the reconstruction for utility. It is not clear how to set appropriate thresholds for such sizes. Indeed, it could be the case that two reconstructions are performed on two subsets of data with the same size but one aims at finding an individual&rsquo;s sensitive information while the other aims at finding general patterns. </span></p><p class="c6"><span class="c31">1.3 Contributions </span></p><p class="c6"><span class="c2">Here are the main contributions in this work: Contribution 1 (Section 2): We present a condition to character- ize the occurrence of disclosures of differentially private answers through NIR. For the Laplace noise distribution, this condition is simple and neat as it is expressed in terms of the ratio of the scale factor to the query answer. </span></p><p class="c11"><span class="c2">Contribution 2 (Section 3): We propose an inaccuracy require- ment on personal reconstruction as a new privacy criterion called reconstruction privacy. This criterion imposes a minimum value </span></p><p class="c6"><span class="c2">for the best upper bound on Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">for the actual and estimated frequency f and F </span><span class="c3">0 </span><span class="c2">of a sensitive value in a personal reconstruction, where and are privacy parameters. Note that </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f </span><span class="c2">be </span><span class="c8">f </span><span class="c2">confused </span><span class="c1">is the error of the reconstruction for f, which should not </span><span class="c2">with the relative increase of the attacker&rsquo;s belief such as the -likeness [7], (n, t)-closeness [17] and (c,2)-diversity [4]. This criterion does not bound the maximum value of F </span><span class="c3">0 </span><span class="c2">or f or re- quire them to be close to the global distribution, making it suitable for learning statistical relationships through aggregate reconstruc- tion. Also, this criterion avoids modeling the prior of an adversary, which can be tricky as shown in [10][11]. </span></p><p class="c11"><span class="c2">Contribution 3 (Sections 4): We present an efficient test of re- construction privacy. First, we show a conversion between an upper bound for the tail probability of Poisson trials into an upper bound </span></p><p class="c6"><span class="c2">on Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c11"><span class="c2">i</span><span class="c13">. Then, we obtain an efficient test of reconstruc- </span><span class="c2">tion privacy by adapting the notion of reconstruction privacy to an existing upper bound for Poisson trials, i.e., the Chernoff bound. </span></p><p class="c11"><span class="c2">Contribution 4 (Section 5): We present an efficient algorithm for producing a perturbed version D</span><span class="c3">&#8676; </span><span class="c2">that satisfies a given specifi- cation of reconstruction privacy. The algorithm is highly efficient because it only needs to sort the records once and make another scan on the sorted data. </span></p><p class="c11"><span class="c2">Contribution 5 (Section 6): We evaluate two claims. The first claim is that reconstruction privacy could be violated by real life data sets even after data perturbation. The second claim is that the proposed method can preserve utility for statistical learning while providing reconstruction privacy. </span></p><p class="c6"><span class="c31">2. OBSERVATIONS ON DIFFERENTIAL PRI- </span></p><p class="c6"><span class="c31">VACY </span><span class="c2">In this section, we answer the question under what condition- s would differentially private answers disclose sensitive informa- tion through NIR? The standard &#9999;-differential privacy mechanis- m [10] ensures that, for any two data sets D</span><span class="c5">1 </span><span class="c13">and D</span><span class="c5">2 </span><span class="c13">differing </span><span class="c2">on at most one record, for all queries Q of interest, and for any value &crarr; in the range for noisy answers, Pr[K(D</span><span class="c5">1</span><span class="c13">,Q) = &crarr;] &#63743; </span><span class="c2">exp(&#9999;) Pr[K(D</span><span class="c8">2</span><span class="c2">,Q) = &crarr;], where K(D</span><span class="c8">i</span><span class="c2">,Q) is a noisy answer a +&#8672; for the actual answer a and a random noise &#8672; following some distribution. The scale E[1&#8672;1] of noises depends on the query class and the privacy parameter &#9999;. The purpose of the noise is to mask the impact of a single record on query answers. </span></p><p class="c11"><span class="c2">Let us construct a disclosure by differentially private answers. Let SA denote the sensitive attribute (e.g., diseases) and NA de- note the public attributes. Suppose that an adversary tries to deter- mine whether a participating individual t has a particular value sa on SA. Let t.NA denote the values for t on NA, which is known to the adversary. The adversary issues two count queries: </span></p><p class="c6"><span class="c2">Q</span><span class="c5">1 </span><span class="c13">:NA = t.NA </span><span class="c2">Q</span><span class="c5">2 </span><span class="c13">:NA = t.NA ^ SA = sa </span><span class="c2">(2) </span></p><p class="c23"><span class="c2">Let X = x + &#8672;</span><span class="c5">1 </span><span class="c13">and Y = y + &#8672;</span><span class="c5">2 </span><span class="c13">be the noisy answers for Q</span><span class="c5">1 </span><span class="c2">and Q</span><span class="c5">2 </span><span class="c13">returned </span><span class="c2">x and y are and </span><span class="c8">Y</span><span class="c5">X </span><span class="c2">= </span><span class="c3">y</span><span class="c8">x </span><span class="c5">x+&#8672;</span><span class="c3">y+&#8672;</span><span class="c1">represents </span><span class="c39">2 </span><span class="c0">1 </span><span class="c2">The intuition any &#8672;</span><span class="c8">i </span><span class="c2">of a decrease and cation specific), </span><span class="c13">by the &#9999;-differential privacy mechanism, where </span><span class="c2">actual </span><span class="c1">the </span><span class="c2">answers </span><span class="c1">chance </span><span class="c2">and </span><span class="c1">that </span><span class="c2">&#8672;</span><span class="c8">i</span><span class="c2">&rsquo;s </span><span class="c1">t has </span><span class="c2">are </span><span class="c1">the </span><span class="c2">the </span><span class="c1">sa </span><span class="c2">noises. </span><span class="c1">value on </span><span class="c2">Note </span><span class="c1">SA. </span><span class="c3">y</span><span class="c8">x </span><span class="c1">&#63743; Note 1 </span></p><p class="c6"><span class="c2">= fixed </span><span class="c3">y/x+&#8672;</span><span class="c8">1+&#8672;</span><span class="c2">that scale, </span><span class="c0">1</span><span class="c8">/x </span><span class="c39">2</span><span class="c8">X </span><span class="c3">Y/x </span></p><p class="c16"><span class="c1">may </span><span class="c2">as </span><span class="c1">. </span><span class="c3">Y</span><span class="c8">X </span><span class="c1">approaches </span><span class="c2">the adversary </span><span class="c1">lead to a disclosure is as follows. For </span><span class="c2">the answer </span><span class="c8">x</span><span class="c3">y</span><span class="c1">. </span><span class="c2">learns </span><span class="c1">If </span><span class="c3">y</span><span class="c8">x </span><span class="c1">is </span><span class="c2">that </span><span class="c1">large </span><span class="c2">x increases, t </span><span class="c1">enough </span><span class="c2">has the </span><span class="c1">(which </span><span class="c2">&#8672;</span><span class="c8">2</span><span class="c2">/x sensitive and </span><span class="c1">is appli- </span><span class="c2">value &#8672;</span><span class="c8">1</span><span class="c2">/x </span></p><p class="c11"><span class="c2">sa with a high probability. This construction is general because it does not assume record correlation and does not depend on the noise distribution except that the noises have a fixed scale. Below, we formalize this intuition. First, we show a lemma. </span></p><p class="c11"><span class="c2">L</span><span class="c15">EMMA </span><span class="c2">1. Let x and y be the true answers to Q</span><span class="c5">1 </span><span class="c13">and Q</span><span class="c5">2</span><span class="c13">, </span><span class="c2">x = 0. Let X = x + &#8672;</span><span class="c5">1 </span><span class="c13">and Y = y + &#8672;</span><span class="c5">2 </span><span class="c13">be the noisy answers </span><span class="c2">for Q</span><span class="c8">1 </span><span class="c2">and Q</span><span class="c8">2 </span><span class="c2">with the noises &#8672;</span><span class="c8">i </span><span class="c2">having the zero mean and the variance V . Then </span></p><p class="c6"><span class="c2">E[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] &#39; </span><span class="c3">y</span><span class="c8">x</span><span class="c1">(1 + </span><span class="c8">x</span><span class="c3">V</span><span class="c12">2 </span><span class="c1">) and V ar[ </span><span class="c8">X</span><span class="c3">Y</span><span class="c1">] &#39; </span><span class="c8">x</span><span class="c3">V</span><span class="c12">2 </span><span class="c1">(1 + </span><span class="c3">y</span><span class="c8">x</span><span class="c12">22 </span><span class="c1">) </span><span class="c2">P</span><span class="c15">ROOF</span><span class="c2">. Note that E[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] is not equal to </span><span class="c8">E[X]</span><span class="c3">E[Y ] </span></p><p class="c6"><span class="c1">. Using the Taylor </span><span class="c2">expansion mated as follows: </span></p><p class="c6"><span class="c2">technique [18, 19], E[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] and V ar[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] can be approxi- </span></p><p class="c6"><span class="c2">E[X </span><span class="c1">Y] &#39; E[Y ] </span></p><p class="c6"><span class="c2">E[X] </span><span class="c1">+ cov[X, Y ] </span></p><p class="c6"><span class="c2">E[X]</span><span class="c3">2 </span><span class="c1">+ V ar[X]E[Y </span><span class="c2">E[X]</span><span class="c3">3 </span></p><p class="c6"><span class="c1">] </span></p><p class="c6"><span class="c29">471 </span></p><p class="c6"><span class="c2">2E[Y V ar[ X </span><span class="c1">Y] &#39; V ar[Y ] </span></p><p class="c6"><span class="c2">E[X]</span><span class="c3">2 </span></p><p class="c6"><span class="c2">E[X]</span><span class="c3">3 </span><span class="c2">] </span></p><p class="c6"><span class="c1">cov[X, Y ] + </span><span class="c2">E[X]</span><span class="c1">E[Y ]</span><span class="c3">2 </span></p><p class="c6"><span class="c3">4 </span><span class="c1">V ar[X] </span></p><p class="c11"><span class="c2">The error of the approximation is the remaining terms of the Taylor expansion that are dropped. E[X] = x and E[Y ] = y (because noises have the zero mean), V ar[X] = V ar[Y ] = V , and the covariance cov[X, Y ] = cov[x + &xi;</span><span class="c5">1</span><span class="c13">,y + &xi;</span><span class="c5">2</span><span class="c13">] = cov[&xi;</span><span class="c5">1</span><span class="c13">,&xi;</span><span class="c5">2</span><span class="c13">]. Since </span><span class="c2">&xi;</span><span class="c8">1 </span><span class="c2">and &xi;</span><span class="c8">2 </span><span class="c2">are unrelated, cov[&xi;</span><span class="c8">1</span><span class="c2">,&xi;</span><span class="c8">2</span><span class="c2">]=0. Substantiating these into the required. </span></p><p class="c6"><span class="c2">above equations and simplifying, we get E[ </span><span class="c8">X</span><span class="c3">Y</span><span class="c1">] and V ar[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] as </span></p><p class="c6"><span class="c2">For any noise distribution with the zero mean and a fixed vari- ance V , as the query proaches proaching stances X </span><span class="c3">y</span><span class="c8">x </span><span class="c3">y</span><span class="c2">and </span><span class="c8">x </span><span class="c1">and does </span><span class="c2">Y </span><span class="c1">V </span><span class="c2">. ation summarized of </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">from E[ </span><span class="c2">in the answer </span><span class="c1">ar[ not </span><span class="c8">X</span><span class="c3">Y</span><span class="c1">entail ] </span><span class="c2">However, </span><span class="c1">approaches </span><span class="c2">x increases, </span><span class="c1">zero. </span><span class="c8">x</span><span class="c3">V</span><span class="c12">2 </span><span class="c1">In decreases, general, </span><span class="c3">Y</span><span class="c2">if </span><span class="c8">X </span><span class="c2">V </span><span class="c3">Y</span><span class="c2">next </span><span class="c8">X </span><span class="c1">] approaches </span><span class="c2">corollary. </span></p><p class="c23"><span class="c1">approaching </span><span class="c2">ar[ </span><span class="c1">zero, </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] approaches </span><span class="c3">Y</span><span class="c8">X </span><span class="c3">y</span><span class="c8">x</span><span class="c1">, for particular E[ E[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] ] ap- ap- in- zero, the devi- approaches </span><span class="c3">y</span><span class="c8">x</span><span class="c1">. This is </span></p><p class="c6"><span class="c2">C</span><span class="c15">OROLLARY </span><span class="c2">1. For any noise distribution with the zero mean and a fixed variance V , as the query answer x increases, proaches </span><span class="c3">y</span><span class="c8">x</span><span class="c1">. </span></p><p class="c6"><span class="c3">Y</span><span class="c8">X </span><span class="c1">ap- </span></p><p class="c23"><span class="c2">To our knowledge, Corollary 1 covers all noise distributions em- ployed by the differential privacy mechanism, including Laplace mechanism [10], Gaussian mechanism [20], and Matrix mechanis- m [21], because these distributions have a zero mean and a fixed variance. nough </span><span class="c8">1</span><span class="c2">er </span><span class="c5">2b</span><span class="c2">To see how exp( for |&xi;|/b), </span><span class="c3">y</span><span class="c8">x</span><span class="c1">, let us consider </span><span class="c2">but a large x </span><span class="c1">the </span><span class="c2">is needed </span><span class="c1">Laplace </span><span class="c2">for </span><span class="c1">mechanism </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">to </span><span class="c2">similar analysis can be performed mechanisms. b is the scale factor. Lap(b) has </span><span class="c1">be accurate e- Lap(b) = </span><span class="c2">for oth- the zero mean and the variance V = 2b</span><span class="c3">2</span><span class="c2">. The setting b = </span><span class="c25">&#8710;</span><span class="c2">/e ensures e- differential privacy, where </span><span class="c25">&#8710; </span><span class="c2">is the sensitivity of the queries of in- terest, which roughly denotes the worst-case change in the query answer on changing one record in any possible database. </span><span class="c25">&#8710; </span><span class="c2">is a property of the queries, not a property of the database. Hence, V is fixed for a given query class and Corollary 1 applies to Lap(b). Substituting </span><span class="c3">y</span><span class="c8">x </span><span class="c1">&#63743; 1 and </span><span class="c3">V</span><span class="c8">x</span><span class="c12">2 </span><span class="c1">= </span><span class="c3">2b</span><span class="c12">2 </span></p><p class="c6"><span class="c8">x</span><span class="c12">2 </span><span class="c1">= 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c23"><span class="c8">2 </span><span class="c13">into Lemma 1 and </span><span class="c2">simplifying, in terms of we get a simple the scale factor b bound and the on query |E[ </span><span class="c8">X</span><span class="c3">Y</span><span class="c2">answer </span><span class="c1">] </span><span class="c3">y</span><span class="c8">x</span><span class="c1">| </span><span class="c2">x </span><span class="c1">and </span><span class="c2">(but </span><span class="c1">V </span><span class="c2">not </span><span class="c1">ar[ </span><span class="c2">the </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] </span></p><p class="c6"><span class="c2">privacy parameter e or the sensitivity </span><span class="c25">&#8710; </span><span class="c2">of queries). </span></p><p class="c11"><span class="c2">C</span><span class="c15">OROLLARY </span><span class="c2">2. Let X and Y be the noisy answers for actual answers x and y, where the noises follow the Laplace distribution Lap(b). (i) |E[ </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] </span><span class="c8">x</span><span class="c3">y</span><span class="c1">| &#63743; 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2</span><span class="c13">. (ii) V ar[ </span><span class="c5">X </span><span class="c8">Y</span><span class="c2">] &#63743; 4 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2</span><span class="c13">. </span></p><p class="c6"><span class="c2">Table 2: 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2 </span></p><p class="c6"><span class="c10">b = </span><span class="c49">(</span><span class="c10">10 b </span></p><p class="c23"><span class="c41">(</span><span class="c10">(e </span><span class="c41">(</span><span class="c10">= x </span><span class="c41">( </span><span class="c10">0.2) </span><span class="c34">5000 </span><span class="c10">0.000008 </span><span class="c34">1000 500 200 100 </span><span class="c10">0.0002 0.0008 0.005 0.02 b = 20 (e = 0.1) 0.000032 0.0008 0.0032 0.02 0.08 b = 40 (e = 0.05) 0.000128 0.0032 0.0128 0.08 0.32 b = 200 (e = 0.01) 0.0032 0.08 0.32 2 8 </span></p><p class="c6"><span class="c2">Thus, the value of 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2 </span><span class="c13">is an indicator of how close </span><span class="c8">Y</span><span class="c5">X </span><span class="c2">is to </span><span class="c8">y</span><span class="c5">x</span><span class="c2">. Table 2 shows the values of 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c11"><span class="c8">2 </span><span class="c13">for various query answers x </span><span class="c2">and settings of b (within the brackets is the corresponding privacy parameter e for the setting of </span><span class="c25">&#8710; </span><span class="c2">= 2, which accounts for answer- ing the two queries Q</span><span class="c5">1 </span><span class="c13">and Q</span><span class="c5">2 </span><span class="c13">in a row). The boldface highlights </span><span class="c2">where 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2 </span><span class="c13">is small enough so that </span><span class="c8">Y</span><span class="c5">X </span><span class="c2">is a good indicator of </span><span class="c8">x</span><span class="c3">y</span><span class="c1">. </span><span class="c2">Take (b = 20,x = 500) as an example where 2 </span><span class="c3">b</span><span class="c8">x </span></p><p class="c6"><span class="c8">2 </span><span class="c13">= 0.0032. </span></p><p class="c23"><span class="c2">|E[ </span><span class="c3">Y</span><span class="c2">Indeed, </span><span class="c8">X </span><span class="c1">] </span><span class="c2">Corollary </span><span class="c8">x</span><span class="c3">y</span><span class="c1">| &#63743; 0.0032 and </span><span class="c2">2 quantifies </span><span class="c1">V </span><span class="c2">a </span><span class="c1">ar[ </span><span class="c2">condition </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">] &#63743; 0.0032 &#8677; 2 = 0.0064. </span><span class="c2">of the occurrence of dis- closures in terms of </span><span class="c8">x</span><span class="c3">b</span><span class="c1">: as a rule of thumb, a ratio </span><span class="c3">b</span><span class="c8">x </span><span class="c1">&#63743; </span><span class="c3">1</span><span class="c8">20 </span><span class="c1">would </span><span class="c2">ensure that </span><span class="c8">X </span><span class="c3">Y</span><span class="c1">is a good indicator of </span><span class="c8">x </span><span class="c3">y</span><span class="c1">because 2 </span><span class="c3">b</span><span class="c8">x 2 </span><span class="c13">&#63743; </span><span class="c2">this sitive case, disclosure if </span><span class="c3">y</span><span class="c8">x </span><span class="c1">is </span><span class="c2">would </span><span class="c1">high enough </span><span class="c2">occur through </span><span class="c1">to be considered </span><span class="c2">accessing </span><span class="c1">as </span><span class="c2">noisy </span><span class="c1">sensitive, </span><span class="c2">answers </span><span class="c8">2</span><span class="c5">400</span><span class="c1">a </span><span class="c2">. </span><span class="c1">sen- </span><span class="c2">In </span></p><p class="c11"><span class="c2">X and Y . This condition also suggests that such disclosures cannot be avoided by choosing a large scale factor b if the actual answer x can be arbitrarily large. </span></p><p class="c11"><span class="c2">We end this section with an explicit acknowledgement of disclo- sures by differential privacy from [10]: &ldquo;Note that a bad disclosure can still occur, but our guarantee assures the individual that it will not be the presence of her data that causes it, nor could the disclo- sure be avoided through any action or inaction on the part of the user&rdquo;. In the rest of the paper, we present an approach to avoid the disclosures of NIR in a data perturbation approach. This effort can be considered as an action on the part of the data publisher. </span></p><p class="c6"><span class="c31">3. PROBLEM STATEMENT </span></p><p class="c6"><span class="c2">We define our model of data perturbation, privacy criterion, and the problems we will study. </span></p><p class="c6"><span class="c31">3.1 Data Perturbation </span></p><p class="c11"><span class="c2">As in [7, 9, 22], we consider a table D that has one sensitive (pri- vate) attribute denoted by SA and several pubic attributes denoted by NA = {A</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,A</span><span class="c5">n</span><span class="c13">}. We assume that the domain of SA has </span><span class="c2">m &gt; 2 sensitive values, sa</span><span class="c8">1</span><span class="c2">,&middot;&middot;&middot; , sa</span><span class="c8">m</span><span class="c2">. </span></p><p class="c11"><span class="c2">Assumptions. To hide the SA information of a record, we per- turb the SA value but keep the attributes in NA unchanged in a record. We assume that an adversary has no prior knowledge on positive correlation between NA and SA; otherwise, the public in- formation on NA already discloses the information about SA. The adversary can have prior knowledge on correlation among the at- tributes in NA, which presents no problem because we never mod- ify the attributes in NA. We also assume that an adversary has no prior knowledge about correlation among SA of different records. This assumption can be satisfied by including exactly one record from a set of correlated records, as suggested in [23]. </span></p><p class="c6"><span class="c2">Prior knowledge on negative correlation [24] deserves some more explanations. Consider the negative correlation &ldquo;females do not have prostate cancer&rdquo;. This correlation tells that the observed prostate cancer is not the original SA value for a female, but does not tell what is the original value because each of the remaining m 1 values has an equal probability. For this reason, we assume that m is larger than 2 (or even larger) so that guessing a remaining value has enough uncertainty. We should emphasize that this situation is not unique for data perturbation, and differentially private answers have similar issues: if the noisy answer for the query on &ldquo;Female and Prostate Cancer&rdquo; is -5 (or more generally, too small according to prior knowledge), the above negative correlation would disclose a small range of the noise added, i.e., -5 or less, after observing the noisy answer, which invalids the Laplace distribution assump- tion. In general, if too much information is leaked through prior knowledge, no mechanism will work. </span></p><p class="c11"><span class="c2">One criticism on distinguishing SA and NA is that such distinc- tion can be tricky sometimes. This deserves some clarification as well. One approach that does not make such distinction is treat- ing all attributes as sensitive attributes and randomizing a record over the Cartesian product of the domains of all attributes [25][23]. Unfortunately, this approach is vulnerable to undoing the random- ization by removing &ldquo;infeasible&rdquo; records added during randomiza- tion. An example of infeasible records is (Age=1, Job=prof, Dis- </span></p><p class="c6"><span class="c29">472 </span></p><p class="c11"><span class="c2">vantage not to use a record that is known not belonging to Bob. In Section 3.4 we will consider the case where further information is available to the adversary and using additional records not be- longing to Bob may help the adversary. An analogy is short-listing the suspect of a robbery: if the eyewitness has reported that the suspect was a male blonde caucasians (i.e., the public attributes), it makes sense to focus on the subset of male blonde caucasian- s in the police database, instead of examining all male caucasians records. The above observation motivates the following two types of reconstruction. </span></p><p class="c11"><span class="c2">D</span><span class="c15">EFINITION </span><span class="c2">1. A personal reconstruction refers to estimating the frequencies of the SA values in a personal group g based on the perturbed g</span><span class="c3">&#8676;</span><span class="c2">. An aggregate reconstruction refers to estimating the frequencies of the SA values in an aggregate group g based on the perturbed g</span><span class="c3">&#8676;</span><span class="c2">. </span><span class="c25">2 </span></p><p class="c11"><span class="c2">We consider a personal reconstruction as the source of privacy concern because it aims specifically at an individual by matching all the individual&rsquo;s public information. In contrast, we consider an aggregate reconstruction as the source of utility because it aims at a larger population without specifically targeting a particular indi- vidual. These different roles of reconstruction are stated in the next principle. </span></p><p class="c11"><span class="c2">D</span><span class="c15">EFINITION </span><span class="c2">2 (S</span><span class="c15">PLIT </span><span class="c2">R</span><span class="c15">OLE </span><span class="c2">P</span><span class="c15">RINCIPLE</span><span class="c2">). A personal recon- struction aims specifically at a particular individual and is respon- sible for privacy violation. An aggregate reconstruction aims at a larger population and is responsible for providing utility. As far as privacy protection is concerned, it suffices to ensure that personal reconstruction is not accurate. </span><span class="c25">2 </span></p><p class="c6"><span class="c2">Remarks. The Split Role Principle provides only a relative pri- vacy guarantee because some disclosure can still occur to an indi- vidual through aggregate reconstruction in the name of utility, such as &ldquo;females tend to have breast cancer (compared to males)&rdquo;. But our principle assures the individual that such disclosures are not specifically targeting him or her, and those that do (i.e., personal reconstruction) have been made unreliable. In fact, any statistical database with any non-trivial utility incurs some amount of dis- closure [10]. Our principle assures that only a limited amount of disclosure is incurred by enabling non-trivial utility. </span><span class="c31">3.3 Reconstruction Privacy </span></p><p class="c11"><span class="c2">Under the Split Role Principle, our privacy guarantee is that all personal reconstructions are not effective for learning the informa- tion about SA. To formalize this guarantee, consider a personal group g</span><span class="c3">&#8676; </span><span class="c2">and g, and a particular SA value sa. Let f denote the fre- quency of sa in g and let F </span><span class="c3">0 </span><span class="c2">denote the estimate of f obtained from the personal reconstruction based on g</span><span class="c3">&#8676;</span><span class="c2">. Note that F</span><span class="c3">0 </span><span class="c2">is a random variable because D</span><span class="c3">&#8676; </span><span class="c2">is a result of coin tosses. </span><span class="c3">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">is the relative </span><span class="c2">error of F </span><span class="c3">0</span><span class="c2">. A larger uncertainty in using F</span><span class="c3">0 F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c23"><span class="c1">means that an adversary faces more </span><span class="c2">to gauge of the likelihood of sa for an indi- vidual. The next definition formalizes an &ldquo;inaccuracy requirement&rdquo; on </span><span class="c3">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">. </span></p><p class="c23"><span class="c2">D</span><span class="c15">EFINITION </span><span class="c2">3 (R</span><span class="c15">ECONSTRUCTION </span><span class="c2">P</span><span class="c15">RIVACY</span><span class="c2">). Let &gt; 0 and 2 [0,1]. sa is ( , )-reconstruction-private in a personal group g</span><span class="c3">&#8676; </span><span class="c2">if Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i &lt; U or Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f </span><span class="c2">ease=HIV) since a 1-year child can not possibly be a professor, so the adversary can easily tell that this record was added by random- ization. Treating Age and Job as public attributes and randomiz- ing only Disease can avoid this problem. In general, treating and randomizing more attributes like sensitive ones when they are ac- tually public attributes would introduce more vulnerabilities to the removal of &ldquo;infeasible&rdquo; records. In this sense, randomizing only the truly sensitive attribute actually provides more protection. </span></p><p class="c23"><span class="c2">We produce the perturbed version D</span><span class="c3">&#8676; </span><span class="c2">of D by applying uniform perturbation [25][16][6] on SA as follows. For a given retention probability p, where 0 &lt; p &lt; 1, for each record in D, we toss a coin with head probability p. If the coin lands on head, retain the SA value in the record; if the coin lands on tail, replace the SA value in the record with a value picked from the domain of SA with equal is characterized probability by (i.e., the following </span><span class="c3">1 </span><span class="c8">m </span><span class="c3">p</span><span class="c1">) at random. </span><span class="c2">matrix </span><span class="c8">f </span><span class="c1">&lt; This perturbation operator </span><span class="c25">P</span><span class="c5">m&#8677;m</span><span class="c13">: </span></p><p class="c6"><span class="c25">P</span><span class="c5">ji </span><span class="c13">= </span></p><p class="c6"><span class="c2">&#8674; </span><span class="c13">p </span><span class="c8">1 </span><span class="c13">+ </span><span class="c8">p1 p</span><span class="c5">m m </span><span class="c2">if j=i (retain sa</span><span class="c8">i</span><span class="c2">) </span></p><p class="c6"><span class="c2">if j=i (perturb sa</span><span class="c5">i </span><span class="c13">to sa</span><span class="c5">j</span><span class="c13">) </span><span class="c2">(3) </span></p><p class="c6"><span class="c2">A proper choice of the retention probability p can ensure some privacy requirements, such as &#8674;</span><span class="c8">1</span><span class="c2">-&#8674;</span><span class="c8">2 </span><span class="c2">privacy [6][25]. We end this section with a comparison between output perturbation and data perturbation in the current work. In output perturbation, such as the differential privacy approach, a noise is added to the query an- swer and the noisy answer is used as is. For this reason, a small and fixed noise scale is essential for good utility. As discussed in Sections 1.1 and 2, as the data size increases, such noises are vul- nerable to NIR. In data perturbation, the SA value in each record is perturbed independently and the original distribution of SA must be reconstructed from the perturbed records by taking into account the perturbation operation performed. As the data size increases, the number of record perturbation increases proportionally, which is less vulnerable to NIR. In addition, data perturbation is more a- mendable to record insertion because each record is perturbed inde- pendently and the reconstruction is performed by the user himself. In contrast, updating (published) noisy query answers can be tricky because a new record could affect multiple queries and a correlated change of query answers can be exploited by the adversary to learn the information about the new record. </span><span class="c31">3.2 Types of Reconstruction </span></p><p class="c23"><span class="c2">We adopt the following notation. Let NA = {A</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,A</span><span class="c5">n</span><span class="c13">}. </span><span class="c2">For 1 &#63743; i &#63743; n, let x</span><span class="c8">i </span><span class="c2">be either a domain value of A</span><span class="c8">i </span><span class="c2">or a wildcard, denoted by , that matches every domain value of A</span><span class="c5">i</span><span class="c13">. D(x</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,x</span><span class="c5">n</span><span class="c13">) </span><span class="c2">denotes and D</span><span class="c3">&#8676;</span><span class="c2">(xthe </span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; </span><span class="c2">subset </span><span class="c13">,x</span><span class="c5">n</span><span class="c13">) </span><span class="c2">of </span><span class="c13">denotes </span><span class="c2">records </span><span class="c13">the </span><span class="c2">in </span><span class="c13">corresponding </span><span class="c2">D that match </span><span class="c13">subset </span><span class="c2">x</span><span class="c8">i </span><span class="c2">on </span><span class="c13">for </span><span class="c2">every </span><span class="c13">D</span><span class="c8">&#8676;</span><span class="c13">. </span><span class="c2">A</span><span class="c8">i</span><span class="c2">, </span><span class="c13">If, </span><span class="c2">for 1 &#63743; i &#63743; n, x</span><span class="c8">i </span><span class="c2">is a non-wildcard, D(x</span><span class="c8">1</span><span class="c2">,&middot;&middot;&middot; ,x</span><span class="c8">n</span><span class="c2">) is a per- sonal group. If at least one x</span><span class="c5">i </span><span class="c13">is a wildcard, D(x</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,x</span><span class="c5">n</span><span class="c13">) is </span><span class="c2">an aggregate group. For example, for NA = {Gender, J ob}, D(male, eng) is a personal group and D( , eng) is an aggregate group. Intuitively, a personal group contains all records that can not be distinguished by any information other than SA. For exam- ple, even if an adversary may know the age of Bob, this informa- tion is not helpful to distinguish any record in the personal group D(male, eng) because all records in the personal group are exactly identical on NA. Without confusion, we call both D(xand D(x</span><span class="c8">1</span><span class="c2">,&middot;&middot;&middot; ,x</span><span class="c8">n</span><span class="c2">)</span><span class="c3">&#8676; </span><span class="c2">a personal or aggregate group as </span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; </span><span class="c2">there </span><span class="c13">,x</span><span class="c2">is </span><span class="c5">n</span><span class="c13">) </span><span class="c2">an one-to-one correspondence between the two. </span></p><p class="c11"><span class="c2">In Example 2, we argued that the personal groupD</span><span class="c3">&#8676;</span><span class="c2">(male, eng) should be used to quantify the risk of inferring the disease breast cancer for the male engineer Bob, instead of the aggregate group- s D</span><span class="c3">&#8676;</span><span class="c2">( , eng), D</span><span class="c3">&#8676;</span><span class="c2">(male, ), or D</span><span class="c3">&#8676;</span><span class="c2">( , ). The rationale is that unless further information is available, it is to the adversary&rsquo;s ad- </span></p><p class="c6"><span class="c2">i </span></p><p class="c11"><span class="c2">&lt; L, for some U and L, implies &#63743; min{U, L}. A personal group g</span><span class="c3">&#8676; </span><span class="c2">is ( , )- reconstruction-private if every sa is ( , )-reconstruction-private in g</span><span class="c3">&#8676;</span><span class="c2">. D</span><span class="c3">&#8676; </span><span class="c2">is ( , )-reconstruction-private if every personal group g</span><span class="c3">&#8676; </span><span class="c2">is ( , )-reconstruction-private. (All probabilities are taken over the space of coin tosses during the perturbation of SA values.) </span><span class="c25">2 </span></p><p class="c6"><span class="c29">473 </span></p><p class="c6"><span class="c2">Note that reconstruction privacy is a property of the perturba- tion matrix </span><span class="c25">P</span><span class="c2">, not a property of a particular instance of D</span><span class="c3">&#8676;</span><span class="c2">. In plain words, ( , )-reconstruction-privacy ensures that the small- est upper bound is not less than ; in this sense, the adversary has difficulty to get an accurate estimate of f, and the larger or is, the greater this difficulty is. As an example, violating (0.3,0.3)-reconstruction-privacy by g</span><span class="c3">&#8676; </span><span class="c2">means that the adversary can get a smaller-than-0.3 upper bound on Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; 0.3i </span></p><p class="c6"><span class="c2">or Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&lt; 0.3i</span><span class="c2">. This implies at least one of the following: </span></p><p class="c6"><span class="c2">Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&#63743; 0.3i </span></p><p class="c6"><span class="c2">70%, where F </span><span class="c3">0 </span><span class="c2">&gt; f Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">0.3i </span></p><p class="c6"><span class="c2">70%, where F </span><span class="c3">0 </span><span class="c2">&lt; f </span></p><p class="c6"><span class="c2">Our definition considers such a high probability of a small error as a potential risk. </span></p><p class="c11"><span class="c2">Remarks. F </span><span class="c3">0 </span><span class="c2">f should not be confused with the change in the posterior belief of an adversary. In fact, f is the probability of sa in the personal group g and F </span><span class="c3">0 </span><span class="c2">is the estimate of f based on the personal reconstruction for g</span><span class="c3">&#8676;</span><span class="c2">, and of the estimate. Our definition considers </span><span class="c3">F </span><span class="c24">0 </span><span class="c8">f </span></p><p class="c23"><span class="c2">a </span><span class="c8">f </span><span class="c2">small </span><span class="c1">is the relative error </span><span class="c2">estimation error as a privacy risk, regardless of the absolute value of f, on the ba- sis that any accurate person reconstruction is potentially a risk be- cause it discloses the actual distribution of SA that aims at a target individual. The choice of the relative error, instead of the abso- lute error, is necessary because a larger actual frequency f requires a larger absolute error for protection. Bounding the accuracy of estimating f, instead of bounding the posterior belief of an adver- sary, has two important benefits: it allows the room for learning statistical relationships (through aggregate reconstruction), and it frees the publisher of measuring the adversary&rsquo;s prior belief and specifying a threshold for posterior beliefs, which can be tricky [10][11]. Finally, the choice of smallest upper bounds, rather than lower bounds, on Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">and Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c11"><span class="c2">i</span><span class="c13">, allows </span><span class="c2">us to leverage the literature on upper bounds for random variables to estimate Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i</span><span class="c13">. </span></p><p class="c6"><span class="c2">D</span><span class="c15">EFINITION </span><span class="c2">4 (E</span><span class="c15">NFORCING </span><span class="c2">P</span><span class="c15">RIVACY</span><span class="c2">). Given a database D, a retention probability p (1 &gt;p&gt; 0) for perturbing SA, and pri- vacy parameters and , devise an algorithm that enforces ( , )- reconstruction-privacy on D</span><span class="c3">&#8676; </span><span class="c2">while preserving aggregate recon- struction as much as possible. </span><span class="c25">2 </span></p><p class="c6"><span class="c2">By leaving the retention probability p as an input parameter to our problem, other privacy criteria, such as &#8674;</span><span class="c8">1</span><span class="c2">-&#8674;</span><span class="c8">2 </span><span class="c2">privacy, can be enforced through a proper choice of p. In this sense, reconstruc- tion privacy can be considered as an additional protection on top of other privacy criteria. </span><span class="c31">3.4 Generalized Personal Groups </span></p><p class="c11"><span class="c2">Consider two personal groups g</span><span class="c3">&#8676; </span><span class="c2">= D(male, eng) and g</span><span class="c3">0&#8676; </span><span class="c2">= D(f emale, eng). Our reconstruction privacy limits the recon- struction for each personal group, but does not limit the reconstruc- tion for the combined g</span><span class="c3">&#8676;</span><span class="c2">[g</span><span class="c3">0&#8676;</span><span class="c2">, i.e., the aggregate group D</span><span class="c3">&#8676;</span><span class="c2">( , eng), because the reconstruction for g</span><span class="c3">&#8676;</span><span class="c2">[g</span><span class="c3">0&#8676; </span><span class="c2">is not relevant to an individ- ual, assuming that males and females have a different distribution on SA, such as on breast cancer. However, this argument may be invalid if the adversary has further knowledge about the distribu- tion of SA values. For example, suppose that FavoriteColor is another public attribute and that the favorite color of an individu- al has nothing to do with the diseases, the adversary may do re- construction after aggregating all personal groups that differ only </span></p><p class="c23"><span class="c2">in the values on FavoriteColor, and such reconstruction is more accurate than the reconstruction based on a single personal group because it uses more randomized records. In this case, aggregate groups disclose sensitive information. To address values x</span><span class="c5">i </span><span class="c2">impact on value, and this issue, for each public attribute </span><span class="c13">and x</span><span class="c8">0</span><span class="c5">i </span><span class="c2">(e.g., male and female) SA, we will merge we define personal x</span><span class="c8">i </span><span class="c2">and groups xbased </span><span class="c3">0</span><span class="c8">i </span><span class="c2">A</span><span class="c5">i</span><span class="c13">, if two domain </span><span class="c2">of A</span><span class="c5">i </span><span class="c13">have the same </span><span class="c1">into a single generalized </span><span class="c2">on such generalized values. With this preprocessing, every generalized value of A</span><span class="c8">i </span><span class="c2">now has a different impact on SA, thus, has a different distribution on SA. Then our previous argument that an aggregate group does not provide a representative statistics for a target individual remain- s valid because such groups combine several sub-populations that follow a different distribution on SA. So the question is how to identify the values of the same impact on SA. To this end, the well studied A</span><span class="c5">i </span><span class="c3">2</span><span class="c13">that </span><span class="c2">-squared </span><span class="c13">have </span></p><p class="c23"><span class="c2">test that tells if two data sets are from different distributions can be used. For two the number of and SA = saOconditioned </span><span class="c8">i </span><span class="c3">0</span><span class="c1">= [o</span><span class="c3">0</span><span class="c8">i1</span><span class="c1">,&middot;&middot;&middot; </span><span class="c2">on disprove, to a domain records </span><span class="c5">j</span><span class="c13">, </span><span class="c1">,o</span><span class="c2">x</span><span class="c5">i </span><span class="c2">certain values in </span><span class="c13">1 &#63743; j </span><span class="c3">0</span><span class="c8">im</span><span class="c13">and </span><span class="c1">], </span><span class="c2">required </span><span class="c13">x</span><span class="c1">which </span><span class="c8">0</span><span class="c5">i</span><span class="c2">D . x</span><span class="c5">i </span><span class="c2">satisfying </span><span class="c13">&#63743; m. and x</span><span class="c8">0</span><span class="c5">i </span><span class="c13">Let </span><span class="c2">A</span><span class="c8">i </span><span class="c2">of </span><span class="c13">O</span><span class="c5">i </span><span class="c2">A= </span><span class="c13">= </span><span class="c5">i</span><span class="c13">, let </span><span class="c2">x</span><span class="c8">i </span><span class="c13">[o</span><span class="c5">i1</span><span class="c13">, o</span><span class="c2">(resp. </span><span class="c5">ij </span><span class="c13">&middot;&middot;&middot; (resp. ,o</span><span class="c2">A</span><span class="c8">i </span><span class="c5">im</span><span class="c13">] o</span><span class="c2">= </span><span class="c8">0</span><span class="c5">ij</span><span class="c2">) </span><span class="c13">and </span><span class="c2">xbe </span><span class="c3">0</span><span class="c8">i</span><span class="c1">) </span></p><p class="c23"><span class="c1">represents the distributions of SA </span><span class="c2">In proper statistical language, can we level of significance, the null hy- pothesis that the population distribution two data sets function? O</span><span class="c8">i </span><span class="c2">Disproving and O</span><span class="c8">i </span><span class="c3">0</span><span class="c1">are drawn from the same </span><span class="c2">the null hypothesis in effect proves Since |O</span><span class="c5">i</span><span class="c13">| </span><span class="c2">ily equal, our that </span><span class="c13">= </span><span class="c2">case Pthe is </span><span class="c5">mj=1 </span><span class="c2">that data o</span><span class="c5">ij </span><span class="c2">of sets </span><span class="c13">and </span><span class="c2">two are </span><span class="c13">|O</span><span class="c2">binned </span><span class="c5">i</span><span class="c8">0</span><span class="c2">from | = </span><span class="c1">P</span><span class="c2">different distributions </span><span class="c8">m</span><span class="c5">j=1 </span><span class="c2">o</span><span class="c3">0</span><span class="c8">ij </span><span class="c2">distributions. </span></p><p class="c23"><span class="c1">are not necessar- </span><span class="c2">with unequal number of data points. In this case, the degree of freedom is equal to m and the </span><span class="c3">2 </span><span class="c2">value is computed as [26]: </span></p><p class="c6"><span class="c8">2 </span><span class="c13">= </span></p><p class="c6"><span class="c2">&#8675;</span><span class="c13">p|O</span><span class="c5">i</span><span class="c8">0</span><span class="c2">|/|O</span><span class="c5">i</span><span class="c13">|o</span><span class="c5">ij </span><span class="c2">p</span><span class="c13">|O</span><span class="c5">i</span><span class="c13">|/|O</span><span class="c5">i</span><span class="c8">0</span><span class="c2">|o</span><span class="c3">0</span><span class="c8">ij</span><span class="c1">&#8984;</span><span class="c8">2 </span></p><p class="c6"><span class="c2">o</span><span class="c5">ij </span><span class="c13">+ o</span><span class="c8">0</span><span class="c5">ij </span><span class="c2">(4) </span></p><p class="c23"><span class="c2">Then we obtain the expected value of </span><span class="c3">2 </span><span class="c2">by checking the chi-square distribution with two parameters, the degree of freedom (e.g., m) and the value of significance, the maximum probability that the computed </span><span class="c3">2 </span><span class="c2">from Equation (4) could be greater than the expected </span><span class="c8">2</span><span class="c13">. We set the conventional setting of 0.05 for significance. If </span><span class="c2">the value computed by Equation (4) is greater than this expected value of </span><span class="c3">2</span><span class="c2">, we can disprove the null hypothesis that the two data sets O</span><span class="c5">i </span><span class="c2">function </span><span class="c13">and </span><span class="c2">because </span><span class="c13">O</span><span class="c5">i </span><span class="c8">0</span><span class="c2">are drawn from the same population distribution the probability for this is less than 5% (i.e., the significance). Otherwise, we consider that the two data sets are consistent with a single distribution function. We represent the </span><span class="c3">2 </span><span class="c2">test results for all pairs A</span><span class="c5">i </span><span class="c13">using a graph. Each value </span><span class="c2">we connect two vertices x</span><span class="c5">i </span><span class="c13">x</span><span class="c5">i </span><span class="c13">and of x</span><span class="c8">0</span><span class="c5">i </span><span class="c13">A</span><span class="c2">if </span><span class="c5">i </span><span class="c2">the </span><span class="c13">is a vertex </span><span class="c3">2 </span><span class="c2">(x</span><span class="c8">i</span><span class="c2">,x</span><span class="c13">in </span><span class="c3">0</span><span class="c8">i</span><span class="c13">the </span><span class="c1">) of </span><span class="c13">graph </span><span class="c1">values </span><span class="c13">and </span><span class="c1">of </span></p><p class="c11"><span class="c2">test on (x</span><span class="c5">i</span><span class="c13">,x</span><span class="c8">0</span><span class="c5">i</span><span class="c2">) fails to disprove the above null hypothesis. Finally, for each connected component of the graph, we merge all the values in the component into a single generalized value. This method ensures that any two values x</span><span class="c5">i </span><span class="c2">on SA. </span></p><p class="c6"><span class="c13">X</span><span class="c8">m</span><span class="c5">j=1 </span></p><p class="c6"><span class="c13">and x</span><span class="c8">0</span><span class="c5">i </span><span class="c2">from different components have a different impact </span></p><p class="c11"><span class="c2">In the rest of the paper, we assume that the domain values of each public attribute A</span><span class="c5">i </span><span class="c13">are generalized values produced by the above </span><span class="c2">merging procedure and that the personal and aggregate groups de- fined in Section 3.2 are based on such generalized domain values. </span></p><p class="c6"><span class="c31">4. TESTING PRIVACY </span></p><p class="c6"><span class="c2">An immediate question is how to test ( , )-reconstruction-privacy. From Definition 3, this requires to obtain the smallest upper bounds U and L on Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">and Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c6"><span class="c2">i</span><span class="c13">. The follow- </span></p><p class="c6"><span class="c29">474 </span></p><p class="c6"><span class="c2">Table 3: Notations </span></p><p class="c6"><span class="c10">Symbols Meaning D, D</span><span class="c3">&#8676; </span><span class="c10">the raw data and perturbed version S, S</span><span class="c3">&#8676; </span><span class="c10">a subset of records and perturbed version g, g</span><span class="c3">&#8676; </span><span class="c10">a personal group and perturbed version m the domain size </span><span class="c35">|</span><span class="c10">SA</span><span class="c35">| </span><span class="c10">t a target individual sa</span><span class="c5">i </span><span class="c34">a domain value of SA </span><span class="c10">f</span><span class="c5">i </span><span class="c34">the frequency of sa</span><span class="c5">i </span><span class="c34">in S </span><span class="c10">o</span><span class="c3">&#8676;</span><span class="c8">i </span><span class="c17">the count of sa</span><span class="c8">i </span><span class="c10">in S</span><span class="c3">&#8676; </span><span class="c10">O</span><span class="c3">&#8676;</span><span class="c8">i </span><span class="c17">the variable for o</span><span class="c3">&#8676;</span><span class="c8">i </span><span class="c34">F </span><span class="c8">0</span><span class="c5">i </span><span class="c10">the variable for the estimate of f</span><span class="c5">i </span><span class="c10">f , F </span><span class="c3">0</span><span class="c10">, O</span><span class="c3">&#8676; </span><span class="c10">the column-vectors of f</span><span class="c5">i</span><span class="c34">, F </span><span class="c8">0</span><span class="c5">i </span><span class="c10">, O</span><span class="c3">&#8676;</span><span class="c8">i </span><span class="c38">P </span><span class="c34">the perturbation matrix in Equation (3) </span><span class="c10">p the retention probability (&lambda;, &delta;) privacy parameters </span></p><p class="c11"><span class="c2">ing discussion refers to a subset S of D and the corresponding subset S</span><span class="c3">&#8676; </span><span class="c2">of D</span><span class="c3">&#8676;</span><span class="c2">. |S| denotes the number of records in S. Let (f</span><span class="c5">1</span><span class="c13">, &middot;&middot;&middot; ,f</span><span class="c5">m</span><span class="c13">) be the frequencies of SA values (sa</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; , sa</span><span class="c5">m</span><span class="c13">) </span><span class="c2">in S, (O</span><span class="c3">&#8676;</span><span class="c8">1</span><span class="c1">,&middot;&middot;&middot; ,O</span><span class="c3">&#8676;</span><span class="c8">m</span><span class="c1">) be the variables for the observed counts of </span><span class="c2">(sa</span><span class="c8">1</span><span class="c2">,&middot;&middot;&middot; , sa</span><span class="c8">m</span><span class="c2">) in S</span><span class="c3">&#8676;</span><span class="c2">, and (F </span><span class="c3">0</span><span class="c8">1</span><span class="c1">,&middot;&middot;&middot; ,F</span><span class="c3">0</span><span class="c8">m</span><span class="c1">) be the variables for an </span><span class="c2">estimate of (f</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,f</span><span class="c5">m</span><span class="c13">) reconstructed using S</span><span class="c8">&#8676;</span><span class="c13">. These vectors </span><span class="c2">are also written as column-vectors f , O</span><span class="c3">&#8676;</span><span class="c2">, and F </span><span class="c3">0</span><span class="c2">. When no con- fusion arises, we drop the subscripts i from f</span><span class="c8">i</span><span class="c2">,O</span><span class="c3">&#8676;</span><span class="c8">i </span><span class="c1">,F </span><span class="c3">0</span><span class="c8">i</span><span class="c1">. Table 3 </span><span class="c2">summarizes the notations used in this paper. </span></p><p class="c6"><span class="c31">4.1 Computing </span><span class="c42">F </span><span class="c9">0 </span></p><p class="c11"><span class="c2">First of all, let us examine the computation of F </span><span class="c3">0</span><span class="c2">. Example 2 illustrates the basic idea of computing the estimate F </span><span class="c3">0 </span><span class="c2">of f for a particular SA value sa based on the perturbed data. Generalizing that idea to the vectors F </span><span class="c3">0 </span><span class="c2">and f , our perturbation operation im- plies the equation </span><span class="c25">P </span><span class="c2">&middot; f = </span><span class="c3">E[ O</span><span class="c24">&#8676;</span><span class="c8">] </span></p><p class="c11"><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c1">, where </span><span class="c19">P </span><span class="c1">is the perturbation ma- </span><span class="c2">trix in Equation (3). Approximating E[ O</span><span class="c3">&#8676;</span><span class="c2">] by the observed counts O</span><span class="c3">&#8676;</span><span class="c2">, we get the estimate of f given by </span><span class="c25">P </span><span class="c3">1 </span><span class="c2">&middot; </span><span class="c3">O</span><span class="c24">&#8676; </span></p><p class="c11"><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c1">, where </span><span class="c19">P </span><span class="c3">1 </span><span class="c2">is the inverse of </span><span class="c25">P</span><span class="c2">. This estimate is called the maximum likelihood estimator (MLE). </span></p><p class="c6"><span class="c2">T</span><span class="c15">HEOREM </span><span class="c2">1 (T</span><span class="c15">HEOREM </span><span class="c2">2, [16]). </span><span class="c25">P </span><span class="c3">1</span><span class="c2">&middot; </span><span class="c3">O</span><span class="c24">&#8676; </span></p><p class="c6"><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c1">is the MLE of f </span><span class="c2">under the constraint that its elements sum to 1. Let F </span><span class="c3">0 </span><span class="c2">denote this MLE. </span><span class="c25">2 </span></p><p class="c6"><span class="c2">The next lemma gives an equivalent computation of F </span><span class="c3">0 </span><span class="c2">without referring to </span><span class="c25">P </span><span class="c3">1</span><span class="c2">. </span></p><p class="c6"><span class="c2">L</span><span class="c15">EMMA </span><span class="c2">2. For any subset S of D and any SA value sa, (i) E[O</span><span class="c3">&#8676;</span><span class="c2">] = |S|(fp + (1 p)/m), (ii) F </span><span class="c3">0 </span><span class="c2">= </span><span class="c3">O</span><span class="c24">&#8676;</span><span class="c8">/</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c8">(1 p)/m </span></p><p class="c6"><span class="c8">p </span><span class="c1">, and </span><span class="c2">(iii) E[F </span><span class="c3">0</span><span class="c2">] = f. </span></p><p class="c6"><span class="c2">P</span><span class="c15">ROOF</span><span class="c2">. (i) O</span><span class="c3">&#8676; </span><span class="c2">comes from two sources of records in S: those that have the SA value sa and are retained, and those that have a SA value other than sa and are perturbed to sa. The expected number of the records in the first source is |S|f(p+(1 p)/m), and the expected number of the records in the second source is |S|(1 f)(1 p)/m). Summing up the two gives E[O</span><span class="c3">&#8676;</span><span class="c2">] = |S|(fp+(1 p)/m). This shows (i). </span></p><p class="c6"><span class="c2">(ii) From Theorem 1, F </span><span class="c3">0 </span><span class="c2">= </span><span class="c25">P </span><span class="c3">1 </span><span class="c2">&middot; </span><span class="c3">O</span><span class="c24">&#8676; </span></p><p class="c6"><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c1">. Let </span><span class="c3">1 p</span><span class="c8">m </span><span class="c1">denote the </span><span class="c2">column-vector of the constant </span><span class="c3">1 p</span><span class="c8">m </span><span class="c1">of length m. We have </span></p><p class="c6"><span class="c2">O</span><span class="c3">&#8676; </span><span class="c2">|S| </span><span class="c1">= </span><span class="c19">P </span><span class="c1">&middot; F </span><span class="c3">0 </span><span class="c2">= p F </span><span class="c3">0 </span><span class="c2">+ </span><span class="c1">1 p</span><span class="c2">m </span></p><p class="c6"><span class="c2">Thus, F </span><span class="c3">0 </span><span class="c2">= </span><span class="c3">O</span><span class="c24">&#8676;</span><span class="c8">/</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c8">(1 p </span><span class="c2">(iii) Taking the mean </span><span class="c8">p)/m </span></p><p class="c23"><span class="c1">, as required for (ii). </span><span class="c2">on both sides of the last equation, E[F</span><span class="c3">0</span><span class="c2">] = get </span><span class="c8">E[O</span><span class="c2">E[F</span><span class="c24">&#8676;</span><span class="c8">]/</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c3">0</span><span class="c2">] </span><span class="c8">p </span><span class="c2">= </span><span class="c8">(1 </span><span class="c2">f. </span><span class="c8">p)/m </span></p><p class="c6"><span class="c2">This </span><span class="c1">. Substituting </span><span class="c2">shows (iii). </span></p><p class="c6"><span class="c1">E[O</span><span class="c3">&#8676;</span><span class="c2">] in (i) and simplifying, we </span></p><p class="c11"><span class="c2">Lemma 2(iii) implies that F </span><span class="c3">0 </span><span class="c2">is an unbiased estimator of f. Lem- ma 2(ii) gives a computation of F </span><span class="c3">0 </span><span class="c2">in terms of the known values O</span><span class="c3">&#8676;</span><span class="c2">, |S|, p, m without referring to </span><span class="c25">P </span><span class="c3">1</span><span class="c2">. In the rest of the paper, we adopt this computation of F </span><span class="c3">0 </span><span class="c2">in the definition of reconstruction privacy (Definition 3). </span></p><p class="c6"><span class="c31">4.2 Bounding </span><span class="c2">Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c39">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span><span class="c32">and </span><span class="c13">Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c39">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">Recall that F </span><span class="c3">0 </span><span class="c2">= </span><span class="c3">O</span><span class="c24">&#8676;</span><span class="c8">/</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c8">(1 p p)/m </span></p><p class="c6"><span class="c1">from Lemma 2(ii). To bound </span><span class="c2">Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">and Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c11"><span class="c2">i</span><span class="c13">, we first obtain the upper </span><span class="c2">bounds for the error of observed O</span><span class="c3">&#8676; </span><span class="c2">and then convert them into the upper bounds for the error of reconstructed F</span><span class="c3">0</span><span class="c2">. The next theorem gives the conversion between these bounds. </span></p><p class="c6"><span class="c2">T</span><span class="c15">HEOREM </span><span class="c2">2 (B</span><span class="c15">OUND </span><span class="c2">C</span><span class="c15">ONVERSION</span><span class="c2">). Consider any subset S of D and any SA value sa with the frequency f in S. Let O</span><span class="c3">&#8676; </span><span class="c2">be the observed count of sa in S</span><span class="c3">&#8676; </span><span class="c2">and let F </span><span class="c3">0 </span><span class="c2">be the MLE of f. Let &mu; = E[O</span><span class="c3">&#8676;</span><span class="c2">]. and for a comparison For any operator functions </span><span class="c1">L </span><span class="c2">U(!,&mu;) that is and L(!,&mu;) of ! and &mu;, </span></p><p class="c6"><span class="c2">either &lt; or &gt;, 1. Pr</span><span class="c1">h </span><span class="c8">O</span><span class="c24">&#8676; </span><span class="c8">&mu; &mu; </span></p><p class="c6"><span class="c1">&gt; !i </span><span class="c2">L</span><span class="c13">U(!,&mu;) if and only if Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">L</span><span class="c13">U(!,&mu;); </span><span class="c2">2. Pr</span><span class="c1">h </span><span class="c8">O</span><span class="c24">&#8676; </span><span class="c8">&mu; &mu; </span></p><p class="c6"><span class="c1">&lt; !i</span><span class="c2">L</span><span class="c13">L(!,&mu;) if and only if Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">L</span><span class="c13">L(!,&mu;). </span><span class="c2">where = </span><span class="c4">|</span><span class="c8">S</span><span class="c4">|</span><span class="c8">pf </span><span class="c3">!&mu; </span></p><p class="c6"><span class="c1">. </span><span class="c2">P</span><span class="c15">ROOF</span><span class="c2">. We show 1) only because the proof for 2) is similar. From (1 F</span><span class="c3">0 </span><span class="c2">= p)/m), </span><span class="c3">O</span><span class="c24">&#8676;</span><span class="c8">/</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span><span class="c8">(1 p)/m </span></p><p class="c23"><span class="c2">and from </span><span class="c8">p </span><span class="c2">Lemma </span><span class="c1">(Lemma 2(ii)), O</span><span class="c3">&#8676; </span><span class="c2">= |S|(F </span><span class="c3">0</span><span class="c2">p + 2(i), &mu; = |S|(fp + (1 p)/m). So </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f </span><span class="c3">O</span><span class="c8">f </span></p><p class="c6"><span class="c24">&#8676; </span><span class="c8">&mu; &mu; </span><span class="c1">&gt; ! , O</span><span class="c3">&#8676; </span><span class="c1">&gt; </span><span class="c4">|</span><span class="c8">S</span><span class="c4">|</span><span class="c8">pf </span><span class="c3">!&mu; </span></p><p class="c6"><span class="c1">. 1) follows </span><span class="c2">&mu; &gt; !&mu; , |S|p(F </span><span class="c3">0 </span><span class="c1">by letting = </span><span class="c4">|</span><span class="c8">S</span><span class="c4">|</span><span class="c8">pf </span><span class="c3">!&mu; </span><span class="c1">. </span></p><p class="c6"><span class="c2">f) &gt; !&mu; , </span></p><p class="c6"><span class="c2">According to Theorem 2, if we have the smallest upper bound- s on Pr </span></p><p class="c6"><span class="c2">h </span><span class="c5">O</span><span class="c28">&#8676; </span><span class="c8">&mu; </span><span class="c5">&mu; </span></p><p class="c6"><span class="c1">&gt; !i </span></p><p class="c6"><span class="c2">or Pr</span><span class="c1">h </span><span class="c8">O</span><span class="c24">&#8676; </span><span class="c8">&mu; &mu; </span></p><p class="c6"><span class="c1">&lt; !i</span><span class="c2">, we immediately have the smallest upper bounds onPr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">or Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c23"><span class="c2">i</span><span class="c13">. </span><span class="c2">This conversion does not hinge functions &lt;) and lower U and bounds L, and (when applies </span><span class="c1">L </span><span class="c2">on the particular form of the to both upper bounds (when is &gt;). Therefore, finding the bound </span><span class="c1">L </span><span class="c2">is small- est upper bounds for F </span><span class="c3">0 </span><span class="c2">is reduced to that for O</span><span class="c3">&#8676;</span><span class="c2">. The latter can benefit from the literature on upper bounds for tail probabilities of Poisson trials. Markov&rsquo;s inequality and Chebyshev&rsquo;s inequality are some early upper bounds, for example. The Chernoff bound, due to [27], is a much tighter bound as it gives exponential fall-off of probability with distance from the error. The following is a simpli- fied yet tight form of the Chernoff bound. </span></p><p class="c11"><span class="c2">T</span><span class="c15">HEOREM </span><span class="c2">3 (C</span><span class="c15">HERNOFF </span><span class="c2">B</span><span class="c15">OUNDS</span><span class="c2">, [27]). Let X</span><span class="c5">1</span><span class="c13">,&middot;&middot;&middot; ,X</span><span class="c5">n </span><span class="c2">be independent Poisson trials such that for 1 &#63743; i &#63743; n, X</span><span class="c8">i </span><span class="c2">2 {0,1}, Pr[X</span><span class="c5">i </span><span class="c13">= 1] = p</span><span class="c5">i</span><span class="c13">, where 0 &lt; p</span><span class="c5">i </span><span class="c13">&lt; 1. Let X = X</span><span class="c5">1 </span><span class="c13">+&middot;&middot;&middot;+ </span><span class="c2">X</span><span class="c5">n </span><span class="c13">and &mu; = E[X] = E[X</span><span class="c5">1</span><span class="c13">] + &middot;&middot;&middot; + E[X</span><span class="c5">n</span><span class="c13">]. For ! 2 (0,1), </span></p><p class="c6"><span class="c2">Pr</span><span class="c1">&#63743;</span><span class="c2">X &mu; &mu; </span></p><p class="c6"><span class="c1">&gt; ! &lt; U(!,&mu;) = exp( </span><span class="c2">2 </span><span class="c1">!</span><span class="c2">+ </span><span class="c3">2</span><span class="c2">&mu; </span></p><p class="c6"><span class="c2">!</span><span class="c1">) (5) </span></p><p class="c6"><span class="c2">and for ! 2 (0,1], </span></p><p class="c6"><span class="c2">Pr </span></p><p class="c6"><span class="c2">&#63743;</span><span class="c13">X </span><span class="c2">&mu; </span><span class="c13">&mu; </span></p><p class="c6"><span class="c1">&lt; ! &lt; L(!,&mu;) = exp( !</span><span class="c13">2 </span><span class="c3">2</span><span class="c2">&mu;).</span><span class="c25">2 </span><span class="c2">(6) </span></p><p class="c6"><span class="c29">475 </span></p><p class="c6"><span class="c2">The observed count O</span><span class="c3">&#8676; </span><span class="c2">of sa in S</span><span class="c3">&#8676; </span><span class="c2">is equal to X = X</span><span class="c5">1 </span><span class="c13">+ </span></p><p class="c6"><span class="c2">&middot;&middot;&middot; in S+ </span><span class="c3">&#8676; </span><span class="c2">has X</span><span class="c8">n</span><span class="c2">, the where value X</span><span class="c8">i </span><span class="c2">sa. is If the the indicator i-th row variable has sa prior whether to perturbation, the i-th row </span></p><p class="c11"><span class="c2">p</span><span class="c8">i </span><span class="c2">= p + (1 p)/m, otherwise, p</span><span class="c8">i </span><span class="c2">= (1 p)/m. E[O</span><span class="c3">&#8676;</span><span class="c2">] = |S|(fp + (1 p)/m) (Lemma 2). To obtain the upper bounds for F</span><span class="c3">0</span><span class="c2">, we instantiate the upper bounds U and L for O</span><span class="c3">&#8676; </span><span class="c2">in Equations (5) and (6) into Theorem 2. This gives the next corollary. </span></p><p class="c6"><span class="c2">C</span><span class="c15">OROLLARY </span><span class="c2">3 (U</span><span class="c15">PPER </span><span class="c2">B</span><span class="c15">OUNDS FOR </span><span class="c2">F </span><span class="c3">0</span><span class="c2">). Let ! = </span><span class="c26">|</span><span class="c3">S</span><span class="c26">|</span><span class="c3">pf </span><span class="c8">&mu; </span><span class="c13">and &mu; = |S|(fp + (1 p)/m). For ! 2 (0,1), </span></p><p class="c6"><span class="c2">Pr </span></p><p class="c6"><span class="c2">&#63743;</span><span class="c13">F </span><span class="c8">0 </span><span class="c2">f </span><span class="c13">f </span></p><p class="c6"><span class="c1">&gt; &lt; U(!,&mu;) = exp( </span><span class="c2">2 </span><span class="c1">!</span><span class="c2">+ </span><span class="c3">2</span><span class="c2">&mu; </span></p><p class="c6"><span class="c2">!</span><span class="c1">) (7) </span></p><p class="c6"><span class="c2">and for ! 2 (0,1], </span></p><p class="c6"><span class="c2">Pr</span><span class="c1">&#63743;</span><span class="c2">F</span><span class="c3">0 </span><span class="c2">f f </span></p><p class="c6"><span class="c1">&lt; &lt; L(!,&mu;) = exp( !</span><span class="c13">2 </span><span class="c3">2</span><span class="c2">&mu;).</span><span class="c25">2 </span><span class="c2">(8) </span></p><p class="c6"><span class="c2">Note that ! = </span><span class="c8">pf+(1 </span><span class="c3">pf </span></p><p class="c23"><span class="c8">p)/m </span><span class="c1">and &mu; = |S|(fp + (1 p)/m). </span><span class="c2">,p,f,m are constants. Reducing |S| decreases &mu;, which increas- es the upper bounds U and L exponentially. Thus, reducing |S| ef- fectively thwarts the attacker from bounding Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">and Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">by a small upper bound. Our enforcement algo- rithm presented in the next section is based on this observation. </span></p><p class="c6"><span class="c2">A remaining question is whether U = exp( </span><span class="c8">2+!</span><span class="c3">!</span><span class="c12">2</span><span class="c8">&mu; </span></p><p class="c23"><span class="c1">) and L = </span><span class="c2">exp( O</span><span class="c3">&#8676; </span><span class="c2">are </span><span class="c3">!</span><span class="c2">the </span><span class="c5">2 </span><span class="c12">2</span><span class="c8">&mu;</span><span class="c2">) smallest in Corollary 3 derived from the Chernoff bound for upper bounds for F</span><span class="c3">0</span><span class="c2">, as required by the defi- nition of ( , )-reconstruction-privacy. Suppose not. There would exist a smaller upper bound U</span><span class="c8">2 </span><span class="c2">on Pr</span><span class="c1">h </span><span class="c8">F </span><span class="c24">0 </span><span class="c8">f f </span></p><p class="c6"><span class="c1">&gt; </span></p><p class="c6"><span class="c2">i </span></p><p class="c6"><span class="c2">or a smaller upper bound L</span><span class="c5">2 </span><span class="c13">on Pr</span><span class="c2">h </span><span class="c5">F </span><span class="c28">0 </span><span class="c8">f </span><span class="c5">f </span></p><p class="c6"><span class="c1">&lt; </span></p><p class="c23"><span class="c2">i</span><span class="c13">. Then Theorem 2 implies </span><span class="c2">that U</span><span class="c5">2 </span><span class="c2">L for O</span><span class="c13">and </span><span class="c3">&#8676;</span><span class="c2">. </span><span class="c13">L</span><span class="c5">2 </span><span class="c13">are better bounds than the Chernoff bounds U and </span><span class="c2">However, the fact that the Chernoff bound remained in use in the past 60 years suggests that finding smaller upper bounds is difficult. Until the Chernoff bound is improved, we assume that the upper bounds U and L in Corollary 3 are the best upper bounds for F </span><span class="c3">0</span><span class="c2">. This assumption is not a real restriction because Theorem 2 allows us to &ldquo;plug in&rdquo; any better bound for O</span><span class="c3">&#8676; </span><span class="c2">for a better bound for F </span><span class="c3">0</span><span class="c2">. If the adversary finds a better bound than the Chernoff bound and the data publisher still uses the Chernoff bound. If the better bound is a general result and the publisher refuses to &ldquo;plug in&rdquo; it, the responsibility is with the publisher. Otherwise, under our assumptions about prior knowledge in Section 3.1, getting a bet- ter bound requires knowledge about the random coin tosses in the perturbation process. Like all randomized mechanisms, we assume that actual results of random trails are not available to the adversary. </span><span class="c31">4.3 Testing </span></p><p class="c23"><span class="c2">With the upper bounds L and U in Corollary 3, it is straightfor- ward to test whether ( , )-reconstruction-privacy holds by testing &#63743; min{L, U}. We can further simplify this test. For ! in the range (0,1], it is easy to see L&lt;U, therefore, &#63743; min{L, U} degenerates into &#63743; L. Substituting the expressions for ! and &mu; in Corollary 3 into L(!,&mu;), we get L = exp( </span><span class="c3">( pf)</span><span class="c12">2</span><span class="c4">|</span><span class="c8">S</span><span class="c4">| </span></p><p class="c6"><span class="c8">2(fp+(1 p)/m)</span><span class="c1">), </span><span class="c2">where range (0,1] is in for the !. range Substituting (0,1+ </span><span class="c3">(1 </span><span class="c2">the </span><span class="c8">pf </span><span class="c3">p)/m </span></p><p class="c23"><span class="c2">expression </span><span class="c1">], which corresponds </span><span class="c2">for L into </span><span class="c1">to the </span><span class="c2">&#63743; L gives rise to the following test of ( , )-reconstruction-privacy. </span></p><p class="c6"><span class="c2">C</span><span class="c15">OROLLARY </span><span class="c2">4. Let sa be a SA value, g be a personal group, and f be the frequency of sa in g. For 2 (0,1 + </span><span class="c3">(1 </span><span class="c8">pf </span><span class="c3">p)/m </span></p><p class="c6"><span class="c1">] and </span></p><p class="c6"><span class="c2">2 [0,1], sa is ( , )-reconstruction-private in g</span><span class="c3">&#8676; </span><span class="c2">if and only if </span></p><p class="c6"><span class="c2">|g| &#63743; </span><span class="c1">2(fp + (1 p)/m) ln </span></p><p class="c6"><span class="c2">( pf)</span><span class="c3">2 </span><span class="c19">2 </span><span class="c1">(9) </span></p><p class="c11"><span class="c2">Given D, the personal groups g and the frequencies f for all SA values in g can be found by sorting the records in D in the order of all attributes in NA followed by SA. Therefore, all the quantities in Equation (9) are either given (i.e., , , p, m) or can be computed efficiently (i.e., f and |g|). A larger |g|,f,p makes this inequality less likely hold, thus, makes ( , )-reconstruction- privacy more likely violated. In fact, under these conditions there are either more random trials or more retention of the SA value, which leads to a more accurate reconstruction. </span></p><p class="c6"><span class="c31">5. ENFORCING PRIVACY </span></p><p class="c11"><span class="c2">If reconstruction privacy is not satisfied, we can restore recon- struction privacy by satisfying the condition in Equation (9) for every SA value and every personal group. Observe that the right- hand side of Equation (9) decreases as f increases. Therefore, a personal group g</span><span class="c3">&#8676; </span><span class="c2">satisfies reconstruction privacy if and only if |g| &#63743; s</span><span class="c5">g</span><span class="c13">, where </span></p><p class="c6"><span class="c2">s</span><span class="c5">g </span><span class="c13">= </span><span class="c2">2(fp + (1 p)/m) ln </span></p><p class="c6"><span class="c2">( pf)</span><span class="c3">2 </span><span class="c1">(10) </span></p><p class="c11"><span class="c2">and f is the maximum frequency for any SA value in g. Anoth- er interpretation is that s</span><span class="c5">g </span><span class="c13">is the maximum number of independent </span><span class="c2">trials if g</span><span class="c3">&#8676; </span><span class="c2">is to satisfy reconstruction privacy. If |g| &gt; s</span><span class="c5">g</span><span class="c13">, re- </span><span class="c2">construction privacy is violated (because of too many independent trails). To fix this, one approach is increasing s</span><span class="c5">g </span><span class="c13">to the current </span><span class="c2">group size |g| by reducing f or p (note that m, , are fixed). This approach is not preferred because reducing f will distort the data distribution and reducing p has a global effect of making the per- turbed data too noisy. Our approach is reducing |g| to the size s</span><span class="c8">g </span><span class="c2">by sampling a subset g</span><span class="c5">1 </span><span class="c13">of the size s</span><span class="c5">g </span><span class="c13">and perturbing g</span><span class="c5">1 </span><span class="c13">instead </span><span class="c2">of g. This sampling essentially reduces the excessive number of independent random trials. To ensure s</span><span class="c5">g</span><span class="c0">1 </span><span class="c2">= s</span><span class="c5">g</span><span class="c13">, g</span><span class="c5">1 </span><span class="c13">must preserve </span><span class="c2">the (relative) frequency of every SA value in g (to the right-hand side of Equation (10) unchanged after sampling). Preserving fre- quencies also helps minimize the distortion to data distribution. Af- ter perturbing the sample g</span><span class="c8">1</span><span class="c2">, a scaling step is needed to scale the perturbed g</span><span class="c3">&#8676;</span><span class="c8">1 </span><span class="c1">back to the original size |g| to minimize the impact </span><span class="c2">on the global distribution. Below, we present an algorithm named Sampling-Perturbing-Scaling (SPS) to meet both the group size re- quirement and the frequency preservation requirement. </span></p><p class="c11"><span class="c2">Sampling-Perturbing-Scaling (SPS) algorithm. The input is a database D, the retention probability p (0 &lt;p&lt; 1), the domain size m of SA, and the privacy parameters and . The output is a modified version of D</span><span class="c3">&#8676; </span><span class="c2">that satisfies ( , )-reconstruction-privacy. For each personal group g in D, this algorithm computes a modified version g</span><span class="c3">&#8676;</span><span class="c8">2 </span><span class="c1">of g</span><span class="c3">&#8676;</span><span class="c2">, then outputs D</span><span class="c3">&#8676;</span><span class="c8">2 </span><span class="c1">= S</span><span class="c2">g</span><span class="c3">&#8676;</span><span class="c8">2</span><span class="c1">. In a preprocessing step, </span><span class="c2">we sort the records in D by the attributes in NA and followed by SA. The result is a collection of personal groups g together with the frequencies f of every SA value in g. </span></p><p class="c11"><span class="c2">For each personal group g in D, compute s</span><span class="c8">g </span><span class="c2">as in Equation (10), if |g| &#63743; s</span><span class="c5">g</span><span class="c13">, g already satisfies the maximum group size constraint, </span><span class="c2">let g</span><span class="c3">&#8676;</span><span class="c8">2 </span><span class="c1">= g</span><span class="c3">&#8676;</span><span class="c2">. We assume |g| &gt; s</span><span class="c5">g</span><span class="c13">. In the following, g</span><span class="c8">&#8676;</span><span class="c5">2 </span><span class="c2">is produced in three steps: Sampling, Perturbing, and Scaling, described below. Let &#8999; = s</span><span class="c5">g</span><span class="c13">/|g|, called the sampling rate. </span></p><p class="c11"><span class="c2">1. Sampling(g, s</span><span class="c5">g</span><span class="c13">) takes a sample of the records in g while p- </span><span class="c2">reserving the frequency of each SA value. For each SA val- ue sa occurring in g, let g</span><span class="c5">sa </span><span class="c13">denote the subset of the records </span></p><p class="c6"><span class="c29">476 </span></p><p class="c6"><span class="c2">&bull; Fact 4: E[O|g</span><span class="c8">1</span><span class="c2">|(f</span><span class="c8">g</span><span class="c0">1</span><span class="c2">p + </span><span class="c8">g</span><span class="c2">(1 </span><span class="c3">&#8676;</span><span class="c0">2</span><span class="c2">] 1). Since Scaling &#39; E[O</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c1">]. From Lemma 2(i), E[O</span><span class="c2">p)/m) duplicates &#39; each s</span><span class="c8">g</span><span class="c2">(f</span><span class="c8">g</span><span class="c2">record </span><span class="c0">1</span><span class="c2">p + in (1 g</span><span class="c8">1 </span><span class="c3">&#8676;</span><span class="c1">by </span><span class="c2">p)/m) </span><span class="c26">|</span><span class="c3">g</span><span class="c26">| </span></p><p class="c23"><span class="c8">s</span><span class="c21">g </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c0">1</span><span class="c2">(Fact ] times, = </span></p><p class="c6"><span class="c2">E[O</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c0">2</span><span class="c2">] &#39; Lemma 2(i), (Fact 1) implies </span><span class="c26">|</span><span class="c3">g</span><span class="c26">| </span></p><p class="c6"><span class="c8">s</span><span class="c21">g </span><span class="c2">E[O&#8677; E[O</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c2">E[O</span><span class="c1">] = </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c0">2</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c1">|g|(f</span><span class="c2">] </span><span class="c0">1</span><span class="c2">] &#39; = E[O</span><span class="c8">g</span><span class="c2">p+(1 |g|(f</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c1">]. </span></p><p class="c6"><span class="c5">g</span><span class="c0">1</span><span class="c2">p p)/m). + (1 p)/m). From Then f</span><span class="c5">g</span><span class="c0">1 </span><span class="c2">&#39; f</span><span class="c5">g </span></p><p class="c6"><span class="c2">T</span><span class="c15">HEOREM </span><span class="c2">4 turned by the SPS (P</span><span class="c15">RIVACY</span><span class="c2">). For algorithm is ( , each )-reconstruction-private. </span></p><p class="c6"><span class="c2">personal group g, g</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">re- </span></p><p class="c23"><span class="c2">reconstruction-private. ( P</span><span class="c15">ROOF</span><span class="c2">. If |g| &#63743; s</span><span class="c5">g</span><span class="c13">, </span><span class="c2">We </span><span class="c13">g</span><span class="c5">2 </span><span class="c8">&#8676;</span><span class="c2">assume = , )-reconstruction-private because g</span><span class="c3">&#8676;</span><span class="c2">, by Corollary |g| &gt; s</span><span class="c5">g</span><span class="c13">. In </span><span class="c2">4, </span><span class="c13">this </span><span class="c2">g</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c13">case, </span><span class="c1">is </span><span class="c2">|g</span><span class="c5">1</span><span class="c13">| &#39; s</span><span class="c5">g </span><span class="c13">(Fact 1). We </span><span class="c1">( , )- </span><span class="c13">claim g</span><span class="c5">1 </span><span class="c8">&#8676;</span><span class="c2">is </span></p><p class="c6"><span class="c8">F </span><span class="c28">g</span><span class="c24">0</span><span class="c0">2 </span><span class="c8">f</span><span class="c21">g </span><span class="c8">f</span><span class="c21">g </span></p><p class="c6"><span class="c2">&#39; </span><span class="c3">F </span><span class="c28">g</span><span class="c24">0</span><span class="c0">1 </span><span class="c8">f</span><span class="c21">g</span><span class="c0">1 </span><span class="c8">f</span><span class="c21">g</span><span class="c0">1 </span><span class="c2">in g that have sa. Note that all records in g</span><span class="c5">sa </span><span class="c13">are identical. </span><span class="c2">We pick any b|g</span><span class="c8">sa</span><span class="c2">|&#8999;c records from g</span><span class="c8">sa </span><span class="c2">and pick one addi- tional record from g</span><span class="c5">sa </span><span class="c13">with the probability |g</span><span class="c5">sa</span><span class="c13">|&#8999; b|g</span><span class="c5">sa</span><span class="c13">|&#8999;c. </span><span class="c2">Let g</span><span class="c8">1 </span><span class="c2">be the set of the picked records. Return g</span><span class="c8">1</span><span class="c2">. </span></p><p class="c6"><span class="c2">2. P erturbing(g</span><span class="c5">1</span><span class="c13">, p, m) perturbs the SA values of the records </span></p><p class="c6"><span class="c2">in g</span><span class="c5">1 </span><span class="c2">turbation </span><span class="c13">with the retention probability p, as in the </span><span class="c2">described in Section 3.1. Return g</span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">. </span></p><p class="c6"><span class="c13">Uniform Per- </span></p><p class="c23"><span class="c2">3. Scaling(greserving For r</span><span class="c3">&#8676; </span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">,|g|) scales up g</span><span class="c8">1 </span><span class="c3">&#8676;</span><span class="c1">to the original </span><span class="c2">the frequency of each SA value. each record r</span><span class="c3">&#8676; </span><span class="c2">and one additional in g</span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">, </span><span class="c2">duplicate </span><span class="c1">let g</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">of </span><span class="c1">contain </span><span class="c2">r</span><span class="c3">&#8676; </span><span class="c1">size |g| while p- </span><span class="c2">Let &#8999;</span><span class="c3">0 </span><span class="c1">b&#8999;</span><span class="c3">0</span><span class="c2">c duplicates = |g|/|g</span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c2">of </span><span class="c1">|. </span></p><p class="c6"><span class="c2">with the probability &#8999;</span><span class="c3">0 </span><span class="c2">b&#8999; </span><span class="c3">0</span><span class="c2">c. Return g</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">. </span></p><p class="c6"><span class="c2">, which implies that F </span><span class="c8">g</span><span class="c3">0</span><span class="c0">2 </span><span class="c2">has the same tail Remarks. Several points are worth noting. First, Sampling kicks in only if |g| exceeds the maximum size s</span><span class="c5">g</span><span class="c13">; otherwise, all record- </span><span class="c2">s in g will be used for perturbation. Therefore, if the data set is small enough to have such a poor accuracy that already satisfies reconstruction privacy, our algorithm will behave like the standard uniform perturbation without performing sampling. In this case, the poor accuracy is not caused by our sampling, but by the inade- quate amount of data. Second, the duplication in Scaling does not introduce new random trials because it is performed after the per- turbation in on gg</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c8">1 </span><span class="c3">&#8676;</span><span class="c1">, but before </span><span class="c2">in </span><span class="c1">this </span><span class="c2">g</span><span class="c1">the </span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">is . The adversary not a problem scaling step. </span></p><p class="c6"><span class="c1">may notice some duplicate records because privacy is actually achieved </span></p><p class="c11"><span class="c2">Complexity analysis. Let |D| denote the number of records in D. The sorting step takes |D|log|D| time to generate all personal groups. Subsequently, each of the steps Sampling, P erturbing, and Scaling takes one data scan. A more efficient implementation, however, is to perform these three steps in a single data scan: as a </span></p><p class="c6"><span class="c2">probability for error private because and F </span><span class="c8">g</span><span class="c3">0</span><span class="c0">1 </span><span class="c2">&#39; F </span><span class="c8">g</span><span class="c3">0</span><span class="c0">2 </span><span class="c2">g</span><span class="c8">1 </span><span class="c3">&#8676;</span><span class="c2">(Fact </span><span class="c1">is. </span><span class="c2">as </span><span class="c1">This </span><span class="c2">F </span><span class="c8">g</span><span class="c3">0</span><span class="c0">1</span><span class="c2">; </span><span class="c1">claim </span><span class="c2">therefore, </span><span class="c1">follows </span><span class="c2">g</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">is ( from </span><span class="c2">3). </span></p><p class="c6"><span class="c1">, )-reconstruction- f</span><span class="c8">g</span><span class="c0">1 </span><span class="c2">&#39; f</span><span class="c5">g </span><span class="c13">(Fact 1) </span></p><p class="c11"><span class="c2">T</span><span class="c15">HEOREM </span><span class="c2">5 (U</span><span class="c15">TILITY</span><span class="c2">). Let S be a set of records for one or more personal groups in D, S</span><span class="c3">&#8676; </span><span class="c2">be the corresponding set for D</span><span class="c3">&#8676;</span><span class="c2">, and of a SSA </span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">reconstructed P</span><span class="c15">ROOF</span><span class="c2">. |S</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">| = </span><span class="c2">|S</span><span class="c3">&#8676;</span><span class="c2">| &#39; and E[FThus, E[FE[F</span><span class="c8">S</span><span class="c3">0</span><span class="c0">2</span><span class="c2">] &#39; </span><span class="c1">be </span><span class="c8">S</span><span class="c2">|S</span><span class="c3">0</span><span class="c2">value </span><span class="c1">P</span><span class="c0">2</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c2">] f. </span></p><p class="c6"><span class="c3">0</span><span class="c1">the </span><span class="c2">Let ] </span><span class="c1">|. </span><span class="c2">|g= &#39; </span><span class="c8">2</span><span class="c2">from </span><span class="c3">&#8676;</span><span class="c1">From corresponding </span><span class="c2">sa </span><span class="c3">E[O</span><span class="c1">|, </span><span class="c2">OE[F</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">where </span><span class="c2">in </span><span class="c39">2</span><span class="c24">&#8676;</span><span class="c2">S</span><span class="c1">= </span><span class="c3">]/</span><span class="c26">|</span><span class="c3">S</span><span class="c1">Lemma </span><span class="c3">&#8676; </span><span class="c2">S, </span><span class="c8">S</span><span class="c3">0</span><span class="c0">2</span><span class="c1">P</span><span class="c2">and </span><span class="c39">2 </span><span class="c24">&#8676;</span><span class="c2">]. and </span><span class="c8">p </span><span class="c1">P </span><span class="c26">| </span><span class="c2">OFrom S</span><span class="c3">(1 </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c2">is </span><span class="c8">2</span><span class="c0">2</span><span class="c2">let </span><span class="c3">&#8676;</span><span class="c1">2(ii), </span><span class="c2">, </span><span class="c1">. set </span><span class="c3">p)/m </span></p><p class="c6"><span class="c2">over O</span><span class="c1">Then </span><span class="c2">F Lemma </span><span class="c3">&#8676; </span><span class="c1">for </span><span class="c3">0 </span><span class="c1">E[F </span><span class="c2">= and </span><span class="c1">. </span><span class="c2">the </span><span class="c1">From E[F DP</span><span class="c8">2</span><span class="c3">0&#8676;</span><span class="c2">F personal ] </span><span class="c1">. </span><span class="c2">2(iii), </span><span class="c8">S</span><span class="c2">O</span><span class="c8">S</span><span class="c3">00</span><span class="c2">= </span><span class="c0">2</span><span class="c1">Fact </span><span class="c0">2 </span><span class="c1">Let </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c2">] </span><span class="c1">, </span><span class="c2">be &#39; </span><span class="c3">E[O</span><span class="c1">|Sf 4, </span><span class="c2">E[F f. </span></p><p class="c6"><span class="c2">the </span><span class="c3">&#8676;</span><span class="c1">be </span><span class="c24">&#8676;</span><span class="c2">| groups </span><span class="c1">E[O</span><span class="c8">]/</span><span class="c4">|</span><span class="c8">S</span><span class="c2">= estimates </span><span class="c3">0</span><span class="c1">the </span><span class="c2">] </span><span class="c1">P</span><span class="c24">&#8676;</span><span class="c3">&#8676;</span><span class="c2">&#39; </span><span class="c8">p </span></p><p class="c23"><span class="c4">| </span><span class="c2">] </span><span class="c1">frequency </span><span class="c2">|g&#39; g </span><span class="c8">(1 </span><span class="c2">f, </span><span class="c3">&#8676;</span><span class="c2">for E[O|, </span><span class="c8">p)/m </span><span class="c2">thus, of and S. f </span></p><p class="c6"><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">]. </span></p><p class="c6"><span class="c2">record r is sampled, immediately we perturb the SA value of r </span></p><p class="c6"><span class="c2">Intuitively, Theorem 5 says that the estimate reconstructed using and then duplicate the perturbed record a certain number of times as described, and add the duplicates takes (|D|log|D| + |D|) time. </span></p><p class="c6"><span class="c2">to g</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">. In total, the algorithm </span></p><p class="c6"><span class="c2">the corresponding actual frequency. </span></p><p class="c6"><span class="c2">records in D</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">is an unbiased estimator of the </span></p><p class="c23"><span class="c31">5.1 Analysis </span><span class="c2">is private. We on privacy prove The two second guarantee: claims claim about each is on the gutility: </span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">output </span><span class="c1">in D</span><span class="c2">for D</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">is </span><span class="c2">any </span><span class="c1">= ( [g, </span><span class="c2">subset </span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">. The first claim )-reconstruction- </span><span class="c2">S consisting of one or more Dparticular </span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">, F </span><span class="c8">g</span><span class="c3">0</span><span class="c0">2 </span><span class="c2">is an SA from S</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">, respectively. </span><span class="c2">Let g be a computed for particular SA </span><span class="c13">be the frequency </span><span class="c2">reconstructed unbiased personal estimator groups and of f, the where corresponding f is the frequency subset S</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">of </span><span class="c1">in </span><span class="c2">a value in S </span><span class="c1">We </span><span class="c2">and </span><span class="c1">first </span><span class="c2">F </span><span class="c8">g</span><span class="c3">0</span><span class="c1">present </span><span class="c0">2 </span><span class="c2">is the estimate of f reconstructed </span></p><p class="c23"><span class="c1">some facts. </span><span class="c2">personal from g value and </span><span class="c13">of </span><span class="c2">g</span><span class="c13">sa </span><span class="c2">sa let </span><span class="c3">&#8676;</span><span class="c2">,ggroup. </span><span class="c13">in </span><span class="c2">Oin </span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">,g</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c13">g </span><span class="c2">g</span><span class="c1">,O</span><span class="c3">&#8676;</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c13">and </span><span class="c2">,g</span><span class="c1">. </span><span class="c2">Assume </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c1">We </span><span class="c0">1</span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c2">,O</span><span class="c13">g</span><span class="c5">1</span><span class="c13">. </span><span class="c1">,gavoid </span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c1">, </span><span class="c0">2 </span><span class="c13">Let </span><span class="c1">respectively. </span><span class="c2">be |g| </span><span class="c13">F </span><span class="c1">to </span><span class="c2">the </span><span class="c5">g</span><span class="c2">&gt; </span><span class="c8">0</span><span class="c2">,F </span><span class="c1">use </span><span class="c2">sobserved </span><span class="c8">g</span><span class="c5">g</span><span class="c13">. </span><span class="c3">0</span><span class="c0">1</span><span class="c1">f</span><span class="c2">,F </span><span class="c8">1</span><span class="c2">,F </span><span class="c13">Let </span><span class="c1">Let </span><span class="c8">g</span><span class="c3">0</span><span class="c0">2 </span><span class="c8">1</span><span class="c3">0</span><span class="c13">g</span><span class="c1">,F </span><span class="c2">be </span><span class="c5">1</span><span class="c13">,g</span><span class="c2">count </span><span class="c1">f</span><span class="c8">g 2 </span><span class="c3">0</span><span class="c2">the </span><span class="c5">1</span><span class="c8">&#8676;</span><span class="c1">as </span><span class="c2">and ,gMLE </span><span class="c1">these </span><span class="c2">for </span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">f</span><span class="c1">be </span><span class="c5">g</span><span class="c0">1 </span><span class="c2">a </span></p><p class="c11"><span class="c2">symbols have been used as the frequencies for SA values sa</span><span class="c5">1 </span><span class="c13">and </span><span class="c2">sa</span><span class="c8">2</span><span class="c2">. Let u &#39; v denote that u and v are equal modulo the random trial for the additional record in Scaling and Sampling. </span></p><p class="c6"><span class="c31">6. EXPERIMENTAL STUDIES </span></p><p class="c6"><span class="c2">We evaluate two claims. The first claim is that reconstruction privacy could be violated on real life data sets. The second claim is that the proposed SPS algorithm eliminates personal reconstruction with minor sacrifice on the utility of aggregate reconstruction. </span><span class="c31">6.1 Experimental Setup </span></p><p class="c11"><span class="c2">We implemented the proposed SPS algorithm as described in Section 5 in C++ and ran all experiments on an Intel Xeon(R) E5630 CPU 2.53GHZ PC with 12GB of RAM. We utilized two publicly available data sets. The first one is the ADULT data set [14]. This data set has 45,222 records (without missing values) extracted from the 1994 Census database with the attributes Educa- tion, Occupation, Race, Gender, and Income. We chose Income as SA and the remaining attributes as the public attributes NA. The second data set is the CENSUS data previously used in [28][22]. This data set contains personal information about 500K American </span></p><p class="c23"><span class="c2">&bull; Fact 1: preserves f</span><span class="c5">g</span><span class="c2">the </span><span class="c0">1 </span><span class="c2">&#39; f</span><span class="c5">g </span><span class="c13">and |g</span><span class="c5">1</span><span class="c13">| &#39; s</span><span class="c5">g</span><span class="c13">. This is because Sampling </span><span class="c2">frequency of sa in g and the sample g</span><span class="c8">1 </span><span class="c2">has the size s</span><span class="c5">g</span><span class="c13">. </span></p><p class="c11"><span class="c2">adults with 6 discrete attributes Age, Gender, Education, Marital, Race, and Occupation. We chose Occupation as SA and the re- maining attributes as NA. We considered five samples of CEN- SUS of sizes 100K, 200K, 300K, 400K, 500K. These data sets </span></p><p class="c6"><span class="c2">&bull; Fact g</span><span class="c8">1 </span><span class="c3">&#8676;</span><span class="c1">to </span><span class="c2">2: </span><span class="c1">g</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c2">O</span><span class="c1">preserves </span><span class="c8">g</span><span class="c3">&#8676;</span><span class="c0">2</span><span class="c2">/|g</span><span class="c8">2</span><span class="c3">&#8676;</span><span class="c1">| &#39; the O</span><span class="c8">g</span><span class="c1">frequency </span><span class="c3">&#8676;</span><span class="c0">1</span><span class="c2">/|g</span><span class="c8">1</span><span class="c3">&#8676;</span><span class="c1">|. This is because Scaling from </span></p><p class="c6"><span class="c1">of sa. </span></p><p class="c11"><span class="c2">have different characteristics: ADULT represents a small data set with very few SA values (with Income having only two values), whereas CENSUS represents a large data set with a large number </span></p><p class="c6"><span class="c2">&bull; Fact i = 3: 1,2 F (Lemma </span><span class="c8">g</span><span class="c3">0</span><span class="c0">1 </span><span class="c2">&#39; F</span><span class="c8">g</span><span class="c3">0</span><span class="c0">2</span><span class="c2">2(ii)) . This follows and Fact 2. </span></p><p class="c6"><span class="c2">from F </span><span class="c8">g</span><span class="c3">0</span><span class="c21">i </span><span class="c2">= </span><span class="c3">O</span><span class="c28">g</span><span class="c24">&#8676;</span><span class="c21">i</span><span class="c8">/</span><span class="c4">|</span><span class="c8">g</span><span class="c28">i </span><span class="c24">&#8676;</span><span class="c26">| </span><span class="c8">p </span><span class="c3">(1 p)/m </span></p><p class="c6"><span class="c1">, </span></p><p class="c11"><span class="c2">of balanced distributed SA values (with Occupation having 50 val- ues). We want to see how these characteristics would affect the evaluation of our claims. </span></p><p class="c6"><span class="c29">477 </span></p><p class="c11"><span class="c2">As discussed in Section 3.4, the values for public attributes with the same impact on SA have to be aggregated before generating personal groups. The aggregation affects data sets to some extent. Tables 4 and 5 show the impacts on the domain size of each public attribute, the total number of personal groups (e.g., |G|), and the averaged personal groups size (e.g., |D|/|G| with |D| as the total number of records) of ADULT and CENSUS 300K. In the rest of this section, we use the generalized values of public attributes. </span></p><p class="c6"><span class="c2">Table 4: NA Aggregation Impact on ADULT </span></p><p class="c6"><span class="c28">Domain Size of NA </span><span class="c0">|</span><span class="c21">G</span><span class="c0">| |</span><span class="c21">D</span><span class="c0">|</span><span class="c21">/</span><span class="c0">|</span><span class="c21">G</span><span class="c0">| </span><span class="c21">Education Occupation Race Gender </span><span class="c28">Before Aggregation 16 14 5 2 2240 20 </span></p><p class="c6"><span class="c28">After Aggregation 7 4 2 2 112 404 </span></p><p class="c6"><span class="c2">Table 5: NA Aggregation Impact on CENSUS 300K </span></p><p class="c6"><span class="c28">Domain Size of NA </span><span class="c0">|</span><span class="c21">G</span><span class="c0">| |</span><span class="c21">D</span><span class="c0">|</span><span class="c21">/</span><span class="c0">|</span><span class="c21">G</span><span class="c0">| </span><span class="c21">Age Gender Education Marital Race </span><span class="c28">Before Aggregation 77 2 14 6 9 116424 3 </span></p><p class="c6"><span class="c28">After Aggregation 1 2 14 6 9 1512 331 </span></p><p class="c6"><span class="c2">The utility of the published data is evaluated by the accuracy of answering count queries of the form: </span></p><p class="c6"><span class="c2">SELECT COUNT (&#8676;) FROM D WHERE A</span><span class="c5">1 </span><span class="c13">= a</span><span class="c5">1 </span><span class="c13">^ &middot;&middot;&middot; ^ A</span><span class="c5">d </span><span class="c13">= a</span><span class="c5">d </span><span class="c13">^ SA = sa</span><span class="c5">i </span><span class="c2">(11) </span></p><p class="c11"><span class="c2">where A</span><span class="c5">j </span><span class="c13">2 NA, a</span><span class="c5">j </span><span class="c13">2 dom(A</span><span class="c5">j</span><span class="c13">), and sa</span><span class="c5">i </span><span class="c13">2 dom(SA). The </span><span class="c2">answer to the query, ans, is the number of records in D satisfying the condition in the WHERE clause. Such answers can be used to learn statistical relationships between the attributes in NA and SA. Given the perturbed data D</span><span class="c3">&#8676;</span><span class="c2">, ans is approximated by est = |S</span><span class="c3">&#8676;</span><span class="c2">| &#8676; F </span><span class="c3">0</span><span class="c2">, where S</span><span class="c3">&#8676; </span><span class="c2">is the set of records in D</span><span class="c3">&#8676; </span><span class="c2">satisfying A</span><span class="c5">1 </span><span class="c13">= </span><span class="c2">a</span><span class="c8">1</span><span class="c2">^&middot;&middot;&middot;^A</span><span class="c5">d </span><span class="c13">= a</span><span class="c5">d</span><span class="c13">, |S</span><span class="c8">&#8676;</span><span class="c13">| is the size of S</span><span class="c8">&#8676;</span><span class="c13">, and F </span><span class="c8">0 </span><span class="c13">is the MLE given </span><span class="c2">by Lemma 2(ii) based on S</span><span class="c3">&#8676;</span><span class="c2">. The relative error of est is defined as </span><span class="c26">|</span><span class="c3">est ans</span><span class="c26">| </span></p><p class="c11"><span class="c8">ans </span><span class="c1">. A smaller relative error means a larger accuracy and </span><span class="c2">better utility. Queries on only NA are not considered because such queries have zero relative error. </span></p><p class="c11"><span class="c2">Data mining and analysis typically focuses on low dimensional statistics, such as 1D or 2D marginals with a size above a sani- ty bound [29]. We generated a pool of 5,000 count queries with the query dimensionality d in {1,2,3} and with the selectivity ans/|D| 0.1%. For each query, we selected d from {1, 2, 3}, s- elected d attributes from NA without replacement, selected a value a</span><span class="c5">i </span><span class="c13">2 dom(A</span><span class="c5">i</span><span class="c13">) for each selected attribute A</span><span class="c5">i</span><span class="c13">, and finally selected a </span><span class="c2">value sa</span><span class="c5">i </span><span class="c13">2 dom(SA). All selections are random with equal prob- </span><span class="c2">ability. If the query&rsquo;s selectivity is 0.1% or more, we replaced the NA value with aggregated values and then added it to the pool. Re- call that we aggregated NA values based on their impact on SA as in Section 3.3. The query pool simulates the set of possible queries generated from real life, therefore, the original NA value (before aggregation) is used to generate the query pool. Since we protect reconstruction privacy on aggregated personal groups we evaluate relative error on these aggregated personal groups as well. We re- port the average of relative error over all queries in this pool. In addition, since D</span><span class="c3">&#8676; </span><span class="c2">is randomly generated in each run, we reported the average of 10 runs to avoid the bias of a particular run. </span></p><p class="c6"><span class="c2">Table 6: Parameter Table </span></p><p class="c6"><span class="c10">Parameters Settings p 0.1, 0.3, 0.5, 0.7, 0.9 &lambda; 0.1, 0.2, 0.3, 0.4, 0.5 &delta; 0.1, 0.2, 0.3, 0.4, 0.5 </span></p><p class="c23"><span class="c2">The uniform perturbation, denoted by UP, as described in Sec- tion 3.1 has been used as a privacy mechanism in [25][16][6]. But these privacy mechanisms do not address the disclosure of personal reconstruction. Our method addresses this disclosure by applying UP to sampled data. So our evaluation has two parts. First, we evaluate how often reconstruction privacy is violated by the per- turbed data D</span><span class="c3">&#8676; </span><span class="c2">produced by UP. Then, we evaluate the cost of achieving reconstruction reconstruction by our SPS algorithm. This cost is measured by the increase in the relative error for queries an- swered of queries using answered D</span><span class="c8">2 </span><span class="c3">&#8676;</span><span class="c1">produced </span><span class="c2">using D</span><span class="c1">by </span><span class="c3">&#8676; </span><span class="c1">SPS, compared to the relative error </span><span class="c2">produced by UP. The same reten- tion probability p is used for both UP and SPS. Table 6 shows the settings of p, , and with the default settings in boldface. </span></p><p class="c6"><span class="c27">2400 </span></p><p class="c6"><span class="c27">p=0.3 </span></p><p class="c6"><span class="c27">2400 </span></p><p class="c6"><span class="c27">p=0.5 p=0.7 </span></p><p class="c6"><span class="c27">0.5 </span><span class="c48">0 </span></p><p class="c6"><span class="c27">0.6 0.7 </span><span class="c43">f </span></p><p class="c6"><span class="c27">0.8 0.9 </span><span class="c43">f </span></p><p class="c6"><span class="c10">(a) ADULT </span></p><p class="c11"><span class="c27">p=0.3 p=0.5 p=0.7 </span></p><p class="c6"><span class="c10">(b) CENSUS </span></p><p class="c6"><span class="c2">Figure 1: Maximum group size s</span><span class="c5">g </span><span class="c13">vs. maximum frequency f </span></p><p class="c6"><span class="c2">Below, a group means a personal group. First, we study the con- dition |g| &#63743; s</span><span class="c5">g </span><span class="c13">for testing whether a group g</span><span class="c8">&#8676; </span><span class="c13">satisfies reconstruction- </span><span class="c2">privacy as described in Section 5, where s</span><span class="c5">g </span><span class="c13">is the maximum thresh- </span><span class="c2">old on the group size defined as </span></p><p class="c6"><span class="c2">s</span><span class="c5">g </span><span class="c13">= </span><span class="c2">2(fp + (1 p)/m) ( pf)</span><span class="c3">2 </span><span class="c2">ln </span></p><p class="c6"><span class="c1">(12) </span></p><p class="c6"><span class="c2">f is the maximum frequency of any SA value occurring in g. Fig- ure 1 plots the relationship between s</span><span class="c5">g </span><span class="c13">and f (for the default set- </span><span class="c2">tings of and ). Note that the range of f is [0.5,0.9] for ADULT, but is [0.1,0.9] for CENSUS. This is because ADULT contains on- ly 2 distinct SA values, as a result, f is at least 50% in all personal groups. Each curve corresponds to a setting of p. For each curve in Figure 1, the region above the curve represents the area where this condition fails, that is, |g| &gt; s</span><span class="c8">g </span><span class="c2">for a given f. The large area above these curves suggests that the maximum group size s</span><span class="c5">g </span><span class="c13">can be easily </span><span class="c2">exceeded, and thus, there is a good chance of violating reconstruc- tion privacy. Observing both Figure 1 and Equation (12) we get that, when parameters: , and p are given, the value of m and f have opposite effects on the value of s</span><span class="c8">g</span><span class="c2">, particularly, f becomes the dominant factor when f is small (e.g., when f &#63743; 0.3 in Figure 1). The value of s</span><span class="c8">g </span><span class="c2">boosts when f is smaller, implying that person- al groups with smaller f tend to be reconstruction private because it is easier for them to satisfy the condition of |g| &#63743; s</span><span class="c5">g</span><span class="c13">. We will </span><span class="c2">confirm this observation on the two real life data sets shortly. </span><span class="c31">6.2 ADULT Data Set </span></p><p class="c11"><span class="c2">Violation. Figure 2 shows the extent to which reconstruction privacy is violated on the perturbed ADULT data set D</span><span class="c3">&#8676; </span><span class="c2">produced by UP. This extent is measured at two levels. v</span><span class="c8">g </span><span class="c2">represents the per- centage of groups that violate reconstruction privacy. v</span><span class="c5">r </span><span class="c13">represents </span><span class="c2">the percentage of records contained in a violating personal group, i.e., the coverage of the violating groups in terms of the number of individuals affected. We consider this coverage because all the records in a violating group are under the same risk of accurate personal reconstruction. </span></p><p class="c6"><span class="c2">Both violations in terms of v</span><span class="c8">r </span><span class="c2">and v</span><span class="c8">g </span><span class="c2">are obvious. Take the de- fault setting of p = 0.5, = 0.3 and = 0.3 as an example. The </span></p><p class="c6"><span class="c29">478 </span></p><p class="c6"><span class="c27">1600 </span></p><p class="c6"><span class="c27">1600 </span></p><p class="c6"><span class="c27">800 </span></p><p class="c6"><span class="c27">800 </span></p><p class="c6"><span class="c48">0 </span><span class="c27">0.1 0.3 0.5 0.7 0.9 </span></p><p class="c6"><span class="c7">100% 100% </span></p><p class="c6"><span class="c7">100% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c16"><span class="c22">25% 25% 25% 0% </span><span class="c7">0.1 0.3 0.5 p 0.7 0.9 </span><span class="c22">0% </span><span class="c7">0.1 0.2 0.3 </span><span class="c14">&lambda; </span></p><p class="c6"><span class="c7">0.4 0.5 </span><span class="c22">0% </span><span class="c7">0.1 0.2 0.3 </span><span class="c14">&delta; </span><span class="c7">0.4 0.5 </span><span class="c10">(a) vs. p </span></p><p class="c6"><span class="c10">(b) vs. &lambda; </span></p><p class="c6"><span class="c10">(c) vs. &delta; </span></p><p class="c6"><span class="c2">Figure 2: ADULT: Privacy Violation </span></p><p class="c6"><span class="c7">100% </span></p><p class="c6"><span class="c7">SPS UP </span></p><p class="c6"><span class="c20">100% </span></p><p class="c6"><span class="c7">100% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">50% 25% 0% </span><span class="c7">0.1 0.3 0.5 p </span></p><p class="c6"><span class="c7">0.7 0.9 </span><span class="c4">&lambda; </span></p><p class="c6"><span class="c14">&delta; </span></p><p class="c6"><span class="c10">(a) vs. p </span></p><p class="c6"><span class="c7">SPS UP </span></p><p class="c6"><span class="c10">(c) vs. &delta; </span></p><p class="c6"><span class="c2">Figure 3: ADULT: Relative Error </span></p><p class="c11"><span class="c2">85% of all groups are violating and covering more than 99% of the records. This privacy risk is interpreted as follows: with probability of 1 = 70%, the estimate F </span><span class="c3">0 </span><span class="c2">of some SA value is within a rel- ative error of = 30%, and this case covers more than v</span><span class="c8">r </span><span class="c2">= 99% of all individuals. The large coverage is expected because a larger group more likely violates reconstruction privacy (Figure 1). </span></p><p class="c6"><span class="c2">Cost. Figure 3 shows the increase of relative error due to the sampling of SPS. Compared to UP, the relative error for SPS in- creases about 50% in the worst case. This increase is due to the sampling required to eliminate the violation of reconstruction pri- vacy. Considering the large coverage of the violation (i.e., v</span><span class="c5">r </span><span class="c13">in </span><span class="c2">Figure 2), having such increase of error is reasonable. We empha- size that this increase is due to the large f in personal groups in ADULT. Recall that f is no less than 50% and when f is larger personal groups tend to violate reconstruction privacy (Figure 1). Note that ADULT is not general in real life in terms of very few number of SA values, for other data sets with more SA values, the increased error would be reduced, which will be confirmed soon on the CENSUS data set. Choosing a small p helps eliminate viola- tion, but also quickly increases the relative error for both UP and SPS (Figures 2a and 3a). Indeed, a too small p makes the perturbed data become nearly pure noises. This study confirms our discussion at the beginning of Section 5 that the approach of reducing p does not preserve utility. </span><span class="c31">6.3 CENSUS Data Set </span></p><p class="c11"><span class="c2">Violation. CENSUS is a larger data set with a much larger num- ber of balanced distributed SA values. We are curious how this characteristic change would affect our claims. Figure 4 shows the extent to which reconstruction privacy is violated. The default data size is 300K when 1D1 is not specified. Compared to the ADULT data set, the frequency f of a SA value is much smaller; conse- quently, the value of s</span><span class="c8">g </span><span class="c2">is much larger (Figure 1). The larger s</span><span class="c8">g </span><span class="c2">makes it easy to satisfy the condition of 1g1 &#63743; s</span><span class="c5">g</span><span class="c13">, therefore, it </span><span class="c2">is less likely that groups in CENSUS would violate reconstruction privacy, which explains the much smaller v</span><span class="c5">g </span><span class="c13">and also confirms our </span><span class="c2">claim on Figure 1 that smaller f may lead to less reconstruction vi- olations. Besides, the larger s</span><span class="c5">g </span><span class="c13">implies that violation groups must </span><span class="c2">have larger g because 1g1 &gt; s</span><span class="c5">g</span><span class="c13">, which explains the small number </span><span class="c2">of violation groups covering the most records in the data set. </span></p><p class="c6"><span class="c2">Cost. Figure 5 compares the relative error of UP and SPS. A big </span></p><p class="c11"><span class="c2">difference from the ADULT data set is that there is less increase in the relative error (e.g., less than 10% for most of settings) for SPS compared to the relative error for UP across all settings of parame- ters. This is a consequence of the smaller percentage r</span><span class="c5">g </span><span class="c13">of the vio- </span><span class="c2">lating groups discussed above. In this case, most of the groups do not need sampling because they satisfy reconstruction privacy and only the small number of violating groups will be sampled. Even for such groups, a small reduction in the number of record pertur- bation is sufficient to increase the error of personal reconstruction to the level required by our privacy criterion. </span></p><p class="c11"><span class="c2">Another interesting point is that even though a larger data size 1D1 causes more violations of reconstruction privacy (Figure 4d), it actually decreases the relative error for SPS (Figure 5d). As ex- plained above, for this data set, eliminating violation incurs little additional error beyond that of UP. Therefore, as the data size in- creases, the relative error of UP gets smaller, so does the relative error of SPS. This finding suggests that the proposed SPS algorith- m could be more effective on a larger data set. </span></p><p class="c11"><span class="c2">In summary, our empirical studies supported the claim that re- construction attack could occur on real life data sets, whether they are small or large and whether the number of sensitive attribute is small or large. The studies also supported the claim that the pro- posed privacy criterion and the sampling method are effective to preserve the utility for data analysis while eliminating such attacks. This effectiveness is more observed on larger data sets with a large number of balanced distributed sensitive attributes. </span></p><p class="c6"><span class="c31">7. CONCLUSION </span></p><p class="c11"><span class="c2">Differential privacy has become a popular privacy definition for sharing statistical information thanks to good utility. However, this good utility comes with the cost of disclosures through non- independent reasoning. In this work, we presented a data perturba- tion approach to prevent sensitive non-independent reasoning while enabling statistical learning. We achieved these goals through a property implied by the law of large numbers, which allows us to separate these two types of learning by their different responses to reduction in random trials. Based on this idea, we use record sampling to reduce the random trials in data perturbation, which mostly affects non-independent reasoning specific to an individual while having only a limited effect on statistical learning. </span></p><p class="c6"><span class="c29">479 </span></p><p class="c6"><span class="c20">SPS UP </span></p><p class="c6"><span class="c45">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c45">50% </span><span class="c22">50% </span><span class="c45">25% </span><span class="c22">25% </span><span class="c45">0% </span><span class="c20">0.1 0.2 0.3 0.4 0.5 </span><span class="c22">0% </span><span class="c7">0.1 0.2 0.3 0.4 0.5 </span><span class="c10">(b) vs. &lambda; </span></p><p class="c6"><span class="c7">100% 100% </span></p><p class="c6"><span class="c7">100% </span></p><p class="c6"><span class="c7">100% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">75% </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">50% </span><span class="c7">v</span><span class="c36">r </span><span class="c7">v</span><span class="c36">g </span></p><p class="c6"><span class="c22">25% 25% 25% 25% 0% </span><span class="c7">0.1 0.3 0.5 p </span></p><p class="c6"><span class="c7">0.7 0.9 </span><span class="c22">0% </span><span class="c7">0.1 0.2 0.3 </span><span class="c14">&lambda; </span></p><p class="c6"><span class="c7">0.4 0.5 </span><span class="c22">0% </span><span class="c7">0.1 0.2 0.3 </span><span class="c14">&delta; </span></p><p class="c6"><span class="c7">0.4 0.5 </span><span class="c22">0% </span><span class="c7">100K 200K 300K |D| 400K 500K </span><span class="c10">(a) vs. p </span></p><p class="c6"><span class="c10">(b) vs. &lambda; </span></p><p class="c6"><span class="c10">(c) vs. &delta; </span></p><p class="c6"><span class="c10">(d) vs. </span><span class="c35">|</span><span class="c10">D</span><span class="c35">| </span></p><p class="c6"><span class="c2">Figure 4: CENSUS: Privacy Violation </span></p><p class="c6"><span class="c7">40% </span></p><p class="c6"><span class="c7">SPS UP </span></p><p class="c6"><span class="c20">40% </span></p><p class="c6"><span class="c20">SPS UP </span></p><p class="c6"><span class="c7">40% </span></p><p class="c6"><span class="c7">SPS UP </span></p><p class="c6"><span class="c7">40% </span></p><p class="c6"><span class="c7">30% </span></p><p class="c6"><span class="c20">30% </span></p><p class="c6"><span class="c7">30% </span></p><p class="c6"><span class="c7">30% </span></p><p class="c6"><span class="c7">20% </span></p><p class="c6"><span class="c20">20% </span></p><p class="c6"><span class="c7">20% </span></p><p class="c6"><span class="c7">20% </span></p><p class="c6"><span class="c22">0% </span></p><p class="c6"><span class="c7">0.1 0.3 0.5 p </span></p><p class="c6"><span class="c7">0.7 0.9 </span><span class="c4">&lambda; </span></p><p class="c6"><span class="c14">&delta; </span></p><p class="c6"><span class="c7">|D| </span></p><p class="c6"><span class="c10">(a) vs. p </span></p><p class="c6"><span class="c10">(b) vs. &lambda; </span></p><p class="c6"><span class="c10">(c) vs. &delta; </span></p><p class="c6"><span class="c7">SPS UP </span></p><p class="c6"><span class="c7">10% </span></p><p class="c6"><span class="c20">10% </span></p><p class="c6"><span class="c7">10% </span></p><p class="c6"><span class="c7">10% </span></p><p class="c6"><span class="c10">(d) vs. </span><span class="c35">|</span><span class="c10">D</span><span class="c35">| </span></p><p class="c6"><span class="c2">Figure 5: CENSUS: Relative Error </span></p><p class="c6"><span class="c31">8. ACKNOWLEDGEMENTS </span></p><p class="c6"><span class="c2">[15] C. Li. Optimizing liner queries under differential privacy. Ke Wang&rsquo;s work is partially supported by a Discovery Grant of the Natural Sciences and Engineering Research Council, Canada. </span></p><p class="c6"><span class="c45">0% </span><span class="c20">0.1 0.2 0.3 0.4 0.5 </span><span class="c2">PhD thesis, Computer Science, University of Massachusetts </span></p><p class="c6"><span class="c2">Amherst, 2013. Raymond Chi-Wing Wong&rsquo;s is partially supported by the grant F- </span></p><p class="c6"><span class="c2">[16] R. Agrawal, R. Srikant, and D. Thomas. Privacy preserving SGRF14EG34. Philip S. Yu&rsquo;s is partially supported by US NSF </span></p><p class="c6"><span class="c2">olap. In SIGMOD, 2005. through grants CNS-1115234 and OISE-1129076. </span></p><p class="c6"><span class="c2">[17] M. NarasimhaRao, J. VenuGopalkrisna, R. Murthy, and </span></p><p class="c6"><span class="c2">C. Ramesh. Closeness: Privacy measure for data publishing </span><span class="c31">9. REFERENCES </span></p><p class="c6"><span class="c2">[1] R. Adam and J. Worthmann. Security-control methods for </span></p><p class="c6"><span class="c2">statistical databases: A comparative study. ACM Comput. Surv., 21(4):515&ndash;556, December 1989. [2] B. Fung, K. Wang, R. Chen, and P. Yu. Privacy-preserving </span></p><p class="c6"><span class="c2">data publishing: a survey of recent developments. ACM Comput. Surv., 42(4):14:1&ndash;14:53, June 2010. [3] B. Chen, D. Kifer, K. LeFevre, and A. Machanavajjhala. </span></p><p class="c6"><span class="c2">Privacy-preserving data publishing. Found. Trends databases, 2(1-2):1&ndash;167, January 2009. [4] A. Machanavajjhala, D. Kifer, J. Gehrke, and </span></p><p class="c6"><span class="c2">M. Venkitasubramaniam. L-diversity: privacy beyound k-anonymity. In ICDE, 2006. [5] N. Li, T. Li, and S. Venkatasubramanian. t-closeness: privacy </span></p><p class="c16"><span class="c2">beyond k-anonymity and l-diversity. In ICDE, 2007. [6] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting privacy </span></p><p class="c6"><span class="c2">breaches in privacy preserving data mining. In PODS, 2003. [7] J. Cao and P. Karras. Publishing microdata with a robust </span></p><p class="c6"><span class="c2">privacy guarantee. In VLDB, 2012. [8] A. Fu, K. Wang, R. Wong, J. Wang, and M. Jiang. Small sum </span></p><p class="c6"><span class="c2">privacy and large sum utility in data publishing. Journal of Biomedical Informatics, 50:20&ndash;31, 2014. [9] Y. Tao, X. Xiao, J. Li, and D. Zhang. On anti-corruption </span></p><p class="c6"><span class="c2">privacy preserving publication. In ICDE, 2008. [10] C. Dwork. Differential privacy. In ICALP, 2006. [11] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical </span></p><p class="c16"><span class="c2">privacy: the sulq framework. In PODS, 2005. [12] D. Kifer and A. Machanavajjhala. No free lunch in data </span></p><p class="c6"><span class="c2">privacy. In SIGMOD, 2011. [13] G. Cormode. Personal privacy vs population privacy: learning to attack anonymization. In SIGKDD, 2011. </span></p><p class="c16"><span class="c2">using multiple sensitive attributes. 2(2):278&ndash;284, 2012. [18] R. C. Elandt-Johnson and N.L. Johnson. Survival models and </span></p><p class="c6"><span class="c2">data analysis. John Wiley &amp; Sons NY, 1980. [19] A. Stuart and K. Ord. Kendall&rsquo;s advanced theory of statistics, </span></p><p class="c16"><span class="c2">volume 1. Arnold, London, 6 edition, 1998. [20] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and </span></p><p class="c6"><span class="c2">M. Naor. Our data, ourselves: privacy via distributed noise generation. In EUROCRYPT, volume 4004, pages 486&ndash;503, 2006. [21] C. Li, M. Hay, V. Rastogi, G. Miklau, and A. McGregor. </span></p><p class="c6"><span class="c2">Optimizing linear counting queries under differential privacy. In PODS, 2010. [22] R. Chaytor and K. Wang. Small domain randomization: </span></p><p class="c16"><span class="c2">same privacy, more utility. In VLDB, 2010. [23] V. Rastogi, S. Hong, and D. Suciu. The boundary between privacy and utility in data publishing. In VLDB, 2007. [24] T. Li and N. Li. Injector: mining background knowledge for </span></p><p class="c6"><span class="c2">data anonymization. In ICDE, 2008. [25] S. Agrawal and J. Haritsa. A framework for high-accuracy </span></p><p class="c16"><span class="c2">privacy preserving mining. In ICDE, 2005. [26] W. Press, B. Flannery, S. Teukolsky, and W. Vetterling. </span></p><p class="c23"><span class="c2">Numerical Recipes in C: The Art of Scientific Computing. Cambridge University Press, New York, NY, USA, 1988. [27] H. Chernoff. A measure of asymptotic efficiency for tests of </span></p><p class="c16"><span class="c2">a hypothesis based on the sum of observations. Annals of Mathematical Statistics, 23(4):493&ndash;507, 1952. [28] X. Xiao and Y. Tao. Anatomy: simple and effective privacy </span></p><p class="c6"><span class="c2">preservation. In VLDB, 2006. [29] X. Xiao, G. Bender, M. Hay, and J. Gehrke. ireduct: </span></p><p class="c6"><span class="c2">Differential privacy with reduced relative errors. In SIGMOD, 2011. </span></p><p class="c6"><span class="c2">[14] Adult data set. http://archive.ics.uci.edu/ml/datasets/Adult. </span></p><p class="c6"><span class="c29">480 </span></p><p class="c6"><span class="c22">0% </span></p><p class="c6"><span class="c7">0.1 0.2 0.3 0.4 0.5 </span><span class="c22">0% </span></p><p class="c6"><span class="c7">100K 200K 300K 400K 500K </span></p></body></html>