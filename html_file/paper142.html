<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c29{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:9.7pt;font-family:"Times New Roman";font-style:normal}.c64{color:#000000;font-weight:700;text-decoration:none;vertical-align:sub;font-size:9.8pt;font-family:"Arial";font-style:normal}.c51{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:11pt;font-family:"Arial";font-style:normal}.c18{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12.3pt;font-family:"Arial";font-style:normal}.c69{margin-left:-16.6pt;padding-top:1.4pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c33{margin-left:-25.7pt;padding-top:8.9pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c74{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.3pt;font-family:"Arial";font-style:normal}.c22{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:6.2pt;font-family:"Times New Roman";font-style:normal}.c52{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c60{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:16.6pt;font-family:"Arial";font-style:normal}.c50{margin-left:-25.7pt;padding-top:1.7pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:14.9pt;font-family:"Arial";font-style:normal}.c31{color:#000000;font-weight:700;text-decoration:none;vertical-align:super;font-size:15.1pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:10pt;font-family:"Arial";font-style:normal}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c10{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.6pt;font-family:"Arial";font-style:normal}.c41{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:5.9pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c68{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:17.9pt;font-family:"Arial";font-style:normal}.c96{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:9.1pt;font-family:"Arial";font-style:normal}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:6.6pt;font-family:"Arial";font-style:normal}.c28{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:3.7pt;font-family:"Times New Roman";font-style:normal}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.2pt;font-family:"Times New Roman";font-style:normal}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:14.9pt;font-family:"Arial";font-style:normal}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6pt;font-family:"Arial";font-style:normal}.c45{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.3pt;font-family:"Courier New";font-style:normal}.c97{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Times New Roman";font-style:italic}.c32{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:4.5pt;font-family:"Times New Roman";font-style:normal}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:18.9pt;font-family:"Arial";font-style:normal}.c55{margin-left:-25.7pt;padding-top:3.8pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7pt;font-family:"Arial";font-style:normal}.c90{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:18.9pt;font-family:"Arial";font-style:normal}.c42{margin-left:-0.5pt;padding-top:6pt;text-indent:220.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:4.3pt}.c71{margin-left:-14.2pt;padding-top:2.2pt;text-indent:247.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.9pt}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.1pt;font-family:"Times New Roman";font-style:normal}.c20{color:#000000;font-weight:400;text-decoration:none;vertical-align:sub;font-size:19.9pt;font-family:"Arial";font-style:normal}.c48{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c89{margin-left:-16.6pt;padding-top:7.2pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:7.2pt;font-family:"Times New Roman";font-style:normal}.c39{margin-left:-16.6pt;padding-top:3.8pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c79{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Courier New";font-style:normal}.c91{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5pt;font-family:"Courier New";font-style:normal}.c36{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:6.8pt;font-family:"Courier New";font-style:normal}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11.4pt;font-family:"Arial";font-style:normal}.c62{margin-left:-16.6pt;padding-top:1.7pt;text-indent:25.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c35{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:8.5pt;font-family:"Times New Roman";font-style:normal}.c15{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c12{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7pt;font-family:"Times New Roman";font-style:normal}.c40{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:7.5pt;font-family:"Times New Roman";font-style:normal}.c19{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Times New Roman";font-style:normal}.c66{margin-left:-25.7pt;padding-top:1.4pt;text-indent:34.8pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c11{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:10pt;font-family:"Arial";font-style:normal}.c86{color:#000000;font-weight:400;text-decoration:none;vertical-align:super;font-size:12.3pt;font-family:"Arial";font-style:normal}.c54{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:5.8pt;font-family:"Times New Roman";font-style:normal}.c93{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-5.3pt}.c83{margin-left:-25.7pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c53{margin-left:-20.9pt;padding-top:1.9pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.9pt}.c24{margin-left:-20.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c80{margin-left:124.8pt;padding-top:1.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-0.2pt}.c23{margin-left:-22.8pt;padding-top:10.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:75pt}.c57{margin-left:-22.8pt;padding-top:10.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:143pt}.c77{margin-left:-25.7pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.2pt}.c94{margin-left:-20.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c38{margin-left:-25.7pt;padding-top:29.8pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-16.4pt}.c67{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-12.5pt}.c58{margin-left:-20.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.9pt}.c43{margin-left:-25.7pt;padding-top:11.3pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:121.4pt}.c0{margin-left:-5.8pt;padding-top:7.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-25.4pt}.c46{margin-left:-14.9pt;padding-top:13.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c65{margin-left:-13.8pt;padding-top:10.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:52.6pt}.c56{margin-left:-25.7pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-10.2pt}.c47{margin-left:-20.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14pt}.c81{margin-left:111.4pt;padding-top:1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.9pt}.c87{margin-left:-20.9pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-15.4pt}.c63{margin-left:-20.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c75{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-18.2pt}.c44{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:center;margin-right:-23.5pt}.c84{margin-left:2.3pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-12.5pt}.c72{margin-left:218.2pt;padding-top:132.2pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c73{margin-left:-25.7pt;padding-top:8.9pt;padding-bottom:0pt;line-height:1.15;text-align:justify;margin-right:-16.4pt}.c95{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-14.4pt}.c59{margin-left:141.8pt;padding-top:11pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:142.3pt}.c88{margin-left:218.2pt;padding-top:54.5pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-36.1pt}.c37{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-20.9pt}.c61{margin-left:-13.8pt;padding-top:10.1pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:131.3pt}.c82{margin-left:-25.7pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:right;margin-right:-16.4pt}.c70{margin-left:-25.7pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-13.8pt}.c76{margin-left:-16.6pt;padding-top:1.4pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-19.7pt}.c85{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-24.7pt}.c78{margin-left:-16.6pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.15;text-align:left;margin-right:-21.6pt}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c26{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:justify}.c92{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c98{margin-left:-16.6pt;text-indent:25.8pt;margin-right:-25.4pt}.c49{margin-left:-16.6pt;margin-right:-23.3pt}.c34{margin-left:5.9pt;margin-right:-25.4pt}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c92"><p class="c2"><span class="c97">Industrial and Applications Paper </span></p><p class="c26"><span class="c68">Parallel Duplicate Detection in Adverse Drug Reaction Databases with Spark </span></p><p class="c2"><span class="c15">Chen Wang </span><span class="c60">CSIRO </span><span class="c20">chen.wang@csiro.au </span></p><p class="c2"><span class="c60">Sydney, Australia </span><span class="c15">Sarvnaz Karimi </span><span class="c60">CSIRO </span><span class="c20">sarvnaz.karimi@csiro.au </span><span class="c60">Sydney, Australia </span><span class="c15">ABSTRACT </span><span class="c3">The World Health Organization (WHO) and drug regula- tors in many countries maintain databases for adverse drug reaction reports. Data duplication is a significant problem in such databases as reports often come from a variety of sources. Most duplicate detection techniques either have limitations on handling large amount of data or lack effec- tive means to deal with data with imbalanced label distribu- tion. In this paper, we propose a scalable duplicate detec- tion method built on top of Spark to address these problems. Our method uses the kNN (k nearest neighbors) classifier to identify labelled report pairs that are most useful for classi- fying new report pairs. To deal with the high computational cost of kNN, we partition the labelled data into clusters for parallel computing. We give a method to minimize the cross- cluster kNN search. Our experimental results show that the proposed method is able to produce robust duplicate detec- tion results and scalable performance. </span></p><p class="c2"><span class="c15">1. INTRODUCTION </span></p><p class="c6"><span class="c3">Adverse drug reactions, or ADRs, impose significant haz- ards to public health. They are one of the leading causes of hospitalization, disabilities, and death around the world. ADRs incur significant costs to health-care systems [10, 19]. Post-marketing drug safety surveillance plays an increas- ingly important role in ADR detection in comparison with pre-marketing drug clinical trails as clinical trials have limi- tations on the number of patients involved and the diversity of patient groups. Post-marketing drug safety surveillance mainly uses Spontaneous Reporting Systems (SRS) to detect signals of potential ADRs. These signals are then further as- sessed by experts to establish a causal relationship between a drug and an ADR. The World Health Organization (WHO) and drug regulators in many countries, such as the FDA in the US and the TGA in Australia maintain databases for adverse drug reaction reports. ADR reports are submit- ted from a variety of sources including general practitioners, pharmacists, hospitals, and consumers etc. The ADR report </span></p><p class="c6"><span class="c3">c </span><span class="c48">2016, Copyright is with the authors. Published in Proc. 19th Inter- national Conference on Extending Database Technology (EDBT), March 15-18, 2016 - Bordeaux, France: ISBN 978-3-89318-070-7, on OpenPro- ceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0 </span></p><p class="c6"><span class="c3">database is the major part of the reporting system. Many drug safety assessment methods detect potential ADR sig- nals through the comparison of the reported ADR ratio of a specific drug and that of other drugs in the database. Dis- proportionality often indicates a potential ADR signal [6, 7]. As these methods are sensitive to the number of ADR re- ports, data quality in these databases is essential to the per- formance of ADR detection. One significant problem faced by such a database is report duplication. Duplicates often result from two sources. First, reports from different data sources have overlaps as the same ADR may be reported by different organizations through different channels. Sec- ond, the follow-up reports of the same ADR are wrongly put as separate records in the databases. Duplicates may dis- tort the report ratio of an ADR and affect the performance of these methods significantly. Nkanza and Walop [17] re- ported a 5% duplication rate in vaccine adverse event data, providing an indication of the spread of the problem. </span></p><p class="c6"><span class="c3">Duplicated reports in an ADR database are often not ex- actly the same in each field. Table 1 shows two examples. In the first example, report A and report B are duplicate, but they differ in the reaction outcome description field and report description field. In the second example, report C and report D are duplicate, but they differ in patient age, ADR name and report description field. The different values in the patient age field are likely to be an error introduced when entering a handwritten report. </span></p><p class="c6"><span class="c3">A database record consists of multiple fields. Duplicate detection techniques therefore have two levels: field match- ing and record matching. Field matching mainly concerns comparing numerical, categorical and string values in each field. Record matching concerns whether two or more fea- ture vectors formed by common fields belonging to different records are duplicate. </span></p><p class="c6"><span class="c3">There are many existing works on duplicate detection in relational databases. Early works are referred as record linkage with a focus on linking together two or more sep- arately recorded pieces of information concerning an indi- vidual case [16]. Large amount of work deals with the com- parison of fields that can identify a particular record, such as name, address, and age. The values of these fields are nor- mally short strings. Many field matching techniques concern approximate comparison of strings based on various similar- ity metrics. Commonly used string similarity metrics include edit distance [13], Hamming distance [8], cosine distance and Jaccard coefficient [3] etc. Field matching alone is not able to detect many duplicates, e.g., two string values in the sur- name field can be totally different in the case that a woman </span></p><p class="c2"><span class="c19">Series ISSN: 2367-2005 551 </span><span class="c79">10.5441/002/edbt.2016.52 </span></p><p class="c42"><span class="c17">(a) Field Name Report A Report B patient age 46 46 patient sex M M patient state - - onset date - - reaction outcome description Unknown Recovered drug name Atorvastatin Atorvastatin ADR name Rhabdomyolysis Rhabdomyolysis report description Reference number xxx is a literature The 46-year-old male subject started treatment </span></p><p class="c80"><span class="c17">report received on 02-Oct-2013 pertaining with atorvastatin calcium 80 mg, start to a 46 year-old male patient who date and duration of therapy unknown. experienced rhabdomyolysis while on In 2009,the subject presented with myalgia atorvastatin for the treatment of shoulder and hips for 2-3 weeks, minimal unknown indication. weakness and was diagnosed with rhabdomyolysi </span></p><p class="c71"><span class="c17">(b) Field Name Report C Report D patient age 84 34 patient sex F F patient state Not Known Not Known onset date 30/04/2013 00:00:00 30/04/2013 00:00:00 reaction outcome description Unknown Recovered drug name Influenza Vaccine,Dtpa Vaccine Influenza Vaccine,Dtpa Vaccine ADR name Vomiting,Pyrexia,Cough,Headache Cough,Headache,Choking sensation,Chills,Vomiting report description On 30 April 2013, in the evening, within hours In the afternoon of 30-Apr-2013, the patient </span></p><p class="c81"><span class="c17">of vaccination with Boostrix, the subject experienced uncontrollable cough for 2 hours, experienced uncontrollable cough and felt then started choking and had to call an ambulance. like she was chocking On the same She required oxygen before she felt better night, the subject experienced headache.On and so didn&rsquo;t go to hospital. She then the 01-05-2013 at 3am, the subjet experienced. reported a headache, cold shive </span></p><p class="c59"><span class="c3">Table 1: Sample duplicated reports. </span></p><p class="c38"><span class="c3">changes her maiden name to her husband&rsquo;s surname, but they belong to the same record. </span></p><p class="c50"><span class="c3">Record matching considers each field as an element of a feature vector of a record. It combines the differences among common fields of two or more records to determine whether they are duplicate. The ways of combining field similarities of records differentiates record matching techniques. Some techniques calculate the probability of difference of values in each common field, converts these probabilities to log values and add them together [16, 11, 12]. Some techniques use su- pervised decision tree induction and unsupervised clustering to determine if a record is likely to match a set of other data records [5]. Active learning is also used for record matching to reduce the amount of training data [20]. </span></p><p class="c82"><span class="c3">However, the effectiveness of existing duplicate detection techniques due to the slow on ADR progress databases of the is industry&acirc;not well Ainvestigated </span><span class="c25">&nbsp;&#774;</span><span class="c3">Zs </span><span class="c25">&nbsp;&#769;</span><span class="c3">mainly adopting infor- mation technologies. We collaborate with the Therapeutic Goods Administration (TGA) in Australia and use the ADR reports they collected during 6 month period to carry out this work. In this paper, we study the duplicate detection problem in ADR databases with a focus on detection per- formance and system scalability that is important for fast growing data in this area. Our contributions are as below: </span></p><p class="c46"><span class="c3">1. To identify duplicates in ADR reports, pairwise dis- tances between these reports often need to be calcu- lated. The distribution of duplicate pairs and non- duplicate pairs is highly imbalance. This poses a sig- nificant challenge when selecting report pairs from a large dataset to train a classifier for exploiting useful information. The classification results are highly influ- enced by the overwhelming majority of non-duplicate report pairs. There is no generally applicable classi- fication method to address this issue. We develop a </span></p><p class="c6 c34"><span class="c3">kNN based method to address this problem for ADR reports. kNN is helpful for the classifier to learn from individual reports and makes the classification results easy to understand. It also offers flexibility through as- signing weights to the information carried in the neigh- bors in decision making. Our extensive experiments show that our method produces more robust detection results in comparison to SVM based classifiers. </span></p><p class="c0"><span class="c3">2. A drug regulator database in a country with a rela- tively small population may already contain a large number of ADR reports that easily overwhelms the computing capacity for effective duplicate detection. In addition, kNN is both data- and compute-intensive when the dataset grows large. The MapReduce model is a convenient way to scale up the duplicate detection. However, its Google and open source implementation are mainly optimized for batch jobs so far [22]. Du- plicate detection for ADR databases has a potential use-case for interactive and fast detection of duplicates for a specific report. Apache Spark [24] has the poten- tial to support interactive data analytics. We imple- ment a Spark based parallel system to support fast and scalable kNN classification for duplicates. Taking ad- vantage of the distributed memory management and parallel data processing support offered by Spark, the system is able to handle large amount of ADR reports in a scalable manner. </span></p><p class="c89"><span class="c3">The rest of this paper is organized as follows: Section 2 introduces the background technologies of our work; Sec- tion 3 defines the problem; Section 4 describes the system and our Fast kNN classification method; Section 5 gives the evaluation results of the performance of the system; Sec- tion 6 summarizes related works; and Section 7 concludes the paper. </span></p><p class="c88"><span class="c19">552 </span></p><p class="c2"><span class="c15">2. BACKGROUND </span></p><p class="c2"><span class="c15">2.1 </span><span class="c3">k</span><span class="c15">NN Classification </span></p><p class="c4"><span class="c3">In a D-dimensional space D, s and t are two vectors rep- resenting two data objects. We use d(s, t) to denote the distance between s and t. Consider S and T are two sets of such vectors, for a vector s &isin; S, we denote its k near- est neighbors according to a given distance function in T as knn(s,T,k). We assume that each t &isin; T is associated with are unknown. a label L</span><span class="c7">t</span><span class="c3">,L</span><span class="c7">t </span><span class="c3">We use &isin; {&minus;1,+1}. knn</span><span class="c11">+</span><span class="c3">(s,T,k) The to labels denote of vectors the vectors in S </span></p><p class="c6"><span class="c3">in knn(s,T,k) with label &ldquo;+1&rdquo; and knn</span><span class="c11">&minus;</span><span class="c3">(s,T,k) to denote vectors with label &ldquo;&minus;1&rdquo;. kNN classifier assign a label to s according to the following equation (note that the number of vectors in knn(s,T,k) is an odd number): </span></p><p class="c2"><span class="c3">L</span><span class="c7">s </span><span class="c3">= </span></p><p class="c2"><span class="c3">{ </span><span class="c9">+1,</span><span class="c3">&minus;1,&sum;</span><span class="c25">&sum;</span><span class="c5">t&isin;knn</span><span class="c7">t&isin;knn</span><span class="c91">+</span><span class="c45">+</span><span class="c5">(s,T,k) </span><span class="c7">(s,T,k) </span><span class="c3">L</span><span class="c7">t </span><span class="c25">L</span><span class="c11">t </span><span class="c3">+ </span><span class="c25">+ &sum;&sum;</span><span class="c7">t&isin;knnt&isin;knn</span><span class="c45">&minus;&minus;</span><span class="c7">(s,T,k) (s,T,k) </span><span class="c25">L</span><span class="c11">t </span><span class="c25">L</span><span class="c11">t </span><span class="c25">&gt; &lt; 0 </span></p><p class="c6"><span class="c25">0</span><span class="c3">(1) Assigning labels to each s &isin; S according to their nearest neighbors requires a kNN join operation between S and T to identify k nearest neighbors of set S in T, denoted as S </span><span class="c5">knn </span><span class="c9">T. </span></p><p class="c2"><span class="c3">S </span><span class="c5">knn </span><span class="c9">T = {(s, knn(s,T,k)|&forall;s &isin; S} (2) </span><span class="c15">2.2 Spark </span></p><p class="c6"><span class="c3">Spark [24] is a cluster computing framework that sup- ports iterative and interactive data processing. It provides a level of data abstraction called resilient distributed datasets (RDDs) [23] to represent a set of immutable data objects. These data objects can be partitioned among a number of cluster nodes. RDDs are fault-tolerant and can be recon- structed when their hosting nodes fail. </span></p><p class="c6"><span class="c3">There are two types of operations that can be applied to a RDD in the Spark framework: transformations and actions. A transformation contains operations that produces a new RDD from an existing RDD while an action returns a value after operating on a RDD. Operations are often executed in parallel on a RDD. In addition to support map, reduce and aggregate operations on a RDD, Spark also offers operations such as join, union and cartesian to manipulate multiple RDDs. Different to MapReduce, RDDs where map and re- duce operate on can be persistent in memory in nodes of the cluster, which greatly improves the efficiency of iterative and interactive applications. A duplicate detection system like the one discussed in this paper is an iterative process that contains data processing of multiple stages and it fits the Spark framework well. </span></p><p class="c2"><span class="c15">3. THE PROBLEM </span></p><p class="c6"><span class="c3">An adverse drug reaction report database A stores reports continuously collected by a regulator. We consider that a set of new reports, denoted by R arrive in the database may contain duplicates among themselves as well as with existing reports in the database. The problem is to identify the following set of report pairs: </span></p><p class="c4"><span class="c3">Dupe(R,A) = {(r, h)|sim(r, h) &lt; &epsilon;,&forall;r &isin; R,&forall;h &isin; A&cup;R&minus;r} (3) in which, sim is a scoring function that measures the similar- ity between two reports and &epsilon; is a threshold that determines whether two reports are duplicate. </span></p><p class="c6"><span class="c3">Duplicate detection within database A can been seen as a recursive process in which reports are sorted according to their arrival time to the database and reports with later arrival time are checked for duplication against those with earlier arrival time. </span></p><p class="c6"><span class="c3">Note that even though an ADR database may contain 5% of reports that have at least one duplicate in the database, when it comes to the number of duplicated report pairs, the rate of duplicates is much lower. This is because the number of report pairs grows quadratically with the number of re- ports and non-duplicate report pairs grows much faster than duplicate report pairs. This results in highly imbalanced dis- tribution of duplicate and non-duplicate report pairs in the dataset derived from A. </span></p><p class="c2"><span class="c15">4. THE SYSTEM </span></p><p class="c2"><span class="c15">4.1 The Workflow </span></p><p class="c6"><span class="c3">The workflow for duplicate detection in ADR database is shown in Figure 1. It contains the following major compo- nents: </span></p><p class="c6"><span class="c3">&bull; Report database: The report database stores reports collected by a regulator and new reports are continu- ously added to this database. </span></p><p class="c6"><span class="c3">&bull; Text processing module: Our system contains a text processing component to clean up text data in a re- port using common natural language processing tech- niques. Free text plays an increasingly important role in ADR reports as consumers increasingly participate in reporting drug side effects to regulators in recent years. Free text in a report not only is helpful for un- derstanding drug side effects, but also contains useful information to identify duplicated reports. Compared to string fields such as name and address in existing duplicate detection systems, a free text field such as &ldquo;report description&rdquo; is significantly longer with major- ity of them being 250 and 300 characters long. This requires NLP techniques to extract useful information from the text for duplicate detection. On the other hand, regulators also increasingly monitor various data sources that contain large amount of text for ADR re- lated information. </span></p><p class="c2"><span class="c3">&bull; Pairwise distance computing module: The module com- putes the pairwise distance among a set of reports in- cluding selected reports from the database and new reports arriving to the system. </span></p><p class="c2"><span class="c3">&bull; Training datasets (labelled datasets): The system main- tains two temporary databases for duplicate detection: one contains report pairs that are known to be du- plicate; the other contains samples of non-duplicate report pairs. The initial duplicate/non-duplicate la- belling is done manually by domain experts from drug regulators, in our case, the TGA. Afterwords, the col- lection of report pairs in the two temporary databases are dynamically adjusted when new duplicates and non-duplicates are identified. Note that the duplicate report pair database stores all known duplicates while the non-duplicate report pair database only keeps a subset of known non-duplicates. The difference is due to the highly imbalanced distribution of duplicate and non-duplicate pairs. </span></p><p class="c2"><span class="c19">553 </span></p><p class="c2"><span class="c10">Unlabelled New Reports </span></p><p class="c2"><span class="c10">report pairs </span></p><p class="c2"><span class="c8">Text field </span></p><p class="c2"><span class="c8">Pairwise report processing </span></p><p class="c2"><span class="c8">distances </span></p><p class="c2"><span class="c8">Report Database </span></p><p class="c2"><span class="c3">Figure 1: The workflow of the system &ndash; the dashed line represents that the source data becomes part of the target data when the processing finishes. </span></p><p class="c2"><span class="c3">&bull; Classification module: The report pairs are fed into the classification module that computes the scores for each pair and generates a list of duplicate pairs given a score threshold. Many classification algorithms fit into this system framework. We use kNN classifier as the default one for this application area. One advantage of kNN is that the classification results are easy to ex- plain with human intuition and the basis of decision making can be justified clearly. This characteristics is particularly useful when the training dataset is highly imbalanced and global algorithms are difficult to sep- arate them with general models. </span><span class="c15">4.2 Report Distance Calculation </span></p><p class="c6"><span class="c3">A typical ADR report contains fields as shown in Table 2. Due to different missing data rates in different fields as well as schema inconsistency in data sources, common practices choose a subset of fields as input for duplicate detection. The fields used in our method are highlighted in bold fonts. The selection of fields is based on the WHO system as de- scribed in [18]. In the selected fields, patient age (&ldquo;calculated age&rdquo;) is numerical type. Patient sex, residential state and onset date are treated as categorical data type. ADR name (&ldquo;MedDRA PT code&rdquo;) and drug name (&ldquo;generic name de- scription&rdquo;) have string type. Different methods deal with string type differently, e.g., they are treated as categorical type in probability based methods and programming level string type in SVM based methods. As mentioned, free text becomes increasingly important in ADR reporting systems, we therefore include the report description field in our du- plicate detection system and treat it as string type. </span></p><p class="c6"><span class="c3">For a numerical field, if the values of two reports in the field is the same, the distance is 0, otherwise 1. The same calculation applies to categorical field types. For fields of string type, we use Jaccard similarity coefficient to measure the distance between two values as below: </span></p><p class="c2"><span class="c3">d(S</span><span class="c5">1</span><span class="c9">,S</span><span class="c5">2</span><span class="c9">)=1 &minus; </span><span class="c3">|S|S</span><span class="c7">1 </span><span class="c5">1 </span><span class="c9">&cap; </span><span class="c3">&cup; </span><span class="c9">S</span><span class="c3">S</span><span class="c7">2</span><span class="c3">| </span><span class="c5">2</span><span class="c9">| </span></p><p class="c2"><span class="c25">(4) </span></p><p class="c6"><span class="c3">in which, |S| is the size of set S. The free text field is of string type, but as mentioned earlier, majority of values in the free text field are between 250 and 300 characters long. In order to eliminate the impact of typographical errors or </span></p><p class="c4"><span class="c8">Classification </span><span class="c51">Duplicated </span><span class="c10">report pairs </span><span class="c74">Processed reports </span></p><p class="c26"><span class="c10">Labelled duplicates </span></p><p class="c26"><span class="c10">Labelled non- duplicates </span></p><p class="c6"><span class="c3">different ways of constructing sentences, we apply common techniques to tokenize the content in the report description field, remove stop words, and then stem tokenized words to their root forms before computing their distances. </span></p><p class="c6"><span class="c3">The distances of values in these selected fields of any two reports form a distance vector between the report pair. The comparison between two distance vectors, i.e., measuring how similar a report pair is in comparison to another pair of reports, is based on the Euclidean distance between the two distance vectors of the two pairs. </span></p><p class="c2"><span class="c3">Information Fields Case Details case number, report date </span></p><p class="c2"><span class="c3">Patient Details calculated age, sex, weight code, eth- </span></p><p class="c2"><span class="c3">nicity code, residential state </span></p><p class="c2"><span class="c3">Reaction Infor- mation </span></p><p class="c6"><span class="c3">onset date, date of outcome, reac- tion outcome code, reaction out- come description, severity code, sever- ity description, report description, treatment text, hospitalisation code, hospitalisation description, MedDRA Low Level Term (LLT) code, LLT name, MedDRA Preferred Term (PT) code, PT name </span></p><p class="c2"><span class="c3">Medicine Infor- mation </span></p><p class="c6"><span class="c3">suspect code, suspect description, trade name code,trade name text, trade name description, generic name code, generic name description, dosage amount, unit proportion code, dosage form code, dosage form de- scription, route of administration code, route of administration description, dosage start date, dosage halt date </span></p><p class="c2"><span class="c3">Reporter Details reporter type, report type description </span></p><p class="c6"><span class="c3">Table 2: Data fields of an ADR report in TGA data. The bold font indicates fields used in our duplicate detection method. </span></p><p class="c2"><span class="c19">554 </span></p><p class="c2"><span class="c15">4.3 Fast </span><span class="c3">k</span><span class="c15">NN Classification </span></p><p class="c6"><span class="c3">With the pairwise distances calculated, a kNN join is ap- plied to labelled report pairs, denoted by T, and report pairs containing new reports, denoted by S. The classification of a report pair s &isin; S is based on the score computed from its nearest neighbors in T. Due to the imbalanced distribution of positive and negative labels, the negative report pairs eas- ily overwhelm the positive ones. We therefore normalize the score using the distance between two pairs as below. </span></p><p class="c2"><span class="c3">score</span><span class="c5">s </span><span class="c9">= </span><span class="c3">&sum; </span></p><p class="c2"><span class="c7">t&isin;knn</span><span class="c45">+</span><span class="c7">(s,T,k) </span></p><p class="c2"><span class="c3">1 sim(s, t) </span><span class="c25">&minus; </span><span class="c7">t&isin;knn</span><span class="c25">&sum; </span></p><p class="c2"><span class="c45">&minus;</span><span class="c7">(s,T,k) </span></p><p class="c4"><span class="c3">1 sim(s, t)</span><span class="c9">(5) </span><span class="c3">The label of s is therefore determined by the following equa- tion, in which &theta; is a given threshold: </span></p><p class="c2"><span class="c3">L</span><span class="c5">s </span><span class="c9">= </span></p><p class="c2"><span class="c3">{ </span><span class="c9">+1, score</span><span class="c5">s </span><span class="c9">&ge; &theta; </span></p><p class="c2"><span class="c3">&minus;1, score</span><span class="c5">s </span><span class="c9">&lt; &theta; </span><span class="c3">(6) </span></p><p class="c2"><span class="c22">4.3.1 Parallelization Strategy </span></p><p class="c4"><span class="c3">Consider the number of report pairs in T is n and the number of report pairs in S is m, the computing complexity of kNN classification is O(m&middot;n) for join and O(m&middot;k) for score calculation. n exhibits quadratic growth with the number of reports. The amount of data to process easily overwhelms a single server. To make the classification scalable, we parti- tion T and S into a set of clusters, denoted by {T</span><span class="c5">1</span><span class="c9">,T</span><span class="c5">2</span><span class="c9">, ..., T</span><span class="c5">b</span><span class="c9">} </span><span class="c3">and {S</span><span class="c7">1</span><span class="c3">,S</span><span class="c7">2</span><span class="c3">, ..., S</span><span class="c7">c</span><span class="c3">} respectively. The cluster size in a parti- tion is adjusted to fit into the memory capacity of a comput- ing node. A naive parallelization strategy is to apply kNN join for each partition group {(T</span><span class="c5">i</span><span class="c9">,S</span><span class="c5">j</span><span class="c9">)|1 &le; i &le; b,1 &le; j &le; c} </span><span class="c3">and then merge the nearest neighbors from each partition group. This approach does not reduce the overall comput- ing complexity and incurs high data transfer cost as each partition in S needs to compare with all partitions in T. The merge of intermediate nearest neighbors may poten- tially become another bottleneck that limits the scalability. To address this problem, we exploit the locality of report pairs in T in partitioning. We first partition report pairs using k &minus; means clustering to obtain c clusters. The center of each cluster is calculated and stored in memory. Note that clusters produced by k &minus; means form a Voronoi di- agram where each report pair in a cluster is closer to the center of the cluster it belongs to than to any other cluster centers. We then assign each report pair s &isin; S to a cluster whose center is the closest to s comparing to other cluster centers. It is likely that most of the k nearest neighbors of s are within the cluster it is assigned, i.e., most of report pairs in knn(s,T,k) can be found in knn(s, T</span><span class="c5">i</span><span class="c9">,k) where T</span><span class="c5">i </span><span class="c3">is the cluster to which s is assigned. Certainly, there are chances that some of the k nearest neighbors of s are in clusters sharing borders with the cluster. The two scenarios are illustrated in Fig. 2. </span></p><p class="c6"><span class="c3">Our method therefore consists of two stages to deal with the two scenarios. In the first stage, we compute the k near- est neighbors within a partition to which each s &isin; S is as- signed. In the second stage, the cross-cluster comparison is performed for those testing report pairs falling into the sec- ond scenario in Fig. 2. The key technical challenge is how to determine whether it is necessary to check neighbor par- titions when identifying the k nearest neighbors of a testing report pair. </span></p><p class="c2"><span class="c22">4.3.2 Observations </span></p><p class="c2"><span class="c3">(a) (b) </span></p><p class="c6"><span class="c3">Figure 2: kNN under partitioned dataset: the cir- cle represents the cluster center of a partition; the triangle represents a testing report pair s; the dark square represents a positive report pair in knn(s,T,k) and the light square represents a negative report pair in knn(s,T,k). (a) knn(s,T,k) are all in one par- tition; (b) knn(s,T,k) are in different partitions. </span></p><p class="c6"><span class="c3">To address this problem, we develop an optimization algo- rithm that intends to prune unnecessary cross-cluster com- parisons. The algorithm is based on the following observa- tions: </span></p><p class="c6"><span class="c3">1. The number of positively labelled report pairs is small and it incurs low computational cost to calculate dis- tances between these positive report pairs and report pairs in testing dataset. </span></p><p class="c6"><span class="c3">2. When the k nearest neighbors of s &isin; S are all labelled negative, there is no ground to classify s as a duplicate report pair. </span></p><p class="c6"><span class="c3">3. When the distance between s and its nearest positive neighbor is greater than that between s and the k-th nearest negative neighbor in a subset of T, it is clear that there is no positive report pair in the knn(s,T,k). </span></p><p class="c6"><span class="c3">4. As mentioned above, k&minus;means produces Voronoi par- titions on the training report pairs, hence the hyper- plane, denoted by h that separates two partitions is in the middle between the two cluster centers of the two partitions. If the distance between s &isin; S and its k-th nearest neighbor, denoted by s</span><span class="c5">k </span><span class="c9">in the partition </span><span class="c3">to which it is assigned is less than its distance to the hyperplane, the distance between s and s</span><span class="c7">k</span><span class="c3">, denoted by d(s, s</span><span class="c5">k</span><span class="c9">) is certainly less than distances from s to any </span><span class="c3">report pairs in the other partition. </span></p><p class="c6"><span class="c3">The scenario of observation 4 is shown in Fig. 3, where the distance between s and the partition hyperplane is d(s, h), the distance between s and the closest report pair s</span><span class="c5">x </span><span class="c9">in the </span><span class="c3">other partition is d(s, s</span><span class="c5">x</span><span class="c9">). d(s, h) can be derived according </span><span class="c3">to [9] as below:</span><span class="c9">d(s, h) = </span><span class="c3">d(s, p</span><span class="c5">j</span><span class="c9">)</span><span class="c7">2 </span><span class="c9">&minus; d(s, p</span><span class="c5">i</span><span class="c9">)</span><span class="c7">2 </span></p><p class="c6"><span class="c3">2 &middot; d(p</span><span class="c7">i</span><span class="c3">,p</span><span class="c7">j</span><span class="c3">) </span><span class="c25">(7) </span><span class="c3">in which, p</span><span class="c5">i </span><span class="c9">and p</span><span class="c5">j </span><span class="c9">denote the center of partition T</span><span class="c5">i </span><span class="c9">and </span><span class="c3">T</span><span class="c7">j </span><span class="c3">respectively. As d(s, b) is the shortest distance between s and the hyperplane b and connecting s and s</span><span class="c5">x </span><span class="c9">needs to </span><span class="c3">cross the hyperplane, we have d(s, s</span><span class="c5">x</span><span class="c9">) &ge; d(s, b) according to </span></p><p class="c2"><span class="c19">555 </span></p><p class="c6"><span class="c3">the triangle inequality. Therefore when d(s, s</span><span class="c5">k</span><span class="c9">) &le; d(s, b), it </span><span class="c3">is not necessary to include the partition T</span><span class="c5">j </span><span class="c9">with center C</span><span class="c5">j </span><span class="c3">in the searching for knn(s,T,k). </span></p><p class="c6"><span class="c3">Algorithm 1 describes the steps for selecting additional partitions to be included kNN computing for a report pair s. Line 2 &ndash; 5 is based on observation 1 &ndash; 3 and line 6 &ndash; 12 is based on observation 4. </span></p><p class="c26"><span class="c13">d</span><span class="c90">(s,s ) </span><span class="c86">k</span><span class="c27">p</span><span class="c18">i </span><span class="c13">d(s, s</span><span class="c18">x</span><span class="c27">) p</span><span class="c18">j </span><span class="c27">s </span></p><p class="c2"><span class="c13">s</span><span class="c18">k </span></p><p class="c2"><span class="c13">s</span><span class="c18">x </span></p><p class="c2"><span class="c13">d(s, h) </span></p><p class="c2"><span class="c13">Partition boundary(h) </span></p><p class="c6"><span class="c3">Figure 3: Additional partition selection for kNN un- der partitioned datasets: p</span><span class="c5">i </span><span class="c9">and p</span><span class="c5">j </span><span class="c9">represent two </span><span class="c3">partition centers; the triangle represents a testing report pair s. </span></p><p class="c2"><span class="c3">Algorithm 1 Additional Partition Selection Require: s &isin; S Require: Require: knn(s, min(s, TT </span><span class="c5">i</span><span class="c9">,k) </span></p><p class="c2"><span class="c11">+</span><span class="c3">): the mininal distance between s and positive report pairs in T Require: The centers of partitions : {p</span><span class="c5">j</span><span class="c9">|1 &le; j &le; b} </span></p><p class="c2"><span class="c3">1: partitions = {} 2: 3: d(s, if d(s, s</span><span class="c5">k</span><span class="c9">) </span><span class="c3">s</span><span class="c5">k</span><span class="c9">) = max(knn(s, &le; min(s, T </span><span class="c7">+</span><span class="c9">T) </span><span class="c5">i</span><span class="c9">,k)) </span></p><p class="c2"><span class="c9">then </span><span class="c3">4: return partitions 5: end if 6: for 1 &le; j &le; b, j = i do 7: compute d(s, h</span><span class="c5">ij</span><span class="c9">) using Equation 7. h</span><span class="c5">ij </span><span class="c9">denotes the </span></p><p class="c2"><span class="c3">hyperplane separating T</span><span class="c7">i </span><span class="c3">and T</span><span class="c7">j</span><span class="c3">. 8: if d(s, s</span><span class="c5">k</span><span class="c9">) &gt; d(s, h</span><span class="c5">ij</span><span class="c9">) then </span><span class="c3">9: partitions = partitions &cup; T</span><span class="c5">j </span><span class="c3">10: end if 11: end for 12: return partitions </span></p><p class="c2"><span class="c22">4.3.3 The Classification Algorithm </span></p><p class="c6"><span class="c3">Algorithm 2 gives main steps of implementing the dupli- cate detection method described above with Spark primi- tives of transformations and actions. The stage 1 (intra- cluster comparison stage) is performed in line 6 &ndash; 8. The stage 2 (cross-cluster comparison stage) is performance in line 9 &ndash; 16. Stage 2 first computes the distances of the testing report pair to all positive training pairs. It skips </span></p><p class="c6"><span class="c3">cross-cluster comparison if the top k most similar report pairs obtained so far are all negative, indicating there will not be any positive training report pairs closer than the k-th nearest negative report pairs. Otherwise, cross-cluster com- parisons are performed in line 12 &ndash; 15. The output score of each report pair is used to assign a label to the pair accord- ing to Equation 6. </span></p><p class="c2"><span class="c3">Algorithm 2 Fast kNN Classification. Require: A training dataset T containing report pairs la- </span></p><p class="c2"><span class="c3">belled as duplicate or non-duplicate Require: A testing dataset S containing unlabelled report </span></p><p class="c2"><span class="c3">pairs Require: b &ndash; the number of clusters for partitioning T; c &ndash; </span></p><p class="c2"><span class="c3">the number of partitions for S 1: use k &minus; means to partition T into b clusters: {T</span><span class="c5">1</span><span class="c9">,T</span><span class="c5">2</span><span class="c9">, ..., T</span><span class="c5">b</span><span class="c9">} with cluster centers of these partitions </span><span class="c3">denoted by P = {p</span><span class="c5">1</span><span class="c9">,p</span><span class="c5">2</span><span class="c9">, ..., p</span><span class="c5">b</span><span class="c9">} </span><span class="c3">2: run map operation to compute distances between P and </span></p><p class="c2"><span class="c3">s &isin; S 3: assign s the partition i where dist(s, p</span><span class="c7">i</span><span class="c3">),(1 &le; i &le; b) is </span></p><p class="c2"><span class="c3">minimal for vectors in P. 4: randomly split S into c partitions : {S</span><span class="c7">1</span><span class="c3">,S</span><span class="c7">2</span><span class="c3">, ..., S</span><span class="c7">c</span><span class="c3">} 5: for i = 1 to c do 6: run join operation on S</span><span class="c5">i </span><span class="c9">and T </span><span class="c7">&minus; </span><span class="c9">based on cluster IDs </span></p><p class="c26"><span class="c3">(T </span><span class="c11">&minus; </span><span class="c3">denotes the negative report pairs in T) 7: run map operation to compute the similarity between </span></p><p class="c2"><span class="c3">joined report pairs 8: run aggregate operation to obtain the top k most sim- ilar report pairs for each s &isin; S</span><span class="c5">i </span><span class="c9">based on the output </span><span class="c3">of the previous step 9: run map operation to compute distances between s &isin; S</span><span class="c7">i </span><span class="c3">and T </span><span class="c11">+ </span><span class="c3">(T </span><span class="c11">+ </span><span class="c3">denotes the subset of positive report pairs in T) 10: run map operation to combine the results from step 8 and step 9 to update the top k most similar reports pairs to s 11: if the output of step 10 contains at least one positive </span></p><p class="c2"><span class="c3">report pair then 12: run map operation on {(s, knn(s,T,k))} for s &isin; S</span><span class="c7">i </span><span class="c3">to compute a set of additional partitions to compare using Algorithm 1 13: run join operation on S</span><span class="c7">i </span><span class="c3">and additional partitions </span></p><p class="c2"><span class="c3">for s &isin; S</span><span class="c5">i </span><span class="c9">to compare </span><span class="c3">14: run map operation to compute the similarity be- </span></p><p class="c2"><span class="c3">tween joined report pairs 15: run union and reduce operation to merge top k </span></p><p class="c2"><span class="c3">nearest neighbors in each partition for s &isin; S</span><span class="c7">i </span><span class="c3">16: end if 17: run map to calculate the score for s &isin; S</span><span class="c7">i </span><span class="c3">according to </span></p><p class="c2"><span class="c3">Equation 5 18: end for 19: return all s &isin; S and corresponding scores </span></p><p class="c2"><span class="c22">4.3.4 Further Pruning of the Testing Dataset </span></p><p class="c6"><span class="c3">To further reducing the execution time of kNN classifica- tion, we can prune some report pairs from the testing dataset before applying the classifier. As shown in Equation 6, a pre-defined &theta; determines the label of a report pair. When the distance between a testing report pair and its positively labelled k-nearest neighbor is further than a threshold, the neighbor offers little hint to the label of the testing report </span></p><p class="c2"><span class="c19">556 </span></p><p class="c2"><span class="c3">pair because of the low similarity between the two pairs. This observation can be used to prune the testing dataset. </span></p><p class="c6"><span class="c3">When the testing dataset is large and the positive training pairs accumulate along time, it is necessary to speedup the computation of distances between each report pair in the testing dataset and each labelled positive report pair in the training dataset. We cluster the report pairs labelled as positive and use the cluster centers to determine whether a report pair in the testing dataset should be included in the classification. Assume the distance threshold between two report pairs is a function of &theta;, denoted as f(&theta;), The process is described as below: </span></p><p class="c6"><span class="c3">Step 1. Cluster the positive report pairs into l clusters using k-means. We denote the cluster centers as cp</span><span class="c7">i</span><span class="c3">(0 &lt; i&lt;l); </span></p><p class="c6"><span class="c3">Step 2. Compute the distance of the furthest report pair to its center in each cluster. We denote these distances as dcp</span><span class="c7">i</span><span class="c3">(0 &lt;i&lt;l); </span></p><p class="c2"><span class="c3">Step 3. For each report pair t in the testing report pair set, </span></p><p class="c2"><span class="c3">do the following: </span></p><p class="c2"><span class="c3">(a) For each 0 &lt;i&lt;l, calculate dist(t, cp</span><span class="c7">i</span><span class="c3">); (b) if any dist(t, cp</span><span class="c5">i</span><span class="c9">) &le; dcp</span><span class="c5">i </span><span class="c9">+ f(&theta;), include t into </span></p><p class="c2"><span class="c3">the testing set; </span></p><p class="c6"><span class="c3">Fig. 4 shows an example of the process in 2-dimensional space. cp</span><span class="c7">i </span><span class="c3">and cp</span><span class="c7">j </span><span class="c3">are the centers of two clusters of positive report pairs. For simplicity, we assume the positive report pairs are partitioned into only two clusters. The inner circles are formed using the distance between the furthest report pair and the center in each cluster. The shortest distance between the dashed circle and its corresponding inner circle is f(&theta;). In Fig. 4, p and q are testing report pairs. p is outside of both dashed circles and those positive report pairs are considered not helpful to decide the label of p. p is therefore pruned from the testing dataset. On the other hand, q is close enough to cp</span><span class="c5">i </span><span class="c9">(within its dashed circle) and </span><span class="c3">the positive report pairs in the cp</span><span class="c5">i </span><span class="c9">cluster may carry useful </span><span class="c3">information for labelling q. q is therefore included in the testing dataset for classification. </span></p><p class="c2"><span class="c36">p </span></p><p class="c2"><span class="c31">cp</span><span class="c41">i </span></p><p class="c2"><span class="c36">q </span><span class="c96">cp</span><span class="c64">j </span></p><p class="c6"><span class="c3">Figure 4: Pruning the testing dataset:&ldquo;+&rdquo;represents a positive report pair and &ldquo;-&rdquo; represents a negative report pair. The triangle represents a testing report pair. </span></p><p class="c2"><span class="c15">5. EVALUATIONS </span></p><p class="c6"><span class="c3">We implement the duplicate detection system in Java with Spark 1.2.1 API. We evaluate the performance of our sys- tem in a cluster consisting of 14 physical nodes. Each node </span></p><p class="c6"><span class="c3">has 2 x Intel Xeon E5-2660@2.20GHz CPU (8 cores) and 128GB physical RAM, in which 96GB is allocated to con- tainers. The connection among nodes is via Infiniband net- works. The OS in each node is Debian Wheezy. Cloudera CDH5 (5.0.0) with Hadoop 2.3.0 is installed with Yarn mode on. We run multiple executors on these nodes. </span></p><p class="c2"><span class="c15">5.1 Datasets </span></p><p class="c6"><span class="c3">We obtain ADR report data from TGA Australia. TGA maintains a database to store ADR reports submitted by various parties and collected by themselves. The sources that submit reports to the database include pharmaceutical companies, hospitals, general physicians, patients etc. TGA provides us 10,382 ADR reports they collected for a period of six months from July 2013 to December 2013. These reports consist 286 pairs of reports labelled as known dupli- cates. These duplicates were annotated by officers of TGA. Table 3 summarizes the dataset. </span></p><p class="c2"><span class="c3">Report Period 1 Jul. 2013 - 31 Dec. 2013 Number of cases 10,382 Number of fields per report 37 Number of unique drugs 1,366 Number of unique ADRs 2,351 Known duplicate pairs 286 </span></p><p class="c2"><span class="c3">Table 3: Summary of TGA dataset. </span></p><p class="c2"><span class="c3">The fields in each report in this dataset are listed in Ta- ble 2. </span></p><p class="c2"><span class="c15">5.2 Fast </span><span class="c3">K</span><span class="c15">NN Performance </span></p><p class="c2"><span class="c22">5.2.1 Baseline </span></p><p class="c6"><span class="c3">Many classification methods are applicable to duplicate detection problem where distance vectors of report pairs are classified as similar or different. Support vector machine (SVM) is a popularly used one in duplicate detection [2, 20]. In our evaluation, we use a SVM classifier as the baseline for comparison. </span></p><p class="c2"><span class="c3">SVM based methods take distance vectors between each pair of reports as input and map them into a high-dimensional space. These methods then use a hyperplane to separate dis- tance vectors that represent duplicate report pairs and those representing non-duplicate report pairs. The hyperplane is obtained through learning from a training dataset contain- ing labelled duplicates and non-duplicates. The hyperplane maximizes its margins to points belonging to the two dif- ferent classes. With the hyperplane, new report pairs are considered duplicates if their distance vectors fall into the match side of the hyperplane with a large margin; otherwise, they are considered non-duplicates. </span></p><p class="c2"><span class="c22">5.2.2 Precision and Recall </span></p><p class="c6"><span class="c3">We measure the classification performance using the area under precision and recall curve (AUPR). Precision and re- call are defined as below in our case: </span></p><p class="c2"><span class="c3">precision = </span><span class="c11">number of correctly identified duplicate pairs </span></p><p class="c2"><span class="c7">number of total identified duplicate pairs </span></p><p class="c2"><span class="c3">recall = </span><span class="c11">number of correctly identified duplicate pairs </span></p><p class="c2"><span class="c7">number of total true duplicate pairs </span></p><p class="c2"><span class="c19">557 </span></p><p class="c33"><span class="c3">AUPR shows how the precision values vary with different recall values. AUPR is able to visualize the difference of algorithms compared to other metrics and suitable for highly imbalanced datasets [4]. The goal to improve an algorithm with the precision-recall curve metric is to move the curve towards the upper-right corner. </span></p><p class="c66"><span class="c3">Fig. 5 compare the performance of our Fast kNN algo- rithm and SVM. Fig. 5(a) and Fig. 5(b) show AUPR curves under different training dataset sizes. It is clear that in both cases, our algorithm significantly outperforms SVM based method. The main reason is that with highly imbalanced datasets, it is difficult to build a consistent model using SVM while large number of negative report pairs are surrounding few positive report pairs. </span></p><p class="c66"><span class="c3">One way to improve the consistency of SVM classifier is to sample representative report pairs into the training dataset in hope that the model is applicable of a wide range of testing dataset. We implement an improved SVM classifier called SVM clustering by clustering training set and make sure report pairs in small clusters are included in the training dataset. Fig. 5(c) shows the actual area size varies with training dataset sizes under the three classification meth- ods. It is easy to see that sampling a variety of report pairs into the training dataset does not have significant impact to SVM performance. Our method improves the classifica- tion performance by 19.1% in average in comparison to SVM classifier. </span></p><p class="c57"><span class="c22">5.2.3 Effect of </span><span class="c3">k </span></p><p class="c55"><span class="c3">We also examine the impact of k on the classification performance and execution time. The results are shown in Fig. 6. We vary k from 5 to 21 and the variation of AUPR values is not significant, as shown in Fig. 6(a). This is due to that the score calculation takes the distance of a neighbor to the report pair being classified into account in Equation 5, which eliminates the impact of neighbors that are far away from the report pair to classify. </span></p><p class="c50"><span class="c3">On the other hand, increasing k does increase the execu- tion time of the Fast kNN classifier. As shown in Fig. 6(b), the execution time grows by 31% when k is increased from 5 to 21. This is mainly due to that a larger k potentially increases the number of partitions to compare. </span></p><p class="c23"><span class="c22">5.2.4 Effect of cluster number </span><span class="c3">b </span></p><p class="c55"><span class="c3">The parallelism is affected by the number of clusters in the k &minus; means step in Algorithm 2, which determines the number of training dataset partitions as well as the number of partitions of joined testing and training datasets. Fig. 7 shows how the system performance is affected by the set- ting of the cluster number. Fig. 7(a) shows that as the number of clusters increases, the overall number of intra- cluster comparisons decreases in general, while the number of additional clusters to check in the next phase increases proportionally as shown in Fig. 7(b). The increase of cluster number results in smaller number of report reports in each cluster, which leads to the reduction of the total number of intra-cluster comparisons. However, the trend stops when the cluster number increases to 70 and the total number of intra-cluster comparisons slightly increases. This is due to the cluster sizes are uneven and the probability that a large portion of report pairs in the testing dataset is assigned to a large cluster increases. Therefore the overall comparison number increases. </span></p><p class="c6 c98"><span class="c3">Note, the total number of additional clusters to check in- creases in the second stage does not mean the total number of cross-cluster comparisons increases. The shrinking cluster size also reduces the number of comparisons in each cluster in stage 2. As shown in Fig. 7(c), the total number of cross- cluster report pair comparisons shows a decreasing trend as the number of cluster increases. Similar to intra-cluster com- parison stage, the trend stops when the number of clusters increases to 70. It is also due to the uneven distribution of cluster sizes. </span></p><p class="c62"><span class="c3">The computational complexity of the cross-cluster com- parison stage is low compared to the intra-cluster compari- son stage. As shown in Fig. 8(a), the total number of cross- cluster comparisons varies from 1.4% to 1.9% of the total number of intra-cluster comparisons. This also indicates that further reducing the number of cross-cluster compar- isons is not able to have big impact on overall execution time. </span></p><p class="c69"><span class="c3">The execution time change with different cluster numbers reflects the change of overall comparison number. Fig. 8(b) shows that the execution time has a decreasing trend when the number of clusters increases. When the cluster number is set to a number below 25, the memory of each executor can not accommodate joined partitions and frequent swapping triggers a few task failures due to timeout. The automatic retries significantly stretches the execution time. When the cluster number increases from 25 to 55, the execution time is reduced by 31%. When the cluster number becomes 70, the execution time slightly increases by 5.7% comparing to that when the cluster number is 55. </span></p><p class="c61"><span class="c22">5.2.5 Scalability </span></p><p class="c39"><span class="c3">We measure the scalability of Fast kNN from two aspects: firstly, we examine how it scales with the size of training dataset; secondly we investigate how it scales with the num- ber of executors. As shown in Fig. 9, with different partition number of the testing dataset, the execution time increases proportionally with the increase of the training dataset size. The execution time increases 1.4 &ndash; 2.1 times when the size of training dataset increases 5 times. </span></p><p class="c62"><span class="c3">Fig. 10(a) shows the execution time change with the num- ber of executors. For different training dataset sizes, the in- crease of executor number leads to the decrease of execution time. The decrease trends become flatter as the executor number increases. This is due to that the overhead of data shuffle gradually increases while more nodes participate the computation. For comparison purpose, we show the pairwise distance computing time separately in Fig. 10(b). The input data for pairwise distance computing is relatively small and the data distribution cost is low in this step. As a result, its speedup is significant when the number of executors further increases. Fig. 10(a) and Fig. 10(b) also show that the time used in the pairwise distance computing step is only a small portion of the overall execution time. </span></p><p class="c65"><span class="c22">5.2.6 Effect of Testing Set Pruning </span></p><p class="c39"><span class="c3">In the following, we measure the effectiveness of the test- ing set pruning method. We use 204, 736 randomly selected report pairs as testing dataset. The training data contains 1,000,000 report pairs, in which 266 pairs are duplicate. Fig. 11 shows the result. When the distance threshold is set to 0.9, nearly 100% of the testing pairs are included in the classification phase. When the threshold is set to 0.7, </span></p><p class="c88"><span class="c19">558 </span></p><p class="c2"><span class="c28">0</span><span class="c16">0 0 ..11</span><span class="c28">kNN SVM </span></p><p class="c6"><span class="c16">0 0 ..11</span><span class="c28">kNN </span></p><p class="c2"><span class="c16">0 .1</span><span class="c28">kNN SVM SVM clustering SVM </span></p><p class="c2"><span class="c16">88..0088..008.06.0n n ooiissiicceerr</span><span class="c28">pp</span><span class="c16">4.02.0</span><span class="c28">0</span><span class="c16">0.</span><span class="c3">(c) </span></p><p class="c6"><span class="c3">Figure 5: Comparison of area under precision and recall curve: kNN vs. SVM. Total number of testing pairs &ndash; 20,000. (a) Total number of training pairs &ndash; 5 millions; (b) Total number of training pairs &ndash; 1 millions; (c) Change of area sizes under precision and recall curves: the number of clusters in SVM clustering is set to 8. </span></p><p class="c2"><span class="c14">5 9 13 17 21 </span></p><p class="c4"><span class="c14">k </span><span class="c16">66..0044..00n n ooiissiicceerr</span><span class="c28">pp</span><span class="c16">66..0044..0022..0022..0000..</span><span class="c28">00</span><span class="c16">00..</span><span class="c28">00.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 1.0 </span></p><p class="c2"><span class="c28">1.0 </span></p><p class="c2"><span class="c28">0.0 0.0 0.2 0.2 0.4 0.4 0.6 0.6 0.8 0.8 1.0 1.0 </span></p><p class="c2"><span class="c28">1 2 3 4 5 </span></p><p class="c2"><span class="c28">recall recall </span></p><p class="c2"><span class="c28">recall recall </span></p><p class="c2"><span class="c28">training set size (million pairs) </span></p><p class="c2"><span class="c3">(a) </span></p><p class="c2"><span class="c3">(b) </span></p><p class="c6"><span class="c14">a</span><span class="c12">0 .18.0e vrucl lacer&minus;noisicerpr ednua er6.04.02.00.</span><span class="c14">0</span><span class="c3">(a) </span></p><p class="c6"><span class="c12">5 202) setunim(e mitn oitucex</span><span class="c14">E</span><span class="c12">51015</span><span class="c14">0k </span></p><p class="c2"><span class="c3">(b) </span></p><p class="c2"><span class="c3">Figure 6: Effect of k: Total number of training pairs &ndash; 3 millions; Total number of testing pairs &ndash; 10,000. (a) Area under precision-recall curve (AUPR) comparison; (b) The execution time comparison. </span></p><p class="c4"><span class="c3">about 75% of testing pairs are included in the classification phase. Setting the threshold to 0.5 does not produce signif- icant pruning and 73% of testing pairs are included. When the threshold is set to 0.3, 65% of testing pairs remain. The pruning ratio is not exactly proportional to the threshold setting because of the non-uniform distribution of both pos- itive training report pairs and testing report pairs. Note that all these threshold settings enable the duplicate report pairs in the testing dataset being included for classification. On the execution time of classification aspect, the reduc- tion is significant. The threshold setting of 0.3, 0.5 and 0.7 reduces the execution time to 35%, 65% and 61% of the clas- sification time without pruning. This is mainly due to the reduced data transfer and memory use. Even though setting the threshold to 0.5 slightly prunes more testing pairs than setting it to 0.7, the classification time under threshold 0.5 is slightly longer than that under threshold 0.7. It is related to the report pair distribution and how balance the workload </span></p><p class="c2"><span class="c14">5 10 15 20 </span></p><p class="c2"><span class="c3">of comparing these report pairs is among Spark data nodes that store them. </span></p><p class="c6"><span class="c3">The setting of the threshold directly affects the perfor- mance improvement of testing set pruning. Potentially, the setting can be learned from the labelled data, which we leave as our future work. </span></p><p class="c2"><span class="c15">6. RELATED WORK </span></p><p class="c6"><span class="c3">We compare our method with closely related works on parallelizing kNN join as well as approaches for handling datasets with imbalanced label distribution. </span></p><p class="c6"><span class="c3">C. Zhang et.al [25] describes a basic Block based data partitioning method for kNN join using Hadoop. It then proposes to build an index using R-tree for each local block in a dataset. The built-in kNN functionality of R-tree is able to speedup the kNN search in the local block. The method does not reduce the overall computing and communication complexity. </span></p><p class="c2"><span class="c19">559 </span></p><p class="c6"><span class="c32">0</span><span class="c40">0 0070 001000600050080004006000300400020001002</span><span class="c32">0Training set cluster number </span></p><p class="c2"><span class="c32">Training set cluster number </span></p><p class="c6"><span class="c40">0 01) snoillim(s nosirapmocr etsulcr enn</span><span class="c32">I</span><span class="c40">08060402</span><span class="c32">0Training set cluster number </span></p><p class="c2"><span class="c3">(a) </span></p><p class="c26"><span class="c40">d ekcehcs retsulcl anoitidd</span><span class="c32">A</span><span class="c40">) snoillim(s nosirapmocl anoitidd</span><span class="c32">A10 20 30 40 50 60 70 </span></p><p class="c2"><span class="c32">10 20 30 40 50 60 70 </span></p><p class="c2"><span class="c32">10 20 30 40 50 60 70 </span></p><p class="c2"><span class="c3">(b) </span></p><p class="c2"><span class="c3">(c) </span></p><p class="c6"><span class="c3">Figure 7: Impact of the cluster number: Total number of training pairs &ndash; 4 millions; Total number of testing pairs &ndash; 10,000. (a) The number of intra-cluster comparisons; (b) The number of additional clusters to check for each element in the testing set; (c) The number of cross-cluster comparisons. </span></p><p class="c2"><span class="c35">0 20.0510.0010.0500.0000.</span><span class="c30">010 20 30 40 50 60 70 </span></p><p class="c2"><span class="c30">Training set cluster number </span></p><p class="c6"><span class="c35">0 5o ita</span><span class="c30">R</span><span class="c35">) </span></p><p class="c2"><span class="c35">setunim(e mitn oitucex</span><span class="c30">E</span><span class="c35">04030201</span><span class="c30">0Training set cluster number </span></p><p class="c2"><span class="c3">(a) </span></p><p class="c2"><span class="c3">(b) </span></p><p class="c6"><span class="c3">Figure 8: Impact of the cluster number of training set on cross-cluster comparison: Total number of training pairs &ndash; 4 millions; Total number of testing pairs &ndash; 10,000. (a) Ratios of cross-cluster/intra-cluster comparison number; (b) The execution time change with the cluster number: memory size of each executor is 32GB. </span></p><p class="c6"><span class="c3">W. Lu et.al [15] gives an improved algorithm for paral- lelizing kNN join using MapReduce and aims to reduce the search space. It partitions datasets into a Voronoi diagram. The differences between our approach and [15] lie in the following aspects: firstly, our method uses k &minus; means to partition the training dataset while [15] uses it as an option in data pre-processing to select pivots (partition centers). A map operation is then applied to use the selected piv- ots to partition datasets and collect partition statistics. As k&minus;means produces Voronoi sets already, it is not necessary to run another data partitioning operation. Secondly, our approach uses the characteristics of imbalanced datasets to reduce the cross-cluster comparison rather than introducing another statistics collection step to achieve this goal. Our experimental results show that the cross-cluster comparison cost is low. Thirdly, our approach makes use of distributed memory management of Spark to cache data partitions in comparison to the ad-hoc caching mechanism in [15]. </span></p><p class="c2"><span class="c30">10 20 30 40 50 60 70 </span></p><p class="c6"><span class="c3">In addition, there are works on set-similarity join using MapReduce [21] and Voronoi partitioning for MapReduce [1]. These works focus on identifying the nearest neighbors. Our work differ from them in using kNN as a means for classi- fying highly imbalanced datasets, which gives us additional information for reducing the search space, e.g., when the distance between a report pair and its nearest positively la- belled neighbor is further than a given distance threshold, the report pair is likely to be non-duplicate and therefore pruned from the search space. </span></p><p class="c2"><span class="c3">W. Liu and S. Chawla [14] illustrates the problem of im- balanced label distribution in classification and proposes a weighted method for handling imbalanced data in kNN clas- sifier. Our results show that kNN classifier is more robust and less affected by over-represented negative data than SVM on detecting highly imbalanced duplicate/non-duplicate report pairs. Further improving the classification perfor- mance of kNN require careful analysis of similarity of report </span></p><p class="c2"><span class="c19">560 </span></p><p class="c26"><span class="c14">0</span><span class="c12">0 0 0 333555222000222555111000111555</span><span class="c14">00Executor Executor Executor number number number </span></p><p class="c2"><span class="c14">training set: 2M </span></p><p class="c2"><span class="c12">4 </span><span class="c14">training set: 3M training set: 4M </span></p><p class="c2"><span class="c12">3) ) ) ssseeetttuuunnniiimmm(((e e e mmmiiitttn n n oooiiitttuuuccceeexxx</span><span class="c14">EEE</span><span class="c12">21</span><span class="c14">05 5 10 10 15 15 20 </span></p><p class="c2"><span class="c14">20 </span></p><p class="c2"><span class="c14">Executor number </span></p><p class="c2"><span class="c3">(a) </span></p><p class="c2"><span class="c12">) setunim(e mitn oitucex</span><span class="c14">E5 10 15 20 </span></p><p class="c2"><span class="c14">5 10 15 20 </span></p><p class="c2"><span class="c3">(b) </span></p><p class="c6"><span class="c3">Figure 10: Execution time change with the number of executors: testing set size &ndash; 10,000; cluster number of the training set &ndash; 48; block number &ndash; 5; executor memory size &ndash; 32GB; executor core &ndash; 1. (a) Overall execution time; (b) Pairwise distance computing time (total number of reports &ndash; 10,382). </span></p><p class="c2"><span class="c54">1 2 3 4 5 </span></p><p class="c2"><span class="c1">0.9 </span></p><p class="c6"><span class="c29">0 0 0 333</span><span class="c54">block numer = 4 </span></p><p class="c2"><span class="c54">block number = 8 </span><span class="c29">555222</span><span class="c54">block number = 12 </span></p><p class="c2"><span class="c21">d lohserh</span><span class="c1">t0.7 </span></p><p class="c2"><span class="c29">000222</span><span class="c21">0 .</span><span class="c1">0</span><span class="c21">2 .</span><span class="c1">0</span><span class="c21">4 .</span><span class="c1">0</span><span class="c21">6 .</span><span class="c1">0</span><span class="c21">8 .</span><span class="c1">0</span><span class="c21">0 .</span><span class="c1">1</span><span class="c29">555111</span><span class="c1">pruning ratio </span></p><p class="c6"><span class="c29">000111555</span><span class="c54">000Training Training Training set set set size size size (million (million (million pairs) pairs) pairs) </span></p><p class="c2"><span class="c1">0.3 </span></p><p class="c6"><span class="c3">Figure 9: Scalability with the size of training dataset: testing set size &ndash; 10,000; cluster number of the training set &ndash; 32; total number of executors &ndash; 25 (32GB memory and 1 core). </span></p><p class="c6"><span class="c3">pairs by taking additional domain knowledge into account, which is our future work. Fortunately, the simplicity of kNN provides flexibility to accommodate new models. </span></p><p class="c2"><span class="c15">7. CONCLUSIONS </span></p><p class="c2"><span class="c3">In this paper, we studied duplicate detection in adverse drug reaction report databases. We proposed a Fast kNN classification method to deal with highly imbalanced label distribution in the dataset. Comparing to some datasets used for evaluating kNN join methods, there were relatively small number of fields chosen to calculate the pairwise dis- tance vector between reports, however, the ADR report database contained a long text field with non-trivial distance calcula- </span></p><p class="c2"><span class="c1">0.5 </span></p><p class="c6"><span class="c29">) ) ) ssseeetttuuunnniiimmm(((e e e mmmiiitttn n n oooiiitttuuuccceeexxx</span><span class="c54">EEE</span><span class="c1">0.3 </span></p><p class="c2"><span class="c54">1 1 2 2 3 3 4 4 5 5 </span></p><p class="c2"><span class="c1">0.9 </span><span class="c21">d lohserh</span><span class="c1">t0 0 </span><span class="c52">1</span><span class="c1">0 </span><span class="c52">2</span><span class="c1">0 </span><span class="c52">3</span><span class="c1">0 </span><span class="c52">4</span><span class="c1">0 </span><span class="c52">5</span><span class="c1">detection time (minutes) </span></p><p class="c6"><span class="c3">Figure 11: Effectiveness of pruning the testing dataset:training set size &ndash; 1,000,000; cluster number of the training set &ndash; 200; testing set size &ndash; 204,736; cluster number of the testing set &ndash; 30; f(&theta;) (thresh- old) is set to 0.3, 0.5, 0.7 and 0.9; executor number &ndash; 20; number of cores per execution &ndash; 4. </span></p><p class="c6"><span class="c3">tion complexity. We showed that our method is effective in detecting duplicates in real ADR data and significantly out- performs SVM based classifier. The system we implemented using this method is capable of handling large amount of ad- verse drug reaction report data in a scalable way. We built the system using Spark. We effectively reduce the comput- </span></p><p class="c2"><span class="c19">561 </span></p><p class="c2"><span class="c1">0.7 </span></p><p class="c2"><span class="c1">0.5 </span></p><p class="c73"><span class="c3">ing complexity by exploiting label imbalance and Voronoi partitioning of the training dataset. We also gave a method to prune the testing dataset to further improve the perfor- mance. We are not aware other parallel duplicate detection system in practical use in this domain with rapidly growing data and increasing importance. Our future work will focus on load balancing among executors for better scalability. </span></p><p class="c43"><span class="c15">8. REFERENCES </span></p><p class="c53"><span class="c3">[1] A. Akdogan, U. Demiryurek, F. Banaei-Kashani, and </span></p><p class="c58"><span class="c3">C. Shahabi. Voronoi-based geospatial query processing with mapreduce. In Cloud Computing Technology and Science (CloudCom), 2010 IEEE Second International Conference on, pages 9&ndash;16. IEEE, 2010. [2] M. Bilenko and R. J. Mooney. Adaptive duplicate </span></p><p class="c24"><span class="c3">detection using learnable string similarity measures. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 39&ndash;48. ACM, 2003. [3] S. Chaudhuri, V. Ganti, and R. Kaushik. A primitive </span></p><p class="c94"><span class="c3">operator for similarity joins in data cleaning. In Proceedings Of the 22nd International Conference On Data Engineering, pages 5&ndash;17, Atlanta, GA, 2006. [4] J. Davis and M. Goadrich. The relationship between precision-recall and roc curves. In Proceedings of the 23rd international conference on Machine learning, pages 233&ndash;240. ACM, 2006. [5] M. Elfeky, V. Verykios, and A. Elmagarmid. TAILOR: </span></p><p class="c47"><span class="c3">A record linkage toolbox. In Proceedings Of the 18th International Conference On Data Engineering, pages 17&ndash;28, San Jose, CA, 2002. [6] S. Evans, P. Waller, and S. Davis. Use of proportional reporting ratios (PRRs) for signal generation from spontaneous adverse drug reaction reports. Pharmacoepidemiology and Drug Safety, 10(6):483&ndash;486, 2001. [7] D. Fram, J. Almenoff, and W. DuMouchel. Empirical </span></p><p class="c63"><span class="c3">Bayesian data mining for discovering patterns in post-marketing drug safety. In PKDD, pages 359&ndash;368, Washington, DC, 2003. [8] R. Hamming. Error detecting and error correcting </span></p><p class="c87"><span class="c3">codes. Bell System Technical Journal, 29(2):147&ndash;160, 1950. [9] G. R. Hjaltason and H. Samet. Index-driven similarity </span></p><p class="c83"><span class="c3">search in metric spaces (survey article). ACM Trans. Database Syst., 28(4):517&ndash;580, Dec. 2003. [10] B. Hug, C. Keohane, D. Seger, C. Yoon, and D. Bates. </span></p><p class="c56"><span class="c3">The costs of adverse drug events in community hospitals. Joint Commission Journal On Quality and Patient Safety, 38(3):120&ndash;126, 2012. [11] M. A. Jaro. Advances in record-linkage methodology </span></p><p class="c77"><span class="c3">as applied to matching the 1985 census of tampa, florida. Journal of the American Statistical Association, 84(406):pp. 414&ndash;420, 1989. [12] M. A. Jaro. Probabilistic linkage of large public health data files. Statistics in medicine, 14(5-7):491&ndash;498, 1995. [13] V. Levenshtein. Binary codes capable of correcting </span></p><p class="c70"><span class="c3">deletions, insertions and reversals. In Soviet Physics Doklady, volume 10, pages 707&ndash;710, 1966. [14] W. Liu and S. Chawla. Class confidence weighted knn algorithms for imbalanced data sets. In Proceedings of </span></p><p class="c2 c49"><span class="c3">the 15th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining - Volume Part II, PAKDD&rsquo;11, pages 345&ndash;356, Berlin, Heidelberg, 2011. Springer-Verlag. [15] W. Lu, Y. Shen, S. Chen, and B. C. Ooi. Efficient </span></p><p class="c67"><span class="c3">processing of k nearest neighbor joins using mapreduce. Proceedings of the VLDB Endowment, 5(10):1016&ndash;1027, 2012. [16] H. B. Newcombe, J. M. Kennedy, S. J. Axford, and </span></p><p class="c76"><span class="c3">A. P. James. Automatic linkage of vital records: Computers can be used to extract &ldquo;follow-up&rdquo; statistics of families from files of routine records. Science, 130(3381):954&ndash;959, 1959. [17] J. Nkanza and W. Walop. Vaccine associated adverse </span></p><p class="c37"><span class="c3">event surveillance (VAAES) and quality assurance. Drug Safety, 27(12):951&ndash;952, 2004. [18] G. N. Nor&eacute;n, R. Orre, and A. Bate. A hit-miss model </span></p><p class="c95"><span class="c3">for duplicate detection in the WHO drug safety database. In KDD, pages 459&ndash;468, Chicago, Illinois, 2005. [19] E. Roughead and S. Semple. Medication safety in </span></p><p class="c85"><span class="c3">acute care in Australia: Where are we now? part 1: A review of the extent and causes of medication problems 2002-2008. Australia and New Zealand Health Policy, 6(1):18, 2009. [20] S. Sarawagi and A. Bhamidipaty. Interactive </span></p><p class="c75"><span class="c3">deduplication using active learning. In The 8th ACM SIGKDD International Conference On Knowledge Discovery and Data Mining, pages 269&ndash;278, Edmonton, Alberta, Canada, 2002. [21] R. Vernica, M. J. Carey, and C. Li. Efficient parallel </span></p><p class="c44"><span class="c3">set-similarity joins using mapreduce. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of data, pages 495&ndash;506. ACM, 2010. [22] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. Mccauley, M. Franklin, S. Shenker, and I. Stoica. Fast and interactive analytics over hadoop data with spark. USENIX; login, 37(4):45&ndash;51, 2012. [23] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, </span></p><p class="c93"><span class="c3">M. McCauley, M. J. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing. In Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation, pages 2&ndash;2. USENIX Association, 2012. [24] M. Zaharia, M. Chowdhury, M. J. Franklin, </span></p><p class="c78"><span class="c3">S. Shenker, and I. Stoica. Spark: cluster computing with working sets. In Proceedings of the 2nd USENIX conference on Hot topics in cloud computing, pages 10&ndash;10, 2010. [25] C. Zhang, F. Li, and J. Jestes. Efficient parallel knn </span></p><p class="c84"><span class="c3">joins for large data in mapreduce. In Proceedings of the 15th International Conference on Extending Database Technology, pages 38&ndash;49. ACM, 2012. </span></p><p class="c72"><span class="c19">562 </span></p></body></html>