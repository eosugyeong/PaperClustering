{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['p99 (1)','p99-shi','p979-satish (2)','p980_manojkagarwal_vldb2012',\n",
    "             'p985','p987','p991-cui','p992_odysseaspapapetrou_vldb2012','p997', 'paper-1', 'paper-10',\n",
    "            'paper-11', 'paper-11_2', 'paper-11_2_2', 'paper-12', 'paper-100', 'paper-101', 'paper-102',\n",
    "            'paper-103', 'paper-105', 'paper-106', 'paper-107', 'paper-108', 'paper-109',\n",
    "            'paper-110', 'paper-112', 'paper-112_2', 'paper-114', 'paper-117', 'paper-119', 'paper-119_2',\n",
    "            'paper-120', 'paper-124', 'paper-124_2', 'paper-125', 'paper-125_2', 'paper-126', 'paper-128',\n",
    "            'paper-129', 'paper-131', 'paper-131_2', 'paper-132', 'paper-133', 'paper-134', 'paper-136',\n",
    "            'paper-137', 'paper-138', 'paper-139', 'paper-142', 'paper-145', 'paper-146', 'paper-148',\n",
    "            'paper-150', 'paper-153', 'paper-155']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_split_file(file_name):\n",
    "    file = open('C:/Users/ehrme/Downloads/data/{0}.txt'.format(file_name), 'r', encoding = 'utf-8')\n",
    "    name = file.read()\n",
    "    name = name.split(' ')\n",
    "    return name\n",
    "\n",
    "def write_txt_file(file, abstract, introduction):\n",
    "    file = open(file, 'w', encoding = 'utf-8')\n",
    "    file.write(abstract + '\\n' + introduction)\n",
    "\n",
    "paper_list = []\n",
    "for i in range(55):\n",
    "    globals()['paper{}'.format(i)] = read_split_file(file_list[i])\n",
    "    paper_list.append(globals()['paper{}'.format(i)])\n",
    "#readline으로 저자랑 제목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reference 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        \n",
    "    def references(self):\n",
    "        for i in range(len(self.file)):\n",
    "            if self.file[i] == '\\nREFERENCES' or self.file[i] == 'REFERENCES':\n",
    "                return i + 1\n",
    "    \n",
    "    def make_txt(self):\n",
    "        file = self.file[Reference.references(self):]\n",
    "        file = ' '.join(file)\n",
    "        return file\n",
    "    \n",
    "    def __call__(self):\n",
    "        pass\n",
    "    \n",
    "tokenize = []\n",
    "for i in range(55):\n",
    "    a = Reference(paper_list[i])\n",
    "    a()\n",
    "    make_txt = Reference.make_txt(a)\n",
    "    make_txt = re.sub('[\\n]', '', make_txt)\n",
    "    tokenize.append(sent_tokenize(make_txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reference - 제목 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On the Bursty Evaluation of Blogspace.', '[3] Tong H. et al., Proximity Tracking on Time-Evolving Bipartite Graphs.', 'SDM, 2008 [4] Backstrom L., et al.', '[6] Cohen E. Size-Estimation Framework with Applications to Transitive Closure and Reachability.', 'J. of Computer and System Sciences 55 (1997): 441–453.', 'Finding Interesting Associations without Support Pruning, ICDE 2000.', 'Cambridge University Press, 1995.', 'ICALP 1991.', 'Earthquake Shakes Twitter Users: Real-time Event Detection by Social Sensors, WWW 2010.', 'What is Twitter, a Social Network or a News Media?, WWW 2010.', '[14] H. Matsuda, Classifying Molecular Sequences using a Linkage Graph with their Pairwise Similarities.', 'STOC 1999.', 'KDD 2005.', '[18] M. Cataldi et al., Emerging Topic Detection on Twitter based on Temporal and Social Terms Evaluation, MDM 2010.', '[18] M. Cataldi et al., Emerging Topic Detection on Twitter based on Temporal and Social Terms Evaluation, MDM 2010.']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def Title_ext(file):\n",
    "    splits = []\n",
    "    for i in range(len(file)-1):\n",
    "        if file[i][0] == '[' and (file[i][2] == ']' or file[i][3] == ']'):\n",
    "            if file[i+1].isdigit() == True:\n",
    "                splits.append(file[i])\n",
    "            else:\n",
    "                splits.append(file[i+1])\n",
    "    return splits\n",
    "\n",
    "ref_title = []\n",
    "for i in range(55):\n",
    "    ref_title.append(Title_ext(tokenize[i][:30]))\n",
    "    \n",
    "print(ref_title[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reference -저자 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "                                             ref_name\n",
      "0   [ R. Agrawal,  S. Arnborg,  A. L. Barabasi and...\n",
      "1   [ Y.Y.,  G. L. Andrienko,  M. Ankerst,  N. Arm...\n",
      "2   [ S. Salihoglu and J. Widom.,  Galois v ... ht...\n",
      "3   [ Kumar R.,  Bansal N.,  Tong H. et al.,  Hopc...\n",
      "4   [ D. J. Abadi,  S. Babu.,  R. Berinde,  B. Li,...\n",
      "5   [ N. R. Alur,  Apache Mahout.,  M. Avriel.,  R...\n",
      "6   [ M. E. J. Newman et al.,  A. Broder et al.,  ...\n",
      "7   [ N. Alon,  M. Arlitt and T. Jin.,  C. Busch a...\n",
      "8   [ httpwww.flickr.com  httpboston.lti.cs.cmu.ed...\n",
      "9   [ B. Babcock,  J. Bao,  M. A. Cheema,  M. A. C...\n",
      "10  [ M. M. Astrahan,  L. Bordeaux,  DBpedia.,  P....\n",
      "11  [ H. Andrade,  J. Afalg,  W.T. Balke,  P. Baum...\n",
      "12  [ N. Beckmann,  S. Berchtold,  Y. Chang,  H. C...\n",
      "13  [ categorize numerical aggregation functions i...\n",
      "14  [ U.,  O.,  T. P. P. Council.,  T. P. P. Counc...\n",
      "15  [ February .,  Sanjay Agrawal,  M. Akdere,  P....\n",
      "16  [ C. C. Aggarwal.,  J. Agrawal,  R. S. Barga, ...\n",
      "17  [ The us sees more money lost to credit card f...\n",
      "18  [ Miguel E. Andrs,  Maede AshouriTalouki,  Bhu...\n",
      "19  [ Miguel Araujo,  Brigitte Boden,  Arnaud Cast...\n",
      "20  [ AllRecipes.com.,  Amazon Mechanical Turk.,  ...\n",
      "21  [ The Graph  Benchmark.,  V. Agarwal,  L. A. N...\n",
      "22  [ th DIMACS Implementation Challenge  Shortest...\n",
      "23  [ OpenStreetMap bulk gps point data.,  S. Acha...\n",
      "24  [ httpwww.cs.sandia.govzoltan.,  httpsnap.stan...\n",
      "25  [ Proton.,  The Wall Street Journal.,  USA Tod...\n",
      "26  [ SPIRIT project.,  G. E. A. P. A. Batista and...\n",
      "27  [ TPCDS.,  TPCH. httpwww.tpc.orgtpch.,  USE PL...\n",
      "28  [ Intel R Math Kernel Library,  CRAN R Matrix ...\n",
      "29  [ Webpage to download the code and dataset.,  ...\n",
      "30  [ A. Balmin et al.,  V. Bonnici et al.,  J. Ch...\n",
      "31  [ Abul,  Abul,  Bayardo,  Chen,  Chow,  Hoh,  ...\n",
      "32  [ M. Arenas,  M. Arenas,  P. C. Arocena,  L. E...\n",
      "33  [ V. Bonnici,  J. Cheng,  J. Cheng,  L. P. Cor...\n",
      "34  [ R. Adam and J. Worthmann.,  B. Fung,  B. Che...\n",
      "35  [ R. Agrawal and R. Srikant.,  M. Becker,  G. ...\n",
      "36  [ Mohamed H. Ali and others.,  James F. Allen....\n",
      "37  [ I.,  R. S. Chavez and T. F. Heatherton.,  R....\n",
      "38  [ improved the accuracy of recom mendations by...\n",
      "39  [ Congenio Configuration generation language.,...\n",
      "40  [ C. R. Aberger,  A. Ailamaki,  M. Aref,  S. A...\n",
      "41  [ R. Bellman and R. Kalaba.,  J. Berclaz,  X. ...\n",
      "42  [ C. Aggarwal and K. Subbian.,  J. Borges and ...\n",
      "43  [ I. Abraham,  T. Akiba,  T. Akiba,  T. Akiba,...\n",
      "44  [ I. Abraham,  I. Abraham,  I. Abraham,  T. Ak...\n",
      "45  [ eBird Trail Tracker Puts Millions of Eyes on...\n",
      "46  [ P. K. Agarwal,  S. Brakatsoulas,  K. Buchin,...\n",
      "47  [ A. Amir,  D. Belazzougui and G. Navarro.,  T...\n",
      "48  [ A. Akdogan,  M. Bilenko and R. J. Mooney.,  ...\n",
      "49  [ A. Cheng,  H. Cho,  T. H. Cormen,  E. D. Dem...\n",
      "50  [ D. J. Abadi,  V. N. Anh and A. Moffat.,  D. ...\n",
      "51  [ K. Braunschweig,  V. Bryl,  M. J. Cafarella,...\n",
      "52  [ R. Agrawal,  R. Ahuja,  M. Alivand and H. H....\n",
      "53  [ C.L.,  Ioannis Alagiannis,  Ahmed M. Aly,  L...\n",
      "54                                          [ Arning]\n"
     ]
    }
   ],
   "source": [
    "def Name_ext(file):\n",
    "    split = []\n",
    "    for i in file:\n",
    "        if i[0] == '[' and (i[2] == ']' or i[3] == ']'):\n",
    "            splits = re.sub('[^a-zA-Z., ]', '', i)\n",
    "            splits = splits.split(',')\n",
    "            split.append(splits[0])\n",
    "    return split\n",
    "\n",
    "name = []\n",
    "for i in range(len(tokenize)):\n",
    "    name.append(Name_ext(tokenize[i]))\n",
    "print(len(name))\n",
    "\n",
    "names = pd.DataFrame({'ref_name': name})\n",
    "print(names)\n",
    "title.to_csv('ref_name.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
